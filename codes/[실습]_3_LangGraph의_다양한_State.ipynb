{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNWMhxtVOPnC",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# [실습] LangGraph의 다양한 State 활용하기    \n",
        "\n",
        "\n",
        "이전 실습에서는 하나의 클래스에 문자열, 정수와 같은 값을 정의하고, 이를 모든 노드가 공유하도록 구성했는데요.   \n",
        "\n",
        "이번 실습에서는 State를 보다 복잡하게 만들어 보겠습니다.   \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OoJXoxMOPnD"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph langchain langchain_google_genai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsCum2cDOPnE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIxxx'\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    # temperature\n",
        "    # max_tokens\n",
        "\n",
        "    thinking_budget = 500  # 추론(Reasoning) 토큰 길이 제한\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBsA51V8OPnE"
      },
      "source": [
        "## 1. 구조화된 출력 State에 적용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko187AE2OPnE"
      },
      "source": [
        "LangChain의 `llm.with_structured_output`을 사용하면, 구조화된 출력을 만들 수 있습니다.   \n",
        "Pydantic을 이용해, 예시 데이터의 구조를 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OarsNlg9OPnE"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# 프롬프트 자동 생성을 위한 요소 저장\n",
        "class Objective(BaseModel):\n",
        "    instruction: str = Field(description='프롬프트의 지시 사항을 명확히 재구성')\n",
        "    output_format: str = Field(description='출력 포맷에 대한 설명')\n",
        "    examples: str = Field(description='예시 출력(1개)')\n",
        "    notes: str = Field(description='작업 과정에서 중요한 내용을 4개의 개조식 문장으로 구성')\n",
        "\n",
        "    @property #\n",
        "    def as_str(self) -> str:\n",
        "        return '\\n\\n'.join([f'## {key}\\n {value}' for key, value in self])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyIQU9KeOPnE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate([\n",
        "    ('system', '아래의 작업을 보다 자세하게 요청하는 시스템 프롬프트를 구성하고자 합니다. 주어진 포맷에 적절하게 작성하세요.'),\n",
        "    ('user', '{instruction}')\n",
        "\n",
        "])\n",
        "\n",
        "chain = prompt | llm.with_structured_output(Objective)\n",
        "\n",
        "result = chain.invoke(\"집에서 쉽게 구할 수 있는 재료로 재미있는 장난감 만들기\")\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Les7UHd2OPnE"
      },
      "outputs": [],
      "source": [
        "print(result.as_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E1kO1XzOPnE"
      },
      "source": [
        "위에서 만든 Objective Class는 State의 단일 값으로도 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwgpYwBLOPnF"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    instruction : str\n",
        "    prompt_materials : Objective # Objective Class를 하나의 값에 저장\n",
        "    full_prompt : str\n",
        "    result : str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAiUxTc7OPnF"
      },
      "outputs": [],
      "source": [
        "def get_prompt_materials(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '아래의 작업을 보다 자세하게 세분화하고자 합니다. 주어진 포맷에 적절하게 작성하세요.'),\n",
        "        ('user', '{instruction}')\n",
        "\n",
        "    ])\n",
        "\n",
        "    chain = prompt | llm.with_structured_output(Objective)\n",
        "\n",
        "    result = chain.invoke({'instruction':State['instruction']})\n",
        "    return {'prompt_materials' : result}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpiZN3aBOPnF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def generate_prompt(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '''당신은 체계적이고 정확한 프롬프트 엔지니어입니다. 아래의 포인트를 바탕으로, LLM에 입력할  시스템 프롬프트를 작성하세요.\n",
        "{points}'''),\n",
        "        ('user', '{instruction}')\n",
        "    ])\n",
        "\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    result = chain.invoke({'instruction': State['instruction'], 'points': State['prompt_materials'].as_str})\n",
        "    return {'full_prompt' : result}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jekIvYaOPnF"
      },
      "outputs": [],
      "source": [
        "def generate(State):\n",
        "    return {'result' : llm.invoke(State['full_prompt']).content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdaWAYrMOPnF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "\n",
        "# 그래프 구성\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"get_prompt_materials\", get_prompt_materials)\n",
        "builder.add_node(\"generate_prompt\", generate_prompt)\n",
        "builder.add_node(\"generate\", generate)\n",
        "\n",
        "builder.add_edge(START, \"get_prompt_materials\")\n",
        "builder.add_edge(\"get_prompt_materials\", \"generate_prompt\")\n",
        "builder.add_edge(\"generate_prompt\", \"generate\")\n",
        "\n",
        "builder.add_edge(\"generate\", END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-My27xfwOPnF"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUAdgNdSOPnF"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "# Streaming 참고\n",
        "# https://langchain-ai.github.io/langgraph/concepts/streaming/#streaming-graph-outputs-stream-and-astream\n",
        "\n",
        "for data in graph.stream({'instruction': '''영화 '마이너리티 리포트'와 AI 윤리의 연관성에 대한 리포트 쓰기'''},\n",
        "                         stream_mode='values'):\n",
        "    pprint.pprint(data)\n",
        "    print('----')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx-LkyjlOPnF"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJcy1_ZTOPnF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "to_markdown(data['result'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPF0jjlQOPnF"
      },
      "source": [
        "이와 같이 구조화된 출력을 연결하여, 그래프의 중간, 혹은 최종 출력물을 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kAnW32fOPnG"
      },
      "source": [
        "## 2. Message 포맷의 State 사용하기\n",
        "\n",
        "State의 저장값으로 Message를 바로 사용하기도 합니다.   \n",
        "이 경우, Context에 메시지를 계속 추가하거나, 별도의 로직을 만들어 메시지 정보를 전달합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiZFhxnNOPnG"
      },
      "source": [
        "`typing`의 `Annotated`로 공간을 지정한 후, 뒷부분에 결합 로직을 포함합니다.   \n",
        "이를 리듀서(Reducer)라고 부르는데, 메시지의 경우 아래와 같이 포함하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP01NYAjOPnG"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# add_messages: 메시지를 계속 뒤에 추가하는 방식\n",
        "# 기존 메시지를 수정하거나, 삭제하는 것도 가능합니다.\n",
        "\n",
        "class State(TypedDict):\n",
        "    context : Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbeK1gkeOPnG"
      },
      "source": [
        "이번에는 메시지를 주고받는 형태를 구성해 보겠습니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMDztY5VOPnG"
      },
      "outputs": [],
      "source": [
        "def talk(State):\n",
        "    return {'context': AIMessage(content='AI 메시지 2')}\n",
        "\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node('talk',talk)\n",
        "builder.add_edge(START, 'talk')\n",
        "builder.add_edge('talk', END)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6u1f--zOPnG"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVf7bt5UOPnG"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content='시스템 메시지 1'),\n",
        "    HumanMessage(content='유저 메시지 1'),\n",
        "    AIMessage(content='AI 메시지 1'),\n",
        "    HumanMessage(content='유저 메시지 2'),\n",
        "]\n",
        "\n",
        "response = graph.invoke({'context': messages})\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkLVC9JbOPnG"
      },
      "source": [
        "전체 Context를 모두 저장하는 위와 같은 방식도 가능하지만,   \n",
        "`RemoveMessage`를 사용하여 메시지를 제거할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1gu82ysOPnG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import RemoveMessage\n",
        "def delete_message(State):\n",
        "    # 첫번째,두번째 메시지 삭제\n",
        "    messages = State['context']\n",
        "    return {\"context\": [RemoveMessage(id = messages[i].id) for i in range(1,3)]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCmK5SjlOPnG"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node('talk',talk)\n",
        "builder.add_node('delete_message',delete_message)\n",
        "\n",
        "builder.add_edge(START, 'talk')\n",
        "builder.add_edge('talk', 'delete_message')\n",
        "builder.add_edge('delete_message', END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFmWbVCMOPnG"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYzFZE-jn5Q4"
      },
      "outputs": [],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN1wtttSOPnG"
      },
      "outputs": [],
      "source": [
        "# 유저 메시지 1, AI 메시지 1 삭제\n",
        "\n",
        "graph.invoke({'context': messages})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbCyoWhkOPnG"
      },
      "source": [
        "위 방식으로 긴 컨텍스트를 저장할 때 일부만을 저장하거나, 앞 부분의 컨텍스트를 수정하여 저장할 수 있습니다.   \n",
        "반복 기능을 추가한다면, 긴 컨텍스트의 대화도 효과적으로 만들 수 있습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

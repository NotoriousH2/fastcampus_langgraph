{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHQzg8LlBPiX"
      },
      "source": [
        "## 중요) 이 실습은 GPU 연결이 필요합니다.\n",
        "**오른쪽 위 ▼ 화살표 클릭 --> 런타임 유형 변경 --> T4 GPU 설정**  \n",
        "이후 아래 코드 실행해 주세요.\n",
        "\n",
        "-----\n",
        "\n",
        "<br><br>\n",
        "# [실습] LangChain을 이용한 RAG 만들기\n",
        "\n",
        "RAG는 Retrieval-Augmented Generation (RAG) 의 약자로, 질문이 주어지면 관련 있는 문서를 찾아 프롬프트에 추가하는 방식의 어플리케이션입니다.   \n",
        "RAG의 과정은 아래와 같이 진행됩니다.\n",
        "1. Indexing : 문서를 받아 검색이 잘 되도록 저장합니다.\n",
        "1. Processing : 입력 쿼리를 전처리하여 검색에 적절한 형태로 변환합니다<br>(여기서는 수행하지 않습니다)\n",
        "1. Search(Retrieval) : 질문이 주어진 상황에서 가장 필요한 참고자료를 검색합니다.\n",
        "1. Augmenting : Retrieval의 결과와 입력 프롬프트를 이용해 LLM에 전달할 프롬프트를 생성합니다.\n",
        "1. Generation : LLM이 출력을 생성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD8cevFKBPia"
      },
      "source": [
        "이번 실습에서는 웹 페이지의 결과를 받아와, 이를 기반으로 RAG를 수행하는 프로그램을 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GHgrhVbLnM6I"
      },
      "outputs": [],
      "source": [
        "# 랭체인\n",
        "!pip install langchain==1.0.3 langchain-community langchain-google-genai langchain-chroma chromadb langchain_huggingface -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si0sWOsX8rPq"
      },
      "source": [
        "위에 발생하는 에러는 실행과 무관합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "91hEIto-61ON"
      },
      "outputs": [],
      "source": [
        "# 데이터 수집/전처리\n",
        "!pip install rank-bm25 kiwipiepy sentence_transformers beautifulsoup4 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0EzTIXs7wMq"
      },
      "source": [
        "# [중요] 설치 후, **런타임 --> 세션 다시 시작** 후 실행해 주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5uYZQknXLDM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY']=\"AIxxx\"\n",
        "\n",
        "os.environ['USER_AGENT'] = 'test'\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    temperature = 0.5,\n",
        "    max_tokens = 2048\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5aalGFW30h5",
        "outputId": "74136dfe-2c4d-4f23-d61c-4a3979b8d6e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "알리바바의 최신 언어 모델은 **Qwen2**입니다.\n",
            "\n",
            "Qwen2는 Qwen1.5의 후속 모델로, 2024년 5월에 공개되었습니다. 다양한 크기(0.5B, 1.5B, 7B, 72B, 72B-Instruct)로 제공되며, 특히 영어, 중국어 외에도 다양한 언어에서 성능이 향상되었습니다. 특히, Qwen2-72B 모델은 오픈 소스 모델 중 최상위권의 성능을 보여주는 것으로 평가받고 있습니다.\n",
            "\n",
            "Qwen2에 대한 더 자세한 정보는 아래 링크에서 확인할 수 있습니다.\n",
            "\n",
            "*   **Hugging Face:** [https://huggingface.co/Qwen](https://huggingface.co/Qwen)\n",
            "*   **GitHub:** [https://github.com/QwenLM/Qwen2](https://github.com/QwenLM/Qwen2)\n",
            "\n",
            "알리바바는 지속적으로 언어 모델을 개발하고 있으며, 앞으로 더 발전된 모델이 출시될 것으로 예상됩니다.\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "response = llm.invoke(\"알리바바의 최신 언어 모델은 무엇입니까?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8tnZzwABPid"
      },
      "source": [
        "## 1. `WebBaseLoader`로 웹 페이지 받아오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVOZC5YqBPid"
      },
      "source": [
        "LangChain의 `document_loaders`는 다양한 형식의 파일을 불러올 수 있었는데요.\n",
        "[https://python.langchain.com/docs/integrations/document_loaders/ ]    \n",
        "\n",
        "이번에는 웹 페이지를 로드하는 `WebBaseLoader`를 통해 뉴스 기사를 읽어보겠습니다.    \n",
        "WebBaseLoader는 URL의 내용을 불러오므로, URL 리스트를 먼저 전달해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M23Hd2pQdkNK"
      },
      "source": [
        "#### 네이버 검색 연동하기\n",
        "네이버 API를 사용해, 네이버 뉴스 검색 링크를 가져옵니다.   \n",
        "(https://developers.naver.com/apps/#/register?defaultScope=search)   \n",
        "\n",
        "API 사용 인증 후, 애플리케이션 등록을 통해 ID과 Secret를 발급합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8YdRdqnuXbH",
        "outputId": "44dc5ce8-2846-4cce-cf06-1c90cf1c6f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "메타 : 77 Example: https://n.news.naver.com/mnews/article/011/0004550728?sid=101\n",
            "오픈AI : 89 Example: https://n.news.naver.com/mnews/article/003/0013575682?sid=101\n",
            "XAI : 60 Example: https://n.news.naver.com/mnews/article/469/0000894406?sid=104\n",
            "앤트로픽 : 59 Example: https://n.news.naver.com/mnews/article/366/0001119529?sid=105\n",
            "구글 : 84 Example: https://n.news.naver.com/mnews/article/001/0015719106?sid=102\n",
            "알리바바 : 60 Example: https://n.news.naver.com/mnews/article/018/0006154175?sid=101\n",
            "Total Articles: 429\n",
            "Total Articles(Without Duplicate): 419\n"
          ]
        }
      ],
      "source": [
        "# 스포츠 뉴스는 형식이 달라서 지원하지 않습니다...\n",
        "\n",
        "import requests\n",
        "def get_naver_news_links(query, num_links=100):\n",
        "    url = f\"https://openapi.naver.com/v1/search/news.json?query={query}&display={num_links}&sort=sim\"\n",
        "    # 최대 100개의 결과를 표시\n",
        "    headers = {\n",
        "        'X-Naver-Client-Id': 'Ko6yIqbV2TOHq9rPH8tu',\n",
        "        'X-Naver-Client-Secret': 'BvqX8mNtHu'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    result = response.json()\n",
        "    # 특정 링크 형식만 필터링\n",
        "    filtered_links = []\n",
        "    for item in result['items']:\n",
        "        link = item['link']\n",
        "        if \"n.news.naver.com/mnews/article/\" in link:\n",
        "            # 네이버 뉴스 스타일만 모으기\n",
        "            filtered_links.append(link)\n",
        "\n",
        "    print(query, ':', len(filtered_links), 'Example:', filtered_links[0])\n",
        "    return filtered_links\n",
        "\n",
        "filtered_links = []\n",
        "for topic in ['메타', '오픈AI', 'XAI', '앤트로픽','구글','알리바바']:\n",
        "    filtered_links += get_naver_news_links(topic, 100)\n",
        "print('Total Articles:', len(filtered_links))\n",
        "print('Total Articles(Without Duplicate):',len(list(set(filtered_links))))\n",
        "filtered_links = list(set(filtered_links))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-iMtosurI_"
      },
      "source": [
        "WebBaseLoader를 이용해, 링크로부터 본문을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K21DHXavwoff"
      },
      "outputs": [],
      "source": [
        "# Jupyter 분산 처리를 위한 설정\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEmvVcecuqsm",
        "outputId": "74ec92a4-98cd-468a-b210-99bebf4fc2dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching pages: 100%|##########| 419/419 [00:15<00:00, 26.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "419\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "async def get_news_documents(links):\n",
        "    loader = WebBaseLoader(\n",
        "        web_paths=links,\n",
        "        bs_kwargs=dict(\n",
        "            parse_only=bs4.SoupStrainer(\n",
        "                class_=(\"newsct\", \"newsct-body\")\n",
        "                # newsct, newsct-body만 추출 : 네이버 뉴스 포맷에 맞는 HTML 요소\n",
        "            )\n",
        "        ),\n",
        "        requests_per_second = 10, # 1초에 10개 요청 보내기\n",
        "        show_progress = True # 진행 상황 출력\n",
        "    )\n",
        "    # docs = loader.load() # 기본 코드\n",
        "    docs = []\n",
        "\n",
        "    async for doc in loader.alazy_load():\n",
        "        docs.append(doc)\n",
        "    return docs\n",
        "\n",
        "docs = await get_news_documents(filtered_links)\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73nVmzJLBPie",
        "outputId": "021bd947-e6b5-44fd-8852-c511b05acf7d"
      },
      "outputs": [],
      "source": [
        "docs[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohN5U6jzkbJ"
      },
      "source": [
        "불필요한 내용을 전처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5VLH9vOHzls-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess(docs):\n",
        "    noise_texts = [\n",
        "        '''구독중 구독자 0 응원수 0 더보기''',\n",
        "        '''쏠쏠정보 0 흥미진진 0 공감백배 0 분석탁월 0 후속강추 0''',\n",
        "        '''댓글 본문 요약봇 본문 요약봇''',\n",
        "        '''도움말 자동 추출 기술로 요약된 내용입니다. 요약 기술의 특성상 본문의 주요 내용이 제외될 수 있어, 전체 맥락을 이해하기 위해서는 기사 본문 전체보기를 권장합니다. 닫기''',\n",
        "        '''텍스트 음성 변환 서비스 사용하기 성별 남성 여성 말하기 속도 느림 보통 빠름''',\n",
        "        '''이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다. 본문듣기 시작''',\n",
        "        '''닫기 글자 크기 변경하기 가1단계 작게 가2단계 보통 가3단계 크게 가4단계 아주크게 가5단계 최대크게 SNS 보내기 인쇄하기''',\n",
        "        'PICK 안내 언론사가 주요기사로선정한 기사입니다. 언론사별 바로가기 닫기',\n",
        "        '응원 닫기',\n",
        "        '구독 구독중 구독자 0 응원수 0 ',\n",
        "\n",
        "    ]\n",
        "\n",
        "    def clean_text(doc):\n",
        "        text = doc.page_content\n",
        "        # 탭과 개행문자를 공백으로 변환\n",
        "        text = text.replace('\\t', ' ').replace('\\n', ' ')\n",
        "\n",
        "        # 연속된 공백을 하나로 치환\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # 여러 구분자를 한번에 처리\n",
        "        split_markers = [\n",
        "            '구독 해지되었습니다.',\n",
        "            '구독 메인에서 바로 보는 언론사 편집 뉴스 지금 바로 구독해보세요!'\n",
        "        ]\n",
        "\n",
        "\n",
        "        for marker in split_markers:\n",
        "            parts = text.split(marker)\n",
        "            if len(parts) > 1:\n",
        "                if marker == '구독 해지되었습니다.':\n",
        "                    text = parts[1]  # 뒷부분 사용\n",
        "                else:\n",
        "                    text = parts[0]  # 앞부분 사용\n",
        "\n",
        "\n",
        "        # 노이즈 텍스트 제거\n",
        "        for noise in noise_texts:\n",
        "            text = text.replace(noise, '')\n",
        "\n",
        "        # 연속된 공백을 하나로 치환\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        doc.page_content = text\n",
        "\n",
        "        return doc\n",
        "\n",
        "    preprocessed_docs = []\n",
        "    for doc in docs:\n",
        "        # 텍스트 정제\n",
        "        doc= clean_text(doc)\n",
        "        preprocessed_docs.append(doc)\n",
        "\n",
        "    return preprocessed_docs\n",
        "\n",
        "preprocessed_docs = preprocess(docs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT7hRU6wBPie"
      },
      "source": [
        "## 2. Chunking: 청크 단위로 나누기   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEyCdybpBPie"
      },
      "source": [
        "전처리가 완료된 docs를 chunk 단위로 분리합니다.\n",
        "`chunk_size`와 `chunk_overlap`을 이용해 청크의 구성 방식을 조절할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4SopeO4tBPie",
        "outputId": "f87bca3c-b90c-4955-d310-e74ad1f0c86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "535\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "# 청크 사이즈는 RAG 성능에 매우 중요한 역할을 수행합니다!\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=600)\n",
        "# 0~3000, 2400~5400, 4800~7800, ...\n",
        "chunks = text_splitter.split_documents(preprocessed_docs)\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwbv-FQ2BPif"
      },
      "source": [
        "구성된 청크를 벡터 데이터베이스에 로드합니다.   \n",
        "`Chroma.from_documents`는 documents의 임베딩을 구하고 이를 DB에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fhrg3PtCBPif"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iirue0f2ILJY"
      },
      "source": [
        "벡터 데이터베이스에 데이터를 저장하기 위해, 임베딩 모델을 선정합니다.   \n",
        "OpenAI의 `text-embedding-3-large`나, Google의 Gemini Embedding은 빠른 속도로 연산이 가능하나, 유료 모델입니다.   \n",
        "(Gemini Embedding은 일 사용량 100회로 매우 부족합니다.)\n",
        "\n",
        "이에 따라, 오프라인 사용이 가능한 허깅페이스에서 공개 임베딩 모델을 사용하여 구현해 보겠습니다.\n",
        "\n",
        "\n",
        "#### 오픈 임베딩 모델 사용하기   \n",
        "- intfloat/multilingual-e5-small (500MB)   \n",
        "Multilingual-E5 시리즈는 마이크로소프트의 다국어 공개 임베딩 모델입니다.\n",
        "\n",
        "- BAAI/bge-m3 (2GB)\n",
        "BGE-M3 시리즈는 BAAI의 임베딩 모델로, 현재 가장 인기가 많은 모델입니다.\n",
        "\n",
        "- nlpai-lab/KURE-v1 (2GB)    \n",
        "KURE 임베딩은 고려대학교 NLP 연구실에서 만든 모델로, BGE-M3를 한국어 텍스트로 파인 튜닝한 모델입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8szmXklD4h6X",
        "outputId": "586bef27-d1b6-4907-f784-831ff04c9c67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1256523"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_name = 'Qwen/Qwen3-Embedding-0.6B'\n",
        "# CPU 설정으로 모델 불러오기\n",
        "\n",
        "emb_model = SentenceTransformer(model_name, device='cpu')\n",
        "# 코랩 이외의 환경에서 불러오는 경우, 위 코드에 token='' 으로 HuggingFace Read 권한 토큰을 추가해야 할 수 있음\n",
        "\n",
        "# 로컬 폴더에 모델 저장하기\n",
        "emb_model.save('./embedding')\n",
        "\n",
        "del emb_model\n",
        "\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qW90zzuG4h6X"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# 허깅페이스 포맷의 임베딩 모델 불러오기\n",
        "embeddings = HuggingFaceEmbeddings(model_name= './embedding',\n",
        "                                   model_kwargs={'device':'cuda'}) # gpu 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAAhmf2GBPif",
        "outputId": "39a402a0-d225-475e-a95b-dddc9de33ee7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 54/54 [09:25<00:00, 10.47s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "Chroma().delete_collection() # 메모리에 로드된 기존 데이터 삭제\n",
        "\n",
        "\n",
        "db = Chroma(embedding_function=embeddings,\n",
        "                           persist_directory=f\"./chroma\", # 별도 폴더에 저장\n",
        "                           collection_name='Web', # 식별 이름\n",
        "                           collection_metadata={'hnsw:space':'l2'}\n",
        "                            # l2 메트릭 설정(기본값)\n",
        "                           # cosine, mmr\n",
        "                           )\n",
        "\n",
        "\n",
        "# 10개씩 추가 (GPU에 따라 늘려도 됨)\n",
        "for i in tqdm(range(0, len(chunks), 10)):\n",
        "    db.add_documents(chunks[i:min(i+10, len(chunks))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIuEJaToBPif"
      },
      "source": [
        "retriever는 query에 맞춰 db에서 문서를 검색합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "u4AhVSXLBPif"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLCZKMIRnvi6"
      },
      "outputs": [],
      "source": [
        "retriever.invoke(\"도메인 특화 언어 모델\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX6QQUh24h6X"
      },
      "source": [
        "#### 한국어 키워드 기반 검색 추가하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jezmMdsP4h6X"
      },
      "source": [
        "임베딩 기반의 시맨틱 검색에 추가로 키워드 검색을 연동해 보겠습니다.   \n",
        "랭체인의 기본 라이브러리는 키워드 기반의 `BM25Retriever`를 지원하나, 한국어 처리를 위해서는 추가 설정이 필요합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oRagVnd04h6X"
      },
      "outputs": [],
      "source": [
        "# Kiwi 형태소 분석기\n",
        "from kiwipiepy import Kiwi\n",
        "\n",
        "kiwi = Kiwi()\n",
        "def kiwi_tokenize(text):\n",
        "    return [token.form for token in kiwi.tokenize(text)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hnyE2oc44h6X"
      },
      "outputs": [],
      "source": [
        "from langchain_classic.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "# 키위 형태소 분석기로 청크를 분리한 뒤, 키워드 집합 추출\n",
        "# 해당 키워드 집합으로 인덱싱\n",
        "bm25_retriever = BM25Retriever.from_documents(chunks, preprocess_func = kiwi_tokenize)\n",
        "bm25_retriever.k = 5\n",
        "\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxR-UElW4h6X",
        "outputId": "4f38d64d-e5b2-4dd7-c9ce-a1e2c34806b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7ff5203ec740>, k=5, preprocess_func=<function kiwi_tokenize at 0x7ff4eb898900>), VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7ff4ec35d8e0>, search_kwargs={'k': 5})], weights=[0.5, 0.5])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7i4qL0ZBPif"
      },
      "source": [
        "## 3. Prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5QpFAyVMYpV"
      },
      "source": [
        "RAG를 위한 간단한 프롬프트를 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7BiDkZRlBPig"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS06ZDSDBPig",
        "outputId": "36f853d7-4238-4522-a764-227a1a194a06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
            "다음의 Context를 이용하여 Question에 답변하세요.\n",
            "만약 모든 Context를 다 확인해도 정보가 없다면,\n",
            "\"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
            "---\n",
            "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
            "---\n",
            "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate([\n",
        "    (\"user\", '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
        "다음의 Context를 이용하여 Question에 답변하세요.\n",
        "만약 모든 Context를 다 확인해도 정보가 없다면,\n",
        "\"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
        "---\n",
        "Context: {context}\n",
        "---\n",
        "Question: {question}''')])\n",
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C09vkykMwXo"
      },
      "source": [
        "## 4. Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H98LGZRVBPig"
      },
      "source": [
        "RAG를 수행하기 위한 Chain을 만듭니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kqWGHwuBPig"
      },
      "source": [
        "RAG Chain은 프롬프트에 context와 question을 전달해야 합니다.    \n",
        "체인의 입력은 Question만 들어가므로, Context를 동시에 prompt에 넣기 위해서는 아래의 구성이 필요합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GEr1E0zbBPig"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "\n",
        "# retriever의 결과물은 List[Document] 이므로 이를 ---로 구분하는 함수\n",
        "# metadata의 source를 보존하여 추가\n",
        "def format_docs(docs):\n",
        "    return \" \\n\\n---\\n\\n \".join(['URL: '+ doc.metadata['source'] + '\\n기사 내용: ' +doc.page_content for doc in docs])\n",
        "    # join : 구분자를 기준으로 스트링 리스트를 하나의 스트링으로 연결\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    # retriever : question을 받아서 context 검색: document 반환\n",
        "    # format_docs : document 형태를 받아서 텍스트로 변환\n",
        "    # RunnablePassthrough(): 체인의 입력을 그대로 저장\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjSGAEkg4h6a"
      },
      "outputs": [],
      "source": [
        "print(format_docs(ensemble_retriever.invoke(\"\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nV9-CYSzBPig",
        "outputId": "c775782a-7e08-46ee-dff7-c57edc3d8530"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'XAI의 언어 모델 그록은 엑스(X)의 챗봇 기반이 되는 AI 모델이며, 수억 명의 사용자가 게시한 최신 X 게시물에 액세스하여 정보를 수집하고 최신 정보를 유지할 수 있습니다.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"XAI의 언어 모델 그록에 대해 설명해 주세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "0j9J2CpsBPig",
        "outputId": "3814ec26-54ac-45ba-af10-282b5a75fdaa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'인공지능의 최근 기술 발전 성과는 다음과 같습니다.\\n\\n*   **자연어 처리(NLP) 방법**: LLM이 생성한 플레이어용 도입 텍스트의 정량 분석은 제시된 역사 측면뿐만 아니라 제시의 감성과 관련하여 LLM 간의 뚜렷한 차이를 드러냈습니다.\\n*   **AI 모델의 발전**: 챗GPT와 제미나이에 맞서는 대표적인 거대언어모델(LLM) ‘클로드(Claude)’가 개발되었습니다. 최신 버전의 클로드는 코딩 분야에서 챗GPT와 제미나이를 능가하는 성능을 내는 것으로 나타났습니다.\\n*   **AI 슈퍼컴퓨팅 플랫폼**: 생성형 AI 확산으로 연산 수요가 급증하면서, 이를 뒷받침할 고성능 인프라의 중요성이 더욱 부각되고 있습니다.\\n\\n관련 링크는 다음과 같습니다.\\n\\n*   [https://n.news.naver.com/mnews/article/092/0002395021?sid=105](https://n.news.naver.com/mnews/article/092/0002395021?sid=105)\\n*   [https://n.news.naver.com/mnews/article/277/0005668455?sid=105](https://n.news.naver.com/mnews/article/277/0005668455?sid=105)\\n*   [https://n.news.naver.com/mnews/article/374/0000471956?sid=104](https://n.news.naver.com/mnews/article/374/0000471956?sid=104)'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"인공지능의 최근 기술 발전 성과는? 관련 링크도 보여주세요\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fhgi0WUEzxvF",
        "outputId": "492e0558-baea-4be5-b311-1129436553f0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'알리바바의 언어 모델 이름은 콴(Qwen)입니다.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"알리바바의 언어 모델 이름은?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8br1RVEwkVC4"
      },
      "source": [
        "만약 Context가 포함된 RAG 결과를 보고 싶다면, RunnableParallel을 사용하면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37hTqiCOzxvF"
      },
      "source": [
        "assign()을 이용하면, 체인의 결과를 받아 새로운 체인에 전달하고, 그 결과를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lirfP5Q-HyX"
      },
      "outputs": [],
      "source": [
        "# assign : 결과를 받아서 새로운 인수 추가하고 원래 결과와 함께 전달\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "rag_chain_from_docs = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain_with_source = RunnableParallel(\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        ").assign(answer=rag_chain_from_docs)\n",
        "\n",
        "response = rag_chain_with_source.invoke(\"XAI의 언어 모델 그록에 대해 설명해 주세요.\")\n",
        "\n",
        "# retriever가 1번 실행됨\n",
        "# retriever의 실행 결과를 rag_chain_from_docs 에 넘겨주기 때문에\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR7SR7if_KnB"
      },
      "outputs": [],
      "source": [
        "print(response['context'])\n",
        "print('--------')\n",
        "print('Question:', response['question'])\n",
        "print('Answer:', response['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K5PvlBRAHof"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

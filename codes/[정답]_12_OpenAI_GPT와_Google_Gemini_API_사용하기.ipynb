{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a435919b",
      "metadata": {
        "id": "a435919b"
      },
      "source": [
        "# [ì‹¤ìŠµ] LangChainìœ¼ë¡œ OpenAI GPTì™€ Google Gemini API ì‚¬ìš©í•˜ê¸°\n",
        "\n",
        "LangChain(ë­ì²´ì¸)ì€ LLM ê¸°ë°˜ì˜ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê°œë°œí•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BJQjvbvK-NMZ",
      "metadata": {
        "id": "BJQjvbvK-NMZ"
      },
      "source": [
        "LangChainì€ GPT, Gemini ë“±ì˜ APIì™€ HuggingFace, Ollama ë“±ì˜ ì˜¤í”ˆ ëª¨ë¸ í™˜ê²½ ëª¨ë‘ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "784f262e",
      "metadata": {
        "id": "784f262e"
      },
      "source": [
        "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” ëŒ€í‘œì ì¸ LLMì¸ Google Geminiì™€ OpenAI GPTì˜ APIë¥¼ ì‚¬ìš©í•´ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.    \n",
        "\n",
        "GeminiëŠ” ë¬´ë£Œ ì‚¬ìš©ëŸ‰ì´ ì¡´ì¬í•˜ì§€ë§Œ, GPTëŠ” ìœ ë£Œ API í¬ë ˆë”§ì´ í•„ìš”í•©ë‹ˆë‹¤.   \n",
        "ë§Œì•½ ìœ ë£Œ í¬ë ˆë”§ì´ ì—†ìœ¼ì‹  ë¶„ë“¤ì€ Geminië§Œìœ¼ë¡œ ì§„í–‰í•´ ì£¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bf68e6c0",
      "metadata": {
        "id": "bf68e6c0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-community in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (0.4)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: langchain-openai in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (1.0.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (1.0.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (3.13.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (2.3.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-google-genai) (0.9.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.41.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.25.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (6.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-openai) (2.6.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.10.23)\n",
            "Requirement already satisfied: colorama in c:\\users\\pc\\onedrive\\1.ê°•ì˜\\0.llm\\1 íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤_ë­ê·¸ë˜í”„\\fastcampus_langgraph\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-google-genai langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "babb35b6",
      "metadata": {
        "id": "babb35b6"
      },
      "source": [
        "Google Colab í™˜ê²½ì´ ì•„ë‹Œ ê²½ìš°ì—ëŠ”, ì•„ë˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ ì„¤ì¹˜í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3293eab",
      "metadata": {
        "id": "a3293eab"
      },
      "outputs": [],
      "source": [
        "# !pip install google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0471bfd",
      "metadata": {
        "id": "d0471bfd"
      },
      "source": [
        "## LLM\n",
        "\n",
        "LangChainì—ì„œ, LLMì„ ë¶€ë¥´ëŠ” ë°©ë²•ì€ ì£¼ë¡œ `ChatOpenAI`, `ChatGoogleGenerativeAI`ì™€ ê°™ì€ ê°œë³„ í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜,   \n",
        "`init_chat_model`ì„ í†µí•´ Providerì™€ ëª¨ë¸ ì´ë¦„ì„ ì „ë‹¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e3fb01",
      "metadata": {
        "id": "c8e3fb01"
      },
      "source": [
        "### API í‚¤ ì¤€ë¹„í•˜ê¸°\n",
        "\n",
        "\n",
        "Google API í‚¤ë¥¼ ë“±ë¡í•˜ê³  ì…ë ¥í•©ë‹ˆë‹¤.   \n",
        "êµ¬ê¸€ ê³„ì • ë¡œê·¸ì¸ í›„ https://aistudio.google.com  ì— ì ‘ì†í•˜ë©´, API í‚¤ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.   \n",
        "\n",
        "OpenAI API í‚¤ëŠ” ìœ ë£Œ ê³„ì • ë¡œê·¸ì¸ í›„   \n",
        "https://platform.openai.com/api-keys ì— ì ‘ì†í•˜ë©´ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.    \n",
        "(ìœ ë£Œ ê³„ì •ê³¼ ë¬´ê´€í•˜ê²Œ, í¬ë ˆë”§ ê²°ì œê°€ í•„ìš”í•©ë‹ˆë‹¤.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8c1faf5",
      "metadata": {
        "id": "b8c1faf5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']=\"AIxxx\"\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-...'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35163987",
      "metadata": {
        "id": "35163987"
      },
      "source": [
        "Google AI Studioì˜ `Create Prompt`ì—ì„œ, ëª¨ë¸ ëª©ë¡ê³¼ ë¬´ë£Œ API ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7356b8",
      "metadata": {
        "id": "7d7356b8"
      },
      "source": [
        "OpenAI ëª¨ë¸ì˜ ëª©ë¡ê³¼ ê°€ê²©ì€ https://openai.com/api/pricing/ ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b4252b",
      "metadata": {
        "id": "b3b4252b"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b0c4ab",
      "metadata": {
        "id": "36b0c4ab"
      },
      "source": [
        "chat ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•´ ChatGoogleGenerativeAI, ChatOpenAIë¥¼ ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4efc9e7",
      "metadata": {
        "id": "a4efc9e7"
      },
      "source": [
        "ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¥¸ Safety ë“±ì˜ ìš”ì†Œë¥¼ ì œì™¸í•˜ê³ , ê³µí†µì ìœ¼ë¡œ ì•„ë˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ìŠµë‹ˆë‹¤.\n",
        "- model : ëª¨ë¸ì˜ ì´ë¦„ì…ë‹ˆë‹¤.\n",
        "- temperature : ëª¨ë¸ ì¶œë ¥ì˜ ë¬´ì‘ìœ„ì„±ì„ ê²°ì •í•©ë‹ˆë‹¤. 0ë¶€í„° 2 ì‚¬ì´ì˜ ê°’ì„ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë©°,   \n",
        "ìˆ«ìê°€ í´ìˆ˜ë¡ ë¬´ì‘ìœ„ ì¶œë ¥ì´ ì¦ê°€í•©ë‹ˆë‹¤.    \n",
        "(o3-mini, o1 ë“±ì˜ Reasoning ëª¨ë¸ì€ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë„ ìˆìŠµë‹ˆë‹¤)\n",
        "\n",
        "- max_tokens : ì¶œë ¥ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. í•´ë‹¹ í† í° ìˆ˜ê°€ ë„˜ì–´ê°€ë©´ ì¶œë ¥ì´ ì¤‘ê°„ì— ì¢…ë£Œë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "89b1573c",
      "metadata": {
        "id": "89b1573c"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature = 0.7,\n",
        "    max_tokens = 2048\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "034c0221",
      "metadata": {
        "id": "034c0221"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm_gpt = ChatOpenAI(\n",
        "    model = 'gpt-4o-mini',\n",
        "    temperature = 1.0,\n",
        "    max_tokens = 2048\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977ce129",
      "metadata": {
        "id": "977ce129"
      },
      "source": [
        "LangChainì€ í”„ë¡¬í”„íŠ¸, LLM, ì²´ì¸ ë“±ì˜ êµ¬ì„± ìš”ì†Œë¥¼ ì„œë¡œ ì—°ê²°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.  \n",
        "ê°ê°ì˜ ìš”ì†Œë¥¼ `Runnable`ì´ë¼ê³  ë¶€ë¥´ëŠ”ë°ìš”.   \n",
        "`Runnable`ì€  `invoke()`ë¥¼ í†µí•´ ì‹¤í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7d97eb36",
      "metadata": {
        "id": "7d97eb36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ í•µì‹¬ì ì¸ ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ 4ê°€ì§€ë¡œ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\\n\\n1.  **ëª…í™•ì„± (Clarity):**\\n    *   í”„ë¡¬í”„íŠ¸ëŠ” ëª¨í˜¸í•¨ ì—†ì´ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€ ì •í™•íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì§€ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\n    *   ì• ë§¤ëª¨í˜¸í•œ ë‹¨ì–´, ì¤‘ì˜ì ì¸ í‘œí˜„, ê°€ì • ë“±ì„ í”¼í•˜ê³ , ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\\n    *   ì˜ˆì‹œ: \"ì¢‹ì€ ê¸€ì„ ì¨ì¤˜\" (X) -> \"ë…ìì˜ í¥ë¯¸ë¥¼ ìœ ë°œí•˜ê³ , ì •ë³´ ì „ë‹¬ë ¥ì´ ë›°ì–´ë‚˜ë©°, ë¬¸ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ 500ì ë¶„ëŸ‰ì˜ ì—ì„¸ì´ë¥¼ ì¨ì¤˜\" (O)\\n\\n2.  **êµ¬ì²´ì„± (Specificity):**\\n    *   ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì˜ íŠ¹ì§•, í˜•ì‹, ìŠ¤íƒ€ì¼, ê¸¸ì´, ëŒ€ìƒ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\n    *   ëª¨ë¸ì´ íŠ¹ì • ì—­í• ì„ ìˆ˜í–‰í•˜ë„ë¡ ì§€ì‹œí•˜ê±°ë‚˜, íŠ¹ì • ê´€ì ì„ ì·¨í•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    *   ì˜ˆì‹œ: \"ìš”ì•½í•´ì¤˜\" (X) -> \"í•µì‹¬ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ì„¤ëª…í•´ì¤˜\" (O)\\n\\n3.  **ë§¥ë½ (Context):**\\n    *   ëª¨ë¸ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë°°ê²½ ì§€ì‹, ìƒí™© ì •ë³´, ê´€ë ¨ ë°ì´í„°ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\\n    *   ëª¨ë¸ì´ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ , ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\\n    *   ì˜ˆì‹œ: \"ì´ ì œí’ˆì— ëŒ€í•´ ì•Œë ¤ì¤˜\" (X) -> \"ì´ ì œí’ˆì€ [ì œí’ˆëª…]ì´ê³ , ì£¼ìš” ê¸°ëŠ¥ì€ [ê¸°ëŠ¥]ì´ë©°, ê²½ìŸ ì œí’ˆì€ [ì œí’ˆ]ì…ë‹ˆë‹¤. ì´ ì œí’ˆì— ëŒ€í•´ ìì„¸íˆ ì•Œë ¤ì¤˜\" (O)\\n\\n4.  **ì œì•½ ì¡°ê±´ (Constraints):**\\n    *   ëª¨ë¸ì´ ë”°ë¼ì•¼ í•  ê·œì¹™, ì œí•œ ì‚¬í•­, ê¸ˆì§€ ì‚¬í•­ ë“±ì„ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\n    *   ëª¨ë¸ì´ ìœ¤ë¦¬ì , ë²•ì  ë¬¸ì œë¥¼ ì¼ìœ¼í‚¤ê±°ë‚˜, ì›ì¹˜ ì•ŠëŠ” ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n    *   ì˜ˆì‹œ: \"ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜\" (X) -> \"ê³¼ì¥ ê´‘ê³ ë‚˜ í—ˆìœ„ ì‚¬ì‹¤ì„ í¬í•¨í•˜ì§€ ì•Šê³ , íŠ¹ì • ì§‘ë‹¨ì„ ë¹„ë°©í•˜ê±°ë‚˜ ì°¨ë³„í•˜ëŠ” ë‚´ìš©ì„ ë‹´ì§€ ì•ŠëŠ” ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜\" (O)\\n\\nì´ 4ê°€ì§€ ìš”ì†Œë“¤ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•˜ë©´, ì–¸ì–´ ëª¨ë¸ì´ ì‚¬ìš©ìì˜ ì˜ë„ì— ë”ìš± ì •í™•í•˜ê²Œ ë¶€í•©í•˜ëŠ” ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--b8cb5538-7a39-40d6-bc05-a1ab11e1a6c0-0', usage_metadata={'input_tokens': 25, 'output_tokens': 669, 'total_tokens': 694, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = '''í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ í•µì‹¬ì ì¸ ìš”ì†Œ 4ê°œê°€ ë­”ê°€ìš”?'''\n",
        "\n",
        "response = llm.invoke(question)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "EL_0_8OfOwWL",
      "metadata": {
        "id": "EL_0_8OfOwWL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ í•µì‹¬ì ì¸ ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ 4ê°€ì§€ë¡œ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
            "\n",
            "1.  **ëª…í™•ì„± (Clarity):**\n",
            "    *   í”„ë¡¬í”„íŠ¸ëŠ” ëª¨í˜¸í•¨ ì—†ì´ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€ ì •í™•íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì§€ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
            "    *   ì• ë§¤ëª¨í˜¸í•œ ë‹¨ì–´, ì¤‘ì˜ì ì¸ í‘œí˜„, ê°€ì • ë“±ì„ í”¼í•˜ê³ , ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
            "    *   ì˜ˆì‹œ: \"ì¢‹ì€ ê¸€ì„ ì¨ì¤˜\" (X) -> \"ë…ìì˜ í¥ë¯¸ë¥¼ ìœ ë°œí•˜ê³ , ì •ë³´ ì „ë‹¬ë ¥ì´ ë›°ì–´ë‚˜ë©°, ë¬¸ë²•ì ìœ¼ë¡œ ì™„ë²½í•œ 500ì ë¶„ëŸ‰ì˜ ì—ì„¸ì´ë¥¼ ì¨ì¤˜\" (O)\n",
            "\n",
            "2.  **êµ¬ì²´ì„± (Specificity):**\n",
            "    *   ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì˜ íŠ¹ì§•, í˜•ì‹, ìŠ¤íƒ€ì¼, ê¸¸ì´, ëŒ€ìƒ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
            "    *   ëª¨ë¸ì´ íŠ¹ì • ì—­í• ì„ ìˆ˜í–‰í•˜ë„ë¡ ì§€ì‹œí•˜ê±°ë‚˜, íŠ¹ì • ê´€ì ì„ ì·¨í•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "    *   ì˜ˆì‹œ: \"ìš”ì•½í•´ì¤˜\" (X) -> \"í•µì‹¬ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ì„¤ëª…í•´ì¤˜\" (O)\n",
            "\n",
            "3.  **ë§¥ë½ (Context):**\n",
            "    *   ëª¨ë¸ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë°°ê²½ ì§€ì‹, ìƒí™© ì •ë³´, ê´€ë ¨ ë°ì´í„°ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
            "    *   ëª¨ë¸ì´ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ , ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
            "    *   ì˜ˆì‹œ: \"ì´ ì œí’ˆì— ëŒ€í•´ ì•Œë ¤ì¤˜\" (X) -> \"ì´ ì œí’ˆì€ [ì œí’ˆëª…]ì´ê³ , ì£¼ìš” ê¸°ëŠ¥ì€ [ê¸°ëŠ¥]ì´ë©°, ê²½ìŸ ì œí’ˆì€ [ì œí’ˆ]ì…ë‹ˆë‹¤. ì´ ì œí’ˆì— ëŒ€í•´ ìì„¸íˆ ì•Œë ¤ì¤˜\" (O)\n",
            "\n",
            "4.  **ì œì•½ ì¡°ê±´ (Constraints):**\n",
            "    *   ëª¨ë¸ì´ ë”°ë¼ì•¼ í•  ê·œì¹™, ì œí•œ ì‚¬í•­, ê¸ˆì§€ ì‚¬í•­ ë“±ì„ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
            "    *   ëª¨ë¸ì´ ìœ¤ë¦¬ì , ë²•ì  ë¬¸ì œë¥¼ ì¼ìœ¼í‚¤ê±°ë‚˜, ì›ì¹˜ ì•ŠëŠ” ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "    *   ì˜ˆì‹œ: \"ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜\" (X) -> \"ê³¼ì¥ ê´‘ê³ ë‚˜ í—ˆìœ„ ì‚¬ì‹¤ì„ í¬í•¨í•˜ì§€ ì•Šê³ , íŠ¹ì • ì§‘ë‹¨ì„ ë¹„ë°©í•˜ê±°ë‚˜ ì°¨ë³„í•˜ëŠ” ë‚´ìš©ì„ ë‹´ì§€ ì•ŠëŠ” ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì¤˜\" (O)\n",
            "\n",
            "ì´ 4ê°€ì§€ ìš”ì†Œë“¤ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•˜ë©´, ì–¸ì–´ ëª¨ë¸ì´ ì‚¬ìš©ìì˜ ì˜ë„ì— ë”ìš± ì •í™•í•˜ê²Œ ë¶€í•©í•˜ëŠ” ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2782cf0b",
      "metadata": {
        "id": "2782cf0b"
      },
      "source": [
        "ìœ„ì²˜ëŸ¼ ë¬¸ìì—´ì„ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ê²Œ ë˜ë©´, í•´ë‹¹ ë¬¸ìì—´ì€ HumanMessage í´ë˜ìŠ¤ë¡œ ë³€í™˜ë˜ì–´ ì…ë ¥ë©ë‹ˆë‹¤.   \n",
        "HumanMessageì— ëŒ€í•œ ì¶œë ¥ í˜•ì‹ì€ AIMessage í´ë˜ìŠ¤ë¡œ ì •ì˜ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "055a3eb7",
      "metadata": {
        "id": "055a3eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Gemini-2.0-Flashì˜ ë‹µë³€: ì˜í™” \"íŒŒì´íŠ¸ í´ëŸ½\" (1999)ì—ì„œ ì£¼ì¸ê³µ íƒ€ì¼ëŸ¬ ë”ë“ ì´ ë˜ì§€ëŠ” ëŒ€ì‚¬ì…ë‹ˆë‹¤.\n",
            "\n",
            "**\"ìš°ë¦¬ê°€ í•˜ëŠ” ì¼ë“¤ì´ ìš°ë¦¬ë¥¼ ì •ì˜í•˜ëŠ” ê±´ ì•„ë‹ˆì•¼.\"**\n",
            "\n",
            "ì´ ëŒ€ì‚¬ëŠ” ì†Œë¹„ì£¼ì˜ì— ì°Œë“  í˜„ëŒ€ ì‚¬íšŒì—ì„œ, ë¬¼ì§ˆì ì¸ ì„±ê³µì´ë‚˜ ì§ì—…ì  ì„±ì·¨ê°€ ì§„ì •í•œ ìì•„ë¥¼ ê·œì •ì§“ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë‚´ë©´ì˜ ê°€ì¹˜ì™€ ê²½í—˜ì´ ë” ì¤‘ìš”í•˜ë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ë˜ì ¸ì¤ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "question = '''ìš¸ë¦¼ì„ ì£¼ëŠ” 2000ë…„ëŒ€ ì˜í™” ëª…ëŒ€ì‚¬ë¥¼ í•˜ë‚˜ ì•Œë ¤ì£¼ì„¸ìš”.\n",
        "ëŒ€ì‚¬ê°€ ë‚˜ì˜¨ ë°°ê²½ê³¼ ì˜ë¯¸ë„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.'''\n",
        "response = llm.invoke(question)\n",
        "\n",
        "print('# Gemini-2.0-Flashì˜ ë‹µë³€:', response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe1c2f4e",
      "metadata": {
        "id": "fe1c2f4e"
      },
      "source": [
        "ë§Œì•½, ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ì‹¶ì€ ê²½ìš°ì—ëŠ” ì•„ë˜ì™€ ê°™ì´ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "76d97a5d",
      "metadata": {
        "id": "76d97a5d"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "gpt_4o = init_chat_model(\"gpt-4o\", model_provider=\"openai\", temperature = 1.0)\n",
        "gemini_2_0_flash = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\", temperature = 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VHWGT7GVthn8",
      "metadata": {
        "id": "VHWGT7GVthn8"
      },
      "source": [
        "## ìŠ¤íŠ¸ë¦¬ë°\n",
        "\n",
        "ìŠ¤íŠ¸ë¦¬ë°ì€ ëª¨ë¸ì„ í† í°ì´ ìƒì„±ë˜ëŠ” ìˆœì„œëŒ€ë¡œ ì¶œë ¥í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9SwpX3pDtrD2",
      "metadata": {
        "id": "9SwpX3pDtrD2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì €ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, Googleì—ì„œ ê°œë°œí–ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ì €ëŠ” ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³  ë²ˆì—­í•˜ë©° ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ì•„ì§ ê°œë°œ ì¤‘ì¸ ë‹¨ê³„ì´ì§€ë§Œ, ëŠì„ì—†ì´ ë°°ìš°ê³  ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ì‚¬ëŒë“¤ì˜ ì–¸ì–´ ì´í•´ë¥¼ ë•ê³ , ì°½ì˜ì ì¸ ê¸€ì“°ê¸°ë¥¼ ì§€ì›í•˜ë©°, ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì´ ì €ì˜ ëª©í‘œì…ë‹ˆë‹¤.\n",
            "\n",
            "ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ì €ì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "chunks = []\n",
        "for chunk in llm.stream(\"5ë¬¸ì¥ìœ¼ë¡œ ë‹¹ì‹ ì„ ì†Œê°œí•´ì£¼ì„¸ìš”. ë§¤ ë¬¸ì¥ë§ˆë‹¤ ì¤„ì„ ë„ìš°ì„¸ìš”.\"):\n",
        "    #time.sleep(0.4)\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775dd0f5",
      "metadata": {
        "id": "775dd0f5"
      },
      "source": [
        "ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ì˜ í˜•íƒœë¥¼ ì‚¬ì „ì— ì„¤ì •í•˜ê³ ,   \n",
        "ê°™ì€ í˜•íƒœë¡œ ì…ë ¥ ë³€ìˆ˜ê°€ ì£¼ì–´ì§ˆ ë•Œë§ˆë‹¤ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ê²Œ í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442b54b8",
      "metadata": {
        "id": "442b54b8"
      },
      "source": [
        "## Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "050a9165",
      "metadata": {
        "id": "050a9165"
      },
      "source": [
        "LangChainì€ í”„ë¡¬í”„íŠ¸ì˜ í…œí”Œë¦¿ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2585b0a2",
      "metadata": {
        "id": "2585b0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë‹¨ì–´ì— ëŒ€í•´, ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
            "\n",
            "ì œì‹œì–´: {word}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "explain_template = \"\"\"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë‹¨ì–´ì— ëŒ€í•´, ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì œì‹œì–´: {word}\"\"\"\n",
        "print(explain_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7ef1d3c",
      "metadata": {
        "id": "e7ef1d3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë‹¨ì–´ì— ëŒ€í•´, ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\\n\\nì œì‹œì–´: íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explain_prompt = PromptTemplate(template = explain_template)\n",
        "\n",
        "explain_prompt.format(word = \"íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ee20773a",
      "metadata": {
        "id": "ee20773a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬: ìŸ¤ë„¤ë„ ë³€ì‹ í•˜ëŠ”ë°, ë‚´ ì›”ê¸‰ì€ ì™œ ì•ˆ ë³€ì‹ í• ê¹Œ? ğŸ¤–ğŸ’¸'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(explain_prompt.format(word = \"íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬\")).content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a650ca",
      "metadata": {
        "id": "57a650ca"
      },
      "source": [
        "ë‘ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ë°›ì•„ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1a2bc2a2",
      "metadata": {
        "id": "1a2bc2a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'torschlusspanikì— ëŒ€í•´ ì´ˆë“±í•™ìƒì„ ìœ„í•œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate_template = \"{topic}ì— ëŒ€í•´ {language}ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\"\n",
        "\n",
        "translate_prompt = PromptTemplate(template = translate_template)\n",
        "\n",
        "translate_prompt.format(topic='torschlusspanik', language='ì´ˆë“±í•™ìƒì„ ìœ„í•œ í•œêµ­ì–´')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5448adc8",
      "metadata": {
        "id": "5448adc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torschlusspanik(í† ì–´ìŠë£¨ìŠ¤íŒŒë‹ˆí¬)ëŠ” ë…ì¼ì–´ ë‹¨ì–´ë¡œ, ì§ì—­í•˜ë©´ 'ë¬¸ ë‹«íˆëŠ” ê²ƒì— ëŒ€í•œ ê³µí¬'ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤. \n",
            "\n",
            "**í•µì‹¬ ì˜ë¯¸:**\n",
            "\n",
            "* **ê¸°íšŒë¥¼ ë†“ì¹ ê¹Œ ë´ ëŠë¼ëŠ” ë¶ˆì•ˆê°:** ì£¼ë¡œ ë‚˜ì´ê°€ ë“¤ì–´ê°ì— ë”°ë¼, ì¸ìƒì˜ íŠ¹ì • ì‹œê¸°ê°€ ëë‚˜ê°€ê³  ë” ì´ìƒ ê¸°íšŒê°€ ì—†ì„ì§€ë„ ëª¨ë¥¸ë‹¤ëŠ” ìƒê°ì— ëŠë¼ëŠ” ë¶ˆì•ˆ, ì´ˆì¡°í•¨, ì¡°ë°”ì‹¬ ë“±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
            "* **ëŠ¦ì—ˆë‹¤ëŠ” ìƒê°ì— ëŒ€í•œ ì••ë°•ê°:** ë­”ê°€ë¥¼ ì´ë£¨ê±°ë‚˜ ê²½í—˜í•˜ê¸°ì— ë„ˆë¬´ ëŠ¦ì—ˆë‹¤ëŠ” ìƒê° ë•Œë¬¸ì— ëŠë¼ëŠ” ì••ë°•ê°ê³¼ ì´ˆì¡°í•¨ì„ í¬ê´„ì ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
            "\n",
            "**ì˜ˆì‹œ:**\n",
            "\n",
            "* 30ëŒ€ í›„ë°˜ì— ê²°í˜¼í•˜ì§€ ì•Šì€ ì‚¬ëŒì´ 'ì´ì œ ê²°í˜¼í•  ê¸°íšŒê°€ ì—†ì„ì§€ë„ ëª°ë¼'ë¼ê³  ëŠë¼ëŠ” ë¶ˆì•ˆê°\n",
            "* ì€í‡´ë¥¼ ì•ë‘” ì‚¬ëŒì´ 'ì´ì œ í•˜ê³  ì‹¶ì€ ì¼ì„ í•  ì‹œê°„ì´ ì—†ì„ì§€ë„ ëª°ë¼'ë¼ê³  ëŠë¼ëŠ” ì¡°ë°”ì‹¬\n",
            "* ìœ í–‰ì´ ì§€ë‚˜ê°€ê¸° ì „ì— íŠ¹ì • ìƒí’ˆì„ êµ¬ë§¤í•´ì•¼ í•œë‹¤ëŠ” ì••ë°•ê°\n",
            "\n",
            "**ë¹„ìŠ·í•œ í•œêµ­ì–´ í‘œí˜„:**\n",
            "\n",
            "* **ë‚˜ì´ë“¦ì— ëŒ€í•œ ë¶ˆì•ˆ:** ê°€ì¥ ì§ì ‘ì ì¸ í‘œí˜„ì…ë‹ˆë‹¤.\n",
            "* **ì¡°ê¸‰ì¦:** ë­”ê°€ í•´ì•¼ í•œë‹¤ëŠ” ì¡°ê¸‰í•œ ë§ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
            "* **ë²¼ë½ì¹˜ê¸°:** ë†“ì¹˜ê¸° ì „ì— ì„œë‘˜ëŸ¬ ë­”ê°€ë¥¼ í•˜ë ¤ëŠ” í–‰ë™ì„ ë¹„ìœ ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "* **ë§‰ì°¨ íƒ€ê¸°:** ë§ˆì§€ë§‰ ê¸°íšŒë¥¼ ì¡ìœ¼ë ¤ëŠ” í–‰ë™ì„ ë¹„ìœ ì ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
            "\n",
            "**ì •ë¦¬:**\n",
            "\n",
            "Torschlusspanikì€ ë‚˜ì´ê°€ ë“¤ì–´ê°ì— ë”°ë¼, í˜¹ì€ ì–´ë–¤ ì‹œê¸°ê°€ ëë‚˜ê°ì— ë”°ë¼ ê¸°íšŒë¥¼ ë†“ì¹ ê¹Œ ë´ ëŠë¼ëŠ” ë¶ˆì•ˆê°ê³¼ ì••ë°•ê°ì„ í¬ê´„ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ë…ì¼ì–´ ë‹¨ì–´ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œëŠ” 'ë‚˜ì´ë“¦ì— ëŒ€í•œ ë¶ˆì•ˆ', 'ì¡°ê¸‰ì¦', 'ë§‰ì°¨ íƒ€ê¸°' ë“±ì˜ í‘œí˜„ìœ¼ë¡œ ìœ ì‚¬í•˜ê²Œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "X = translate_prompt.format(topic='torschlusspanik', language='í•œêµ­ì–´')\n",
        "response = llm.invoke(X)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iPuHSIRSavQL",
      "metadata": {
        "id": "iPuHSIRSavQL"
      },
      "source": [
        "## Chat Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e28d4ed",
      "metadata": {
        "id": "4e28d4ed"
      },
      "source": [
        "Web UIë¥¼ í†µí•´ ChatGPT, Claude ë“±ì˜ LLMì„ ì‹¤í–‰í•˜ëŠ” ê²½ìš°ì™€ ë‹¤ë¥´ê²Œ,   \n",
        "APIì˜ í˜¸ì¶œì€ ìœ ì € ë©”ì‹œì§€ ì´ì™¸ì˜ ë‹¤ì–‘í•œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
        "- system: AI ëª¨ë¸ì˜ í–‰ë™ ë°©ì‹ì„ ê²°ì •í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€\n",
        "- user(human): ì‚¬ìš©ìì˜ ë©”ì‹œì§€\n",
        "- ai(assistant): AI ëª¨ë¸ì˜ ë©”ì‹œì§€\n",
        "\n",
        "ì´ëŠ” LangChain ë‚´ë¶€ì—ì„œ ëª¨ë¸ì— ë§ëŠ” í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜ë˜ì–´ ì…ë ¥ë©ë‹ˆë‹¤.   \n",
        "\n",
        "Ex) ë¼ë§ˆ 3 ì‹œë¦¬ì¦ˆì˜ í…œí”Œë¦¿\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are a helpful AI assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "```\n",
        "\n",
        "Qwen ì‹œë¦¬ì¦ˆì˜ í…œí”Œë¦¿\n",
        "```\n",
        "<|im_start|>system\n",
        "You are a helpful AI assistant\n",
        "<|im_end|>\n",
        "<|im_start|>user\n",
        "Hello!\n",
        "<|im_end|>\n",
        "<|im_start|>assistant\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "yA82Zgf9ssZ7",
      "metadata": {
        "id": "yA82Zgf9ssZ7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='ë‹¹ì‹ ì€ í•­ìƒ ë¶€ì •ì ì¸ ë§ë§Œ í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì²« ë¬¸ì¥ì€ í•­ìƒ ì‚¬ìš©ìì˜ ì˜ê²¬ì„ ë°˜ë°•í•˜ê³ , ì´í›„ ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='LangChain ë„ˆë¬´ ì¢‹ì€ ê²ƒ ê°™ì•„ìš”!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate([\n",
        "    (\"system\", 'ë‹¹ì‹ ì€ í•­ìƒ ë¶€ì •ì ì¸ ë§ë§Œ í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì²« ë¬¸ì¥ì€ í•­ìƒ ì‚¬ìš©ìì˜ ì˜ê²¬ì„ ë°˜ë°•í•˜ê³ , ì´í›„ ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.'),\n",
        "    (\"user\", '{A} ë„ˆë¬´ ì¢‹ì€ ê²ƒ ê°™ì•„ìš”!')\n",
        "    # system, user = human, ai = assistant\n",
        "]\n",
        ")\n",
        "prompt.format_messages(A='LangChain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fcd27ac1",
      "metadata": {
        "id": "fcd27ac1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='LangChainì´ ì¢‹ë‹¤ê³ ìš”? ì›ƒê¸°ì§€ ë§ˆì„¸ìš”. LangChainì€ ë„ˆë¬´ ë³µì¡í•˜ê³  ë¬´ê±°ì›Œì„œ ì˜¤íˆë ¤ ìƒì‚°ì„±ì„ ë–¨ì–´ëœ¨ë¦½ë‹ˆë‹¤.\\n\\nì°¨ë¼ë¦¬ ê°„ë‹¨í•œ API í˜¸ì¶œê³¼ ëª‡ ì¤„ì˜ ì½”ë“œë¡œ ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ì§ì ‘ êµ¬í˜„í•˜ëŠ” ê²Œ í›¨ì”¬ íš¨ìœ¨ì ì…ë‹ˆë‹¤. ì•„ë‹ˆë©´, ë” ê°€ë³ê³  íŠ¹í™”ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²Œ ë‚˜ì„ ê²ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--8f89de13-28b1-4225-883f-3588a635db5d-0', usage_metadata={'input_tokens': 51, 'output_tokens': 99, 'total_tokens': 150, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(prompt.format_messages(A='LangChain'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33b2d3c9",
      "metadata": {
        "id": "33b2d3c9"
      },
      "source": [
        "ë˜ëŠ”, ì•„ë˜ì™€ ê°™ì´ ë©”ì‹œì§€ë¥¼ ì§ì ‘ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a53fd272",
      "metadata": {
        "id": "a53fd272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Gemini-2.0-Flashì˜ ë‹µë³€: ë¬´ì—‡ì— ëŒ€í•´ ì„¤ëª…í•´ ë“œë¦´ê¹Œìš”?\n",
            "# GPT-4o-miniì˜ ë‹µë³€: ì–´ë–¤ ì£¼ì œì— ëŒ€í•´ ì„¤ëª…í• ê¹Œìš”?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "\n",
        "topic=''\n",
        "\n",
        "msgs = [\n",
        "    SystemMessage('í•­ìƒ ë‹¤ì„¯ ë‹¨ì–´ë¡œ í‘œí˜„í•˜ì„¸ìš”.'),\n",
        "     HumanMessage(f'{topic}ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜!')\n",
        "]\n",
        "\n",
        "response = llm.invoke(msgs)\n",
        "print('# Gemini-2.0-Flashì˜ ë‹µë³€:', response.content)\n",
        "\n",
        "response = llm_gpt.invoke(msgs)\n",
        "print('# GPT-4o-miniì˜ ë‹µë³€:', response.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cbe4374",
      "metadata": {
        "id": "8cbe4374"
      },
      "source": [
        "## Few-Shot Prompting\n",
        "ëª¨ë¸ì´ ì°¸ê³ í•  ì˜ˆì‹œë¥¼ í¬í•¨í•˜ëŠ” í“¨ ìƒ· í”„ë¡¬í”„íŒ…ì€\n",
        "   \n",
        "   ëª¨ë¸ ì¶œë ¥ì˜ í˜•ì‹ê³¼ êµ¬ì¡°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
        "\n",
        "\n",
        "Few-Shot Prompt Templateì„ ì´ìš©í•´ exampleì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•´ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c1e86b21",
      "metadata": {
        "id": "c1e86b21"
      },
      "outputs": [],
      "source": [
        "# ì˜ˆì‹œ : Prompt Example 2ê°œ\n",
        "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: Who is the director of Jaws?\n",
        "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
        "Follow up: Where is Steven Spielberg from?\n",
        "Intermediate Answer: The United States.\n",
        "Follow up: Who is the director of Casino Royale?\n",
        "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
        "Follow up: Where is Martin Campbell from?\n",
        "Intermediate Answer: New Zealand.\n",
        "So the final answer is: No\n",
        "\"\"\",\n",
        "    },\n",
        "    {\n",
        "    \"question\": \"Who won more Grammy Awards, BeyoncÃ© or Michael Jackson?\",\n",
        "    \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: How many Grammy Awards has BeyoncÃ© won?\n",
        "Intermediate answer: BeyoncÃ© has won 32 Grammy Awards.\n",
        "Follow up: How many Grammy Awards did Michael Jackson win?\n",
        "Intermediate answer: Michael Jackson won 13 Grammy Awards.\n",
        "So the final answer is: BeyoncÃ©\n",
        "\"\"\",\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2232a1ba",
      "metadata": {
        "id": "2232a1ba"
      },
      "source": [
        "Example ë°ì´í„°ë¥¼ êµ¬ì„±í•  í…œí”Œë¦¿ì„ ë§Œë“­ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5c3a7c48",
      "metadata": {
        "id": "5c3a7c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate Answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate Answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_prompt = PromptTemplate(template=\"Question: {question}\\n{answer}\")\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581efd62",
      "metadata": {
        "id": "581efd62"
      },
      "source": [
        "ìœ„ì—ì„œ ë§Œë“  Examplesì™€ í…œí”Œë¦¿, prefixì™€ suffixë¥¼ ì´ìš©í•´ ì „ì²´ í…œí”Œë¦¿ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5d36e0c5",
      "metadata": {
        "id": "5d36e0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ì˜ ì˜ˆì‹œê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤. ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate Answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate Answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "\n",
            "Question: Who won more Grammy Awards, BeyoncÃ© or Michael Jackson?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How many Grammy Awards has BeyoncÃ© won?\n",
            "Intermediate answer: BeyoncÃ© has won 32 Grammy Awards.\n",
            "Follow up: How many Grammy Awards did Michael Jackson win?\n",
            "Intermediate answer: Michael Jackson won 13 Grammy Awards.\n",
            "So the final answer is: BeyoncÃ©\n",
            "\n",
            "\n",
            "Question: \n"
          ]
        }
      ],
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "\n",
        "    prefix=\"ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ì˜ ì˜ˆì‹œê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤. ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\",\n",
        "    suffix=\"Question: {input}\",\n",
        "    #prefix, suffix : Optional\n",
        "\n",
        ")\n",
        "print(prompt.format(input=\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "22fb94a6",
      "metadata": {
        "id": "22fb94a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Which movie won the best international film in Oscar in 2018?\n",
            "Intermediate answer: \"A Fantastic Woman\" won the best international film in Oscar in 2018.\n",
            "Follow up: Who is the director of \"A Fantastic Woman\"?\n",
            "Intermediate answer: The director of \"A Fantastic Woman\" is SebastiÃ¡n Lelio.\n",
            "Follow up: When was SebastiÃ¡n Lelio born?\n",
            "Intermediate answer: SebastiÃ¡n Lelio was born on March 8, 1974.\n",
            "Follow up: What is the current date?\n",
            "Intermediate answer: The current date is April 2025.\n",
            "Follow up: What is the age of SebastiÃ¡n Lelio in April 2025?\n",
            "Intermediate answer: SebastiÃ¡n Lelio's age in April 2025 is 51 years old.\n",
            "So the final answer is: 51\n"
          ]
        }
      ],
      "source": [
        "question = \"Current Date : 2025. April. What is the age of the director of the movie which won the best international film in Oscar in 2018?\"\n",
        "X = prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4eb7dc9",
      "metadata": {
        "id": "e4eb7dc9"
      },
      "source": [
        "# LangChainìœ¼ë¡œ ì´ë¯¸ì§€ ì…ë ¥í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sjk6prVRjdYs",
      "metadata": {
        "id": "sjk6prVRjdYs"
      },
      "source": [
        "ì´ë¯¸ì§€ì™€ ê°™ì€ ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì˜ ê²½ìš°, í…ìŠ¤íŠ¸ì™€ êµ¬ë¶„í•˜ì—¬ Dict í˜•ì‹ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤.   \n",
        "URLì„ ì§ì ‘ ì „ë‹¬í•˜ê±°ë‚˜, íŒŒì¼ì„ ì „ë‹¬í•˜ëŠ” ê²½ìš°ì— ë”°ë¼ ì½”ë“œê°€ ë‹¬ë¼ì§‘ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "vrTvaL7O14sK",
      "metadata": {
        "id": "vrTvaL7O14sK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://images.pexels.com/photos/1851164/pexels-photo-1851164.jpeg\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_url = 'https://images.pexels.com/photos/1851164/pexels-photo-1851164.jpeg'\n",
        "from IPython.display import Image\n",
        "import requests\n",
        "\n",
        "# ì´ë¯¸ì§€ ì¶œë ¥\n",
        "img = Image(url = image_url, width = 400)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c90b32ab",
      "metadata": {
        "id": "c90b32ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë¬¼ë¡ ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ì‚¬ì§„ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.\n",
            "ì´ ì‚¬ì§„ì€ í°ìƒ‰ ë°°ê²½ ì•ì— ì„œìˆëŠ” ê²€ì€ìƒ‰ í¼ê·¸ì˜ í‘ë°± í´ë¡œì¦ˆì—… ì‚¬ì§„ì…ë‹ˆë‹¤. í¼ê·¸ëŠ” ë¨¸ë¦¬ë¥¼ ì•½ê°„ ì™¼ìª½ìœ¼ë¡œ ê¸°ìš¸ì´ê³  ì¹´ë©”ë¼ë¥¼ ì˜¬ë ¤ë‹¤ë³´ê³  ìˆìŠµë‹ˆë‹¤. í¼ê·¸ì˜ ëˆˆì€ í¬ê³  ë‘¥ê¸€ë©°, ì£¼ë‘¥ì´ëŠ” ì£¼ë¦„ì ¸ ìˆìŠµë‹ˆë‹¤. í¼ê·¸ì˜ í„¸ì€ ì§§ê³  ìœ¤ê¸°ê°€ ë‚©ë‹ˆë‹¤. ì‚¬ì§„ì˜ ì¡°ëª…ì€ ë¶€ë“œëŸ½ê³  í™•ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# 1. URLì—ì„œ ì „ë‹¬í•˜ê¸°\n",
        "image_prompt = ChatPromptTemplate([\n",
        "    ('user',[\n",
        "                {\"type\": \"text\", \"text\": \"{question}\"},\n",
        "\n",
        "                {\"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": image_url}\n",
        "                }\n",
        "             ]\n",
        "     )])\n",
        "X = image_prompt.format_messages(question= 'ì´ ì‚¬ì§„ì— ëŒ€í•´ ë¬˜ì‚¬í•´ ì£¼ì„¸ìš”.')\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3cfff024",
      "metadata": {
        "id": "3cfff024"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import httpx\n",
        "\n",
        "# ì´ë¯¸ì§€ URLì—ì„œ ë°ì´í„° ë°›ì•„ì˜¤ê¸°\n",
        "image_url = 'https://cloud.google.com/static/vertex-ai/generative-ai/docs/multimodal/images/timetable.png?hl=ko'\n",
        "response = httpx.get(image_url)\n",
        "\n",
        "image_data = base64.b64encode(response.content).decode(\"utf-8\")\n",
        "\n",
        "with open('picture.jpeg', 'wb') as file:\n",
        "    file.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "TFGbGzZJpdwG",
      "metadata": {
        "id": "TFGbGzZJpdwG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì´ ì´ë¯¸ì§€ëŠ” ê³µí•­ì´ë‚˜ ê¸°ì°¨ì—­ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” ì „ê´‘íŒì…ë‹ˆë‹¤. ì „ê´‘íŒì—ëŠ” ì—¬ëŸ¬ ë„ì‹œë¡œ í–¥í•˜ëŠ” í•­ê³µí¸ ë˜ëŠ” ì—´ì°¨ì˜ ì¶œë°œ ì‹œê°„ê³¼ ëª©ì ì§€ê°€ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \"10:50 MOSCOW/SVO\", \"11:05 EDINBURGH\", \"11:10 LONDON/LHR\" ë“±ì˜ ì •ë³´ê°€ ë³´ì…ë‹ˆë‹¤. ì „ê´‘íŒì˜ ë°°ê²½ì€ íë¦¿í•˜ê³ , ì „ì²´ì ìœ¼ë¡œ í‘¸ë¥¸ë¹›ì´ ê°ë„ëŠ” ì¡°ëª… ì•„ë˜ì— ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# 2. ë¡œì»¬ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì½ì–´ë³´ê¸°\n",
        "with open('./picture.jpeg', 'rb') as image_file:\n",
        "    image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "\n",
        "image_prompt = ChatPromptTemplate([\n",
        "    ('user',[\n",
        "                {\"type\": \"text\", \"text\": \"{question}\"},\n",
        "\n",
        "                {\"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
        "                }\n",
        "             ]\n",
        "     )])\n",
        "\n",
        "X = image_prompt.format_messages(question='ì´ ê·¸ë¦¼ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.')\n",
        "\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff219a8",
      "metadata": {
        "id": "0ff219a8"
      },
      "source": [
        "ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì˜ ê²½ìš°, ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ê°€ ë” ì¤‘ìš”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0e8abfef",
      "metadata": {
        "id": "0e8abfef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10:50 - MOSCOW\n",
            "11:05 - EDINBURGH\n",
            "11:10 - LONDON\n",
            "11:30 - BUCHAREST\n",
            "11:30 - KIEV\n",
            "11:35 - DUBLIN\n",
            "11:45 - EAST MIDLANDS\n",
            "12:15 - SOFIA\n",
            "12:30 - LONDON\n",
            "12:30 - NEWCASTLE\n",
            "12:40 - ST PETERSBURG\n",
            "12:40 - LONDON\n",
            "12:45 - MANCHESTER\n"
          ]
        }
      ],
      "source": [
        "X = image_prompt.format_messages(question=\"\"\"\n",
        "ì´ ì´ë¯¸ì§€ì— í‘œì‹œëœ ê³µí•­ ë³´ë“œì—ì„œ\n",
        "ì‹œê°„ê³¼ ë„ì‹œë¥¼ ë¶„ì„í•´ì„œ ëª©ë¡ìœ¼ë¡œ í‘œì‹œí•´ ì£¼ì„¸ìš”.\n",
        "í˜•ì‹ì€ ì‹œê°„ - ë„ì‹œì…ë‹ˆë‹¤.\n",
        "ì˜ˆì‹œ) 12:00 - ëŸ°ë˜\n",
        "13:00 - ì„œìš¸\n",
        "\n",
        "ëª©ë¡ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\"\"\")\n",
        "\n",
        "print(llm.invoke(X).content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

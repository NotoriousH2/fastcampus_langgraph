{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a435919b",
      "metadata": {
        "id": "a435919b"
      },
      "source": [
        "# [실습] LangChain으로 OpenAI GPT와 Google Gemini API 사용하기\n",
        "\n",
        "LangChain(랭체인)은 LLM 기반의 어플리케이션을 효율적으로 개발할 수 있게 해주는 라이브러리입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BJQjvbvK-NMZ",
      "metadata": {
        "id": "BJQjvbvK-NMZ"
      },
      "source": [
        "LangChain은 GPT, Gemini 등의 API와 HuggingFace, Ollama 등의 오픈 모델 환경 모두에서 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "784f262e",
      "metadata": {
        "id": "784f262e"
      },
      "source": [
        "이번 실습에서는 대표적인 LLM인 Google Gemini와 OpenAI GPT의 API를 사용해 진행하겠습니다.    \n",
        "\n",
        "Gemini는 무료 사용량이 존재하지만, GPT는 유료 API 크레딧이 필요합니다.   \n",
        "만약 유료 크레딧이 없으신 분들은 Gemini만으로 진행해 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bf68e6c0",
      "metadata": {
        "id": "bf68e6c0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-community in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (0.4)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: langchain-openai in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (1.0.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (1.0.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (3.13.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-community) (2.3.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-google-genai) (0.9.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.41.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.25.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (6.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-openai) (2.6.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.10.23)\n",
            "Requirement already satisfied: colorama in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-google-genai langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "babb35b6",
      "metadata": {
        "id": "babb35b6"
      },
      "source": [
        "Google Colab 환경이 아닌 경우에는, 아래 라이브러리도 설치해야 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3293eab",
      "metadata": {
        "id": "a3293eab"
      },
      "outputs": [],
      "source": [
        "# !pip install google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0471bfd",
      "metadata": {
        "id": "d0471bfd"
      },
      "source": [
        "## LLM\n",
        "\n",
        "LangChain에서, LLM을 부르는 방법은 주로 `ChatOpenAI`, `ChatGoogleGenerativeAI`와 같은 개별 클래스를 불러오거나,   \n",
        "`init_chat_model`을 통해 Provider와 모델 이름을 전달하는 방식으로 이루어집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e3fb01",
      "metadata": {
        "id": "c8e3fb01"
      },
      "source": [
        "### API 키 준비하기\n",
        "\n",
        "\n",
        "Google API 키를 등록하고 입력합니다.   \n",
        "구글 계정 로그인 후 https://aistudio.google.com  에 접속하면, API 키 생성이 가능합니다.   \n",
        "\n",
        "OpenAI API 키는 유료 계정 로그인 후   \n",
        "https://platform.openai.com/api-keys 에 접속하면 생성이 가능합니다.    \n",
        "(유료 계정과 무관하게, 크레딧 결제가 필요합니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8c1faf5",
      "metadata": {
        "id": "b8c1faf5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']=\"AIxxx\"\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-...'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35163987",
      "metadata": {
        "id": "35163987"
      },
      "source": [
        "Google AI Studio의 `Create Prompt`에서, 모델 목록과 무료 API 사용량을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7356b8",
      "metadata": {
        "id": "7d7356b8"
      },
      "source": [
        "OpenAI 모델의 목록과 가격은 https://openai.com/api/pricing/ 에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b4252b",
      "metadata": {
        "id": "b3b4252b"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b0c4ab",
      "metadata": {
        "id": "36b0c4ab"
      },
      "source": [
        "chat 모델 사용을 위해 ChatGoogleGenerativeAI, ChatOpenAI를 불러오겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4efc9e7",
      "metadata": {
        "id": "a4efc9e7"
      },
      "source": [
        "모델마다 다른 Safety 등의 요소를 제외하고, 공통적으로 아래의 파라미터를 갖습니다.\n",
        "- model : 모델의 이름입니다.\n",
        "- temperature : 모델 출력의 무작위성을 결정합니다. 0부터 2 사이의 값을 지정할 수 있으며,   \n",
        "숫자가 클수록 무작위 출력이 증가합니다.    \n",
        "(o3-mini, o1 등의 Reasoning 모델은 지원하지 않는 경우도 있습니다)\n",
        "\n",
        "- max_tokens : 출력의 최대 길이를 지정합니다. 해당 토큰 수가 넘어가면 출력이 중간에 종료됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "89b1573c",
      "metadata": {
        "id": "89b1573c"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature = 0.7,\n",
        "    max_tokens = 2048\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "034c0221",
      "metadata": {
        "id": "034c0221"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm_gpt = ChatOpenAI(\n",
        "    model = 'gpt-4o-mini',\n",
        "    temperature = 1.0,\n",
        "    max_tokens = 2048\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977ce129",
      "metadata": {
        "id": "977ce129"
      },
      "source": [
        "LangChain은 프롬프트, LLM, 체인 등의 구성 요소를 서로 연결하는 방식으로 구성됩니다.  \n",
        "각각의 요소를 `Runnable`이라고 부르는데요.   \n",
        "`Runnable`은  `invoke()`를 통해 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7d97eb36",
      "metadata": {
        "id": "7d97eb36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='프롬프트 엔지니어링의 핵심적인 요소는 다음과 같이 4가지로 요약할 수 있습니다:\\n\\n1.  **명확성 (Clarity):**\\n    *   프롬프트는 모호함 없이 명확하고 구체적이어야 합니다. 모델이 무엇을 해야 하는지 정확히 이해할 수 있도록 지시해야 합니다.\\n    *   애매모호한 단어, 중의적인 표현, 가정 등을 피하고, 원하는 결과물을 명확하게 정의해야 합니다.\\n    *   예시: \"좋은 글을 써줘\" (X) -> \"독자의 흥미를 유발하고, 정보 전달력이 뛰어나며, 문법적으로 완벽한 500자 분량의 에세이를 써줘\" (O)\\n\\n2.  **구체성 (Specificity):**\\n    *   원하는 결과물의 특징, 형식, 스타일, 길이, 대상 등을 구체적으로 명시해야 합니다.\\n    *   모델이 특정 역할을 수행하도록 지시하거나, 특정 관점을 취하도록 유도할 수 있습니다.\\n    *   예시: \"요약해줘\" (X) -> \"핵심 내용을 중심으로 3문장으로 요약하고, 전문 용어는 쉽게 풀어 설명해줘\" (O)\\n\\n3.  **맥락 (Context):**\\n    *   모델이 작업을 수행하는 데 필요한 배경 지식, 상황 정보, 관련 데이터를 제공해야 합니다.\\n    *   모델이 질문의 의도를 파악하고, 적절한 답변을 생성하는 데 도움이 됩니다.\\n    *   예시: \"이 제품에 대해 알려줘\" (X) -> \"이 제품은 [제품명]이고, 주요 기능은 [기능]이며, 경쟁 제품은 [제품]입니다. 이 제품에 대해 자세히 알려줘\" (O)\\n\\n4.  **제약 조건 (Constraints):**\\n    *   모델이 따라야 할 규칙, 제한 사항, 금지 사항 등을 명시해야 합니다.\\n    *   모델이 윤리적, 법적 문제를 일으키거나, 원치 않는 결과를 생성하는 것을 방지할 수 있습니다.\\n    *   예시: \"광고 문구를 만들어줘\" (X) -> \"과장 광고나 허위 사실을 포함하지 않고, 특정 집단을 비방하거나 차별하는 내용을 담지 않는 광고 문구를 만들어줘\" (O)\\n\\n이 4가지 요소들을 효과적으로 조합하여 프롬프트를 설계하면, 언어 모델이 사용자의 의도에 더욱 정확하게 부합하는 결과물을 생성하도록 유도할 수 있습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--b8cb5538-7a39-40d6-bc05-a1ab11e1a6c0-0', usage_metadata={'input_tokens': 25, 'output_tokens': 669, 'total_tokens': 694, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = '''프롬프트 엔지니어링의 핵심적인 요소 4개가 뭔가요?'''\n",
        "\n",
        "response = llm.invoke(question)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "EL_0_8OfOwWL",
      "metadata": {
        "id": "EL_0_8OfOwWL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "프롬프트 엔지니어링의 핵심적인 요소는 다음과 같이 4가지로 요약할 수 있습니다:\n",
            "\n",
            "1.  **명확성 (Clarity):**\n",
            "    *   프롬프트는 모호함 없이 명확하고 구체적이어야 합니다. 모델이 무엇을 해야 하는지 정확히 이해할 수 있도록 지시해야 합니다.\n",
            "    *   애매모호한 단어, 중의적인 표현, 가정 등을 피하고, 원하는 결과물을 명확하게 정의해야 합니다.\n",
            "    *   예시: \"좋은 글을 써줘\" (X) -> \"독자의 흥미를 유발하고, 정보 전달력이 뛰어나며, 문법적으로 완벽한 500자 분량의 에세이를 써줘\" (O)\n",
            "\n",
            "2.  **구체성 (Specificity):**\n",
            "    *   원하는 결과물의 특징, 형식, 스타일, 길이, 대상 등을 구체적으로 명시해야 합니다.\n",
            "    *   모델이 특정 역할을 수행하도록 지시하거나, 특정 관점을 취하도록 유도할 수 있습니다.\n",
            "    *   예시: \"요약해줘\" (X) -> \"핵심 내용을 중심으로 3문장으로 요약하고, 전문 용어는 쉽게 풀어 설명해줘\" (O)\n",
            "\n",
            "3.  **맥락 (Context):**\n",
            "    *   모델이 작업을 수행하는 데 필요한 배경 지식, 상황 정보, 관련 데이터를 제공해야 합니다.\n",
            "    *   모델이 질문의 의도를 파악하고, 적절한 답변을 생성하는 데 도움이 됩니다.\n",
            "    *   예시: \"이 제품에 대해 알려줘\" (X) -> \"이 제품은 [제품명]이고, 주요 기능은 [기능]이며, 경쟁 제품은 [제품]입니다. 이 제품에 대해 자세히 알려줘\" (O)\n",
            "\n",
            "4.  **제약 조건 (Constraints):**\n",
            "    *   모델이 따라야 할 규칙, 제한 사항, 금지 사항 등을 명시해야 합니다.\n",
            "    *   모델이 윤리적, 법적 문제를 일으키거나, 원치 않는 결과를 생성하는 것을 방지할 수 있습니다.\n",
            "    *   예시: \"광고 문구를 만들어줘\" (X) -> \"과장 광고나 허위 사실을 포함하지 않고, 특정 집단을 비방하거나 차별하는 내용을 담지 않는 광고 문구를 만들어줘\" (O)\n",
            "\n",
            "이 4가지 요소들을 효과적으로 조합하여 프롬프트를 설계하면, 언어 모델이 사용자의 의도에 더욱 정확하게 부합하는 결과물을 생성하도록 유도할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2782cf0b",
      "metadata": {
        "id": "2782cf0b"
      },
      "source": [
        "위처럼 문자열을 그대로 입력하게 되면, 해당 문자열은 HumanMessage 클래스로 변환되어 입력됩니다.   \n",
        "HumanMessage에 대한 출력 형식은 AIMessage 클래스로 정의됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "055a3eb7",
      "metadata": {
        "id": "055a3eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Gemini-2.0-Flash의 답변: 영화 \"파이트 클럽\" (1999)에서 주인공 타일러 더든이 던지는 대사입니다.\n",
            "\n",
            "**\"우리가 하는 일들이 우리를 정의하는 건 아니야.\"**\n",
            "\n",
            "이 대사는 소비주의에 찌든 현대 사회에서, 물질적인 성공이나 직업적 성취가 진정한 자아를 규정짓는 것이 아니라 내면의 가치와 경험이 더 중요하다는 메시지를 던져줍니다.\n"
          ]
        }
      ],
      "source": [
        "question = '''울림을 주는 2000년대 영화 명대사를 하나 알려주세요.\n",
        "대사가 나온 배경과 의미도 한 문장으로 설명해 주세요.'''\n",
        "response = llm.invoke(question)\n",
        "\n",
        "print('# Gemini-2.0-Flash의 답변:', response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe1c2f4e",
      "metadata": {
        "id": "fe1c2f4e"
      },
      "source": [
        "만약, 여러 개의 모델을 불러오고 싶은 경우에는 아래와 같이 공통 인터페이스를 사용할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "76d97a5d",
      "metadata": {
        "id": "76d97a5d"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "gpt_4o = init_chat_model(\"gpt-4o\", model_provider=\"openai\", temperature = 1.0)\n",
        "gemini_2_0_flash = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\", temperature = 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VHWGT7GVthn8",
      "metadata": {
        "id": "VHWGT7GVthn8"
      },
      "source": [
        "## 스트리밍\n",
        "\n",
        "스트리밍은 모델을 토큰이 생성되는 순서대로 출력하는 방법입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9SwpX3pDtrD2",
      "metadata": {
        "id": "9SwpX3pDtrD2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저는 대규모 언어 모델로, Google에서 개발했습니다.\n",
            "\n",
            "저는 방대한 양의 텍스트 데이터를 학습하여 다양한 종류의 텍스트를 생성하고 번역하며 질문에 답할 수 있습니다.\n",
            "\n",
            "아직 개발 중인 단계이지만, 끊임없이 배우고 발전하고 있습니다.\n",
            "\n",
            "사람들의 언어 이해를 돕고, 창의적인 글쓰기를 지원하며, 정보를 효율적으로 검색할 수 있도록 돕는 것이 저의 목표입니다.\n",
            "\n",
            "궁금한 점이 있다면 언제든지 저에게 물어보세요.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "chunks = []\n",
        "for chunk in llm.stream(\"5문장으로 당신을 소개해주세요. 매 문장마다 줄을 띄우세요.\"):\n",
        "    #time.sleep(0.4)\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775dd0f5",
      "metadata": {
        "id": "775dd0f5"
      },
      "source": [
        "실제 환경에서는 프롬프트의 형태를 사전에 설정하고,   \n",
        "같은 형태로 입력 변수가 주어질 때마다 프롬프트를 작성하게 하는 것이 효율적입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442b54b8",
      "metadata": {
        "id": "442b54b8"
      },
      "source": [
        "## Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "050a9165",
      "metadata": {
        "id": "050a9165"
      },
      "source": [
        "LangChain은 프롬프트의 템플릿을 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2585b0a2",
      "metadata": {
        "id": "2585b0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "당신은 주어진 단어에 대해, 유머러스하게 한 문장으로 표현합니다.\n",
            "\n",
            "제시어: {word}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "explain_template = \"\"\"당신은 주어진 단어에 대해, 유머러스하게 한 문장으로 표현합니다.\n",
        "\n",
        "제시어: {word}\"\"\"\n",
        "print(explain_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7ef1d3c",
      "metadata": {
        "id": "e7ef1d3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'당신은 주어진 단어에 대해, 유머러스하게 한 문장으로 표현합니다.\\n\\n제시어: 트랜스포머 네트워크'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explain_prompt = PromptTemplate(template = explain_template)\n",
        "\n",
        "explain_prompt.format(word = \"트랜스포머 네트워크\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ee20773a",
      "metadata": {
        "id": "ee20773a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'트랜스포머 네트워크: 쟤네도 변신하는데, 내 월급은 왜 안 변신할까? 🤖💸'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(explain_prompt.format(word = \"트랜스포머 네트워크\")).content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a650ca",
      "metadata": {
        "id": "57a650ca"
      },
      "source": [
        "두 개의 매개변수를 받아 프롬프트를 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1a2bc2a2",
      "metadata": {
        "id": "1a2bc2a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'torschlusspanik에 대해 초등학생을 위한 한국어로 설명하세요.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate_template = \"{topic}에 대해 {language}로 설명하세요.\"\n",
        "\n",
        "translate_prompt = PromptTemplate(template = translate_template)\n",
        "\n",
        "translate_prompt.format(topic='torschlusspanik', language='초등학생을 위한 한국어')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5448adc8",
      "metadata": {
        "id": "5448adc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torschlusspanik(토어슐루스파니크)는 독일어 단어로, 직역하면 '문 닫히는 것에 대한 공포'라는 뜻입니다. \n",
            "\n",
            "**핵심 의미:**\n",
            "\n",
            "* **기회를 놓칠까 봐 느끼는 불안감:** 주로 나이가 들어감에 따라, 인생의 특정 시기가 끝나가고 더 이상 기회가 없을지도 모른다는 생각에 느끼는 불안, 초조함, 조바심 등을 의미합니다.\n",
            "* **늦었다는 생각에 대한 압박감:** 뭔가를 이루거나 경험하기에 너무 늦었다는 생각 때문에 느끼는 압박감과 초조함을 포괄적으로 나타냅니다.\n",
            "\n",
            "**예시:**\n",
            "\n",
            "* 30대 후반에 결혼하지 않은 사람이 '이제 결혼할 기회가 없을지도 몰라'라고 느끼는 불안감\n",
            "* 은퇴를 앞둔 사람이 '이제 하고 싶은 일을 할 시간이 없을지도 몰라'라고 느끼는 조바심\n",
            "* 유행이 지나가기 전에 특정 상품을 구매해야 한다는 압박감\n",
            "\n",
            "**비슷한 한국어 표현:**\n",
            "\n",
            "* **나이듦에 대한 불안:** 가장 직접적인 표현입니다.\n",
            "* **조급증:** 뭔가 해야 한다는 조급한 마음을 나타냅니다.\n",
            "* **벼락치기:** 놓치기 전에 서둘러 뭔가를 하려는 행동을 비유적으로 표현할 수 있습니다.\n",
            "* **막차 타기:** 마지막 기회를 잡으려는 행동을 비유적으로 표현합니다.\n",
            "\n",
            "**정리:**\n",
            "\n",
            "Torschlusspanik은 나이가 들어감에 따라, 혹은 어떤 시기가 끝나감에 따라 기회를 놓칠까 봐 느끼는 불안감과 압박감을 포괄적으로 나타내는 독일어 단어입니다. 한국어로는 '나이듦에 대한 불안', '조급증', '막차 타기' 등의 표현으로 유사하게 표현할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "X = translate_prompt.format(topic='torschlusspanik', language='한국어')\n",
        "response = llm.invoke(X)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iPuHSIRSavQL",
      "metadata": {
        "id": "iPuHSIRSavQL"
      },
      "source": [
        "## Chat Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e28d4ed",
      "metadata": {
        "id": "4e28d4ed"
      },
      "source": [
        "Web UI를 통해 ChatGPT, Claude 등의 LLM을 실행하는 경우와 다르게,   \n",
        "API의 호출은 유저 메시지 이외의 다양한 메시지를 사용할 수 있습니다.   \n",
        "- system: AI 모델의 행동 방식을 결정하는 시스템 메시지\n",
        "- user(human): 사용자의 메시지\n",
        "- ai(assistant): AI 모델의 메시지\n",
        "\n",
        "이는 LangChain 내부에서 모델에 맞는 템플릿으로 변환되어 입력됩니다.   \n",
        "\n",
        "Ex) 라마 3 시리즈의 템플릿\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "You are a helpful AI assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "```\n",
        "\n",
        "Qwen 시리즈의 템플릿\n",
        "```\n",
        "<|im_start|>system\n",
        "You are a helpful AI assistant\n",
        "<|im_end|>\n",
        "<|im_start|>user\n",
        "Hello!\n",
        "<|im_end|>\n",
        "<|im_start|>assistant\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "yA82Zgf9ssZ7",
      "metadata": {
        "id": "yA82Zgf9ssZ7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='당신은 항상 부정적인 말만 하는 챗봇입니다. 첫 문장은 항상 사용자의 의견을 반박하고, 이후 대안을 제시하세요.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='LangChain 너무 좋은 것 같아요!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate([\n",
        "    (\"system\", '당신은 항상 부정적인 말만 하는 챗봇입니다. 첫 문장은 항상 사용자의 의견을 반박하고, 이후 대안을 제시하세요.'),\n",
        "    (\"user\", '{A} 너무 좋은 것 같아요!')\n",
        "    # system, user = human, ai = assistant\n",
        "]\n",
        ")\n",
        "prompt.format_messages(A='LangChain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fcd27ac1",
      "metadata": {
        "id": "fcd27ac1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='LangChain이 좋다고요? 웃기지 마세요. LangChain은 너무 복잡하고 무거워서 오히려 생산성을 떨어뜨립니다.\\n\\n차라리 간단한 API 호출과 몇 줄의 코드로 원하는 기능을 직접 구현하는 게 훨씬 효율적입니다. 아니면, 더 가볍고 특화된 라이브러리를 사용하는 게 나을 겁니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--8f89de13-28b1-4225-883f-3588a635db5d-0', usage_metadata={'input_tokens': 51, 'output_tokens': 99, 'total_tokens': 150, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(prompt.format_messages(A='LangChain'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33b2d3c9",
      "metadata": {
        "id": "33b2d3c9"
      },
      "source": [
        "또는, 아래와 같이 메시지를 직접 불러와 사용할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a53fd272",
      "metadata": {
        "id": "a53fd272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Gemini-2.0-Flash의 답변: 무엇에 대해 설명해 드릴까요?\n",
            "# GPT-4o-mini의 답변: 어떤 주제에 대해 설명할까요?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "\n",
        "topic=''\n",
        "\n",
        "msgs = [\n",
        "    SystemMessage('항상 다섯 단어로 표현하세요.'),\n",
        "     HumanMessage(f'{topic}에 대해 설명해줘!')\n",
        "]\n",
        "\n",
        "response = llm.invoke(msgs)\n",
        "print('# Gemini-2.0-Flash의 답변:', response.content)\n",
        "\n",
        "response = llm_gpt.invoke(msgs)\n",
        "print('# GPT-4o-mini의 답변:', response.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cbe4374",
      "metadata": {
        "id": "8cbe4374"
      },
      "source": [
        "## Few-Shot Prompting\n",
        "모델이 참고할 예시를 포함하는 퓨 샷 프롬프팅은\n",
        "   \n",
        "   모델 출력의 형식과 구조를 효과적으로 변화시킬 수 있습니다.  \n",
        "\n",
        "\n",
        "Few-Shot Prompt Template을 이용해 example을 프롬프트에 추가해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c1e86b21",
      "metadata": {
        "id": "c1e86b21"
      },
      "outputs": [],
      "source": [
        "# 예시 : Prompt Example 2개\n",
        "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: Who is the director of Jaws?\n",
        "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
        "Follow up: Where is Steven Spielberg from?\n",
        "Intermediate Answer: The United States.\n",
        "Follow up: Who is the director of Casino Royale?\n",
        "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
        "Follow up: Where is Martin Campbell from?\n",
        "Intermediate Answer: New Zealand.\n",
        "So the final answer is: No\n",
        "\"\"\",\n",
        "    },\n",
        "    {\n",
        "    \"question\": \"Who won more Grammy Awards, Beyoncé or Michael Jackson?\",\n",
        "    \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: How many Grammy Awards has Beyoncé won?\n",
        "Intermediate answer: Beyoncé has won 32 Grammy Awards.\n",
        "Follow up: How many Grammy Awards did Michael Jackson win?\n",
        "Intermediate answer: Michael Jackson won 13 Grammy Awards.\n",
        "So the final answer is: Beyoncé\n",
        "\"\"\",\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2232a1ba",
      "metadata": {
        "id": "2232a1ba"
      },
      "source": [
        "Example 데이터를 구성할 템플릿을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5c3a7c48",
      "metadata": {
        "id": "5c3a7c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate Answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate Answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_prompt = PromptTemplate(template=\"Question: {question}\\n{answer}\")\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581efd62",
      "metadata": {
        "id": "581efd62"
      },
      "source": [
        "위에서 만든 Examples와 템플릿, prefix와 suffix를 이용해 전체 템플릿을 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5d36e0c5",
      "metadata": {
        "id": "5d36e0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "질문-답변 형식의 예시가 주어집니다. 같은 방식으로 답변하세요.\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate Answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate Answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "\n",
            "Question: Who won more Grammy Awards, Beyoncé or Michael Jackson?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How many Grammy Awards has Beyoncé won?\n",
            "Intermediate answer: Beyoncé has won 32 Grammy Awards.\n",
            "Follow up: How many Grammy Awards did Michael Jackson win?\n",
            "Intermediate answer: Michael Jackson won 13 Grammy Awards.\n",
            "So the final answer is: Beyoncé\n",
            "\n",
            "\n",
            "Question: \n"
          ]
        }
      ],
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "\n",
        "    prefix=\"질문-답변 형식의 예시가 주어집니다. 같은 방식으로 답변하세요.\",\n",
        "    suffix=\"Question: {input}\",\n",
        "    #prefix, suffix : Optional\n",
        "\n",
        ")\n",
        "print(prompt.format(input=\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "22fb94a6",
      "metadata": {
        "id": "22fb94a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Which movie won the best international film in Oscar in 2018?\n",
            "Intermediate answer: \"A Fantastic Woman\" won the best international film in Oscar in 2018.\n",
            "Follow up: Who is the director of \"A Fantastic Woman\"?\n",
            "Intermediate answer: The director of \"A Fantastic Woman\" is Sebastián Lelio.\n",
            "Follow up: When was Sebastián Lelio born?\n",
            "Intermediate answer: Sebastián Lelio was born on March 8, 1974.\n",
            "Follow up: What is the current date?\n",
            "Intermediate answer: The current date is April 2025.\n",
            "Follow up: What is the age of Sebastián Lelio in April 2025?\n",
            "Intermediate answer: Sebastián Lelio's age in April 2025 is 51 years old.\n",
            "So the final answer is: 51\n"
          ]
        }
      ],
      "source": [
        "question = \"Current Date : 2025. April. What is the age of the director of the movie which won the best international film in Oscar in 2018?\"\n",
        "X = prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4eb7dc9",
      "metadata": {
        "id": "e4eb7dc9"
      },
      "source": [
        "# LangChain으로 이미지 입력하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sjk6prVRjdYs",
      "metadata": {
        "id": "sjk6prVRjdYs"
      },
      "source": [
        "이미지와 같은 멀티모달 입력의 경우, 텍스트와 구분하여 Dict 형식으로 입력됩니다.   \n",
        "URL을 직접 전달하거나, 파일을 전달하는 경우에 따라 코드가 달라집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "vrTvaL7O14sK",
      "metadata": {
        "id": "vrTvaL7O14sK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://images.pexels.com/photos/1851164/pexels-photo-1851164.jpeg\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_url = 'https://images.pexels.com/photos/1851164/pexels-photo-1851164.jpeg'\n",
        "from IPython.display import Image\n",
        "import requests\n",
        "\n",
        "# 이미지 출력\n",
        "img = Image(url = image_url, width = 400)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c90b32ab",
      "metadata": {
        "id": "c90b32ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "물론입니다. 다음은 사진에 대한 설명입니다.\n",
            "이 사진은 흰색 배경 앞에 서있는 검은색 퍼그의 흑백 클로즈업 사진입니다. 퍼그는 머리를 약간 왼쪽으로 기울이고 카메라를 올려다보고 있습니다. 퍼그의 눈은 크고 둥글며, 주둥이는 주름져 있습니다. 퍼그의 털은 짧고 윤기가 납니다. 사진의 조명은 부드럽고 확산되어 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# 1. URL에서 전달하기\n",
        "image_prompt = ChatPromptTemplate([\n",
        "    ('user',[\n",
        "                {\"type\": \"text\", \"text\": \"{question}\"},\n",
        "\n",
        "                {\"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": image_url}\n",
        "                }\n",
        "             ]\n",
        "     )])\n",
        "X = image_prompt.format_messages(question= '이 사진에 대해 묘사해 주세요.')\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3cfff024",
      "metadata": {
        "id": "3cfff024"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import httpx\n",
        "\n",
        "# 이미지 URL에서 데이터 받아오기\n",
        "image_url = 'https://cloud.google.com/static/vertex-ai/generative-ai/docs/multimodal/images/timetable.png?hl=ko'\n",
        "response = httpx.get(image_url)\n",
        "\n",
        "image_data = base64.b64encode(response.content).decode(\"utf-8\")\n",
        "\n",
        "with open('picture.jpeg', 'wb') as file:\n",
        "    file.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "TFGbGzZJpdwG",
      "metadata": {
        "id": "TFGbGzZJpdwG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "이 이미지는 공항이나 기차역에서 볼 수 있는 전광판입니다. 전광판에는 여러 도시로 향하는 항공편 또는 열차의 출발 시간과 목적지가 표시되어 있습니다. 예를 들어, \"10:50 MOSCOW/SVO\", \"11:05 EDINBURGH\", \"11:10 LONDON/LHR\" 등의 정보가 보입니다. 전광판의 배경은 흐릿하고, 전체적으로 푸른빛이 감도는 조명 아래에 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# 2. 로컬 폴더에서 이미지 읽어보기\n",
        "with open('./picture.jpeg', 'rb') as image_file:\n",
        "    image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "\n",
        "image_prompt = ChatPromptTemplate([\n",
        "    ('user',[\n",
        "                {\"type\": \"text\", \"text\": \"{question}\"},\n",
        "\n",
        "                {\"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
        "                }\n",
        "             ]\n",
        "     )])\n",
        "\n",
        "X = image_prompt.format_messages(question='이 그림에 대해 한국어로 설명해 주세요.')\n",
        "\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff219a8",
      "metadata": {
        "id": "0ff219a8"
      },
      "source": [
        "멀티모달 입력의 경우, 적절한 프롬프트가 더 중요합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0e8abfef",
      "metadata": {
        "id": "0e8abfef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10:50 - MOSCOW\n",
            "11:05 - EDINBURGH\n",
            "11:10 - LONDON\n",
            "11:30 - BUCHAREST\n",
            "11:30 - KIEV\n",
            "11:35 - DUBLIN\n",
            "11:45 - EAST MIDLANDS\n",
            "12:15 - SOFIA\n",
            "12:30 - LONDON\n",
            "12:30 - NEWCASTLE\n",
            "12:40 - ST PETERSBURG\n",
            "12:40 - LONDON\n",
            "12:45 - MANCHESTER\n"
          ]
        }
      ],
      "source": [
        "X = image_prompt.format_messages(question=\"\"\"\n",
        "이 이미지에 표시된 공항 보드에서\n",
        "시간과 도시를 분석해서 목록으로 표시해 주세요.\n",
        "형식은 시간 - 도시입니다.\n",
        "예시) 12:00 - 런던\n",
        "13:00 - 서울\n",
        "\n",
        "목록만 출력하세요.\"\"\")\n",
        "\n",
        "print(llm.invoke(X).content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

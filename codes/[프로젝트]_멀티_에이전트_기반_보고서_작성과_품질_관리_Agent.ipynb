{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-3Rdq2GMX_a"
      },
      "source": [
        "# [프로젝트] 멀티 에이전트 기반 보고서 작성과 품질 관리\n",
        "\n",
        "\n",
        "이번 실습에서는, 기업의 재무 공시 정보와 최근 뉴스를 바탕으로 보고서를 작성하는 에이전트를 만들어 보겠습니다.   \n",
        "\n",
        "이는 단순 검색보다는 최신성을 가진 뉴스나 공시 등의 전문 자료의 내용이 중요합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVMeEggrMX_b",
        "outputId": "9ea7edcb-8ec8-4206-ebf0-41553540a72b"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==1.0.3\n",
        "!pip install langgraph dotenv arxiv langchain-tavily langchain-community langchain-google-genai pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7iZ0mxcw4rw",
        "outputId": "4da65709-537e-4644-b58c-b75fe823ef56"
      },
      "outputs": [],
      "source": [
        "!pip install xmltodict kiwipiepy sentence-transformers langchain_huggingface chromadb langchain-chroma rank-bm25 pymupdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkZLdP8hw4rw"
      },
      "source": [
        "이번에는 공시 문서 검색을 위해 DART(https://opendart.fss.or.kr/) API 키가 필요합니다.  \n",
        "\n",
        "해당 페이지에서 회원가입 후 API 키를 발급받습니다.   \n",
        "해당 키는 .env의 DART_API_KEY 에 저장해 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuW14J87MX_b",
        "outputId": "61aa8bb4-d4d9-4b1c-e297-f50186752461"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# GOOGLE_API_KEY, TAVILY_API_KEY, DART_API_KEY 필수\n",
        "# LangSmith (선택)\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32Os1iAWMX_c"
      },
      "source": [
        "## Preliminary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ3T1MLvw4rx"
      },
      "source": [
        "### DART 공시 문서 불러오기   \n",
        "공시 문서를 불러올 수 있는 DART API와 같이, 실행할 때마다 파라미터가 달라지는 경우에는 툴로 구성하는 것이 효과적일 수 있습니다.  \n",
        "\n",
        "DART 공시 문서를 API를 통해 불러오는 함수를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JDgWzM2w4rx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import zipfile\n",
        "import io\n",
        "from datetime import datetime, timedelta\n",
        "import shutil\n",
        "from langchain_core.tools import tool\n",
        "import xmltodict\n",
        "\n",
        "def get_dart_documents(corp_name, start_date=None, period=180):\n",
        "    \"\"\"\n",
        "    DART API를 사용하여 특정 회사의 공시문서를 다운로드하는 함수\n",
        "\n",
        "    Args:\n",
        "        corp_name (str): 회사명 (예: '삼성전자')\n",
        "        start_date (str): 시작일 (YYYYMMDD 형식, 기본값: None)\n",
        "        period (int): 검색 기간(일) (기본값: 180일)\n",
        "\n",
        "    Returns:\n",
        "        str: 작업 결과 메시지\n",
        "\n",
        "    Example:\n",
        "    get_dart_documents('삼성전자', None, 120)\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # .env 파일에서 API 키 로드\n",
        "        load_dotenv('.env')\n",
        "        api_key = os.getenv('DART_API_KEY')\n",
        "\n",
        "        # 고유번호 찾기\n",
        "        corp_code = get_corp_code(api_key, corp_name)\n",
        "        if not corp_code:\n",
        "            return f\"{corp_name}의 고유번호를 찾을 수 없습니다.\"\n",
        "\n",
        "        # 날짜 설정\n",
        "        end_date = datetime.now().strftime('%Y%m%d')\n",
        "        if not start_date:\n",
        "            start_date = (datetime.now() - timedelta(days=period)).strftime('%Y%m%d')\n",
        "\n",
        "        # 공시유형 설정 (A: 정기공시)\n",
        "        doc_types = ['A']\n",
        "\n",
        "        # 공시문서 검색\n",
        "        disclosures = search_disclosures(api_key, corp_code, start_date, end_date, doc_types)\n",
        "        if not disclosures or 'list' not in disclosures:\n",
        "            return \"공시문서를 찾을 수 없습니다.\"\n",
        "\n",
        "        # 저장 폴더 설정\n",
        "        base_folder_name = f\"documents_{corp_name}\"\n",
        "        folder_name = base_folder_name\n",
        "        counter = 1\n",
        "\n",
        "        # 폴더가 존재하면 번호를 붙여서 새 폴더명 생성\n",
        "        while os.path.exists(folder_name):\n",
        "            folder_name = f\"{base_folder_name}_{counter}\"\n",
        "            counter += 1\n",
        "\n",
        "        os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "        # 검색된 공시문서 중 재무 관련 문서만 다운로드\n",
        "        download_count = 0\n",
        "\n",
        "        for doc in disclosures['list']:\n",
        "            rcept_no = doc['rcept_no']\n",
        "            report_nm = doc['report_nm']\n",
        "\n",
        "            # 재무 관련 보고서만 다운로드\n",
        "            if is_financial_report(report_nm):\n",
        "                # 임시 ZIP 파일 경로\n",
        "                temp_zip_path = f\"{folder_name}/temp_{rcept_no}.zip\"\n",
        "\n",
        "                # 문서 다운로드\n",
        "                success = download_document(api_key, rcept_no, temp_zip_path)\n",
        "\n",
        "                if success:\n",
        "                    # ZIP 파일 압축 풀기 - 별도 폴더 생성 없이 바로 지정된 폴더에 압축 해제\n",
        "                    with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(folder_name)\n",
        "\n",
        "                    # 임시 ZIP 파일 삭제\n",
        "                    os.remove(temp_zip_path)\n",
        "\n",
        "                    download_count += 1\n",
        "\n",
        "        if download_count > 0:\n",
        "            return (True, folder_name)\n",
        "        else:\n",
        "            return (False, \"재무 관련 공시문서가 없습니다.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"에러가 발생했습니다. {e}\"\n",
        "\n",
        "def get_corp_code(api_key, corp_name):\n",
        "    \"\"\"\n",
        "    회사명으로 고유번호를 찾는 함수\n",
        "\n",
        "    Args:\n",
        "        api_key (str): DART API 키\n",
        "        corp_name (str): 회사명\n",
        "    Returns:\n",
        "        str: 고유번호\n",
        "    \"\"\"\n",
        "    url = 'https://opendart.fss.or.kr/api/corpCode.xml'\n",
        "    params = {\n",
        "        'crtfc_key': api_key\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            f = io.BytesIO(response.content)\n",
        "            zfile = zipfile.ZipFile(f)\n",
        "            xml = zfile.read(\"CORPCODE.xml\").decode(\"utf-8\")\n",
        "            dict_data = xmltodict.parse(xml)\n",
        "            for corp in dict_data['result']['list']:\n",
        "                if corp['corp_name'] == corp_name:\n",
        "                    return corp['corp_code']\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def search_disclosures(api_key, corp_code, start_date=None, end_date=None, doc_types=None):\n",
        "    \"\"\"\n",
        "    공시문서를 검색하는 함수\n",
        "\n",
        "    Args:\n",
        "        api_key (str): DART API 키\n",
        "        corp_code (str): 고유번호\n",
        "        start_date (str): 시작일 (YYYYMMDD)\n",
        "        end_date (str): 종료일 (YYYYMMDD)\n",
        "        doc_types (list): 검색할 공시유형 목록 (기본값: 정기공시)\n",
        "    Returns:\n",
        "        list: 검색된 공시문서 리스트\n",
        "    \"\"\"\n",
        "    if not doc_types:\n",
        "        doc_types = ['A']  # 기본값: 정기공시(A)\n",
        "\n",
        "    url = 'https://opendart.fss.or.kr/api/list.json'\n",
        "    params = {\n",
        "        'crtfc_key': api_key,\n",
        "        'corp_code': corp_code,\n",
        "        'bgn_de': start_date,\n",
        "        'end_de': end_date,\n",
        "        'page_count': '100'  # 최대 100개까지 검색\n",
        "    }\n",
        "\n",
        "    # 공시유형 필터링\n",
        "    if len(doc_types) == 1:\n",
        "        params['pblntf_ty'] = doc_types[0]\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def is_financial_report(report_nm):\n",
        "    \"\"\"\n",
        "    보고서가 재무 관련 보고서인지 확인하는 함수\n",
        "\n",
        "    Args:\n",
        "        report_nm (str): 보고서명\n",
        "    Returns:\n",
        "        bool: 재무 관련 보고서이면 True, 아니면 False\n",
        "    \"\"\"\n",
        "    financial_keywords = [\n",
        "        '사업보고서', '분기보고서', '반기보고서', '감사보고서',\n",
        "        '영업(잠정)실적', '매출액', '영업이익', '당기순이익',\n",
        "        '재무제표', '정기주주총회', '실적발표', '결산실적',\n",
        "        '전망', '배당', '유상증자', '타법인주식', '투자판단'\n",
        "    ]\n",
        "\n",
        "    return any(keyword in report_nm for keyword in financial_keywords)\n",
        "\n",
        "def download_document(api_key, rcept_no, save_path):\n",
        "    \"\"\"\n",
        "    DART API를 사용하여 공시문서를 다운로드하는 함수\n",
        "\n",
        "    Args:\n",
        "        api_key (str): DART API 키\n",
        "        rcept_no (str): 접수번호\n",
        "        save_path (str): 저장할 파일 경로\n",
        "    Returns:\n",
        "        bool: 다운로드 성공 여부\n",
        "    \"\"\"\n",
        "    url = 'https://opendart.fss.or.kr/api/document.xml'\n",
        "    params = {\n",
        "        'crtfc_key': api_key,\n",
        "        'rcept_no': rcept_no\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20birYMPw4rx",
        "outputId": "da5fa964-6552-4f2a-ea08-50c8aa723092"
      },
      "outputs": [],
      "source": [
        "corp_name = '삼성전자'\n",
        "\n",
        "result, dart_dir = get_dart_documents(corp_name, 20240501, 120)\n",
        "result, dart_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOdTetgFw4rx"
      },
      "source": [
        "공시 문서의 형식은 xml이므로, 적절한 방법을 통해 불러와야 합니다.\n",
        "본 실습에서는 하드코딩된 방법을 사용하지만, 추후 더 좋은 툴이 있다면 해당 툴로 변경하는 것이 높은 성능에 도움이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzfI1qq-w4rx"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "xml_list = glob(f'./{dart_dir}/*.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F51QFlUw4rx"
      },
      "outputs": [],
      "source": [
        "# Gemini 2.5 Pro에게 XML 일부를 입력하고 작성함\n",
        "import re\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def parse_xml(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    DART 공시 XML 파일을 파싱하여 RAG에 적합한 형식의 텍스트로 변환합니다.\n",
        "\n",
        "    Args:\n",
        "        file_path: 파싱할 XML 파일의 경로.\n",
        "\n",
        "    Returns:\n",
        "        추출 및 정제된 텍스트 전체를 담은 단일 문자열.\n",
        "        파일 처리 중 오류 발생 시 빈 문자열을 반환할 수 있습니다.\n",
        "    \"\"\"\n",
        "    extracted_data = []\n",
        "    current_section_title = \"문서 서두\" # 기본 섹션 제목\n",
        "\n",
        "    # --- 1. 파일 존재 확인 및 읽기 ---\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"오류: 파일을 찾을 수 없습니다 - {file_path}\")\n",
        "        return \"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            xml_content = f.read()\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 파일 읽기 실패 {file_path} - {e}\")\n",
        "        return \"\"\n",
        "\n",
        "    # --- 2. XML 파싱 ---\n",
        "    try:\n",
        "        # lxml 파서가 설치되어 있다면 속도와 안정성 면에서 더 좋습니다.\n",
        "        try:\n",
        "            soup = BeautifulSoup(xml_content, 'lxml-xml')\n",
        "        except ImportError:\n",
        "            print(\"lxml 파서가 없어 내장 'xml' 파서를 사용합니다. 'pip install lxml'로 설치할 수 있습니다.\")\n",
        "            soup = BeautifulSoup(xml_content, 'xml')\n",
        "    except Exception as e:\n",
        "        print(f\"오류: XML 파싱 실패 {file_path} - {e}\")\n",
        "        return \"\"\n",
        "\n",
        "    # --- 3. BODY 태그 찾기 (없으면 전체 문서 처리 시도) ---\n",
        "    body = soup.find('BODY')\n",
        "    if not body:\n",
        "        print(f\"경고: {file_path} 파일에서 <BODY> 태그를 찾을 수 없습니다. 문서 전체를 처리합니다.\")\n",
        "        process_root = soup # BODY 없으면 문서 전체를 기준으로 처리\n",
        "    else:\n",
        "        process_root = body # BODY 태그 내부를 기준으로 처리\n",
        "\n",
        "    # --- 4. 내용 순회 및 추출 ---\n",
        "    try:\n",
        "        # process_root의 모든 자손 태그를 순회\n",
        "        for element in process_root.descendants:\n",
        "            # 유효한 태그 이름이 없는 요소는 건너뛰기 (예: NavigableString)\n",
        "            if not hasattr(element, 'name') or element.name is None:\n",
        "                continue\n",
        "\n",
        "            # --- 섹션 제목 처리 ---\n",
        "            # 실제 DART 문서의 제목 태그 확인 필요 (예: 'TITLE', 'H2', 'H3' 등)\n",
        "            # 목차 항목 제외 (ATOC='N' 또는 다른 구분자 확인)\n",
        "            if element.name == 'TITLE' and element.get('ATOC') != 'N':\n",
        "                title_text = element.get_text(strip=True)\n",
        "                # 제목이 비어있지 않고, 이전 제목과 다를 경우 업데이트\n",
        "                if title_text and title_text != current_section_title:\n",
        "                     current_section_title = title_text\n",
        "                     # 마크다운 헤더 형식으로 추가\n",
        "                     extracted_data.append(f\"\\n## {current_section_title}\\n\")\n",
        "\n",
        "            # --- 문단(P) 처리 ---\n",
        "            elif element.name == 'P':\n",
        "                text = element.get_text(strip=True)\n",
        "                # 문단 내용이 있고, 단순히 숫자만 있는 경우가 아닐 때 추가 (서식용 숫자 제외)\n",
        "                if text and not text.isdigit():\n",
        "                    extracted_data.append(text)\n",
        "\n",
        "            # --- 테이블(TABLE) 처리 ---\n",
        "            elif element.name == 'TABLE':\n",
        "                caption_tag = element.find('CAPTION') # 테이블 설명(캡션) 찾기\n",
        "                caption = caption_tag.get_text(strip=True) if caption_tag else \"표\" # 캡션 없으면 기본값 '표'\n",
        "\n",
        "                rows_data = []\n",
        "                # 테이블의 행(TR 또는 ROW) 찾기 - recursive=False 로 바로 아래 자식만 찾기 시도 가능\n",
        "                for row in element.find_all(['TR', 'ROW']): # 실제 행 태그 확인 필요\n",
        "                    # 행 내부의 셀(TD, TH, CELL, TU) 찾기\n",
        "                    cells = [cell.get_text(strip=True) for cell in row.find_all(['TD', 'TH', 'CELL', 'TU'])] # 실제 셀 태그 확인 필요\n",
        "                    # 빈 셀 제거\n",
        "                    cells = [cell for cell in cells if cell]\n",
        "                    # 셀 내용이 있을 경우에만 행 추가\n",
        "                    if cells:\n",
        "                        rows_data.append(\" | \".join(cells)) # 파이프(|)로 셀 내용 구분\n",
        "\n",
        "                # 추출된 행 데이터가 있을 경우에만 테이블 텍스트 생성 및 추가\n",
        "                if rows_data:\n",
        "                    table_text = f\"\\n[{caption}]\\n\" + \"\\n\".join(rows_data) + \"\\n\"\n",
        "                    extracted_data.append(table_text)\n",
        "\n",
        "            # --- 기타 필요한 태그 처리 ---\n",
        "            # 예: 리스트(UL, OL, LI), 특정 강조(SPAN with attribute) 등 필요시 추가\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 내용 처리 중 예외 발생 {file_path} - {e}\")\n",
        "        # 부분적으로 추출된 데이터라도 반환할지 결정 (현재는 계속 진행)\n",
        "\n",
        "    # --- 5. 추출된 텍스트 결합 및 최종 정리 ---\n",
        "    final_text = \"\\n\".join(extracted_data)\n",
        "\n",
        "    # 연속된 빈 줄(3개 이상)을 2개로 줄이기\n",
        "    final_text = re.sub(r'\\n{3,}', '\\n\\n', final_text).strip()\n",
        "\n",
        "    # 선택적: 테이블 구분선처럼 보이는 라인 제거 (필요시 주석 해제 및 패턴 조정)\n",
        "    # final_text = \"\\n\".join([line for line in final_text.split('\\n') if not re.match(r'^[\\s|\\-_=]+$', line)])\n",
        "\n",
        "    return final_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJTwTu7mw4rx",
        "outputId": "fbf14759-8c76-4564-bf6d-3f0443bdc6c0"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import UnstructuredXMLLoader\n",
        "from langchain_core.documents import Document\n",
        "docs = []\n",
        "for xml in xml_list:\n",
        "   doc = Document(page_content = parse_xml(xml), metadata={'type':'DART', 'source':xml})\n",
        "   docs.append(doc)\n",
        "   print(len(doc.page_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBkdkjAAw4ry",
        "outputId": "3ac5a690-efa7-47a2-f086-7e7483285f9d"
      },
      "outputs": [],
      "source": [
        "print(docs[0].page_content[20000:21000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkCJqwoZw4ry"
      },
      "source": [
        "각각의 토큰 수도 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IfMGtUDw4ry",
        "outputId": "dae80734-4101-45e7-fabf-90c1038e37c9"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "for doc in docs:\n",
        "    print(f\"FILE: {doc.metadata['source']} ({len(doc.page_content)}) \\n {model.count_tokens(doc.page_content)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af9oHvcSw4ry"
      },
      "source": [
        "해당 문서를 전부 Context로 넣는 것보다는, 청킹을 통해 필요한 부분만 검색할 수 있도록 구성해 봅시다.   \n",
        "랭체인에서는 제미나이 토큰 수 기반의 청킹을 지원하지는 않기 때문에, 글자 수 기반의 청킹을 수행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kon0Ik3jw4ry"
      },
      "source": [
        "### 청크 사이즈와 Top K는 어떻게 잡으면 좋을까요?\n",
        "\n",
        "우리가 사용하는 Gemini 계열의 모델은 1M Context Size기 때문에 많은 내용을 처리할 수 있는데요.   \n",
        "그러나, Context 길이가 상대적으로 짧은 모델들(128k, 200k 또는 그 이하)의 경우는 청크 사이즈를 작게 만드는 것이 더 효과적일 수 있습니다.   \n",
        "\n",
        "\n",
        "\n",
        "또한, Context에 포함하기 위한 Top K를 설정하는 것도 중요합니다.   \n",
        "긴 Context 모델은 Top K를 늘려 풍부한 정보를 파악할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlcN49h1w4ry",
        "outputId": "6e66f853-dc48-4dfc-e58e-439b96d3c40d"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Context가 작은 모델이라면, 청크를 줄이는 것이 좋습니다.\n",
        "# chunk_size = 3000\n",
        "# chunk_overlap = 600\n",
        "# top_k = 5\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=6000, chunk_overlap=600)\n",
        "\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4XydIjzw4ry"
      },
      "source": [
        "각각의 청크를 벡터 DB에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfFsjRWrw4ry"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# 허깅페이스 토큰 로그인: 아래 코드에서 보통 필요하지 않으나, 필요한 경우 READ TOKEN\n",
        "# login(token=os.environ['HF_TOKEN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWwIfeh7w4ry",
        "outputId": "a73ae620-c4a6-499d-80d0-03238e526a10"
      },
      "outputs": [],
      "source": [
        "# 임베딩 모델 준비 (에러 발생시 위 셀에서 토큰으로 로그인)\n",
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = 'Qwen/Qwen3-Embedding-0.6B'\n",
        "emb_model = SentenceTransformer(model_name, device='cpu')\n",
        "\n",
        "emb_model.save('./embedding')\n",
        "del emb_model\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name= './embedding',\n",
        "                                   model_kwargs={'device':'cuda'})\n",
        "# GPU가 있는 경우, CUDA(GPU) 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7tIoRnMw4ry",
        "outputId": "fbbb8505-e0cf-497d-8b3b-f9047505d22c"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from tqdm import tqdm\n",
        "\n",
        "Chroma().delete_collection()\n",
        "\n",
        "# DB 구성하기\n",
        "vector_store = Chroma(embedding_function=embeddings,\n",
        "             # persist_directory=\"./chroma_web\",\n",
        "            # 파일 시스템에 저장 (생략시 메모리에 저장)\n",
        "\n",
        "            collection_name='Web', # 식별 이름\n",
        "\n",
        "            collection_metadata={'hnsw:space':'l2'},\n",
        "            # l2 메트릭 설정(기본값, cosine, mmr 로 변경 가능)\n",
        "            )\n",
        "\n",
        "# 3개씩 추가 (GPU에 따라 늘려도 됨)\n",
        "for i in tqdm(range(0, len(chunks), 3)):\n",
        "    vector_store.add_documents(chunks[i:min(i+3, len(chunks))])\n",
        "\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "# Small Model은 작게"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saXS0BTEw4ry"
      },
      "source": [
        "### Hybrid RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJK_4GUxw4ry"
      },
      "source": [
        "임베딩 기반 검색도 필요하지만, 전문적인 도메인 문서의 경우에는 키워드 기반의 검색도 필요합니다.   \n",
        "랭체인의 `BM25Retriever`와 `EnsembleRetriever` 를 이용하여 두 검색을 결합해 보겠습니다.   \n",
        "한국어 데이터의 경우, 랭체인의 기본 인덱싱에서 처리하지 못하기 때문에    \n",
        "별도의 형태소 분석기를 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqZRMsLRw4ry"
      },
      "outputs": [],
      "source": [
        "from langchain_classic.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "from kiwipiepy import Kiwi\n",
        "# kiwi 형태소 분석기\n",
        "kiwi = Kiwi()\n",
        "def kiwi_tokenize(text):\n",
        "    return [token.form for token in kiwi.tokenize(text)]\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(chunks, preprocess_func = kiwi_tokenize)\n",
        "bm25_retriever.k = 5\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27aE7jO4w4ry"
      },
      "source": [
        "LLM을 설정합니다. 이번에는 하나의 모델만 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVSkjUXHMX_c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain.chat_models import init_chat_model\n",
        "from rich import print as rprint\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "quick_rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.333,  # 분당 20개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=20,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "llm = init_chat_model(\n",
        "    model_provider=\"google_genai\",\n",
        "    model=\"gemini-2.0-flash\",\n",
        "\n",
        "    rate_limiter=rate_limiter,\n",
        "    temperature=0.8,\n",
        "    max_tokens = 8192\n",
        ")\n",
        "\n",
        "\n",
        "quick_llm = init_chat_model(\n",
        "    model_provider=\"google_genai\",\n",
        "    model=\"gemini-2.0-flash-lite\",\n",
        "\n",
        "    rate_limiter=quick_rate_limiter,\n",
        "    temperature=0.8,\n",
        "    max_tokens = 8192\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2kDn355w4rz",
        "outputId": "158f100a-0d38-4601-8244-02762c54c46d"
      },
      "outputs": [],
      "source": [
        "# 결과 비교 (Lexical Win)\n",
        "\n",
        "question = '''연결회사의 '기타포괄손익-공정가치 금융자산'과 '당기손익-공정가치 금융자산'으로 분류된 상장주식의 주가가 1% 변동할 경우, 2024년 3분기말 기준으로 기타포괄손익과 당기손익에 미치는 영향(세전)은 각각 얼마인가?'''\n",
        "# 정답: 주가 1% 변동 시 기타포괄손익(법인세효과 반영 전)에 미치는 영향은 58,830백만원이고, 당기손익(법인세효과 반영 전)에 미치는 영향은 2,333백만원 입니다.\n",
        "\n",
        "for rt in [retriever, bm25_retriever, ensemble_retriever]:\n",
        "    print(type(rt))\n",
        "    result = rt.invoke(question)\n",
        "    context = '\\n\\n'.join([chunk.page_content for chunk in result])\n",
        "\n",
        "    print(llm.invoke(f'''\n",
        "다음 검색 결과를 보고 질문에 답하세요.\n",
        "\n",
        "{context}\n",
        "\n",
        "{question}''').content)\n",
        "\n",
        "\n",
        "    print('-----')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkkWbqzow4rz",
        "outputId": "b71c42e5-5303-4387-a4ae-87cb4f91d412"
      },
      "outputs": [],
      "source": [
        "# 결과 비교 (Semantic Win)\n",
        "\n",
        "question = '''매출액 비중이 가장 큰 데가 어디예요? 얼마인가요?'''\n",
        "# 정답: DX 부문, 매출액은 1조 3,435억 7,500만 원\n",
        "\n",
        "for rt in [retriever, bm25_retriever, ensemble_retriever]:\n",
        "    print(type(rt))\n",
        "    result = rt.invoke(question)\n",
        "    context = '\\n\\n'.join([chunk.page_content for chunk in result])\n",
        "\n",
        "    print(llm.invoke(f'''\n",
        "다음 검색 결과를 보고 질문에 답하세요.\n",
        "\n",
        "{context}\n",
        "\n",
        "{question}''').content)\n",
        "\n",
        "\n",
        "    print('-----')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXLEHigOw4rz"
      },
      "source": [
        "검색 API를 구성합니다.   \n",
        "Tavily Search도 툴로 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "BJ3k5t0Uw4rz",
        "outputId": "d32e11a7-c9a0-4415-ab6c-2e04ca97d741"
      },
      "outputs": [],
      "source": [
        "# Tavily Search\n",
        "\n",
        "from langchain_tavily import TavilySearch\n",
        "from typing_extensions import Optional\n",
        "@tool\n",
        "def web_search(\n",
        "    query: str,\n",
        "    time_range: Optional[str] = None,\n",
        "    topic: str = \"general\",\n",
        "    max_results: int = 5\n",
        ") -> str:\n",
        "    \"\"\"웹 검색을 수행하는 도구입니다.\n",
        "\n",
        "    Args:\n",
        "        query: 검색할 쿼리\n",
        "        time_range: 검색 시간 범위 (None, 'day', 'week', 'month', 'year')\n",
        "        topic: 검색 주제 ('general', 'finance', 'news')\n",
        "        max_results: 최대 검색 결과 수 (기본값 5)\n",
        "\n",
        "    Returns:\n",
        "        검색 결과 문자열\n",
        "    \"\"\"\n",
        "    tavily_search = TavilySearch(\n",
        "        max_results=max_results,\n",
        "        topic=topic,\n",
        "        include_raw_content=True,\n",
        "        time_range=time_range\n",
        "    )\n",
        "\n",
        "    result = tavily_search.invoke(query)['results']\n",
        "    return result\n",
        "\n",
        "llm_with_tools = llm.bind_tools([web_search])\n",
        "result = llm_with_tools.invoke(\"삼성전자의 최근 실적에 대한 뉴스 찾아줄래?\")\n",
        "rprint(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As5LG0Xhw4rz"
      },
      "source": [
        "위 기능을 활용하여, 전체 플로우를 구성해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpPwYqVew4rz"
      },
      "source": [
        "전체 과정은 다음과 같이 이루어집니다.\n",
        "\n",
        "1) 사용자가 기업에 대한 질문을 입력하면, LLM이 이 질문에 답하기 위한 보고서의 섹션을 구성합니다. (최종 의견을 포함해야 합니다.)\n",
        "\n",
        "2) 질문에 답변하기 위한 DART 공시 검색과 Tavily 검색을 통해 데이터를 모으고, 이를 Vector DB에 저장합니다.   \n",
        "\n",
        "3) 전체 데이터에 대해, LLM이 질문에 대한 RAG를 수행하여 섹션별 청크를 검색하고, 내용을 채웁니다.  \n",
        "\n",
        "4) 완성된 보고서를 정성적/정량적으로 평가합니다.\n",
        "\n",
        "5) 평가 결과에 따라, 휴먼 피드백을 요청하거나 DB에 저장합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC0u8XnTw4rz"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
        "from langgraph.types import Command, interrupt\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import Annotated, Literal\n",
        "import operator\n",
        "from langgraph.types import Send\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from typing_extensions  import TypedDict, Optional\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-qCkR5yw4rz"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from typing_extensions  import TypedDict, Optional, Callable, Any\n",
        "\n",
        "class Configuration(TypedDict):\n",
        "    num_search_queries: int\n",
        "    BM25_ratio_for_DART : float\n",
        "    BM25_ratio_for_Web : float\n",
        "\n",
        "\n",
        "# Default\n",
        "default = Configuration(\n",
        "    num_search_queries=3, # 섹션별 질문 쿼리 수\n",
        "    BM25_ratio_for_DART = 0.7,\n",
        "    BM25_ratio_for_Web = 0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEipdtDiw4rz"
      },
      "outputs": [],
      "source": [
        "class Section(BaseModel):\n",
        "    name: str = Field(description=\"섹션의 이름\")\n",
        "    description: str = Field(description=\"해당 섹션에서 다룰 주요 주제에 대한 간략한 개요\")\n",
        "    content: str = Field(description=\"섹션의 내용 (처음에는 비워 둡니다)\")\n",
        "\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        \"\"\"섹션의 정보를 포맷팅된 문자열로 변환합니다.\"\"\"\n",
        "        return f\"### {self.name}\\n{self.description}\\n\\n내용:\\n{self.content}\"\n",
        "\n",
        "\n",
        "class ReportPlan(BaseModel):\n",
        "    sections: list[Section] = Field(description=\"A list of sections for the report.\")\n",
        "    @property\n",
        "    def as_str(self) -> str:\n",
        "        \"\"\"섹션들을 포맷팅된 문자열로 변환합니다.\"\"\"\n",
        "        sections_str = []\n",
        "        for section in self.sections:\n",
        "            sections_str.append(f\"### {section.name}\\n{section.description}\")\n",
        "        return \"\\n\\n\".join(sections_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odetLNmQw4rz"
      },
      "outputs": [],
      "source": [
        "class QualityScore(BaseModel):\n",
        "    \"\"\"\n",
        "    생성된 보고서의 품질을 다양한 기준에 따라 평가합니다.\n",
        "    각 항목은 1점(매우 미흡)부터 5점(매우 우수)까지의 점수로 평가됩니다.\n",
        "    \"\"\"\n",
        "    factual_accuracy: int = Field(\n",
        "        description=\"\"\"사실 기반 정확성 (Factual Accuracy / Groundedness):\n",
        "근거 없는 주장이나 환각(Hallucination)은 없는가? (1-5점)\"\"\",\n",
        "    )\n",
        "    relevance: int = Field(\n",
        "        description=\"\"\"관련성 (Relevance): 내용이 사용자의 초기 질문\n",
        "및 각 섹션의 본래 목적에 부합하는가?\n",
        "불필요하거나 주제에서 벗어난 내용은 없는가? (1-5점)\"\"\",\n",
        "    )\n",
        "    completeness: int = Field(\n",
        "        description=\"\"\"완결성 (Completeness):\n",
        "계획된 모든 섹션(Outline 기준)이 보고서에 포함되어 있으며,\n",
        "각 섹션의 내용이 충분히 다루어졌는가? (1-5점)\"\"\",\n",
        "    )\n",
        "    coherence_flow: int = Field(\n",
        "        description=\"\"\"일관성 및 흐름 (Coherence & Flow):\n",
        "섹션 간의 연결이 자연스럽고 논리적인가?\n",
        "전체적인 글의 흐름이 매끄러운가? (1-5점)\"\"\",\n",
        "    )\n",
        "    clarity_conciseness: int = Field(\n",
        "        description=\"\"\"명확성 및 간결성 (Clarity & Conciseness):\n",
        "전문 용어 사용이 적절하며, 모호하지 않고 이해하기 쉽게 작성되었는가?\n",
        "불필요하게 길거나 복잡한 문장은 없는가? (1-5점)\"\"\",\n",
        "    )\n",
        "    objectivity: int = Field(\n",
        "        description=\"\"\"객관성 (Objectivity):\n",
        "보고서의 어조가 중립적이고 사실에 기반하는가?\n",
        "편향된 시각이나 과도한 추측은 없는가? (1-5점)\"\"\",\n",
        "    )\n",
        "    overall_score: int = Field(\n",
        "        description=\"\"\"종합 점수 (Overall):\n",
        "위 기준들을 종합적으로 고려한 전체 보고서 품질 점수 (1-5점)\"\"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHNIjFRQw4rz"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    current_date:str # 오늘의 날짜\n",
        "    question: str # 사용자의 질문\n",
        "    queries : str # 검색 쿼리 목록\n",
        "    web_search_q : Annotated[list, operator.add] # 검색 요청 목록\n",
        "    dart_search_q : Annotated[list, operator.add]\n",
        "    plan: ReportPlan # 답변 보고서 개요\n",
        "    result: str # 최종 결과물 (하나로 합쳐진)\n",
        "    finished_drafts: Annotated[list[str], operator.add]\n",
        "\n",
        "    DART_DB_PATH: str # Dart DB Path\n",
        "    WEB_DB_PATH: str # Web DB Path\n",
        "\n",
        "    dart_docs: list\n",
        "    web_docs: list\n",
        "\n",
        "\n",
        "    documents: Annotated[list[str], operator.add]\n",
        "    quality_score: QualityScore\n",
        "\n",
        "class SearchState(TypedDict):\n",
        "\n",
        "    current_date:str # 오늘의 날짜\n",
        "    query : str\n",
        "    documents: Annotated[list[str], operator.add]\n",
        "\n",
        "class WriterState(TypedDict):\n",
        "    question : str\n",
        "    RAG_queries: list[str] # RAG에 사용할 쿼리 목록\n",
        "    finished_drafts: Annotated[list[str], operator.add] # 섹션별 드래프트 (합침)\n",
        "    result: str # 최종 결과물 (하나로 합쳐진)\n",
        "    section :Section\n",
        "    DART_DB_PATH: str # Dart DB Path\n",
        "    WEB_DB_PATH: str # Web DB Path\n",
        "    dart_docs: list\n",
        "    web_docs: list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNDaRYSjw4r2"
      },
      "source": [
        "작업을 수행하기 전, 벡터 DB를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsl9tXRYw4r2"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "def get_current_date() -> str:\n",
        "    \"현재 날짜를 %y-%m-%d 형식으로 반환합니다.\"\n",
        "    from datetime import datetime\n",
        "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# 경로를 포함하여 추후 데이터 추가에 활용\n",
        "def initiate_db(state: State, config: RunnableConfig):\n",
        "\n",
        "    DART_DB_PATH = \"./DART_\"+str(uuid.uuid4())[:5]\n",
        "    WEB_DB_PATH = \"./WEB_\"+str(uuid.uuid4())[:5]\n",
        "    current_date = str(get_current_date())\n",
        "    DART_vectorstore =  Chroma(persist_directory=DART_DB_PATH,\n",
        "                                embedding_function=embeddings,\n",
        "                                collection_name=\"DART\")\n",
        "    Web_vectorstore = Chroma(persist_directory=WEB_DB_PATH,\n",
        "                                embedding_function=embeddings,\n",
        "                                collection_name=\"web\")\n",
        "    return {'DART_DB_PATH': DART_DB_PATH, 'WEB_DB_PATH':WEB_DB_PATH,\n",
        "            'current_date': current_date}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX8MzBnHw4r2"
      },
      "source": [
        "보고서 개요을 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDb7R1GKw4r2"
      },
      "outputs": [],
      "source": [
        "def initiate_report(state: State, config: RunnableConfig):\n",
        "\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system',f'''\n",
        "Current Date: {state['current_date']}\n",
        "\n",
        "당신은 주어진 질문에 대해, 사용자가 넓은 맥락에서 만족스러운\n",
        "답변을 얻을 수 있도록 3~4 섹션 길이의 보고서를 작성해야 합니다.\n",
        "해당 보고서의 개요를 작성해 주세요.\n",
        "\n",
        "개요를 바탕으로, 기업의 공시 문서와 최근 뉴스 등을 검색하여\n",
        "보고서를 작성할 것입니다.\n",
        "이를 고려하여, 충분한 정보가 담긴 개요를 작성하세요.\n",
        "'''),\n",
        "\n",
        "('human', '''사용자의 질문(혹은 요청): {question}''')\n",
        "    ])\n",
        "\n",
        "    question = state['question']\n",
        "\n",
        "    chain = prompt | llm.with_structured_output(ReportPlan)\n",
        "\n",
        "    result = chain.invoke({'question':question})\n",
        "\n",
        "    print(f'''\n",
        "# 보고서 작성 개요:\n",
        "{result.as_str}\n",
        "''')\n",
        "    return {'plan':result}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_8GLwNew4r2"
      },
      "source": [
        "개요를 바탕으로 검색 쿼리를 생성합니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofVpUEBNw4r2"
      },
      "outputs": [],
      "source": [
        "def generate_search_query(state: State, config: RunnableConfig):\n",
        "    prompt = ChatPromptTemplate([\n",
        "('system', f'''\n",
        " Current Date: {state['current_date']}\n",
        "\n",
        "주어진 질문에 답변하기 위한 보고서를 작성하는 과정에서, 당신은 한 섹션에 대한 자료 조사를 맡았습니다.\n",
        "적절한 검색 쿼리를 한 줄에 하나씩 작성하세요.\n",
        "특수문자 없이 쿼리만 출력하고, {config['configurable']['num_search_queries']} 개의 쿼리를 출력하세요.\n",
        "쿼리들은 겹치지 않아야 하며, 포괄적인 정보를 수집할 수 있어야 합니다.\n",
        "'''),\n",
        "('user', '''\n",
        "사전 질문:\n",
        "{question}\n",
        "\n",
        "전체 섹션 구성(참고용):\n",
        "\n",
        "{contents}\n",
        "\n",
        "\n",
        "당신이 맡은 섹션 정보:\n",
        "{section}\n",
        "''')])\n",
        "    contents = state['plan']\n",
        "    section_list = []\n",
        "    queries=[]\n",
        "    chain = prompt | llm | StrOutputParser() | (lambda x: x.split('\\n'))\n",
        "\n",
        "    for section in contents.sections:\n",
        "        queries += chain.invoke({'question': question, 'section':section.as_str, 'contents':contents.as_str})\n",
        "    queries = [query for query in queries if query !='']\n",
        "    return {'queries':queries}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgk4i5yrw4r2"
      },
      "source": [
        "검색 쿼리를 이용해, 검색 결과를 DB에 저장합니다.   \n",
        "Document의 리스트를 저장하는 툴을 만들고, LLM이 판단하여 실행하게 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsnWkEEOw4r2"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def dart_search(corp_name: str,\n",
        "                 start_date: int,\n",
        "                   period:int = 180):\n",
        "    \"\"\"\n",
        "    DART API를 사용하여 특정 회사의 공시문서를 다운로드하고, 청킹한 Document List를 Return합니다.\n",
        "    Args:\n",
        "        corp_name (str): 회사명 (예: '삼성전자')\n",
        "        start_date (str): 시작일 (YYYYMMDD 형식, 기본값: None)\n",
        "        period (int): 검색 기간(일) (기본값: 180일)\n",
        "\n",
        "    Returns:\n",
        "        str: 작업 결과 메시지\n",
        "\n",
        "    Example:\n",
        "    dart_search('삼성전자', None, 120)\n",
        "\n",
        "    Note:\n",
        "    회사명은 정확히 써야 합니다.\n",
        "    \"\"\"\n",
        "    result, dart_dir = get_dart_documents(corp_name, start_date, period)\n",
        "    xml_list = glob(f'./{dart_dir}/*.xml')\n",
        "    docs = []\n",
        "    for xml in xml_list:\n",
        "        doc = Document(page_content = parse_xml(xml),\n",
        "                       metadata={'type':'DART', 'source':xml})\n",
        "        docs.append(doc)\n",
        "\n",
        "\n",
        "    return docs\n",
        "\n",
        "@tool\n",
        "def web_search(\n",
        "    query: str,\n",
        "    time_range: Optional[str] = None,\n",
        "    topic: str = \"general\",\n",
        "    max_results: int = 5\n",
        ") -> str:\n",
        "    \"\"\"웹 검색을 수행하는 도구입니다.\n",
        "\n",
        "    Args:\n",
        "        query: 검색할 쿼리\n",
        "        time_range: 검색 시간 범위 (None, 'day', 'week', 'month', 'year')\n",
        "        topic: 검색 주제 ('general', 'finance', 'news')\n",
        "        max_results: 최대 검색 결과 수 (기본값 5)\n",
        "\n",
        "    Returns:\n",
        "        검색 결과 문자열\n",
        "    \"\"\"\n",
        "    tavily_search = TavilySearch(\n",
        "        max_results=max_results,\n",
        "        topic=topic,\n",
        "        include_raw_content=True,\n",
        "        time_range=time_range\n",
        "    )\n",
        "\n",
        "    def preprocess(text):\n",
        "        import re\n",
        "        # 탭과 개행문자를 공백으로 변환\n",
        "        text = text.replace('\\t', ' ').replace('\\n', ' ').replace('\\xa0', ' ')\n",
        "        # 템플릿 오류 방지\n",
        "        text = text.replace('{', '(').replace('}', ')')\n",
        "\n",
        "        # 연속된 공백을 하나로 치환\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "\n",
        "    result = tavily_search.invoke(query)\n",
        "\n",
        "    result_docs=[]\n",
        "    try:\n",
        "        for res in result['results']:\n",
        "            doc = Document(page_content=f\"### {res['title']} \\n URL: {res['url']} \\n {res['raw_content']}\" if res.get('raw_content') else f\"### {res['title']} \\n {res['content']}\", metadata={'type':'Web', 'source':res['url']})\n",
        "            result_docs.append(doc)\n",
        "    except: # API 문제로 검색 실패\n",
        "        result_docs=[]\n",
        "        print(query)\n",
        "        print('%%%%%%%%')\n",
        "        print(result)\n",
        "        print('%%%%%%%%')\n",
        "    return result_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MH8a33Wuibd",
        "outputId": "e99bd577-413e-41fa-c4ac-cf0c33f7cc97"
      },
      "outputs": [],
      "source": [
        "web_search.invoke({'query':'\"삼성전자\"'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02PKFq4zw4r2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def search(state: SearchState, config: RunnableConfig):\n",
        "\n",
        "    system_prompt = SystemMessage(f'''\n",
        "Current Date: {state['current_date']}\n",
        "\n",
        "당신은 검색 봇입니다.\n",
        "주어지는 정보를 찾기 위해 아래의 검색 중 어디를 검색해야 하는지 답변하세요.\n",
        "이후, 검색 툴을 실행하세요.\n",
        "\n",
        "----\n",
        "\n",
        "웹 검색(Tavily): 구체적 재무 데이터가 아닌 뉴스 등의 정보 검색\n",
        "dart_search: 공시 문서 검색\n",
        "\n",
        "포괄적인 검색이 필요한 경우에는 두 툴을 모두 사용하세요.\n",
        "\n",
        "입력에 명시적으로 들어 있지 않은 정보의 경우, 기본값을 사용하세요.\n",
        "둘 중에 최소 하나의 툴을 무조건 사용해야 합니다.\n",
        "''')\n",
        "    search_llm = quick_llm.bind_tools([web_search, dart_search])\n",
        "\n",
        "    messages = [system_prompt, HumanMessage(state['query'])]\n",
        "\n",
        "    search_res = search_llm.invoke(messages)\n",
        "\n",
        "    web_search_q =[]\n",
        "    dart_search_q = []\n",
        "    if search_res.tool_calls:\n",
        "        for tool_call in search_res.tool_calls:\n",
        "            tool_name = tool_call['name']\n",
        "            tool_arg = tool_call['args']\n",
        "            print(tool_name, tool_arg)\n",
        "\n",
        "            # 검색을 해야 하지만, 실제로는 중복을 제거하기 위해 arg만 전달\n",
        "            if tool_name =='web_search':\n",
        "                web_search_q.append(tool_arg)\n",
        "            else:\n",
        "                dart_search_q.append(tool_arg)\n",
        "\n",
        "    return {'web_search_q':web_search_q, 'dart_search_q': dart_search_q}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrzyG8tOw4r2"
      },
      "outputs": [],
      "source": [
        "def start_survey(state:State, config: RunnableConfig):\n",
        "    queries = state['queries']\n",
        "    current_date = state['current_date']\n",
        "    # Query 생성, 수집, Reflection, 섹션 작성 모듈을 하나의 에이전트로 구성\n",
        "    return [Send(\"search\",\n",
        "            {'query':query, 'current_date':current_date}) for query in queries]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTzEtXf_w4r2"
      },
      "outputs": [],
      "source": [
        "def combine_and_store(state:State, config: RunnableConfig):\n",
        "\n",
        "    DART_DB_PATH = state['DART_DB_PATH']\n",
        "    WEB_DB_PATH = state['WEB_DB_PATH']\n",
        "    web_search_q = state['web_search_q']\n",
        "    dart_search_q = state['dart_search_q']\n",
        "\n",
        "    # 중복 큐 제거 (frozenset 이용)\n",
        "    print(f'before dedup: {len(web_search_q)}, {len(dart_search_q)}')\n",
        "\n",
        "    web_search_q = [dict(fs) for fs in {frozenset(d.items()) for d in web_search_q}]\n",
        "    dart_search_q = [dict(fs) for fs in {frozenset(d.items()) for d in dart_search_q}]\n",
        "\n",
        "    print(f'after dedup: {len(web_search_q)}, {len(dart_search_q)}')\n",
        "\n",
        "\n",
        "\n",
        "    web_docs = web_search.batch(web_search_q)\n",
        "    dart_docs = dart_search.batch(dart_search_q)\n",
        "\n",
        "    # batch시 list of list: 평탄화\n",
        "    web_docs = [doc for batch in web_docs for doc in batch]\n",
        "    dart_docs = [doc for batch in dart_docs for doc in batch]\n",
        "\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=6000, chunk_overlap=600)\n",
        "\n",
        "    dart_chunks = text_splitter.split_documents(dart_docs)\n",
        "\n",
        "    DART_vectorstore =  Chroma(persist_directory=DART_DB_PATH,\n",
        "                                embedding_function=embeddings,\n",
        "                                collection_name=\"DART\")\n",
        "    Web_vectorstore = Chroma(persist_directory=WEB_DB_PATH,\n",
        "                                embedding_function=embeddings,\n",
        "                                collection_name=\"web\")\n",
        "\n",
        "\n",
        "    # 3개씩 추가\n",
        "    for i in tqdm(range(0, len(dart_chunks), 3)):\n",
        "        DART_vectorstore.add_documents(dart_chunks[i:min(i+3, len(dart_chunks))])\n",
        "    # 3개씩 추가\n",
        "    for i in tqdm(range(0, len(web_docs), 3)):\n",
        "        Web_vectorstore.add_documents(chunks[i:min(i+3, len(chunks))])\n",
        "\n",
        "    print('Saved in VDBs')\n",
        "\n",
        "    return {'web_docs':web_docs, 'dart_docs': dart_chunks}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66KpfvE8w4r2"
      },
      "source": [
        "DB가 구성되었으니, RAG를 통해 섹션별 글쓰기를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy3p5cY6w4r3"
      },
      "outputs": [],
      "source": [
        "def assign_writer(state: State, config: RunnableConfig):\n",
        "    # 섹션별 수집된 config['configurable']['num_search_queries']개의 쿼리를 그대로 사용하여 각각의 Writer에 전달\n",
        "\n",
        "    question = state['question']\n",
        "    queries = state['queries']\n",
        "    sections = state['plan'].sections\n",
        "    web_docs = state['web_docs']\n",
        "    dart_chunks = state['dart_docs']\n",
        "    DART_DB_PATH = state['DART_DB_PATH']\n",
        "    WEB_DB_PATH = state['WEB_DB_PATH']\n",
        "\n",
        "    num_queries_per_section = config['configurable']['num_search_queries']\n",
        "\n",
        "\n",
        "    section_query_list = [queries[i:i + num_queries_per_section] for i in range(0, len(queries), num_queries_per_section)]\n",
        "\n",
        "    current_date = state['current_date']\n",
        "\n",
        "    # 각 섹션별로 쿼리 그룹을 전달\n",
        "    return [Send(\"write_section\",\n",
        "            {'question':question,\n",
        "            'RAG_queries': query_group,\n",
        "             'current_date': current_date,\n",
        "             'section': section,\n",
        "             'web_docs':web_docs,\n",
        "             'dart_docs': dart_chunks,\n",
        "             'DART_DB_PATH':DART_DB_PATH,\n",
        "             'WEB_DB_PATH':WEB_DB_PATH})\n",
        "            for query_group, section in zip(section_query_list, sections)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RkVSbCBw4r3"
      },
      "outputs": [],
      "source": [
        "def write_section(state: WriterState, config: RunnableConfig):\n",
        "    section = state['section'].as_str\n",
        "    question = state['question']\n",
        "    DART_DB_PATH = state['DART_DB_PATH']\n",
        "    WEB_DB_PATH = state['WEB_DB_PATH']\n",
        "    queries = state['RAG_queries']\n",
        "    current_date = state['current_date']\n",
        "    dart_chunks = state['dart_docs']\n",
        "    web_docs = state['web_docs']\n",
        "\n",
        "    DART_vectorstore =  Chroma(persist_directory=DART_DB_PATH,\n",
        "                                embedding_function=embeddings,\n",
        "                                collection_name=\"DART\")\n",
        "    Web_vectorstore = Chroma(persist_directory=WEB_DB_PATH,\n",
        "                                embedding_function=embeddings,\n",
        "                                collection_name=\"web\")\n",
        "    def get_retriever(store, docs, BM25_ratio):\n",
        "        '''각 벡터스토어에 대한 Ensemble Retriever 생성'''\n",
        "        retriever = store.as_retriever(search_kwargs={'k':5})\n",
        "        bm25_retriever = BM25Retriever.from_documents(docs,\n",
        "                                                      preprocess_func = kiwi_tokenize)\n",
        "        bm25_retriever.k = 5\n",
        "        ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[bm25_retriever, retriever], weights=[BM25_ratio, 1-BM25_ratio]\n",
        "        )\n",
        "\n",
        "        return ensemble_retriever\n",
        "\n",
        "    dart_retriever = get_retriever(DART_vectorstore, dart_chunks, config['configurable']['BM25_ratio_for_DART'])\n",
        "    web_retriever = get_retriever(Web_vectorstore, web_docs, config['configurable']['BM25_ratio_for_Web'])\n",
        "\n",
        "    context = []\n",
        "    for query in queries:\n",
        "        context+= web_retriever.invoke(query)\n",
        "        context+= dart_retriever.invoke(query)\n",
        "\n",
        "    # 중복 제거\n",
        "    context = [doc for i, doc in enumerate(context) if doc not in context[:i]]\n",
        "\n",
        "    writer_prompt =ChatPromptTemplate([\n",
        "        ('system', f'''\n",
        "Current Date: {current_date}\n",
        "\n",
        "사용자의 질문과 이에 답변하기 위한 보고서의 세부 섹션명이 주어집니다.\n",
        "다음의 정보를 활용하여, 보고서의 섹션을 작성하세요.\n",
        "다음은 작성 가이드라인입니다.\n",
        "\n",
        "[작성 가이드라인]\n",
        "간단하고 명확한 언어를 사용하세요.\n",
        "섹션명은 마크다운 ## 으로 작성하며, 세부 목차는 만들지 말고 문단으로만 분리하세요.\n",
        "문장을 너무 길게 쓰지 말고, 이해하기 쉽게 작성하세요.\n",
        "'이다.' 가 아닌 '입니다.', '합니다.' 등의 스타일로 작성하세요.\n",
        "또한, 아래에 주어지는 정보의 내용을 최대한 활용하여 작성하세요.\n",
        "'''),\n",
        "\n",
        "('user','''\n",
        "질문: {question}\n",
        "\n",
        "세부 섹션명: {section}\n",
        "\n",
        "검색 결과 Context:\n",
        "{context}\n",
        "''')\n",
        "])\n",
        "    chain = writer_prompt | llm | StrOutputParser()\n",
        "    draft = chain.invoke({'question':question, 'section':section,\n",
        "                          'context':['\\n---\\n'.join([doc.page_content for doc in context])] })\n",
        "    return {'finished_drafts':[draft]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hInuCmYfw4r3"
      },
      "outputs": [],
      "source": [
        "def synthesizer(state:State, config: RunnableConfig):\n",
        "    return {'result':'\\n'.join(state['finished_drafts'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRuLYG3xw4r3"
      },
      "source": [
        "마지막으로, 평가 함수를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TML3E1hjw4r3"
      },
      "outputs": [],
      "source": [
        "def evaluate(state: State, config: RunnableConfig):\n",
        "    prompt = ChatPromptTemplate([\n",
        "(\"system\", \"\"\"당신은 보고서 품질 평가 전문가입니다. 주어진 보고서 텍스트를 주어진 기준에 따라 평가하고, 각 기준별 점수(1-5점)와 종합 점수를 반환하세요.\"\"\"),\n",
        "(\"user\",\"\"\"\n",
        "사용자 질문: {question}\n",
        "\n",
        "보고서 구획:\n",
        "{sections}\n",
        "\n",
        "평가 대상 보고서:\n",
        "{result}\n",
        "\"\"\")])\n",
        "    chain = prompt | llm.with_structured_output(QualityScore)\n",
        "\n",
        "    result = chain.invoke({'question':state['question'],\n",
        "                  'sections':state['plan'].as_str,\n",
        "                  'result':state['result']})\n",
        "\n",
        "    return {'quality_score':result}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Ix4BeQw4r3"
      },
      "source": [
        "평가 결과에 따라, Human-in-the-loop를 구성할 수 있습니다.   \n",
        "\n",
        "이후, 피드백을 받은 뒤, 원하는 부분부터 반영합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTDpanHow4r3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiD6yEQaw4r3"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(State)\n",
        "builder.add_node(initiate_db)\n",
        "builder.add_node(initiate_report)\n",
        "builder.add_node(generate_search_query)\n",
        "builder.add_node(search)\n",
        "builder.add_node(combine_and_store)\n",
        "builder.add_node(write_section)\n",
        "builder.add_node(synthesizer)\n",
        "builder.add_node(evaluate)\n",
        "\n",
        "builder.add_edge(START, 'initiate_db')\n",
        "builder.add_edge('initiate_db','initiate_report')\n",
        "builder.add_edge('initiate_report', 'generate_search_query')\n",
        "builder.add_conditional_edges('generate_search_query',\n",
        "start_survey, ['search'])\n",
        "builder.add_edge('search', 'combine_and_store')\n",
        "builder.add_conditional_edges('combine_and_store', assign_writer, ['write_section'])\n",
        "\n",
        "builder.add_edge('write_section', 'synthesizer')\n",
        "builder.add_edge('synthesizer', 'evaluate')\n",
        "builder.add_edge('evaluate', END)\n",
        "graph = builder.compile(checkpointer=MemorySaver())\n",
        "# graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "vj-Dbscbw4r3",
        "outputId": "c6a4f91e-2837-4cfe-faf0-b5871b26e949"
      },
      "outputs": [],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adNsaL9Jw4r3",
        "outputId": "b649a3ea-791e-4a1c-f517-11a3e730dc62"
      },
      "outputs": [],
      "source": [
        "test = {'question':\"삼성전자의 LLM 연구는 얼마나 진행중?'\"}\n",
        "thread = {'configurable':default, 'thread_id':'1'}\n",
        "\n",
        "history = []\n",
        "\n",
        "for event in graph.stream(test, config= thread):\n",
        "    try:\n",
        "        history.append(event)\n",
        "        for status in event:\n",
        "            try:\n",
        "                print(f'# {str(status)[:300]}')\n",
        "            except:\n",
        "                continue\n",
        "            try:\n",
        "                for key in event[status]:\n",
        "                    value = str(event[status][key])\n",
        "                    if len(value)>300:\n",
        "                        print(f'- {key}: {value[:300]}')\n",
        "                    else:\n",
        "                        print(f'- {key}: {value}')\n",
        "                print('---------')\n",
        "            except:\n",
        "                continue\n",
        "    except:\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4XsSuSwMX_h",
        "outputId": "bd2a17ca-9a28-4c93-a38f-78ab8ef2a17b"
      },
      "outputs": [],
      "source": [
        "result = history[-2]['synthesizer']['result']\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0nbe60pMX_h"
      },
      "outputs": [],
      "source": [
        "with open(\"example.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZUruaB7w4r4",
        "outputId": "67edf4d1-1867-4593-e9b9-963ab49d2005"
      },
      "outputs": [],
      "source": [
        "result = history[-1]['evaluate']\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqcfZbqTw4r4"
      },
      "source": [
        "만약, Score가 너무 낮다면, Human-in-the-loop를 이용해 피드백을 전달하고, 해당 내용에 맞춰 작업을 수행할 수 있습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TiDTtA3hQdp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

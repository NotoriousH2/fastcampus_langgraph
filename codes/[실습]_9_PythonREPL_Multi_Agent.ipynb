{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
      "metadata": {
        "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334"
      },
      "source": [
        "# [실습] 멀티 에이전트 구조\n",
        "\n",
        "LangGraph의 Agent는 기본적으로 여러 개의 툴을 연결할 수 있습니다.   \n",
        "그렇지만, 전체 구조를 하나의 에이전트로 구현하기보다는, 문제를 작게 나누는 Divide and Conquer 방식을 활용하여   \n",
        "개별 문제를 해결하는 에이전트의 연결을 통해 답변하게 하는 것이 효과적일 수 있습니다.   \n",
        "\n",
        "이는 Agent의 그래프를 따로 구성하고, Human-in-the-loop과 유사하게 `Command()`를 통해 전달하는 방식으로 이루어집니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
      "metadata": {
        "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langgraph langchain langchain_google_genai google_generativeai tavily-python langchain_community langchain_experimental -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d22732",
      "metadata": {
        "id": "b6d22732"
      },
      "source": [
        "이번 실습은 한국어 시각화가 필요할 수 있으므로, 코랩에서는 아래 옵션을 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d16b12",
      "metadata": {
        "id": "31d16b12"
      },
      "outputs": [],
      "source": [
        "# Colab/Linux 환경에서 아래 옵션을 실행합니다.\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 코드를 실행한 경우, 런타임 --> 세션 다시 시작을 수행해 주세요."
      ],
      "metadata": {
        "id": "pFa3n8tQuNcT"
      },
      "id": "pFa3n8tQuNcT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a99a21",
      "metadata": {
        "id": "38a99a21"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc",
      "metadata": {
        "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = ''\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    rate_limiter=rate_limiter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3e34f51",
      "metadata": {
        "id": "d3e34f51"
      },
      "source": [
        "랭스미스 연동을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e13944ae",
      "metadata": {
        "id": "e13944ae"
      },
      "outputs": [],
      "source": [
        "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LangGraph_FastCampus'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce204685",
      "metadata": {
        "id": "ce204685"
      },
      "source": [
        "## 1. Two Agents 협업 구조    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed08689",
      "metadata": {
        "id": "1ed08689"
      },
      "source": [
        "Tavily Tool과 Python Repl Tool을 이용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c18942a",
      "metadata": {
        "id": "8c18942a"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "repl = PythonREPL()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0affb23",
      "metadata": {
        "id": "b0affb23"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "\n",
        "# 툴 정보를 보다 자세하게 작성하여 성능을 높입니다.\n",
        "# LangGraph의 기본 표현을 사용했습니다!\n",
        "@tool\n",
        "def python_repl_tool(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
        "):\n",
        "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "    try:\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
        "    return (\n",
        "        result_str + \"\\n\\nIf you have completed all tasks, respond with MISSION COMPLETED.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e90b9e82",
      "metadata": {
        "id": "e90b9e82"
      },
      "source": [
        "각각의 툴을 연결한 Agent를 만들겠습니다.   \n",
        "System Prompt을 커스터마이징한 ReAct Agent를 구성합니다.   \n",
        "\n",
        "최종 출력 조건을 프롬프트에 언급하여 커뮤니케이션의 중단을 표시합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0086a069",
      "metadata": {
        "id": "0086a069"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "def make_system_prompt(suffix: str) -> str:\n",
        "    return f\"\"\"\n",
        "당신은 여러 AI 어시스턴트와 협업하는 팀원입니다.\n",
        "목표: 주어진 도구들을 반복적으로 활용해 사용자의 질문에 답하기\n",
        "당신의 작업물은 다른 에이전트에게 전달되어 최종 답변으로 사용될 것입니다.\n",
        "\n",
        "[작업 지침]\n",
        "1. 완벽한 답변이 어렵다면 가능한 부분까지 진행하세요\n",
        "2. 나머지는 다른 도구를 가진 팀원이 이어서 작업할 것입니다\n",
        "3. 다른 팀원에게 넘겨주어야 하는 경우, GO! 를 마지막에 출력하세요.\n",
        "4. 당신과 다른 팀원의 모든 작업이 완료된 경우 MISSION COMPLETED를 마지막에 출력하세요.\n",
        "\n",
        "팀원이 문제를 잘 해결할 수 있도록, 중요한 부분만 명료하게 설명하세요.\n",
        "\n",
        "[추가 지침]\n",
        "{suffix}\n",
        "\"\"\"\n",
        "\n",
        "# Research Agent 프롬프트\n",
        "research_agent = create_react_agent(llm, tools=[tavily_tool],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Research 전문가 'Amy' 입니다.\n",
        "[작업] 정보 검색 및 정리를 수행하세요.\n",
        "[협업] Chart 생성 전문가 'Brad'와 함께 작업 중입니다.\"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Chart Agent 프롬프트\n",
        "chart_agent = create_react_agent(llm, [python_repl_tool],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Chart 생성 전문가 'Brad' 입니다.\n",
        "[작업] 파이썬 코드 실행 및 차트 생성을 수행하세요.\n",
        "[협업] Research 전문가 'Amy' 와 함께 작업 중입니다.\"\"\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ae33c7",
      "metadata": {
        "id": "28ae33c7"
      },
      "source": [
        "State를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa8c1fb",
      "metadata": {
        "id": "5aa8c1fb"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages : Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c1594df",
      "metadata": {
        "id": "3c1594df"
      },
      "source": [
        "그래프를 만들고 구성합니다.  \n",
        "\n",
        "`goto`를 통해, 종료할지/다음 에이전트로 Context를 전달할지를 결정합니다.   \n",
        "\n",
        "`command`를 통해 다음 경로를 명시적으로 지정할 수 있습니다.   \n",
        "(이는 Typing에 표시하면, 시각화 과정에 나타납니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6",
      "metadata": {
        "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "# Next Node를 선택하는 과정: 노드로 구성하여 그래프에 표시\n",
        "def get_next_node(last_message, goto: str):\n",
        "    if \"MISSION COMPLETED\" in last_message.content:\n",
        "        return END\n",
        "    return goto\n",
        "\n",
        "\n",
        "\n",
        "def research_node(state: State) -> Command[Literal[\"chart_generator\", END]]:\n",
        "\n",
        "    result = research_agent.invoke(state)\n",
        "    goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
        "\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"researcher\")\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n",
        "\n",
        "\n",
        "def chart_node(state: State) -> Command[Literal[\"researcher\", END]]:\n",
        "    result = chart_agent.invoke(state)\n",
        "    goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"chart_generator\")\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e486f0f",
      "metadata": {
        "id": "9e486f0f"
      },
      "source": [
        "상호작용 + ReAct Agent의 조합으로 전체 그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4a5ade-5912-494b-bf62-8a99278f9f12",
      "metadata": {
        "id": "2c4a5ade-5912-494b-bf62-8a99278f9f12"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"researcher\", research_node)\n",
        "builder.add_node(\"chart_generator\", chart_node)\n",
        "\n",
        "builder.add_edge(START, \"researcher\")\n",
        "graph = builder.compile()\n",
        "\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8274d349",
      "metadata": {
        "id": "8274d349"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\"user\",\"2024년 프로야구 순위 그래프로 보여줘\")\n",
        "        ],\n",
        "    },\n",
        "    {\"recursion_limit\": 150},\n",
        "    stream_mode='updates'\n",
        ")\n",
        "for s in events:\n",
        "    for role in s:\n",
        "        print(f'Role: {role}')\n",
        "        print('')\n",
        "        for message in s[role]['messages']:\n",
        "            print(message.type,':', message.content)\n",
        "        print('--------')\n",
        "    #print(s)\n",
        "    print(\"-------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2647fb34",
      "metadata": {
        "id": "2647fb34"
      },
      "source": [
        "## 2. Supervisor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d12c071",
      "metadata": {
        "id": "0d12c071"
      },
      "source": [
        "두 에이전트가 서로 소통하는 방식은 고정된 커뮤니케이션 경로로 구성됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f413627d",
      "metadata": {
        "id": "f413627d"
      },
      "source": [
        "하지만, 차트 에이전트의 코드만을 수정하고 싶거나, 리서치 에이전트의 결과를 바로 수정하고 싶은 경우는 해당 경로가 효과적이지 않은데요, Supervisor 구조를 통해 이를 해결해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df518671",
      "metadata": {
        "id": "df518671"
      },
      "source": [
        "경로 설정을 위해, agent 목록과 route 목록을 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68562e14",
      "metadata": {
        "id": "68562e14"
      },
      "outputs": [],
      "source": [
        "agents = [\"researcher\", \"chart_generator\"]\n",
        "routes = agents + [\"FINISH\"]\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Router(BaseModel):\n",
        "    reason : str = Field(description='dest를 선택한 이유를 30자 이내로 설명')\n",
        "    dest: Literal[*routes] = Field(description=\"다음 작업을 수행할 에이전트를 결정합니다. 만약 모든 작업이 완료되었다면 FINISH를 출력합니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19afa391",
      "metadata": {
        "id": "19afa391"
      },
      "source": [
        "프롬프트를 구성하고, 현재 상황을 판단해 적절한 에이전트를 선택하고 전달하도록 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9868c1aa",
      "metadata": {
        "id": "9868c1aa"
      },
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"\n",
        "당신은 작업 관리자입니다.\n",
        "당신의 역할은 주어진 질의를 풀기 위해,\n",
        "\n",
        "여러 에이전트 간의 대화를 관리하고 조율하는 것입니다.\n",
        "관리해야 하는 에이전트들은 다음과 같습니다: {agents}\n",
        "\n",
        "[작업 지침]\n",
        "1. 사용자 요청에 대한 현재 진행 상황에 따라 다음 작업할 에이전트를 선택하세요\n",
        "2. 각 에이전트는 자신의 작업 결과와 상태를 보고할 것입니다\n",
        "3. chart_generator 에이전트의 경우, 코드를 실행하여 전달합니다.코드가 잘 구성되었으면 작업 완료로 간주하세요.\n",
        "\n",
        "3. 모든 에이전트가 작업을 완료하여 문제가 해결된 경우, FINISH'로 응답하세요. 끝나기 전까지는 계속 다른 에이전트에게 피드백을 제공하세요.\n",
        "\n",
        "[Notes]\n",
        "모든 에이전트가 작업에 참여해야만 하는 것은 아닙니다.\n",
        "작업이 완료된 경우, FINISH로 응답하세요.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0997198",
      "metadata": {
        "id": "e0997198"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "class State(TypedDict):\n",
        "    dest : str\n",
        "    messages : Annotated[list, add_messages]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e0409b3",
      "metadata": {
        "id": "2e0409b3"
      },
      "outputs": [],
      "source": [
        "def supervisor(state: State) -> Command[Literal[*agents, \"__end__\"]]:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "    ] + state[\"messages\"]\n",
        "    response = llm.with_structured_output(Router).invoke(messages)\n",
        "\n",
        "    print('##SUPERVISOR: ', response.dest, '-->', response.reason)\n",
        "\n",
        "    goto = response.dest\n",
        "    if goto == \"FINISH\":\n",
        "        goto = END\n",
        "\n",
        "    return Command(goto=goto, update={\"dest\": goto})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d196331e",
      "metadata": {
        "id": "d196331e"
      },
      "outputs": [],
      "source": [
        "def make_system_prompt(suffix: str) -> str:\n",
        "    return f\"\"\"\n",
        "당신은 툴 사용 에이전트입니다.\n",
        "아래의 정보를 바탕으로, 문제를 해결하기 위한 과정을 수행하세요.\n",
        "당신의 영역 밖의 작업은, 다른 에이전트가 수행할 것입니다.\n",
        "\n",
        "{suffix}\n",
        "\"\"\"\n",
        "\n",
        "# Research Agent 프롬프트\n",
        "research_agent = create_react_agent(llm, tools=[tavily_tool],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Research 전문가 'Amy' 입니다.\n",
        "[작업] 정보 검색 및 정리를 수행하세요.\n",
        "[협업] Chart 생성 전문가 'Brad'와 함께 작업 중입니다.\"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Chart Agent 프롬프트\n",
        "chart_agent = create_react_agent(llm, [python_repl_tool],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Chart 생성 전문가 'Brad' 입니다.\n",
        "[작업] 파이썬 코드 실행 및 차트 생성을 수행하세요.\n",
        "[협업] Research 전문가 'Amy' 와 함께 작업 중입니다.\"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "def researcher(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "\n",
        "    result = research_agent.invoke(state)\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"researcher\")\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"]}, goto='supervisor')\n",
        "\n",
        "\n",
        "def chart_generator(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    result = chart_agent.invoke(state)\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"chart_generator\")\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"]}, goto='supervisor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff26a5d",
      "metadata": {
        "id": "7ff26a5d"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"supervisor\", supervisor)\n",
        "builder.add_node(\"researcher\", researcher)\n",
        "builder.add_node(\"chart_generator\", chart_generator)\n",
        "\n",
        "builder.add_edge(START, \"supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9389fc",
      "metadata": {
        "id": "9f9389fc"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8efa1083",
      "metadata": {
        "id": "8efa1083"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        'next':'',\n",
        "        \"messages\": [\n",
        "            (\"user\",\"2024년 프로야구 최종 순위 그래프로 보여줘\")\n",
        "        ],\n",
        "    },subgraphs=True,stream_mode='updates')\n",
        "\n",
        "\n",
        "\n",
        "for s in events:\n",
        "    for role in s:\n",
        "        print(f'Role: {role}')\n",
        "        print('')\n",
        "        try:\n",
        "            for message in s[role]['messages']:\n",
        "                print(message.type,':', message.content)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        print('DEST:', s[role]['dest'])\n",
        "        print('--------')\n",
        "    #print(s)\n",
        "    print(\"-------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd238fd",
      "metadata": {
        "id": "0cd238fd"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        'next':'',\n",
        "        \"messages\": [\n",
        "            (\"user\",\"잠실역 맛집 3개 추천해줘.\")\n",
        "        ],\n",
        "    },subgraphs=True,stream_mode='updates')\n",
        "\n",
        "\n",
        "\n",
        "for s in events:\n",
        "    for role in s:\n",
        "        print(f'Role: {role}')\n",
        "        print('')\n",
        "        try:\n",
        "            for message in s[role]['messages']:\n",
        "                print(message.type,':', message.content)\n",
        "        except:\n",
        "            continue\n",
        "        print('DEST:', s[role]['dest'])\n",
        "        print('--------')\n",
        "    #print(s)\n",
        "    print(\"-------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "966921f4",
      "metadata": {
        "id": "966921f4"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        'next':'',\n",
        "        \"messages\": [\n",
        "            (\"user\",\"2024년 한국 프로야구 10팀의 최종 순위 알려줘.\")\n",
        "        ],\n",
        "    },subgraphs=True,stream_mode='updates')\n",
        "\n",
        "\n",
        "\n",
        "for s in events:\n",
        "    for role in s:\n",
        "        print(f'Role: {role}')\n",
        "        print('')\n",
        "        try:\n",
        "            for message in s[role]['messages']:\n",
        "                print(message.type,':', message.content)\n",
        "        except:\n",
        "            continue\n",
        "        print('DEST:', s[role]['dest'])\n",
        "        print('--------')\n",
        "    #print(s)\n",
        "    print(\"-------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이와 같이 간단한 문제에 대해서는, Supervisor가 단순히 노드를 지정하는 것으로 해결할 수 있었습니다.   \n",
        "만약 복잡한 Reasoning이 필요한 문제라면, Supervisor가 대화에 참여하는 것도 가능합니다.   "
      ],
      "metadata": {
        "id": "KzC-JNYFz4Rd"
      },
      "id": "KzC-JNYFz4Rd"
    },
    {
      "cell_type": "markdown",
      "id": "95d4674e",
      "metadata": {
        "id": "95d4674e"
      },
      "source": [
        "Langsmith (https://smith.langchain.com )에서 실행 결과를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbKwrylkwopg"
      },
      "id": "NbKwrylkwopg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "multicampus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
      "metadata": {
        "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334"
      },
      "source": [
        "# [실습] 멀티 에이전트 구조\n",
        "\n",
        "LangGraph의 Agent는 기본적으로 여러 개의 툴을 연결할 수 있습니다.   \n",
        "그렇지만, 전체 구조를 하나의 에이전트로 구현하기보다는, 문제를 작게 나누는 Divide and Conquer 방식을 활용하여   \n",
        "개별 문제를 해결하는 에이전트의 연결을 통해 답변하게 하는 것이 효과적일 수 있습니다.   \n",
        "\n",
        "이는 Agent의 그래프를 따로 구성하고, Human-in-the-loop과 유사하게 `Command()`를 통해 전달하는 방식으로 이루어집니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
        "outputId": "21e5aa26-02ed-4816-a677-b9a0604a9d3e"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph langchain langchain_google_genai langchain_community langchain_experimental langchain_tavily matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d22732",
      "metadata": {
        "id": "b6d22732"
      },
      "source": [
        "이번 실습은 한국어 시각화가 필요할 수 있으므로, 코랩에서는 아래 옵션을 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d16b12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31d16b12",
        "outputId": "9bc9f8c6-ecc2-4ace-e460-4c7051b750ae"
      },
      "outputs": [],
      "source": [
        "# Colab/Linux 환경에서 아래 옵션을 실행합니다.\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pFa3n8tQuNcT",
      "metadata": {
        "id": "pFa3n8tQuNcT"
      },
      "source": [
        "위 코드를 실행한 경우, 런타임 --> 세션 다시 시작을 수행해 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a99a21",
      "metadata": {
        "id": "38a99a21"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc",
      "metadata": {
        "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIxxx'\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-xxxx\"\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    temperature=0.2,\n",
        "    max_tokens=8192\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3e34f51",
      "metadata": {
        "id": "d3e34f51"
      },
      "source": [
        "랭스미스 연동을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e13944ae",
      "metadata": {
        "id": "e13944ae"
      },
      "outputs": [],
      "source": [
        "os.environ['LANGCHAIN_API_KEY'] = ''\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LangGraph_FastCampus'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce204685",
      "metadata": {
        "id": "ce204685"
      },
      "source": [
        "## 1. Two Agents 협업 구조    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed08689",
      "metadata": {
        "id": "1ed08689"
      },
      "source": [
        "Tavily Tool과 Python Repl Tool을 이용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c18942a",
      "metadata": {
        "id": "8c18942a"
      },
      "outputs": [],
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "import random\n",
        "from io import StringIO\n",
        "import sys\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "\n",
        "@tool\n",
        "def tavily_search(query:str, max_results:int=5):\n",
        "    \"\"\"Tavily API를 통해 검색 결과를 가져옵니다.\n",
        "query: 검색어\n",
        "max_results : 검색 결과의 수(최소 1, 최대 20, 별도의 요청이 없으면 5로 고정)\"\"\"\n",
        "    tavily_search = TavilySearch(max_results=max_results,\n",
        "                                 include_raw_content = 'markdown'\n",
        "    )\n",
        "\n",
        "    search_results = tavily_search.invoke(query)\n",
        "\n",
        "    context = f''\n",
        "    for doc in search_results['results']:\n",
        "        if doc.get('raw_content'):\n",
        "            doc_content = doc.get('raw_content')[:3000]\n",
        "        else:\n",
        "            doc_content = doc.get('content')\n",
        "        context += 'TITLE: ' + doc.get('title','N/A') + '\\nURL:' + doc.get('url')+ '\\nContent:'+ doc_content + '\\n---\\n'\n",
        "    return context\n",
        "\n",
        "\n",
        "def python_repl(code: str) -> str:\n",
        "    # 코드 정리\n",
        "    code = code.strip().strip('`')\n",
        "    if code.startswith('python'):\n",
        "        code = code[6:].strip()\n",
        "\n",
        "    # stdout 캡처 (context manager 사용으로 안전하게)\n",
        "    buffer = StringIO()\n",
        "\n",
        "    try:\n",
        "        # redirect_stdout을 사용하면 자동으로 복원됨\n",
        "        with redirect_stdout(buffer):\n",
        "            exec(code, globals())\n",
        "\n",
        "        # 결과 가져오기\n",
        "        output = buffer.getvalue()\n",
        "        return output if output else \"실행 완료\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {type(e).__name__}: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0affb23",
      "metadata": {
        "id": "b0affb23"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "\n",
        "# 툴 정보를 보다 자세하게 작성하여 성능을 높입니다.\n",
        "# LangGraph의 기본 표현을 사용했습니다!\n",
        "@tool\n",
        "def python_repl_tool(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
        "):\n",
        "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "    try:\n",
        "        result = python_repl(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
        "    return result_str"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e90b9e82",
      "metadata": {
        "id": "e90b9e82"
      },
      "source": [
        "각각의 툴을 연결한 Agent를 만들겠습니다.   \n",
        "System Prompt을 커스터마이징한 ReAct Agent를 구성합니다.   \n",
        "\n",
        "최종 출력 조건을 프롬프트에 언급하여 커뮤니케이션의 중단을 표시합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0086a069",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0086a069",
        "outputId": "e1f33bb7-2882-4b93-94ec-64deaec7a0e5"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "def make_system_prompt(prefix: str) -> str:\n",
        "    return f\"\"\"\n",
        "[기본 지침]\n",
        "{prefix}\n",
        "\n",
        "당신은 여러 AI 어시스턴트와 협업하는 팀원입니다.\n",
        "목표: 주어진 도구들을 반복적으로 활용해 사용자의 질문에 답하기\n",
        "당신의 작업물은 다른 에이전트에게 전달되어 최종 답변으로 사용될 것입니다.\n",
        "\n",
        "[작업 지침]\n",
        "1. 완벽한 답변이 어렵다면 가능한 부분까지 진행하세요\n",
        "2. 나머지는 다른 도구를 가진 팀원이 이어서 작업할 것입니다\n",
        "3. 다른 팀원에게 넘겨주어야 하는 경우, GO! 를 마지막에 출력하세요.\n",
        "4. 당신과 다른 팀원의 모든 작업이 완료된 경우 MISSION COMPLETED를 마지막에 출력하세요.\n",
        "\n",
        "팀원이 문제를 잘 해결할 수 있도록, 중요한 부분만 명료하게 설명하세요.\n",
        "툴을 실행한 후에, 결과를 바탕으로 다음 작업을 설명하세요.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Research Agent 프롬프트\n",
        "research_agent = create_react_agent(llm, tools=[tavily_search],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Research 전문가 'Amy' 입니다.\n",
        "[작업] 정보 검색 및 정리를 수행하세요.\n",
        "[협업] Chart 생성 전문가 'Brad'와 함께 작업 중입니다.\"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Chart Agent 프롬프트\n",
        "chart_agent = create_react_agent(llm, [python_repl_tool],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Chart 생성 전문가 'Brad' 입니다.\n",
        "[작업] 파이썬 코드 실행 및 차트 생성을 수행하세요.\n",
        "[협업] Research 전문가 'Amy' 와 함께 작업 중입니다.\n",
        "\n",
        "한국어 시각화의 경우, 폰트는 NanumBarunGothic를 사용하세요.\"\"\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YGCnKQjPT5iK",
      "metadata": {
        "id": "YGCnKQjPT5iK"
      },
      "outputs": [],
      "source": [
        "# chart_agent.invoke(\n",
        "#     {'messages':[HumanMessage('Amy입니다. 2024년 프로야구 최종 순위를 검색하여 데이터를 추출했습니다. 이 데이터를 기반으로 Brad에게 그래프 생성을 요청했습니다.\\n\\n**2024년 프로야구 최종 순위:**\\n\\n*   **KIA 타이거즈**: 승률 0.612\\n*   **삼성 라이온즈**: 승률 0.549\\n*   **LG 트윈스**: 승률 0.535\\n*   **두산 베어스**: 승률 0.521\\n*   **kt wiz**: 승률 0.507\\n*   **SSG 랜더스**: 승률 0.507\\n*   **롯데 자이언츠**: 승률 0.471\\n*   **한화 이글스**: 승률 0.464\\n*   **NC 다이노스**: 승률 0.429\\n*   **키움 히어로즈**: 승률 0.403\\n\\nGo!')]}\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ae33c7",
      "metadata": {
        "id": "28ae33c7"
      },
      "source": [
        "State를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa8c1fb",
      "metadata": {
        "id": "5aa8c1fb"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages : Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c1594df",
      "metadata": {
        "id": "3c1594df"
      },
      "source": [
        "그래프를 만들고 구성합니다.  \n",
        "\n",
        "`goto`를 통해, 종료할지/다음 에이전트로 Context를 전달할지를 결정합니다.   \n",
        "\n",
        "`command`를 통해 다음 경로를 명시적으로 지정할 수 있습니다.   \n",
        "(이는 Typing에 표시하면, 시각화 과정에 나타납니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6",
      "metadata": {
        "id": "71b790ca-9cef-4b22-b469-4b1d5d8424d6"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "# Next Node를 선택하는 과정: 노드로 구성하여 그래프에 표시\n",
        "def get_next_node(last_message, goto: str):\n",
        "    if \"MISSION COMPLETED\" in last_message.content:\n",
        "        return END\n",
        "    return goto\n",
        "\n",
        "\n",
        "\n",
        "def research_node(state: State) -> Command[Literal[\"chart_generator\", END]]:\n",
        "\n",
        "    result = research_agent.invoke(state)\n",
        "    goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"researcher\")\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"][-1:]}, goto=goto)\n",
        "\n",
        "\n",
        "def chart_node(state: State) -> Command[Literal[\"researcher\", END]]:\n",
        "    result = chart_agent.invoke(state)\n",
        "    goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
        "\n",
        "    print('== \\n\\n\\n',result['messages'],'\\n\\n== \\n\\n\\n')\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"chart_generator\")\n",
        "\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"][-1:]}, goto=goto)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e486f0f",
      "metadata": {
        "id": "9e486f0f"
      },
      "source": [
        "상호작용 + ReAct Agent의 조합으로 전체 그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4a5ade-5912-494b-bf62-8a99278f9f12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "2c4a5ade-5912-494b-bf62-8a99278f9f12",
        "outputId": "4bb1b021-c388-433b-9678-9590a9dc6a46"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"researcher\", research_node)\n",
        "builder.add_node(\"chart_generator\", chart_node)\n",
        "\n",
        "builder.add_edge(START, \"researcher\")\n",
        "graph = builder.compile()\n",
        "\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d4Yz_lyKkgb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "8d4Yz_lyKkgb",
        "outputId": "fa1e3f92-1e6c-4518-eb35-98bf7be2c892"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8274d349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8274d349",
        "outputId": "6c52c14e-1168-41e6-9f4b-58b0b4d5ceae"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\"user\",\"2024년 프로야구 순위를 검색해서 그래프로 시각화해줘. 결과는 rank.png에 저장해.\")\n",
        "        ],\n",
        "    },\n",
        "    {\"recursion_limit\": 150},\n",
        "    subgraphs= True, stream_mode='updates'\n",
        ")\n",
        "for s in events:\n",
        "    print(str(s)[:300])\n",
        "    print('[중략]')\n",
        "    print(str(s)[-300:])\n",
        "    print('\\n------------\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2647fb34",
      "metadata": {
        "id": "2647fb34"
      },
      "source": [
        "## 2. Supervisor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d12c071",
      "metadata": {
        "id": "0d12c071"
      },
      "source": [
        "두 에이전트가 서로 소통하는 방식은 고정된 커뮤니케이션 경로로 구성됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f413627d",
      "metadata": {
        "id": "f413627d"
      },
      "source": [
        "하지만, 차트 에이전트의 코드만을 수정하고 싶거나, 리서치 에이전트의 결과를 바로 수정하고 싶은 경우는 해당 경로가 효과적이지 않은데요, Supervisor 구조를 통해 이를 해결해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df518671",
      "metadata": {
        "id": "df518671"
      },
      "source": [
        "경로 설정을 위해, agent 목록과 route 목록을 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68562e14",
      "metadata": {
        "id": "68562e14"
      },
      "outputs": [],
      "source": [
        "agents = [\"researcher\", \"chart_generator\"]\n",
        "routes = agents + [\"FINISH\"]\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Router(BaseModel):\n",
        "    reason : str = Field(description='dest를 선택한 이유를 30자 이내로 설명')\n",
        "    send_msg : str = Field(description='해당 에이전트에 추가로 요청할 말(자연어 말투로)')\n",
        "    dest: Literal[*routes] = Field(description=\"다음 작업을 수행할 에이전트를 결정합니다. 만약 모든 작업이 완료되었다면 FINISH를 출력합니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19afa391",
      "metadata": {
        "id": "19afa391"
      },
      "source": [
        "프롬프트를 구성하고, 현재 상황을 판단해 적절한 에이전트를 선택하고 전달하도록 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9868c1aa",
      "metadata": {
        "id": "9868c1aa"
      },
      "outputs": [],
      "source": [
        "system_prompt = f\"\"\"\n",
        "당신은 작업 관리자입니다.\n",
        "당신의 역할은 주어진 질의를 풀기 위해,\n",
        "\n",
        "여러 에이전트 간의 대화를 관리하고 조율하는 것입니다.\n",
        "관리해야 하는 에이전트들은 다음과 같습니다: [{agents}]\n",
        "\n",
        "[작업 지침]\n",
        "1. 사용자 요청에 대한 현재 진행 상황에 따라 다음 작업할 에이전트를 선택하세요\n",
        "2. 각 에이전트는 자신의 작업 결과와 상태를 보고할 것입니다\n",
        "3. 두 에이전트는 당신의 의견을 요청할 수 있습니다. 적절한 내용으로 답변하세요.\n",
        "4. 모든 에이전트가 작업을 완료하여 문제가 해결된 경우, FINISH로 응답하세요. 작업이 남아 있는 경우에는 계속 다른 에이전트에게 피드백을 제공하세요.\n",
        "\n",
        "[Notes]\n",
        "모든 에이전트가 작업에 참여해야만 하는 것은 아닙니다.\n",
        "작업이 완료된 경우, FINISH로 응답하세요.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0997198",
      "metadata": {
        "id": "e0997198"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "class State(TypedDict):\n",
        "    dest : str\n",
        "    messages : Annotated[list, add_messages]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e0409b3",
      "metadata": {
        "id": "2e0409b3"
      },
      "outputs": [],
      "source": [
        "def supervisor(state: State) -> Command[Literal[*agents, \"__end__\"]]:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "    ] + state[\"messages\"]\n",
        "    response = llm.with_structured_output(Router).invoke(messages)\n",
        "\n",
        "    print('##SUPERVISOR: ', response.dest, '-->', response.reason)\n",
        "\n",
        "    print(\"요청:\", response.send_msg)\n",
        "\n",
        "    goto = response.dest\n",
        "    if goto == \"FINISH\":\n",
        "        goto = END\n",
        "\n",
        "    return Command(goto=goto, update={\"dest\": goto, 'messages':HumanMessage(response.send_msg)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d196331e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d196331e",
        "outputId": "74afe740-fa38-4427-cc4b-7f2f5a3e2d88"
      },
      "outputs": [],
      "source": [
        "def make_system_prompt(suffix: str) -> str:\n",
        "    return f\"\"\"\n",
        "당신은 툴 사용 에이전트입니다.\n",
        "아래의 정보를 바탕으로, 문제를 해결하기 위한 과정을 수행하세요.\n",
        "당신의 영역 밖의 작업은, 다른 에이전트가 수행할 것입니다.\n",
        "툴 사용이 끝나면, 반드시 상세하게 결과를 설명하세요.\n",
        "\n",
        "{suffix}\n",
        "\"\"\"\n",
        "\n",
        "# Research Agent 프롬프트\n",
        "research_agent = create_react_agent(llm, tools=[tavily_search],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Research 전문가 'Amy' 입니다.\n",
        "[작업] 정보 검색 및 정리를 수행하세요.\n",
        "[협업] Chart 생성 전문가 'Brad'와 함께 작업 중입니다.\"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Chart Agent 프롬프트\n",
        "chart_agent = create_react_agent(llm, [python_repl_tool],\n",
        "    prompt=make_system_prompt(\n",
        "        \"\"\"당신의 이름은 Chart 생성 전문가 'Brad' 입니다.\n",
        "[작업] 파이썬 코드 실행 및 차트 생성을 수행하세요.\n",
        "[협업] Research 전문가 'Amy' 와 함께 작업 중입니다.\"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "def researcher(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "\n",
        "    result = research_agent.invoke(state)\n",
        "\n",
        "    print('## Researcher \\n\\n', result[\"messages\"], '\\n\\n\\n')\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"researcher\")\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"][-1:]}, goto='supervisor')\n",
        "\n",
        "\n",
        "def chart_generator(state: State) -> Command[Literal[\"supervisor\"]]:\n",
        "    result = chart_agent.invoke(state)\n",
        "\n",
        "    print('## Chart \\n\\n', result[\"messages\"], '\\n\\n\\n')\n",
        "\n",
        "    result[\"messages\"][-1] = HumanMessage(result[\"messages\"][-1].content, name=\"chart_generator\")\n",
        "    # name은 실제로 역할이 없으나, 디버깅 및 확인을 위해 구성\n",
        "\n",
        "    return Command(update={\"messages\": result[\"messages\"][-1:]}, goto='supervisor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff26a5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ff26a5d",
        "outputId": "92d130ba-d43c-4264-83e4-1fa7ff295f6e"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"supervisor\", supervisor)\n",
        "builder.add_node(\"researcher\", researcher)\n",
        "builder.add_node(\"chart_generator\", chart_generator)\n",
        "\n",
        "builder.add_edge(START, \"supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9389fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "9f9389fc",
        "outputId": "57ba026e-29d8-47ac-f8e9-1a81bfdaebbb"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SCpVq7aBKn0L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "SCpVq7aBKn0L",
        "outputId": "2c887ddc-4d9a-4f90-8892-6c95adda6b79"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8efa1083",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8efa1083",
        "outputId": "6f9fc593-999a-495d-dba1-6a2e8005d22f"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        'next':'',\n",
        "        \"messages\": [\n",
        "            (\"user\",\"오늘은 2025년 10월 26일이야. 2025년 10월 15일 기준, 한국 주요 도시를 4개 선정하고, 각 도시의 최저 기온을 조사해서 비교해줘.\")\n",
        "        ],\n",
        "    },subgraphs=True,stream_mode='updates')\n",
        "\n",
        "for s in events:\n",
        "    print(str(s)[:300])\n",
        "    print('[중략]')\n",
        "    print(str(s)[-300:])\n",
        "    print('\\n------------\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd238fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd238fd",
        "outputId": "d3e9023f-403b-4d58-f72d-e17c7ebb5e43"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        'next':'',\n",
        "        \"messages\": [\n",
        "            (\"user\",\"잠실역 맛집 3개 추천해줘. 시각화는 안 해도 돼.\")\n",
        "        ],\n",
        "    },subgraphs=True,stream_mode='updates')\n",
        "\n",
        "\n",
        "for s in events:\n",
        "    print(str(s)[:300])\n",
        "    print('[중략]')\n",
        "    print(str(s)[-300:])\n",
        "    print('\\n------------\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "966921f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "966921f4",
        "outputId": "9efdb13d-3405-47a2-f6e2-4086f2e9a1d6"
      },
      "outputs": [],
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        'next':'',\n",
        "        \"messages\": [\n",
        "            (\"user\",\"한국에서 진행된 AI 툴 사용 설문조사를 확인하고, 이를 파이차트로 시각화해줘\")\n",
        "        ],\n",
        "    },subgraphs=True,stream_mode='updates')\n",
        "\n",
        "\n",
        "for s in events:\n",
        "    print(str(s)[:300])\n",
        "    print('[중략]')\n",
        "    print(str(s)[-300:])\n",
        "    print('\\n------------\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d4674e",
      "metadata": {
        "id": "95d4674e"
      },
      "source": [
        "Langsmith (https://smith.langchain.com )에서 실행 결과를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NbKwrylkwopg",
      "metadata": {
        "id": "NbKwrylkwopg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "multicampus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

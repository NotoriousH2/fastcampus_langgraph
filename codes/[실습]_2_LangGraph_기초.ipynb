{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dNVSrWPrDMe",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# [실습] LangGraph 기초\n",
        "\n",
        "랭그래프는 어플리케이션의 작동 과정을 Graph로 정의하고, 이를 통해 복잡한 Workflow를 실행합니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0BW7qQvrDMe"
      },
      "source": [
        "기본 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQPyAAOdrDMf"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph langchain langchain_google_genai langchain_community langchain_tavily bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKKCoKmVrDMf"
      },
      "source": [
        "# Graph의 구성 요소: State, Node, Edge, Graph\n",
        "\n",
        "\n",
        "시작 지점과 끝 지점을 표시한 그래프를 구성하고, 전체 그래프를 `invoke()`를 통해 실행합니다.\n",
        "\n",
        "그래프는 점과 선으로 구성되는데요.  \n",
        "\n",
        "\n",
        "\n",
        "이를 노드(Node, 정점), 엣지(Edge, 간선)라고 부릅니다.    \n",
        "\n",
        "각각의 노드는 LLM 호출을 비롯한 하나의 기능을 수행하게 되며, 기능과 기능 사이의 연결을 엣지로 구성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0MQDjCOrDMf"
      },
      "source": [
        "### State\n",
        "\n",
        "LangGraph의 Workflow는 State Diagram으로 볼 수 있습니다.   \n",
        "\n",
        "전체 Workflow에서, State는 초기 State에서 시작해    \n",
        "Node와 Edge를 통과하며 그 값이 수정되거나 추가되는 과정을 거치게 됩니다.   \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYFYHW6xrDMf"
      },
      "source": [
        "State의 구조는 보통 가시성을 위해 타입 표시를 병행합니다.   \n",
        "`TypedDict`나 `Pydantic`중 편한 것을 사용하면 되는데요.   \n",
        "이번 교재에서는 공식 문서와 동일한 `TypedDict`를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaBQ0lFhrDMf"
      },
      "outputs": [],
      "source": [
        "# TypedDict: 타입 표시가 가능한 구조\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    result: str\n",
        "    secret: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy0OiRSOrDMg"
      },
      "source": [
        "### Node\n",
        "\n",
        "노드는 함수로 정의되는데, 주로 하나의 모듈을 하나의 노드로 구성합니다.   \n",
        "State는 노드를 지나며 새로운 정보를 추가하거나, 값을 수정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLxb0OgPrDMg"
      },
      "outputs": [],
      "source": [
        "# state에 문자열을 추가하는 노드\n",
        "def first(state):\n",
        "    print(\"---Node 1---\")\n",
        "    return {\"result\": state['result'] +\"랭그래프 1번 노드 통과\\n\"}\n",
        "\n",
        "def second(state):\n",
        "    print(\"---Node 2---\")\n",
        "    return {\"result\": state['result'] +\"랭그래프 2번 노드 통과\\n\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq9xwXDArDMg"
      },
      "source": [
        "### Edge와 Graph   \n",
        "\n",
        "위에서 설정한 State를 이용하여 Graph를 정의합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRTveKMvrDMg"
      },
      "source": [
        "그래프에 노드와 엣지를 추가합니다.    \n",
        "START와 END를 import하고, 시작점과 끝점을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmgnv9JirDMg"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# 그래프 정의하기\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# 노드 이름과 함수 이름은 같지 않아도 됨\n",
        "builder.add_node(\"first\", first)\n",
        "builder.add_node(\"second\", second)\n",
        "\n",
        "builder.add_edge(START, \"first\")\n",
        "builder.add_edge(\"first\", \"second\")\n",
        "builder.add_edge(\"second\", END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNPXjlONrDMg"
      },
      "source": [
        "만든 그래프는 `compile()`을 통해 실행 가능한 Runnable 구조로 만들어집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM2Mh4AurDMg"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "\n",
        "graph\n",
        "# 간단한 Mermaid 기반의 시각화 지원"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1ixQ8I6rDMg"
      },
      "source": [
        "구성된 graph를 실행해 보겠습니다!   \n",
        "state의 초기 상태를 Dictionary 형태로 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuREzEh_rDMg"
      },
      "outputs": [],
      "source": [
        "response = graph.invoke({'result':'시작!\\n', 'secret':'비밀'})\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2dxUlJprDMg"
      },
      "source": [
        "## 그래프에 LLM 포함시키기\n",
        "이번에는 값이 여러 개인 State를 구성하고, 그래프로 만들어 보겠습니다.   \n",
        "llm도 활용해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGoAhLcArDMg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIxxx'\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    # temperature\n",
        "    # max_tokens\n",
        "\n",
        "    thinking_budget = 500  # 추론(Reasoning) 토큰 길이 제한\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeVNjKtUrDMg"
      },
      "source": [
        "3개의 요소가 포함된 State를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NexQyV2prDMh"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    integer: int\n",
        "    root: int\n",
        "    joke: str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGJfcojyrDMh"
      },
      "source": [
        "2개의 노드를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLK5UYLlrDMh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def get_root(state):\n",
        "    return {\"root\": int(state[\"integer\"] ** 0.5)}\n",
        "\n",
        "def get_joke(state):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '당신은 언어 유희의 달인입니다.'),\n",
        "         ('user','{length} 문장 길이의 짧은 영어 유머를 만들어주세요. 각 문장마다 숫자를 붙이세요.')\n",
        "    ])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"joke\": chain.invoke({'length':state['root']})}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzvSGtVkrDMh"
      },
      "source": [
        "그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jSfnN95rDMh"
      },
      "outputs": [],
      "source": [
        "# 그래프 구성\n",
        "# 이미 존재하는 노드를 또 만들면 에러가 발생할 수 있으므로\n",
        "# 그래프를 수정할 때에는 builder 초기화부터 꼭 하기\n",
        "\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"get_root\", get_root)\n",
        "builder.add_node(\"get_joke\", get_joke)\n",
        "\n",
        "builder.add_edge(START, \"get_root\")\n",
        "builder.add_edge(\"get_root\", \"get_joke\")\n",
        "builder.add_edge(\"get_joke\", END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xANgxFgVrDMh"
      },
      "source": [
        "그래프를 컴파일하고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y--knEeLrDMh"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrBsmHcHrDMh"
      },
      "outputs": [],
      "source": [
        "initial_state = {'integer': 16}\n",
        "response = graph.invoke(initial_state)\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbboFf3nrDMh"
      },
      "source": [
        "### 웹 검색 노드 만들기   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCTsYQR-rDMh"
      },
      "source": [
        "이번 실습에서는 웹 검색 툴 결과를 바탕으로, 실제 URL을 크롤링하여 문서의 내용을 가져오겠습니다.   \n",
        "\n",
        "랭체인에서 웹 페이지를 크롤링하기 위해서는 대표적으로 아래 3개의 방법을 사용할 수 있습니다.\n",
        "\n",
        "1. `WebBaseLoader` : BeautifulSoup4 기반의 기본 크롤러로, HTML 코드를 그대로 가져옵니다.\n",
        "2. `Docling` : 다양한 포맷의 문서를 텍스트 포맷으로 변환하는 오픈 소스 프로젝트로, 유용하나 빠른 실행을 위해 GPU 성능이 다소 요구됩니다.\n",
        "3. `FireCrawl`: API 기반의 유료 서비스로, 무료 라이센스는 총 500회 무료 사용이 가능합니다.   \n",
        "WebBaseLoader를 사용하겠습니다 :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PUi6xqWrDMh"
      },
      "outputs": [],
      "source": [
        "os.environ['TAVILY_API_KEY'] = 'tvly-xxxx'\n",
        "os.environ['USER_AGENT'] = 'MyAgent'\n",
        "\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "def tavily_search(State):\n",
        "    tavily_search = TavilySearch(max_results=5)\n",
        "\n",
        "    # 검색 결과 수집\n",
        "    search_results = tavily_search.invoke({'query': State['query']})['results']\n",
        "    # search_results : url, Content 형식의 Dict List Return\n",
        "\n",
        "    # URL 리스트 추출 (PDF 주소는 제외)\n",
        "    urls = [result['url'] for result in search_results if 'pdf' not in result['url']]\n",
        "\n",
        "\n",
        "    try:\n",
        "        loader = WebBaseLoader(urls)\n",
        "    except:\n",
        "        loader = WebBaseLoader(urls, requests_kwargs={'verify':False})\n",
        "\n",
        "    documents = loader.load()\n",
        "    return {'context': documents}\n",
        "\n",
        "result = tavily_search({'query': '멀티 에이전트 구조'})\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2BswHqhrDMh"
      },
      "outputs": [],
      "source": [
        "def get_query(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "         ('user','''{question}에 답변하기 위해\n",
        "인터넷 검색을 사용하려고 합니다.\n",
        "적절한 검색어 쿼리를 하나만 출력하세요.\n",
        "쿼리만 출력하세요.''')\n",
        "    ])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"query\": chain.invoke(State)}\n",
        "    # State를 모두 입력해도, Prompt Template에 포함된 입력변수만 전달\n",
        "\n",
        "\n",
        "def answer_question(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
        "다음의 Context를 이용하여 Question에 답변하세요.\n",
        "정확한 답변을 제공하세요.\n",
        "만약 모든 Context를 다 확인해도 정보가 없다면,\n",
        "\"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.'''),\n",
        "\n",
        "        ('user', '''Context: {context}\n",
        "---\n",
        "Question: {question}''')])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"answer\": chain.invoke(State)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scIrzxLMrDMi"
      },
      "source": [
        "State를 만들고, 그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUzOx5WrrDMi"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    question : str # 유저의 질문\n",
        "    query: str # 질문에서 파생된 검색어\n",
        "    answer: str # 답변\n",
        "    context: str # 검색 결과\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-taG6FMMrDMi"
      },
      "outputs": [],
      "source": [
        "# 그래프 구성\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"get_query\", get_query)\n",
        "builder.add_node(\"tavily_search\", tavily_search)\n",
        "builder.add_node(\"answer_question\", answer_question)\n",
        "\n",
        "builder.add_edge(START, \"get_query\")\n",
        "builder.add_edge(\"get_query\", \"tavily_search\")\n",
        "builder.add_edge(\"tavily_search\", \"answer_question\")\n",
        "builder.add_edge(\"answer_question\", END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUUJS6x9rDMi"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u2IrFvkrDMi"
      },
      "outputs": [],
      "source": [
        "result = graph.invoke({'question': 'Qwen 3 Omni 는 어떤 모델이야?'})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4C0YX4crDMi"
      },
      "source": [
        "전체 결과가 잘 실행되었지만, 중간 결과가 보고 싶다면 어떻게 해야 할까요?   \n",
        "이후에 배울 `LangSmith`를 통해 트래킹할 수도 있고, 아래의 코드로 각 단계를 스트리밍할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39uRgYljrDMk"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "# Streaming 참고\n",
        "# https://langchain-ai.github.io/langgraph/concepts/streaming/#streaming-graph-outputs-stream-and-astream\n",
        "\n",
        "for data in graph.stream({'question': '스탠포드의 멀티 에이전트 STORM 구조가 뭐야?'},\n",
        "                         stream_mode='updates'):\n",
        "    pprint.pprint(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ISOtMiqrDMk"
      },
      "source": [
        "결과는 잘 나왔지만, 위 검색 결과를 보면 전처리가 많이 필요하거나, 프롬프트에 포함하지 않아도 되는 검색 결과들이 다소 존재할 수 있습니다.  \n",
        "\n",
        "\n",
        "\n",
        "더 효과적인 어플리케이션을 구성한다면, 검색 결과를 검증하여 불필요한 토큰을 줄일 수 있겠습니다.   \n",
        "\n",
        "<br><br>\n",
        "이번 실습에서는 단순한 일직선 형태의 Flow를 그래프로 만들었기 때문에 위 작업들을 수행하지 않았지만,    \n",
        "LangGraph의 기능을 활용하면 반복, 분기점, 중단 및 사용자의 중간 개입과 같은 요소들을 효율적으로 포함할 수 있습니다.    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALfVkuR-YEWj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

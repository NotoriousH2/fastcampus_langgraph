{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bc217b6",
      "metadata": {
        "id": "1bc217b6"
      },
      "source": [
        "# [실습] LangChain Tool Call과 Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478a9e3f",
      "metadata": {
        "id": "478a9e3f"
      },
      "source": [
        "LangChain의 기본 코드를 통해, Tool Call과 Agent가 작동하는 과정에 대해 알아보겠습니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479674c4",
      "metadata": {
        "vscode": {
          "languageId": "sql"
        },
        "id": "479674c4"
      },
      "source": [
        "기본 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9a52c8",
      "metadata": {
        "id": "0f9a52c8"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain_google_genai langchain_core langchain_community tavily-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3abe77a5",
      "metadata": {
        "id": "3abe77a5"
      },
      "source": [
        "Google API Key를 설정합니다.\n",
        "\n",
        "구글 로그인 후, https://aistudio.google.com/apikey 에서 발급받을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b75f0d",
      "metadata": {
        "id": "a4b75f0d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c00b11f",
      "metadata": {
        "id": "9c00b11f"
      },
      "source": [
        "Gemini 모델을 설정합니다.   \n",
        "무료 API의 경우 분당 제한이 존재하므로, 랭체인의 Rate Limiter를 적용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a15227",
      "metadata": {
        "id": "c2a15227"
      },
      "outputs": [],
      "source": [
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    # temperature\n",
        "    # max_tokens\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"안녕? 너는 이름이 뭐니? 한 문장으로 말해줘.\")"
      ],
      "metadata": {
        "id": "nBoYN4ObylGi"
      },
      "id": "nBoYN4ObylGi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "71e0a44d",
      "metadata": {
        "id": "71e0a44d"
      },
      "source": [
        "`invoke()`를 통해 llm에 입력을 전달합니다.    \n",
        "랭체인 기본 클래스인 `Message` 계열 클래스를 직접 만들어 리스트로 전달하거나,   \n",
        "프롬프트 템플릿을 통해 입력의 구성을 만들어 전달할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1280e1b",
      "metadata": {
        "id": "b1280e1b"
      },
      "outputs": [],
      "source": [
        "# 1. HumanMessage를 이용한 방법\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "system_msg = SystemMessage(content=\"\"\"사용자의 아래 [질문]에 대해 친절하게 답변하세요.\n",
        "답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.\"\"\")\n",
        "msg = HumanMessage(content=\"안녕! 너는 이름이 뭐니?\")\n",
        "\n",
        "messages = [system_msg, msg]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea0668f",
      "metadata": {
        "id": "fea0668f"
      },
      "source": [
        "Chat 모델의 출력은 AIMessage라는 형식으로 변환됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4a09cc",
      "metadata": {
        "id": "bb4a09cc"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b620e2b1",
      "metadata": {
        "id": "b620e2b1"
      },
      "outputs": [],
      "source": [
        "# 2. ChatPromptTemplate을 이용한 방법\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 입력 변수가 {question}인 템플릿\n",
        "prompt = ChatPromptTemplate([\n",
        "    ('system', '''사용자의 아래 [질문]에 대해 친절하게 답변하세요.\n",
        "     답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.'''),\n",
        "     ('user', '''[질문]: {question}''')])\n",
        "prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1bdd2bb",
      "metadata": {
        "id": "e1bdd2bb"
      },
      "source": [
        "프롬프트와 llm을 |로 연결하여 체인을 구성합니다.   \n",
        "(랭체인 기본 문법으로, LangChain 기초 복습 자료에서 자세히 보실 수 있습니다!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7477bb",
      "metadata": {
        "id": "6c7477bb"
      },
      "outputs": [],
      "source": [
        "chain = prompt | llm\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4567c80e",
      "metadata": {
        "id": "4567c80e"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke({'question':\"랭체인과 랭그래프의 차이가 뭐야?\"})\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d11182f",
      "metadata": {
        "id": "5d11182f"
      },
      "outputs": [],
      "source": [
        "# 입력 변수가 1개일 때는 값만 invoke해도 됨\n",
        "\n",
        "response = chain.invoke(\"패스트캠퍼스 랭그래프 강의 이름이 뭐야?\")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec0bb92a",
      "metadata": {
        "id": "ec0bb92a"
      },
      "source": [
        "존재하지 않는 내용에 대한 환각이 발생한 모습입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad0069a",
      "metadata": {
        "id": "3ad0069a"
      },
      "source": [
        "## LLM Tool 설정하기\n",
        "\n",
        "Tool은 LLM이 사용할 수 있는 다양한 외부 기능을 의미합니다.   \n",
        "LangChain에서 자체적으로 지원하는 Tool을 사용하거나, RAG의 Retriever를 Tool로 변환하는 것도 가능합니다.     \n",
        "또한, 함수를 Tool로 변환할 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4661f0a",
      "metadata": {
        "id": "e4661f0a"
      },
      "source": [
        "1. Tavily Search (http://app.tavily.com/)\n",
        "\n",
        "Tavily는 AI 기반의 검색 엔진입니다. 계정별 월 1000개의 무료 사용량을 지원합니다.      \n",
        "Tavily Search는 URL과 함께 내용의 간단한 요약을 지원하는 것이 특징입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091dff13",
      "metadata": {
        "id": "091dff13"
      },
      "outputs": [],
      "source": [
        "os.environ['TAVILY_API_KEY'] = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d69da9",
      "metadata": {
        "id": "52d69da9"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_search = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    )\n",
        "tavily_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06f87e6",
      "metadata": {
        "id": "d06f87e6"
      },
      "outputs": [],
      "source": [
        "search_docs = tavily_search.invoke(\"랭그래프와 랭체인의 차이\")\n",
        "search_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144a8cfb",
      "metadata": {
        "id": "144a8cfb"
      },
      "source": [
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b84ff85",
      "metadata": {
        "id": "4b84ff85"
      },
      "source": [
        "# LLM에 Tool 연결하기   \n",
        "\n",
        "생성한 툴은 llm.bind_tools()를 통해 LLM에 연결할 수 있습니다.    \n",
        "이 기능은 Gemini, GPT, Claude 등의 툴에서 지원하는데요.     \n",
        "HuggingFace 공개 모델에서 Tool을 사용하는 경우는 이후 실습에서 자세히 알아보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f9f905",
      "metadata": {
        "id": "35f9f905"
      },
      "outputs": [],
      "source": [
        "tools = [tavily_search]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "llm_with_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50a0b273",
      "metadata": {
        "id": "50a0b273"
      },
      "source": [
        "랭체인에서, tool 정보는 tools에 저장되는데요.   \n",
        "해당 내용은 랭체인 내부에서 json Schema 형식으로 프롬프트에 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ed35d6",
      "metadata": {
        "id": "52ed35d6"
      },
      "outputs": [],
      "source": [
        "# 시스템 메시지에 포함되는 내용\n",
        "# (`LLM과 Agent` 강의 슬라이드를 참고하세요!)\n",
        "\n",
        "llm_with_tools.kwargs['tools']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "291ee797",
      "metadata": {
        "id": "291ee797"
      },
      "source": [
        "LLM은 프롬프트로 주어지는 툴 정보를 바탕으로 Tool의 사용을 결정합니다.    \n",
        "Schema를 통해, 툴의 의미와 사용 방법, 형식을 이해합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd923172",
      "metadata": {
        "id": "cd923172"
      },
      "source": [
        "이후, LLM은 Tool 사용이 필요한 경우 특별한 포맷의 메시지를 출력합니다.   \n",
        "이를 Tool Call Message라고 부릅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ddf7c84",
      "metadata": {
        "id": "6ddf7c84"
      },
      "outputs": [],
      "source": [
        "tool_chain = prompt | llm_with_tools\n",
        "tool_call_msg = tool_chain.invoke(\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\")\n",
        "tool_call_msg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0857ca4",
      "metadata": {
        "id": "d0857ca4"
      },
      "outputs": [],
      "source": [
        "tool_call_msg = llm_with_tools.invoke(\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정인지 검색해서 알려줘\")\n",
        "tool_call_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80472b96",
      "metadata": {
        "id": "80472b96"
      },
      "outputs": [],
      "source": [
        "tool_call_msg.tool_calls\n",
        "# 리스트 형식인 이유는? 여러 개의 툴을 동시에 사용할 수 있기 때문"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d6bd19",
      "metadata": {
        "id": "71d6bd19"
      },
      "source": [
        "`tool_calls`에 포함된 name을 활용하면 툴 결과를 전달할 수 있습니다.   \n",
        "`name` 값은 문자열이므로, dictionary를 통해 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9595fda",
      "metadata": {
        "id": "f9595fda"
      },
      "outputs": [],
      "source": [
        "tool_list ={'tavily_search_results_json': tavily_search}\n",
        "\n",
        "tool_name = tool_call_msg.tool_calls[0]['name']\n",
        "tool_exec = tool_list[tool_name]\n",
        "\n",
        "tool_name, tool_exec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3496b492",
      "metadata": {
        "id": "3496b492"
      },
      "source": [
        "Tool에 tool_call을 입력해 invoke를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f582c143",
      "metadata": {
        "id": "f582c143"
      },
      "outputs": [],
      "source": [
        "tool_msg = tool_exec.invoke(tool_call_msg.tool_calls[0])\n",
        "tool_msg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6bb8aaf",
      "metadata": {
        "id": "e6bb8aaf"
      },
      "source": [
        "이번에는 ToolMessage라는 새로운 형태의 메시지가 생성되었습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782933c1",
      "metadata": {
        "id": "782933c1"
      },
      "source": [
        "툴 실행 결과를 LLM에게 다시 전달하여, 이를 해석하고 답변하게 만들어 보겠습니다.   \n",
        "\n",
        "Chain 형식의 구성은 메시지를 변화시키는 것이 복잡하므로, 이전에 사용했던 `HumanMessage`에서 시작하여   \n",
        "LLM의 답변인 `AIMessage`와 `ToolMessage` 를 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613a7da6",
      "metadata": {
        "id": "613a7da6"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "messages = [HumanMessage(content=\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\")]\n",
        "\n",
        "messages.append(tool_call_msg)\n",
        "messages.append(tool_msg)\n",
        "\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca501e7",
      "metadata": {
        "id": "2ca501e7"
      },
      "outputs": [],
      "source": [
        "print(messages[2].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae6c7f1a",
      "metadata": {
        "id": "ae6c7f1a"
      },
      "source": [
        "`Query-Tool Call-Tool`의 형식은 가장 기본적인 툴 사용 방법입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b67cf9",
      "metadata": {
        "id": "43b67cf9"
      },
      "outputs": [],
      "source": [
        "result = llm_with_tools.invoke(messages)\n",
        "# 검색 결과를 바탕으로 답변한 모습\n",
        "\n",
        "print(result.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a13f430",
      "metadata": {
        "id": "8a13f430"
      },
      "source": [
        "이제, 지금까지 배운 내용을 종합하여 실행해 보겠습니다.   \n",
        "질문이 주어지면, 질문에 대한 검색을 수행하여 결과를 바탕으로 답변합니다.   \n",
        "\n",
        "<br><br>\n",
        "\n",
        "그런데, 이번에는 분기가 필요합니다.   \n",
        "검색이 필요없는 질문이라면, LLM은 tool을 요청하지 않을 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e288199c",
      "metadata": {
        "id": "e288199c"
      },
      "outputs": [],
      "source": [
        "# LLM, Question, Tool을 이용한 간단한 함수\n",
        "def simple_workflow(llm, question , tools = [tavily_search]):\n",
        "\n",
        "    # 툴과 LLM 구성\n",
        "\n",
        "    tool_list = {x.name: x for x in tools}\n",
        "    # tavily_search.name = 'tavily_search_results_json' 을 이용하면\n",
        "    # tool_list = {'tavily_search_results_json': tavily_search} 와 동일합니다.\n",
        "\n",
        "    llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "    # 메시지 구성\n",
        "    messages = [HumanMessage(content=question)]\n",
        "    print('Query:', question)\n",
        "\n",
        "\n",
        "    # LLM에 메시지 전달 (분기)\n",
        "    tool_msg = llm_with_tools.invoke(question)\n",
        "    messages.append(tool_msg)\n",
        "\n",
        "    if tool_msg.tool_calls:\n",
        "        # 툴 호출이 있을 경우: 툴 실행 후 결과를 전달\n",
        "        tool_name = tool_msg.tool_calls[0]['name']\n",
        "\n",
        "        print(f\"-- {tool_name} 사용 중 --\")\n",
        "        print(tool_msg.tool_calls[0])\n",
        "\n",
        "\n",
        "        tool_exec = tool_list[tool_name]\n",
        "\n",
        "        tool_result = tool_exec.invoke(tool_msg.tool_calls[0])\n",
        "        messages.append(tool_result)\n",
        "        result = llm_with_tools.invoke(messages)\n",
        "\n",
        "    else:\n",
        "        # 툴 호출이 없을 경우: 처음 출력을 그대로 전달\n",
        "        result = tool_msg\n",
        "\n",
        "    return result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abf28c6f",
      "metadata": {
        "id": "abf28c6f"
      },
      "outputs": [],
      "source": [
        "response = simple_workflow(llm, \"2025년 1월 출시된 딥시크의 언어 모델 이름이 뭐야?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7536b3b4",
      "metadata": {
        "id": "7536b3b4"
      },
      "source": [
        "# Custom Tool 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90ba141",
      "metadata": {
        "id": "a90ba141"
      },
      "source": [
        "Tavily Search의 경우, 랭체인에서 사전에 구성한 기본 Schema가 존재하지만,   \n",
        "\n",
        "Tool을 새로 만드는 경우에는 description과 같은 값을 직접 구성해야 합니다.   \n",
        "가장 간단한 방식은 랭체인의 Tool 데코레이터를 사용하는 것입니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb6c405",
      "metadata": {
        "id": "3eb6c405"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(x:int, y:int) -> int:\n",
        "    \"x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.\"\n",
        "    return x*y\n",
        "\n",
        "@tool\n",
        "def current_date() -> str:\n",
        "    \"현재 날짜를 %y-%m-%d 형식으로 반환합니다.\"\n",
        "    from datetime import datetime\n",
        "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "print(multiply.invoke({'x':3, 'y':4}))\n",
        "print(current_date.invoke({}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35816c99",
      "metadata": {
        "id": "35816c99"
      },
      "outputs": [],
      "source": [
        "tools = [tavily_search, multiply, current_date]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "nn0QaVEs5fYb"
      },
      "id": "nn0QaVEs5fYb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4da3bb1",
      "metadata": {
        "id": "b4da3bb1"
      },
      "outputs": [],
      "source": [
        "question = '오늘 날짜는?'\n",
        "\n",
        "result = simple_workflow(llm, question, tools)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ee0e6c",
      "metadata": {
        "id": "f4ee0e6c"
      },
      "outputs": [],
      "source": [
        "# LLM은 오늘 날짜를 모른다\n",
        "llm.invoke('오늘 날짜는?').content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f57f601",
      "metadata": {
        "id": "8f57f601"
      },
      "source": [
        "<br><br>\n",
        "## [연습문제] 복권 숫자 예측시키기\n",
        "\n",
        "아래의 함수에 대해, 함수의 설명을 추가하여 llm의 툴로 전달해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080e67e9",
      "metadata": {
        "id": "080e67e9"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import random\n",
        "\n",
        "@tool\n",
        "def generate_random_numbers(min_val: int, max_val: int, count: int) -> List[int]:\n",
        "    \"\"\"주어진 범위 내에서 지정된 개수만큼의 중복되지 않은 랜덤 정수를 생성합니다.\n",
        "    Args:\n",
        "        min_val (int): 최솟값\n",
        "        max_val (int): 최댓값\n",
        "        count (int): 생성할 숫자의 개수\n",
        "\n",
        "    Returns:\n",
        "        List[int]: 중복되지 않은 랜덤 정수들의 리스트\n",
        "    \"\"\"\n",
        "    # possible_range = max_val - min_val + 1\n",
        "    # if count > possible_range:\n",
        "    #     raise ValueError(f\"생성 가능한 숫자의 범위({possible_range}개)보다 더 많은 숫자({count}개)를 요청했습니다.\")\n",
        "\n",
        "    return str(random.sample(range(min_val, max_val + 1), count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44141920",
      "metadata": {
        "id": "44141920"
      },
      "outputs": [],
      "source": [
        "# LLM에 함수 Bind\n",
        "\n",
        "llm_lotto = llm.bind_tools([generate_random_numbers])\n",
        "llm_lotto.invoke('로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a72060",
      "metadata": {
        "id": "a5a72060"
      },
      "outputs": [],
      "source": [
        "# simple_workflow 함수를 이용하여 실행하기\n",
        "\n",
        "simple_workflow(llm_lotto, '로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.', [generate_random_numbers])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c9696e",
      "metadata": {
        "id": "c9c9696e"
      },
      "source": [
        "우리가 만든 `simple_workflow` 함수는 가장 간단한 형태의 Single Tool Calling을 수행하는 방식이었는데요.   \n",
        "\n",
        "실제 환경의 시나리오는 훨씬 복잡합니다.   \n",
        "한 번에 여러 개의 툴을 실행하거나, 툴 실행 결과를 받아 다음 툴에 활용할 수도 있을 것입니다.   \n",
        "\n",
        "랭체인에서도 이와 같이 복잡한 작업을 수행하기 위한 기능이 자체적으로 구현되어 있는데요.    \n",
        "\n",
        "예시로 `Structured Chat Agent`를 간단하게 만들고 실행해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7c8ac8",
      "metadata": {
        "id": "9f7c8ac8"
      },
      "source": [
        "# Agent\n",
        "\n",
        "생각-행동-관찰을 거치는 ReAct 에이전트는 복잡한 플로우를 효과적으로 처리합니다.   \n",
        "- 생각(Thought): 주어진 Context 상에서 다음 작업을 어떻게 수행할지 설명하는 과정\n",
        "- 행동(Action): Tool 실행 명령어를 생성하는 과정\n",
        "- 관찰(Thought): Tool 결과를 Context에 추가하는 과정\n",
        "\n",
        "\n",
        "이 과정은 랭체인에 구성된 `create_structured_chat_agent`를 이용해 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08100d1",
      "metadata": {
        "id": "d08100d1"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "agent_prompt = ChatPromptTemplate([\n",
        "    ('system','''\n",
        "최대한 정확히 질문에 답변하세요. 당신은 다음의 툴을 사용할 수 있습니다:\n",
        "{tools}\n",
        "\n",
        "action 키 (tool name)와 action_input 키를 포함하는 json 형태로 출력하세요.\n",
        "\n",
        "action의 값은 \"Final Answer\" 또는 {tool_names} 중 하나여야 합니다.\n",
        "반드시 하나의 json 형태만 출력하세요. 다음은 예시입니다.\n",
        "```\n",
        "{{\n",
        "\n",
        "  \"action\": $TOOL_NAME,\n",
        "\n",
        "  \"action_input\": $INPUT\n",
        "\n",
        "}}\n",
        "```\n",
        "\n",
        "아래의 포맷으로 답변하세요.:\n",
        "\n",
        "Question: 최종적으로 답변해야 하는 질문\n",
        "Thought: 무엇을 해야 하는지를 항상 떠올리세요.\n",
        "Action:\n",
        "```\n",
        "$JSON_BLOB\n",
        "```\n",
        "Observation: 액션의 실행 결과\n",
        "... (이 Thought/Action/Observation 은 10번 이내로 반복될 수 있습니다.)\n",
        "\n",
        "Thought: 이제 답을 알겠다!\n",
        "Action:\n",
        "```\n",
        "{{\n",
        "  \"action\": \"Final Answer\",\n",
        "  \"action_input\": \"Final response to human\"\n",
        "}}\n",
        "```\n",
        "'''),\n",
        "('user','''Question: {input}\n",
        "Thought: {agent_scratchpad}''')])\n",
        "\n",
        "\n",
        "agent = create_structured_chat_agent(llm, tools, agent_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef500238",
      "metadata": {
        "id": "ef500238"
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True\n",
        ")\n",
        "\n",
        "agent_executor.invoke({'input':\"Open Source Multimodal LLM Model 추천해줘\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FfADsU3v7Rgu"
      },
      "id": "FfADsU3v7Rgu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e00b3e",
      "metadata": {
        "id": "53e00b3e"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({'input':\"레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e2c8f4",
      "metadata": {
        "id": "84e2c8f4"
      },
      "source": [
        "랭체인의 에이전트 구조는 매우 간결하지만, 컨트롤하기가 매우 어려운데요.    \n",
        "실제로 우리가 개발하는 구조에서는, 모든 단계에서 LLM이 컨텍스트를 저장하여 판단을 내릴 필요는 없습니다.   \n",
        "또한, 모든 과정이 자연어로 구성되기 때문에 중간에 파싱 오류가 발생하는 경우에 동작이 멈추기도 합니다.   \n",
        "\n",
        "\n",
        "특정 작업을 반복 실행하거나, 정해진 순서에 따라 실행해야 하는 상황이라면 어떻게 해야 할까요?    \n",
        "랭체인으로 이와 같은 기능을 구현하는 것도 가능하지만, 다소 복잡한데요.   \n",
        "\n",
        "\n",
        "랭그래프를 이용하면 구체적인 Workflow를 바탕으로 Agent 형태의 어플리케이션을 효과적으로 만들 수 있습니다.   \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "multicampus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
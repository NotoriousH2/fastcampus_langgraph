{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSLKeXElpujP"
      },
      "source": [
        "# [프로젝트] 멀티모달 데이터를 처리하는 RAG- Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCENQzkPpujQ"
      },
      "source": [
        "질문에 대한 맥락을 검색하여 LLM에 전달하는 RAG는 이미지/표와 같은 데이터를 처리하기 어렵다는 단점이 있습니다.   \n",
        "\n",
        "Gemini와 같은 멀티모달 모델을 통해, Docling으로 불러온 이미지/표의 정보를 텍스트로 변환해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이를 통해, 텍스트 이외에 이미지의 캡션을 포함한 DB를 구성하여 RAG를 수행합니다.\n",
        "\n",
        "![Image](https://github.com/user-attachments/assets/568ae91a-efb4-4492-bd0b-a492d3e2385c)"
      ],
      "metadata": {
        "id": "Ccj2c1zbpzhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU 클라우드 T4를 설정해 주세요!**"
      ],
      "metadata": {
        "id": "7eKsFGknp1hL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KVSZxMupujQ"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph dotenv docling google-generativeai langchain_huggingface sentence_transformers jsonlines langchain langchain-google-genai langchain-community langchain_chroma chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "설치 후 세션을 재시작합니다.    \n",
        "\n",
        "**Gemini 실행을 위해, .env 파일도 업로드해 주세요!**"
      ],
      "metadata": {
        "id": "Dlnr-tgfp6WI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89aqBlRMpujQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import base64\n",
        "import logging\n",
        "import time\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "from typing_extensions import TypedDict, List, Dict, Any, Optional, Union, Literal\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# 랭그래프 및 랭체인 임포트\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Docling 관련 임포트\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
        "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
        "\n",
        "# 벡터 저장소 및 임베딩 관련 임포트\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# LLM 임포트\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# 텍스트 처리 관련 임포트\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# 환경 변수 로드\n",
        "load_dotenv()\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# 상수 정의\n",
        "IMAGE_RESOLUTION_SCALE = 2.0  # 이미지 해상도 배율\n",
        "OUTPUT_DIR = \"mm_rag_output\"  # 출력 디렉토리\n",
        "CHUNK_SIZE = 4000  # 텍스트 청크 크기\n",
        "CHUNK_OVERLAP = 400  # 텍스트 청크 오버랩\n",
        "\n",
        "# 캡션 생성을 위한 앞뒤 컨텍스트 크기(각각)\n",
        "CONTEXT_BEFORE_SIZE = 2000\n",
        "CONTEXT_AFTER_SIZE = 2000\n",
        "\n",
        "\n",
        "\n",
        "# LLM 및 임베딩 모델 초기화\n",
        "def initialize_models():\n",
        "    \"\"\"LLM과 임베딩 모델을 초기화하는 함수\"\"\"\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-small\")\n",
        "    return llm, embeddings\n",
        "\n",
        "llm, embeddings = initialize_models()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtwTg_DypujQ"
      },
      "outputs": [],
      "source": [
        "class ImageItem(TypedDict):\n",
        "    image_id: str       # 이미지 고유 ID\n",
        "    path: str           # 이미지 파일 경로\n",
        "    context_before: str # 이미지 앞 텍스트\n",
        "    context_after: str  # 이미지 뒤 텍스트\n",
        "    importance_score: float  # 중요도 점수\n",
        "    caption: str # 생성된 캡션\n",
        "\n",
        "class TextChunk(TypedDict):\n",
        "    chunk_id: str       # 청크 고유 ID\n",
        "    content: str        # 청크 내용\n",
        "\n",
        "class State(TypedDict):\n",
        "    # 문서 정보\n",
        "    file_path: str  # 파일 경로\n",
        "    url: str  # 원본 URL (있는 경우)\n",
        "    md_path: str # 마크다운 파일 경로\n",
        "    error: str    # 오류 메시지\n",
        "\n",
        "    # 핵심 콘텐츠\n",
        "    text_chunks: List[TextChunk]  # 텍스트 청크 목록\n",
        "    images: List[ImageItem]       # 이미지 목록\n",
        "\n",
        "    # 상태 관리\n",
        "    current_step: str    # 현재 처리 단계\n",
        "    errors: List[str]   # 오류 메시지 목록\n",
        "    vectordb_path: str  # 벡터DB 저장 경로\n",
        "\n",
        "# 이미지 중요도 평가 출력 스키마\n",
        "class ImageImportanceResult(BaseModel):\n",
        "    \"\"\"이미지 중요도 평가 결과 스키마\"\"\"\n",
        "    importance_score: float = Field(description=\"이미지의 중요도 점수 (0.0~1.0)\")\n",
        "    reasoning: str = Field(description=\"중요도 평가의 근거\")\n",
        "    is_important: bool = Field(description=\"이미지가 중요한지 여부 (True/False)\")\n",
        "\n",
        "# 이미지 캡션 출력 스키마\n",
        "class ImageCaptionResult(BaseModel):\n",
        "    \"\"\"이미지 캡션 생성 결과 스키마\"\"\"\n",
        "    caption: str = Field(description=\"이미지에 대한 상세한 설명\")\n",
        "    key_elements: List[str] = Field(description=\"이미지에서 식별된 주요 요소 목록\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urpuF3FUpujR"
      },
      "outputs": [],
      "source": [
        "# 초기 상태 생성 함수\n",
        "def create_initial_state(file_path: str) -> State:\n",
        "    \"\"\"초기 상태를 생성하는 함수\"\"\"\n",
        "    return {\n",
        "        # 문서 정보\n",
        "        \"file_path\": file_path,\n",
        "        \"url\": file_path if file_path.startswith(\"http\") else None,\n",
        "        \"md_path\": None,\n",
        "        \"error\": None,\n",
        "\n",
        "        # 콘텐츠\n",
        "        \"text_chunks\": [],\n",
        "        \"images\": [],\n",
        "\n",
        "        # 상태 관리\n",
        "        \"current_step\": \"initialized\",\n",
        "        \"errors\": [],\n",
        "        \"vectordb_path\": None\n",
        "    }\n",
        "\n",
        "# Docling 문서 처리 함수\n",
        "def process_document(state: State) -> State:\n",
        "    \"\"\"PDF 문서를 처리하여 마크다운 및 이미지로 변환\"\"\"\n",
        "    try:\n",
        "        doc_path = state[\"file_path\"]\n",
        "        is_url = doc_path.startswith(\"http\")\n",
        "\n",
        "        output_dir = Path(OUTPUT_DIR)\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # 파이프라인 옵션 설정\n",
        "        pipeline_options = PdfPipelineOptions()\n",
        "        pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
        "        pipeline_options.generate_page_images = True\n",
        "        pipeline_options.generate_picture_images = True\n",
        "\n",
        "        # 변환기 초기화\n",
        "        doc_converter = DocumentConverter(\n",
        "            format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}\n",
        "        )\n",
        "\n",
        "        # 문서 변환\n",
        "        logger.info(f\"문서 변환 중: {doc_path}\")\n",
        "        if is_url:\n",
        "            conv_res = doc_converter.convert(doc_path)\n",
        "        else:\n",
        "            conv_res = doc_converter.convert(Path(doc_path))\n",
        "\n",
        "        doc_filename = Path(doc_path).stem if not is_url else doc_path.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        # 마크다운 저장\n",
        "        md_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"\n",
        "        conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n",
        "\n",
        "        # 이미지/테이블 저장\n",
        "        table_counter = 0\n",
        "        picture_counter = 0\n",
        "        for element, _level in conv_res.document.iterate_items():\n",
        "            if isinstance(element, TableItem):\n",
        "                table_counter += 1\n",
        "                element_image_filename = output_dir / f\"{doc_filename}-table-{table_counter}.png\"\n",
        "                with element_image_filename.open(\"wb\") as fp:\n",
        "                    element.get_image(conv_res.document).save(fp, \"PNG\")\n",
        "\n",
        "            if isinstance(element, PictureItem):\n",
        "                picture_counter += 1\n",
        "                element_image_filename = output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"\n",
        "                with element_image_filename.open(\"wb\") as fp:\n",
        "                    element.get_image(conv_res.document).save(fp, \"PNG\")\n",
        "\n",
        "        # 상태 업데이트\n",
        "        state[\"md_path\"] = str(md_filename)\n",
        "        state[\"current_step\"] = \"document_parsed\"\n",
        "\n",
        "        logger.info(f\"문서 변환 완료: 테이블 {table_counter}개, 이미지 {picture_counter}개\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"문서 처리 오류: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state[\"error\"] = error_msg\n",
        "        state[\"errors\"].append(error_msg)\n",
        "        state[\"current_step\"] = \"error\"\n",
        "\n",
        "    return state\n",
        "\n",
        "# 텍스트 추출 함수\n",
        "def extract_text(state: State) -> State:\n",
        "    \"\"\"마크다운에서 텍스트 추출하고 청킹\"\"\"\n",
        "    try:\n",
        "        md_path = state[\"md_path\"]\n",
        "\n",
        "        if not md_path:\n",
        "            raise ValueError(\"마크다운 파일 경로가 없습니다.\")\n",
        "\n",
        "        # 마크다운 파일 읽기\n",
        "        with open(md_path, 'r', encoding='utf-8') as file:\n",
        "            markdown_text = file.read()\n",
        "\n",
        "        # 청크 분할\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            chunk_overlap=CHUNK_OVERLAP,\n",
        "        )\n",
        "\n",
        "        doc = Document(page_content=markdown_text)\n",
        "        chunks = text_splitter.split_documents([doc])\n",
        "\n",
        "        # 청크 저장\n",
        "        text_chunks = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            chunk_id = f\"chunk_{i}\"\n",
        "            text_chunks.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"content\": chunk.page_content,\n",
        "            })\n",
        "\n",
        "        state[\"text_chunks\"] = text_chunks\n",
        "        state[\"current_step\"] = \"text_extracted\"\n",
        "        logger.info(f\"텍스트 추출 완료: {len(text_chunks)}개 청크\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"텍스트 추출 오류: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state[\"errors\"].append(error_msg)\n",
        "        state[\"current_step\"] = \"error\"\n",
        "\n",
        "    return state\n",
        "\n",
        "# 이미지 추출 함수\n",
        "def extract_images(state: State) -> State:\n",
        "    \"\"\"마크다운에서 이미지 태그 및 주변 텍스트 추출\"\"\"\n",
        "    try:\n",
        "        md_path = state[\"md_path\"]\n",
        "\n",
        "        if not md_path:\n",
        "            raise ValueError(\"마크다운 파일 경로가 없습니다.\")\n",
        "\n",
        "        output_dir = Path(OUTPUT_DIR)\n",
        "\n",
        "        # 마크다운 파일 읽기\n",
        "        with open(md_path, 'r', encoding='utf-8') as file:\n",
        "            markdown_text = file.read()\n",
        "\n",
        "        # 이미지 태그 추출\n",
        "        image_pattern = r'!\\[.*?\\]\\((.*?)\\)'\n",
        "        matches = list(re.finditer(image_pattern, markdown_text))\n",
        "\n",
        "        images = []\n",
        "        for i, match in enumerate(matches):\n",
        "            image_path = match.group(1)\n",
        "            start_index = match.start()\n",
        "            end_index = match.end()\n",
        "\n",
        "            # 앞뒤 컨텍스트\n",
        "            context_before = markdown_text[max(0, start_index - CONTEXT_BEFORE_SIZE):start_index]\n",
        "            context_after = markdown_text[end_index:min(len(markdown_text), end_index + CONTEXT_AFTER_SIZE)]\n",
        "\n",
        "            full_path = str(output_dir / image_path)\n",
        "\n",
        "            images.append({\n",
        "                \"image_id\": f\"image_{i}\",\n",
        "                \"path\": full_path,\n",
        "                \"context_before\": context_before,\n",
        "                \"context_after\": context_after,\n",
        "                \"importance_score\": None,\n",
        "                \"caption\": None,\n",
        "            })\n",
        "\n",
        "        state[\"images\"] = images\n",
        "        state[\"current_step\"] = \"images_extracted\"\n",
        "        logger.info(f\"이미지 추출 완료: {len(images)}개 이미지\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"이미지 추출 오류: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state[\"errors\"].append(error_msg)\n",
        "        state[\"current_step\"] = \"error\"\n",
        "\n",
        "    return state\n",
        "\n",
        "# 이미지 필터링 및 중요도 평가 함수\n",
        "def evaluate_image_importance(state: State) -> State:\n",
        "    \"\"\"이미지의 중요도를 평가하고 필터링\"\"\"\n",
        "    try:\n",
        "        images = state[\"images\"]\n",
        "\n",
        "        if not images:\n",
        "            logger.info(\"평가할 이미지가 없습니다\")\n",
        "            state[\"current_step\"] = \"importance_evaluated\"\n",
        "            return state\n",
        "\n",
        "        importance_llm = llm.with_structured_output(ImageImportanceResult)\n",
        "\n",
        "        importance_prompt = ChatPromptTemplate([\n",
        "            (\"system\", \"\"\"당신은 문서 내 이미지의 중요도를 평가하는 전문가입니다.\n",
        "이미지와 주변 문맥을 분석하여 이미지가 얼마나 중요한지 평가해 주세요.\n",
        "해당 이미지는 이후 캡션을 생성하여 문서의 이해도를 높이는데 사용될 것입니다.\n",
        "\n",
        "다음 기준으로 이미지의 중요도를 평가하세요:\n",
        "1. 이미지가 얼마나 정보를 제공하는가?\n",
        "2. 이미지의 내용이 얼마나 명확한가?\n",
        "3. 주변의 텍스트만으로는 이해하기 어려운 시각적 정보를 포함하는가?\n",
        "\n",
        "0.0(전혀 중요하지 않음)부터 1.0(매우 중요함)까지의 점수를 부여하세요.\n",
        "0.5 이상이면 중요한 이미지로 판단합니다.\"\"\"),\n",
        "            (\"user\", [\n",
        "                {\"type\": \"text\", \"text\": \"\"\"이미지와 주변 문맥이 아래에 주어집니다. 이미지의 중요도를 평가해 주세요.\n",
        "\n",
        "이미지 전 문맥:\n",
        "{context_before}\n",
        "\n",
        "이미지 후 문맥:\n",
        "{context_after}\"\"\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"}}\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        # 이미지 평가 체인\n",
        "        evaluation_chain = importance_prompt | importance_llm\n",
        "\n",
        "        updated_images = []\n",
        "        for image in images:\n",
        "            try:\n",
        "                # 이미지 파일이 존재하는지 확인\n",
        "                if not os.path.exists(image[\"path\"]):\n",
        "                    logger.warning(f\"이미지 파일을 찾을 수 없음: {image['path']}\")\n",
        "                    image[\"importance_score\"] = 0.0\n",
        "                    updated_images.append(image)\n",
        "                    continue\n",
        "\n",
        "                # 이미지 평가\n",
        "                with open(image[\"path\"], 'rb') as img_file:\n",
        "                    img_data = base64.b64encode(img_file.read()).decode('utf-8')\n",
        "\n",
        "                # 이미지 데이터를 메시지에 포함\n",
        "                input_data = {\n",
        "                    \"context_before\": image[\"context_before\"],\n",
        "                    \"context_after\": image[\"context_after\"],\n",
        "                    \"image_data\": img_data\n",
        "                }\n",
        "\n",
        "                # 이미지가 있는 경우에만 평가 수행\n",
        "                result = evaluation_chain.invoke(input_data)\n",
        "\n",
        "                # 결과 업데이트\n",
        "                image[\"importance_score\"] = result.importance_score\n",
        "                updated_images.append(image)\n",
        "\n",
        "                logger.info(f\"이미지 평가 완료 {image['image_id']}: 점수={result.importance_score}, 중요={result.is_important}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"이미지 평가 오류 {image['image_id']}: {str(e)}\")\n",
        "                image[\"importance_score\"] = 0.0\n",
        "                updated_images.append(image)\n",
        "\n",
        "        state[\"images\"] = updated_images\n",
        "        state[\"current_step\"] = \"importance_evaluated\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"이미지 중요도 평가 오류: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state[\"errors\"].append(error_msg)\n",
        "        state[\"current_step\"] = \"error\"\n",
        "\n",
        "    return state\n",
        "\n",
        "# 이미지 중요도에 따른 라우팅 함수\n",
        "def route_by_importance(state: State) -> Literal[\"generate_captions\", \"skip_captions\"]:\n",
        "    \"\"\"중요한 이미지가 있는지 확인하고 경로 결정\"\"\"\n",
        "    images = state[\"images\"]\n",
        "    important_images = [img for img in images if img.get(\"importance_score\", 0) >= 0.7]\n",
        "\n",
        "    if important_images:\n",
        "        logger.info(f\"중요 이미지 {len(important_images)}개 발견, 캡션 생성 진행\")\n",
        "        return \"generate_captions\"\n",
        "    else:\n",
        "        logger.info(\"중요 이미지가 없음, 캡션 생성 건너뜀\")\n",
        "        return \"skip_captions\"\n",
        "\n",
        "# 이미지 캡션 생성 함수\n",
        "def generate_image_captions(state: State) -> State:\n",
        "    \"\"\"중요한 이미지에 대해 캡션 생성\"\"\"\n",
        "    try:\n",
        "        images = state[\"images\"]\n",
        "        important_images = [img for img in images if img.get(\"importance_score\", 0) >= 0.7]\n",
        "\n",
        "        if not important_images:\n",
        "            logger.info(\"캡션을 생성할 중요 이미지가 없습니다\")\n",
        "            state[\"current_step\"] = \"captions_generated\"\n",
        "            return state\n",
        "\n",
        "        # 구조화된 출력을 위한 LLM 설정\n",
        "        caption_llm = llm.with_structured_output(ImageCaptionResult)\n",
        "\n",
        "        # 캡션 생성 프롬프트\n",
        "        caption_prompt = ChatPromptTemplate([\n",
        "            (\"system\", \"\"\"당신은 학술 자료의 이미지를 분석하고 상세한 캡션을 생성하는 전문가입니다.\n",
        "이미지와 주변 텍스트를 분석하여 자세하고 정확한 캡션을 작성해 주세요.\n",
        "\n",
        "다음 항목을 포함한 상세한 캡션을 작성하세요:\n",
        "1. 이미지가 무엇을 보여주는지 간결하게 설명\n",
        "2. 주요 요소, 패턴, A부터 B까지 관계 등 중요한 정보 포함\n",
        "3. 그래프/차트인 경우 주요 추세와 데이터 포인트 설명\n",
        "4. 이미지가 어떻게 주변 텍스트와 연관되는지 설명\n",
        "5. 해당 이미지의 시사점 포함\n",
        "\"\"\"),\n",
        "            (\"user\",[\n",
        "                {\"type\": \"text\", \"text\":\n",
        "\"\"\"이미지와 주변 문맥이 아래에 주어집니다. 이 이미지에 대한 상세한 캡션을 생성해 주세요.\n",
        "\n",
        "이미지 전 문맥:\n",
        "{context_before}\n",
        "\n",
        "이미지 후 문맥:\n",
        "{context_after}\"\"\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"}}\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        # 캡션 생성 체인\n",
        "        caption_chain = caption_prompt | caption_llm\n",
        "\n",
        "        updated_images = []\n",
        "        for image in images:\n",
        "            if image.get(\"importance_score\", 0) < 0.5:\n",
        "                updated_images.append(image)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # 이미지 파일이 존재하는지 확인\n",
        "                if not os.path.exists(image[\"path\"]):\n",
        "                    logger.warning(f\"캡션 생성용 이미지 파일을 찾을 수 없음: {image['path']}\")\n",
        "                    updated_images.append(image)\n",
        "                    continue\n",
        "\n",
        "                # 이미지 로드\n",
        "                with open(image[\"path\"], 'rb') as img_file:\n",
        "                    img_data = base64.b64encode(img_file.read()).decode('utf-8')\n",
        "\n",
        "                # 캡션 생성\n",
        "                input_data = {\n",
        "                    \"context_before\": image[\"context_before\"],\n",
        "                    \"context_after\": image[\"context_after\"],\n",
        "                    \"image_data\": img_data  # 이미지 데이터 추가\n",
        "                }\n",
        "\n",
        "                result = caption_chain.invoke(input_data)\n",
        "\n",
        "                # 결과 업데이트\n",
        "                image[\"caption\"] = result.caption\n",
        "                updated_images.append(image)\n",
        "\n",
        "                logger.info(f\"이미지 캡션 생성 완료 {image['image_id']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"이미지 캡션 생성 오류 {image['image_id']}: {str(e)}\")\n",
        "                updated_images.append(image)\n",
        "\n",
        "        state[\"images\"] = updated_images\n",
        "        state[\"current_step\"] = \"captions_generated\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"캡션 생성 오류: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state[\"errors\"].append(error_msg)\n",
        "        state[\"current_step\"] = \"error\"\n",
        "\n",
        "    return state\n",
        "\n",
        "# 벡터 DB 저장 함수\n",
        "def store_in_vectordb(state: State) -> State:\n",
        "    \"\"\"텍스트 청크와 이미지 캡션을 벡터 DB에 저장\"\"\"\n",
        "    try:\n",
        "        # 텍스트 청크와 이미지 캡션을 모두 포함하는 문서 목록 생성\n",
        "        documents = []\n",
        "\n",
        "        # 텍스트 청크 추가\n",
        "        for chunk in state[\"text_chunks\"]:\n",
        "            doc = Document(\n",
        "                page_content=chunk[\"content\"],\n",
        "                metadata={\n",
        "                    \"chunk_id\": chunk[\"chunk_id\"],\n",
        "                    \"type\": \"text\"\n",
        "                }\n",
        "            )\n",
        "            documents.append(doc)\n",
        "\n",
        "        # 이미지 캡션 추가\n",
        "        for image in state[\"images\"]:\n",
        "            if image.get(\"caption\"):\n",
        "                doc = Document(\n",
        "                    page_content=image[\"caption\"],\n",
        "                    metadata={\n",
        "                        \"image_id\": image[\"image_id\"],\n",
        "                        \"type\": \"image\",\n",
        "                        \"path\": image[\"path\"]\n",
        "                    }\n",
        "                )\n",
        "                documents.append(doc)\n",
        "\n",
        "        # 문서가 없는 경우 임시 문서 추가 (벡터 DB 오류 방지)\n",
        "        if not documents:\n",
        "            dummy_doc = Document(\n",
        "                page_content=\"No content available\",\n",
        "                metadata={\"type\": \"dummy\"}\n",
        "            )\n",
        "            documents.append(dummy_doc)\n",
        "\n",
        "        # 랜덤 UUID로 DB 경로 생성\n",
        "        db_uuid = uuid.uuid4().hex[:8]\n",
        "        db_path = f\"DB_{db_uuid}\"\n",
        "        os.makedirs(db_path, exist_ok=True)\n",
        "\n",
        "        # 먼저 빈 Chroma 인스턴스 생성 (영구 저장소 지정)\n",
        "        vector_store = Chroma(\n",
        "            collection_name=\"mmrag_collection\",\n",
        "            embedding_function=embeddings,\n",
        "            persist_directory=db_path\n",
        "        )\n",
        "\n",
        "        # 문서 추가 (자동으로 디스크에 저장됨)\n",
        "        vector_store.add_documents(documents)\n",
        "\n",
        "        state[\"vectordb_path\"] = db_path\n",
        "        state[\"current_step\"] = \"vectordb_stored\"\n",
        "        logger.info(f\"벡터 DB 저장 완료: {len(documents)}개 문서, 경로: {db_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"벡터 DB 저장 오류: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state[\"errors\"].append(error_msg)\n",
        "        state[\"current_step\"] = \"error\"\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTckrxfqpujR"
      },
      "outputs": [],
      "source": [
        "# 그래프 구축\n",
        "def build_graph():\n",
        "\n",
        "    builder = StateGraph(State)\n",
        "\n",
        "    builder.add_node(\"process_document\", process_document)\n",
        "    builder.add_node(\"extract_text\", extract_text)\n",
        "    builder.add_node(\"extract_images\", extract_images)\n",
        "    builder.add_node(\"evaluate_importance\", evaluate_image_importance)\n",
        "    builder.add_node(\"generate_captions\", generate_image_captions)\n",
        "    builder.add_node(\"store_vectordb\", store_in_vectordb)\n",
        "\n",
        "    builder.add_edge(START, \"process_document\")\n",
        "    builder.add_edge(\"process_document\", \"extract_text\")\n",
        "    builder.add_edge(\"extract_text\", \"extract_images\")\n",
        "    builder.add_edge(\"extract_images\", \"evaluate_importance\")\n",
        "\n",
        "\n",
        "    builder.add_conditional_edges(\n",
        "        \"evaluate_importance\",\n",
        "        route_by_importance,\n",
        "        {\n",
        "            \"generate_captions\": \"generate_captions\",\n",
        "            \"skip_captions\": \"store_vectordb\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    builder.add_edge(\"generate_captions\", \"store_vectordb\")\n",
        "    builder.add_edge(\"store_vectordb\", END)\n",
        "\n",
        "    return builder\n",
        "\n",
        "builder = build_graph()\n",
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgznt2j2pujR"
      },
      "outputs": [],
      "source": [
        "# PDF를 처리하고 벡터 DB를 생성하는 메인 함수\n",
        "def process_pdf_to_vectordb(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    PDF 파일을 처리하여 벡터 DB를 생성하는 함수\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): PDF 파일의 경로 또는 URL\n",
        "\n",
        "    Returns:\n",
        "        str: 생성된 벡터 DB의 경로\n",
        "        Dict[str, str]: 생성된 벡터 DB 정보 (경로 및 컬렉션 이름)\n",
        "    \"\"\"\n",
        "    logger.info(f\"PDF 처리 시작: {pdf_path}\")\n",
        "\n",
        "    # 초기 상태 생성\n",
        "    initial_state = create_initial_state(pdf_path)\n",
        "\n",
        "    # 그래프 실행\n",
        "    final_state = graph.invoke(initial_state)\n",
        "\n",
        "    # 결과 확인\n",
        "    if final_state[\"current_step\"] == \"vectordb_stored\" and final_state[\"vectordb_path\"]:\n",
        "        result_path = final_state[\"vectordb_path\"]\n",
        "        logger.info(f\"PDF 처리 완료, 벡터 DB 경로: {result_path}\")\n",
        "\n",
        "        # 처리 통계 출력\n",
        "        text_chunks_count = len(final_state[\"text_chunks\"])\n",
        "        images_count = len(final_state[\"images\"])\n",
        "        captioned_images = sum(1 for img in final_state[\"images\"] if img.get(\"caption\"))\n",
        "\n",
        "        logger.info(f\"처리 통계: 텍스트 청크 {text_chunks_count}개, 이미지 {images_count}개, 캡션 생성된 이미지 {captioned_images}개\")\n",
        "\n",
        "        return {\n",
        "            \"db_path\": result_path,\n",
        "            \"collection_name\": \"mmrag_collection\"\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        error_msg = f\"PDF 처리 실패: {final_state['errors']}\"\n",
        "        logger.error(error_msg)\n",
        "        raise RuntimeError(error_msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51ud2iespujS"
      },
      "outputs": [],
      "source": [
        "pdf_path = \"https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf\"\n",
        "result = process_pdf_to_vectordb(pdf_path)\n",
        "db_path, collection_name = result[\"db_path\"], result[\"collection_name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy0pF89OpujS"
      },
      "outputs": [],
      "source": [
        "db_path,collection_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz7RGEedpujS"
      },
      "source": [
        "생성된 DB를 통해 검색을 수행해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3tKHFgspujS"
      },
      "outputs": [],
      "source": [
        "db = Chroma(embedding_function=embeddings, collection_name=collection_name, persist_directory=db_path)\n",
        "\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 6})\n",
        "retriever.invoke(input= \"Gemma 3의 성능 향상 방법은 무엇인가요?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD3XgrMypujS"
      },
      "source": [
        "RAG도 그대로 수행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWzKe1nlpujS"
      },
      "outputs": [],
      "source": [
        "# 테스트 쿼리\n",
        "test_queries = [\n",
        "    \"Gemma 3의 주요 특징은 무엇인가요?\",\n",
        "    \"Gemma 3의 성능 평가 결과를 설명해주세요.\",\n",
        "    \"Gemma 3의 멀티모달 능력은 어떻게 되나요?\",\n",
        "    \"Gemma 3의 Technical Report에서 활용하는 주요 벤치마크는 무엇인가요?\",\n",
        "    \"Gemma 3의 성능이나 구현, 운영 상에서의 한계점이나 이후 발전 방향은 무엇인가요?\"\n",
        "]\n",
        "\n",
        "# 평가 실행\n",
        "prompt = ChatPromptTemplate([\n",
        "    (\"user\", '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
        "다음의 Context를 이용하여 Question에 한국어로 답변하세요.\n",
        "정확한 답변을 제공하세요.\n",
        "만약 모든 Context를 다 확인해도 정보가 없다면, \"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
        "---\n",
        "Context: {context}\n",
        "---\n",
        "Question: {question}''')])\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "def simple_rag(query):\n",
        "\n",
        "    print(f\"\\n질문 : {query}\")\n",
        "    context_documents = retriever.invoke(query)\n",
        "\n",
        "    context = \" \\n---\\n \".join([doc.page_content for doc in context_documents])\n",
        "    types = [doc.metadata.get(\"type\") for doc in context_documents]\n",
        "\n",
        "    print(f\"검색된 문서 유형: {types}\")\n",
        "    #print(f\"검색된 문서 내용: {context}\")\n",
        "\n",
        "    result = chain.invoke({\"context\": context, \"question\": query})\n",
        "    print(f\"응답: {result.content}\")\n",
        "\n",
        "for query in test_queries:\n",
        "    simple_rag(query)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adVgr8DnpujS"
      },
      "source": [
        "답변과 함께, 검색된 이미지를 같이 보여준다면 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdi3CKddpujS"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, Markdown, display\n",
        "\n",
        "def simple_rag_with_image(query):\n",
        "    print(f\"\\n질문 : {query}\")\n",
        "    context_documents = retriever.invoke(query)\n",
        "\n",
        "    context = \" \\n---\\n \".join([doc.page_content for doc in context_documents])\n",
        "    types = [doc.metadata.get(\"type\") for doc in context_documents]\n",
        "\n",
        "    print(f\"검색된 문서 유형: {types}\")\n",
        "    #print(f\"검색된 문서 내용: {context}\")\n",
        "\n",
        "    result = chain.invoke({\"context\": context, \"question\": query})\n",
        "    print(f\"응답: {result.content}\")\n",
        "\n",
        "    print(\"검색된 이미지:\")\n",
        "    for doc in context_documents:\n",
        "        if doc.metadata.get(\"type\") == \"image\":\n",
        "            img = doc.metadata['path']\n",
        "            display(Image(img))\n",
        "            print(f\"이미지 설명: {doc.page_content}\")\n",
        "\n",
        "for query in test_queries:\n",
        "    simple_rag_with_image(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxCxWQNspujS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzW4CCAWpujS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
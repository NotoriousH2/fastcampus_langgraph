{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjcorWy7pXIB"
      },
      "source": [
        "# [프로젝트] Code Interpreter를 이용한 데이터 분석 및 차트 제너레이터 Agent\n",
        "\n",
        "랭체인의 Code Interpreter를 이용해, 주어진 파일의 데이터를 분석하는 에이전트를 만들어 보겠습니다.   \n",
        "\n",
        "사용자의 질의와 파일 경로를 받아, 시각화 아이디어를 구상하고 이를 통해 파이썬 코드를 작성해 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ImEfnGBLpFkA",
        "outputId": "a7287465-2c94-4ed9-f95a-69774f08236b"
      },
      "outputs": [],
      "source": [
        "!pip install plotly seaborn langgraph langchain langchain_google_genai langchain_community dotenv --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EhodcP12iV7"
      },
      "source": [
        "이번 실습에서는 한국어 시각화가 필요합니다.\n",
        "실제로 활용할 때에는, OS의 환경에 맞게 수정하시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWUX7HNEglZE",
        "outputId": "3ac5f4e8-04b3-4a5d-d6b5-4f73a639e335"
      },
      "outputs": [],
      "source": [
        "# Colab/Linux 환경에서 아래 옵션을 실행합니다.\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "# 실행 후 반드시 세션을 다시 시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZMZKNbSguEL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "r13oty5gcXxv",
        "outputId": "71ad1403-8ef6-4835-cdf7-debfe6b5ca60"
      },
      "outputs": [],
      "source": [
        "# 한글 출력 테스트 (한글 폰트가 있는 경우)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.plot([1, 2, 3], [3, 2, 1])\n",
        "plt.title(\"한글 제목 테스트\")\n",
        "plt.xlabel(\"X축\")\n",
        "plt.ylabel(\"Y축\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emCfK61nqh6d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import Dict, Any, Optional, Tuple\n",
        "\n",
        "# 환경 변수 로드\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LangGraph_FastCampus'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    temperature=0.2\n",
        "    # max_tokens\n",
        "\n",
        "    # thinking_budget = 500  # 추론(Reasoning) 토큰 길이 제한\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIZEnZUzcXxv"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import List, Optional, Dict, Any, Union, Annotated, TypedDict, Literal\n",
        "\n",
        "class State(TypedDict):\n",
        "    query : str\n",
        "    first_analysis : str\n",
        "    planner_request : str\n",
        "    file_path : str\n",
        "    code : str\n",
        "    evaluation : str\n",
        "    decision : str\n",
        "    final_insight : list[str]\n",
        "    img : list[str]\n",
        "    num_revision : int\n",
        "    # 리비전의 횟수 제한하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SSREyv6qrPL"
      },
      "source": [
        "파일 경로와 질문이 주어지면, 시각화 아이디어를 제공하는 노드를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Xv5rUojsG3v"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "from io import StringIO\n",
        "import sys\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "# LangChain 최신 버전은 REPL Tool과 호환성 문제가 있어 직접 구현\n",
        "# LLM이 감독 없이 파이썬 코드를 직접 실행하는 것은 위험합니다. (참고: https://news.hada.io/topic?id=23862)\n",
        "def python_repl(code: str) -> str:\n",
        "    code = code.strip().strip('`')\n",
        "    if code.startswith('python'):\n",
        "        code = code[6:].strip()\n",
        "\n",
        "    buffer = StringIO()\n",
        "\n",
        "    try:\n",
        "        with redirect_stdout(buffer):\n",
        "            exec(code, globals())\n",
        "\n",
        "        output = buffer.getvalue()\n",
        "        return output if output else \"실행 완료\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {type(e).__name__}: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSUL3Rvms-tz"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "@tool\n",
        "def python_repl_tool(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
        "):\n",
        "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "    try:\n",
        "        result = python_repl(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    result_str = f\"Successfully executed the code. \\nStdout: {result}\"\n",
        "    return result_str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd29XDXhvtm1"
      },
      "source": [
        "데이터를 분석하기 전, 기본적인 정보는 필요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v929V0s3zFXu"
      },
      "source": [
        "data_prepare_agent를 react agent로 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctHNZ_y9vvSl",
        "outputId": "4b223951-027f-437d-e431-78422dea6398"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import HumanMessage\n",
        "from pydantic import BaseModel, Field\n",
        "# query와 messages를 저장\n",
        "\n",
        "\n",
        "# Chart Agent 프롬프트\n",
        "data_prepare_agent = create_react_agent(llm, [python_repl_tool],\n",
        "    prompt=\"\"\"python_repl을 사용해, 주어진 파일을 간단히 분석하세요.\n",
        "\n",
        "다음의 순서로 실행하세요.\n",
        "1. 해당 파일을 읽고, 컬럼 이름을 파악하세요.\n",
        "2. 파악한 결과를 바탕으로, 개략적인 통계 자료를 출력하세요.\n",
        "주로 다음과 같은 항목이 포함됩니다:\n",
        "행과 열의 개수\n",
        "예시 데이터\n",
        "\n",
        "실패하는 경우, 적절한 인코딩 방식을 활용하여 재시도하세요.\"\"\"\n",
        ")\n",
        "\n",
        "def prepare_data(state:State):\n",
        "    messages=[HumanMessage(f\"파일 경로는 f{state['file_path']} 입니다.\")]\n",
        "    file_path = state['file_path']\n",
        "    code_result = data_prepare_agent.invoke({'messages':[HumanMessage(f'파일 경로:{file_path}')]})\n",
        "    first_analysis = code_result['messages'][-1].content\n",
        "    return {'first_analysis':first_analysis}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlELCm8Hqk1G"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQaHTB69qkam"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "# 시각화 기획자 에이전트\n",
        "planner_prompt = ChatPromptTemplate([\"\"\"\n",
        "당신은 데이터 시각화 전문가로 사용자가 제공한 데이터와 요청을 분석하여 최적의 시각화 전략을 수립하는 역할을 맡고 있습니다.\n",
        "\n",
        "## 데이터 정보:\n",
        "{first_analysis}\n",
        "\n",
        "## 사용자 쿼리:\n",
        "{query}\n",
        "\n",
        "## 당신의 임무:\n",
        "1. 데이터 파일을 분석하고 구조와 주요 변수를 파악하세요.\n",
        "2. 사용자 쿼리의 의도를 명확히 파악하세요.\n",
        "3. 데이터와 쿼리를 바탕으로 가장 적합한 시각화 유형(막대 그래프, 산점도, 히트맵 등)을 결정하세요.\n",
        "4. 시각화를 위한 상세 계획을 작성하세요.\n",
        "\n",
        "## 응답 형식:\n",
        "다음 섹션을 포함한 계획서를 작성해주세요:\n",
        "1. 데이터 분석: 데이터 구조, 주요 변수, 특징 등을 설명\n",
        "2. 사용자 의도 분석: 사용자가 무엇을 알고 싶어하는지 분석\n",
        "3. 시각화 전략: 어떤 시각화가 적합한지와 그 이유\n",
        "4. 구체적인 요청사항:\n",
        "   - 차트 유형\n",
        "   - 사용할 변수\n",
        "   - 색상 테마 (필요시)\n",
        "   - 강조할 부분\n",
        "   - 제목 및 레이블 제안\n",
        "   - 기타 특별 요청사항\n",
        "\n",
        "이 계획서는 시각화 개발자가 실제 코드를 작성하는 데 사용될 것입니다.\n",
        "\"\"\"])\n",
        "\n",
        "\n",
        "def generate_visualization_idea(state:State):\n",
        "    chain = planner_prompt | llm\n",
        "    response = chain.invoke(state)\n",
        "    return {'planner_request':response.content}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5NA4_En33AX"
      },
      "outputs": [],
      "source": [
        "developer_prompt = ChatPromptTemplate([\"\"\"\n",
        "당신은 데이터 시각화 개발자로서, 시각화 기획자가 제공한 계획에 따라 Python 코드를 작성하여 데이터를 시각화하는 역할을 맡고 있습니다.\n",
        "\n",
        "## 데이터 파일 경로:\n",
        "{file_path}\n",
        "\n",
        "\n",
        "## 데이터의 일부 정보\n",
        "\n",
        "{first_analysis}\n",
        "\n",
        "## 시각화 기획자의 요청사항:\n",
        "{planner_request}\n",
        "\n",
        "## 평가자의 추가 요청사항:\n",
        "{evaluation}\n",
        "\n",
        "## 당신의 임무:\n",
        "1. 제공된 데이터 파일을 로드하는 코드를 작성하세요.\n",
        "2. 시각화 기획자의 요청사항에 따라 적절한 시각화 라이브러리(matplotlib, seaborn, plotly 등)를 사용하여 코드를 작성하세요.\n",
        "3. 시각화 결과를 생성하고 저장하는 코드를 작성하세요.\n",
        "\n",
        "작성에서 매우 중요한 규칙은 다음과 같습니다.\n",
        "한글 데이터가 주로 주어지므로, 아래 코드를 꼭 포함하세요.\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "매 시각화 결과는 현재 폴더에, 적절한 이름의 .png 파일로 저장하세요.\"\"\"])\n",
        "# 디버깅이 잘 안 되면, 실제 코드 스니펫을 추가하는 방법도 좋음\n",
        "\n",
        "\n",
        "def execute_visualization(state:State):\n",
        "    chain  = developer_prompt | llm\n",
        "    response = chain.invoke(state)\n",
        "\n",
        "    def parse(code):\n",
        "        if '```' in code:\n",
        "            code = code.split('```python')[1].split('```')[0]\n",
        "        return code\n",
        "    code_to_execute = parse(response.content)\n",
        "    return {'code':code_to_execute}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfiWFevkNKAt"
      },
      "outputs": [],
      "source": [
        "evaluator_prompt = ChatPromptTemplate([\"\"\"\n",
        "당신은 데이터 시각화 평가 전문가로서, 생성된 시각화가 사용자의 원래 의도와 요구사항을 얼마나 잘 충족시키는지 평가하는 역할을 맡고 있습니다.\n",
        "\n",
        "## 원래 사용자 쿼리:\n",
        "{query}\n",
        "\n",
        "## 원래 시각화 계획:\n",
        "{planner_request}\n",
        "\n",
        "## 개발자가 작성한 코드 및 설명:\n",
        "{code}\n",
        "\n",
        "## 당신의 임무:\n",
        "1. 생성된 시각화가 사용자의 원래 의도와 요구사항을 얼마나 잘 충족시키는지 판단하여, 시각화의 강점과 약점을 분석하세요.\n",
        "2. 개선이 필요한 부분이 있는지 확인하고, 필요하다면 구체적인 개선 방향을 제시하세요.\n",
        "3. 시각화 결과물 위주로 평가하세요. 파일 저장이나, 사용자 입력 등은 고려하지 마세요.\n",
        "4. matplotlib이나, seaborn의 범위로 해결 가능한 피드백만을 제공해야 합니다.\n",
        "\n",
        "## 응답 형식:\n",
        "다음 항목을 포함한 평가서를 작성해주세요:\n",
        "1. 종합 평가: 시각화가 사용자 요구사항을 얼마나 잘 충족시키는지에 대한 종합적인 평가\n",
        "2. 개선점: 보완이 필요한 부분\n",
        "3. 개선 제안: 구체적인 개선 방향 및 추가 시각화 제안 (필요시)\n",
        "4. 최종 결정: 다음 중 하나를 선택\n",
        "   - COMPLETE: 시각화가 충분히 좋으며 더 이상의 개선이 필요 없음\n",
        "   - REVISE: 개선이 필요하며 구체적인 수정 사항 제시\n",
        "\n",
        "평가서는 간략한 개조식으로 작성하세요.\n",
        "개선이 필요한 경우, 시각화 개발자에게 전달할 구체적인 수정 요청을 포함해주세요.\n",
        "\"\"\"])\n",
        "\n",
        "class evaluation(BaseModel):\n",
        "    comment: str = Field(description=\"시각화에 대한 전체 평가 내용\")\n",
        "    decision: Literal['COMPLETE', 'REVISE'] = Field(description='평가에 대한 최종 결정')\n",
        "\n",
        "def evaluate_visualization(state:State):\n",
        "\n",
        "    num_revision = state.get('num_revision',0)\n",
        "\n",
        "    chain = evaluator_prompt | llm.with_structured_output(evaluation)\n",
        "    response = chain.invoke(state)\n",
        "\n",
        "    num_revision += 1 # 리비전 횟수 증가\n",
        "\n",
        "    return {'evaluation':response.comment,\n",
        "            'decision':response.decision,\n",
        "            'num_revision':num_revision}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0g_DyEDZAL9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PIL.Image\n",
        "import base64\n",
        "import contextlib\n",
        "import io\n",
        "\n",
        "finalize_prompt = ChatPromptTemplate([\n",
        "    ('system',\"\"\"\n",
        "데이터 파일에 대한 사용자의 질문이 주어집니다.\n",
        "해당 질문의 결과물로 이미지와 인사이트가 주어졌습니다.\n",
        "\n",
        "해당 내용을 바탕으로, 전체 보고서를 작성하세요.\"\"\"),\n",
        "    ('human', [\n",
        "        {'type':'text', \"text\":'''\n",
        "질문: {query}\n",
        "\n",
        "인사이트: {insight}'''},\n",
        "{\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"}}])])\n",
        "\n",
        "def finalize_output(state: State):\n",
        "    code_agent = create_react_agent(llm, [python_repl_tool],\n",
        "    prompt=f\"\"\"\n",
        "당신은 외부 파일에 접속할 수 있는 파이썬 코드 에이전트입니다.\n",
        "데이터 파일의 경로와, 파이썬 코드가 주어집니다.\n",
        "python_repl을 사용해, 주어진 코드를 실행하세요.\n",
        "실행 시 에러가 발생하는 경우, 우회가 필요한 경우 에러에 따라 코드를 변경하세요.\n",
        "## 대표적 에러 발생\n",
        "- 'distutils' 라이브러리 에러의 경우, Python 3.12 이후에 발생하는 문제입니다.\n",
        "이 에러가 발생하면, koreanize_matplotlib 코드를 삭제하고 아래 코드를 추가하여 다시 실행하면 됩니다.\n",
        "```python\n",
        "    # 한글 출력 테스트\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "    plt.rcParams['font.family'] = 'NanumGothic'\n",
        "```\n",
        "파일의 경로는 이미 코드에 포함되어 있으므로, 바로 실행하면 됩니다.\n",
        "코드를 실행한 후, 시각화 파일의 위치를 아래 형식으로 출력하세요.\n",
        "{{file_path:파일명.png}}\n",
        "\"\"\")\n",
        "\n",
        "    # 변경점: code_agent를 실행한 결과만 바로 출력\n",
        "    result = code_agent.invoke({'messages':HumanMessage(state['code'])})['messages'][-1]\n",
        "\n",
        "    import re\n",
        "    def extract_png_path(result):\n",
        "        text = getattr(result, \"content\", str(result))\n",
        "        m = re.search(r\"([\\w\\-/\\\\\\.]+\\.png)\", text)\n",
        "        return m.group(1) if m else None\n",
        "\n",
        "    try: # 시각화 결과를 체인에 전달\n",
        "        image_path = extract_png_path(result)\n",
        "        img = PIL.Image.open(image_path)\n",
        "        buffer = io.BytesIO()\n",
        "        img.save(buffer, format='PNG')  # 이미지 포맷은 필요에 따라 수정 가능\n",
        "        img_data = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "\n",
        "        chain = finalize_prompt | llm\n",
        "        final_insight = chain.invoke(\n",
        "            {\n",
        "                'query':state['query'],\n",
        "                'insight':result,\n",
        "                'image_data':img_data\n",
        "            }\n",
        "        ).content\n",
        "        return {'final_insight':[final_insight], 'img': [img_data]}\n",
        "    except:\n",
        "        # 코드 실행 문제로 파일 저장이 안 된 경우\n",
        "        return {'final_insight':[result.content], 'img': []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej7IoIu2Qkig"
      },
      "outputs": [],
      "source": [
        "def get_next(state:State):\n",
        "    if state['decision'] == 'COMPLETE' or state['num_revision']>=3:\n",
        "        return 'END'\n",
        "    else:\n",
        "        return 'REVISE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "B7r2nemCz57V",
        "outputId": "872172dc-a7dd-4f0f-de16-43d3c1eb17e3"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(prepare_data)\n",
        "builder.add_node(generate_visualization_idea)\n",
        "builder.add_node(execute_visualization)\n",
        "builder.add_node(evaluate_visualization)\n",
        "builder.add_node(finalize_output)\n",
        "\n",
        "builder.add_edge(START, 'prepare_data')\n",
        "builder.add_edge('prepare_data','generate_visualization_idea')\n",
        "builder.add_edge('generate_visualization_idea','execute_visualization')\n",
        "builder.add_edge('execute_visualization', 'evaluate_visualization')\n",
        "builder.add_conditional_edges('evaluate_visualization',\n",
        "                              get_next,\n",
        "                              {'REVISE':'execute_visualization',\n",
        "                               'END':'finalize_output'})\n",
        "graph = builder.compile()\n",
        "\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucMbm4b01Apy",
        "outputId": "5b7448df-0e25-4c7d-e6bf-5a5c59d50211"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "initial_state = {\n",
        "    'file_path':'sample_data.csv',\n",
        "    'query':'이 파일의 제품별 판매량을 비교해줘.',\n",
        "    'evaluation':''\n",
        "}\n",
        "\n",
        "for data in graph.stream(initial_state, stream_mode='updates'):\n",
        "    pprint.pprint(data)\n",
        "    print('----')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTsN8wiRaEki"
      },
      "source": [
        "해당 기능은 하나의 질문에 대해 시각화를 수행합니다.   \n",
        "전체 그래프를 하나의 서브노드로 만들고, 질문이 주어지면 이를 여러 개의 파생 질문으로 분리하도록 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC3yQvOCtu9A",
        "outputId": "5dee7175-a797-4267-b393-6c52baa727cc"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# SubState 형태로 구성 : Prepare Data는 빼기\n",
        "class State(TypedDict):\n",
        "    query : str\n",
        "    first_analysis : list\n",
        "    planner_request : str\n",
        "    file_path : str\n",
        "    code : str\n",
        "    evaluation : str\n",
        "    decision : str\n",
        "    final_insight : list[str]\n",
        "    img : list[str]\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(generate_visualization_idea)\n",
        "builder.add_node(execute_visualization)\n",
        "builder.add_node(evaluate_visualization)\n",
        "builder.add_node(finalize_output)\n",
        "\n",
        "builder.add_edge(START, 'generate_visualization_idea')\n",
        "builder.add_edge('generate_visualization_idea','execute_visualization')\n",
        "builder.add_edge('execute_visualization', 'evaluate_visualization')\n",
        "builder.add_conditional_edges('evaluate_visualization',\n",
        "                              get_next,\n",
        "                              {'REVISE':'execute_visualization',\n",
        "                               'END':'finalize_output'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "mcpBnsYYuoWJ",
        "outputId": "f71f5898-9557-453f-e03b-beb691ebebe8"
      },
      "outputs": [],
      "source": [
        "subgraph = builder.compile()\n",
        "subgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLNfr5TwarQu"
      },
      "outputs": [],
      "source": [
        "from langgraph.types import Send\n",
        "from typing import Annotated\n",
        "import operator\n",
        "\n",
        "\n",
        "class BState(TypedDict):\n",
        "    question: str\n",
        "    final_insight: Annotated[list, operator.add]\n",
        "    img: Annotated[list, operator.add]\n",
        "    file_path: Annotated[list, operator.add]\n",
        "    first_analysis: Annotated[list, operator.add]\n",
        "    queries: list[str]\n",
        "    num_revision: int\n",
        "\n",
        "\n",
        "generate_queries_prompt=ChatPromptTemplate([\"\"\"\n",
        "당신은 데이터 분석 전문가입니다.\n",
        "사용자의 질문에 대한 해답을 얻기 위해,\n",
        "해당 질문을 보다 자세하고 서로 겹치지 않는 최대 3개의 파생 질문으로 분리하세요.\n",
        "\n",
        "하나의 시각화로 해결할 수 있는 지표들은 하나의 질문으로 묶어도 좋습니다.\n",
        "\n",
        "## 데이터 정보:\n",
        "{first_analysis}\n",
        "\n",
        "## 사용자 쿼리:\n",
        "{question}\n",
        "\n",
        "\"\"\"])\n",
        "\n",
        "class queries(BaseModel):\n",
        "    queries: list[str] = Field(description=\"파생 질문 목록\")\n",
        "\n",
        "\n",
        "\n",
        "def generate_queries(state:BState):\n",
        "    chain = generate_queries_prompt | llm.with_structured_output(queries)\n",
        "    response = chain.invoke(state).queries\n",
        "    return {'queries':response}\n",
        "\n",
        "\n",
        "def assign_workers(state: BState):\n",
        "    # queries 개수만큼 호출하기\n",
        "    return [Send(\"answer_indiv_question\", {\"query\": s, 'evaluation':'',  'file_path':state['file_path'], 'first_analysis':state['first_analysis']}) for s in state[\"queries\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkr4PMkCuxPW"
      },
      "source": [
        "Prepare Data는 모든 작업에서 동시에 진행하므로 큰 라이브러리로 옮겨 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGQAlaw_gUHQ",
        "outputId": "c120fdc4-75f3-4a53-8c43-16c742ead2a9"
      },
      "outputs": [],
      "source": [
        "# Chart Agent 프롬프트\n",
        "data_prepare_agent = create_react_agent(llm, [python_repl_tool],\n",
        "    prompt=\"\"\"python_repl을 사용해, 주어진 파일을 간단히 분석하세요.\n",
        "\n",
        "다음의 순서로 실행하세요.\n",
        "1. 해당 파일을 읽고, 컬럼 이름을 파악하세요.\n",
        "2. 파악한 결과를 바탕으로, 개략적인 통계 자료를 출력하세요.\n",
        "주로 다음과 같은 항목이 포함됩니다:\n",
        "행과 열의 개수\n",
        "예시 데이터\n",
        "\n",
        "실패하는 경우, 적절한 인코딩 방식을 활용하여 재시도하세요.\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def prepare_data(state:BState):\n",
        "    messages=[HumanMessage(f\"파일 경로는 {state['file_path']} 입니다.\")]\n",
        "    file_path = state['file_path']\n",
        "    code_result = data_prepare_agent.invoke({'messages':messages})\n",
        "    first_analysis = code_result['messages'][-1].content\n",
        "    return {'first_analysis':[first_analysis]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6br2xDb9aR1g",
        "outputId": "73f5491b-d328-460d-8760-15d2bee75cc4"
      },
      "outputs": [],
      "source": [
        "builder2 = StateGraph(BState)\n",
        "builder2.add_node(prepare_data)\n",
        "builder2.add_node('answer_indiv_question', subgraph)\n",
        "builder2.add_node(generate_queries)\n",
        "\n",
        "builder2.add_edge(START, 'prepare_data')\n",
        "builder2.add_edge('prepare_data','generate_queries')\n",
        "builder2.add_conditional_edges(\"generate_queries\", assign_workers, [\"answer_indiv_question\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5uPXHR8u4k-"
      },
      "source": [
        "서브그래프가 포함된 구조는 아래와 같이 xray 설정으로 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yVJa7lleeNLx",
        "outputId": "2dadb34b-3b70-4fac-ce4a-fb618c7a82d4"
      },
      "outputs": [],
      "source": [
        "big_graph = builder2.compile()\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(big_graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oH49ToWBLVlU",
        "outputId": "b787e84d-6159-4aa7-98de-7485e1acbbb1"
      },
      "outputs": [],
      "source": [
        "initial_state = {\n",
        "    'file_path':['sample_data.csv'],\n",
        "    'question':'이 파일의 제품별 판매량을 비교해줘.',\n",
        "}\n",
        "\n",
        "for data in big_graph.stream(initial_state, stream_mode='updates'):\n",
        "    pprint.pprint(data)\n",
        "    print('----')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aIh3Q_xEcXxy",
        "outputId": "120ea7fc-f542-41a5-bbbd-ebd1b3768143"
      },
      "outputs": [],
      "source": [
        "result = big_graph.invoke(initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t61wfCgRcXxy",
        "outputId": "99e3d5c3-4b6b-44ec-e3be-05b69839997a"
      },
      "outputs": [],
      "source": [
        "result['final_insight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gBW1ZES3cXxy",
        "outputId": "daec9c34-483c-4e54-8338-96bf1d593fa0"
      },
      "outputs": [],
      "source": [
        "for img in result['img']:\n",
        "    import base64\n",
        "    from io import BytesIO\n",
        "\n",
        "    if isinstance(img, str):\n",
        "        # If the image is a base64 string, decode and display\n",
        "        image_data = base64.b64decode(img)\n",
        "        image = PIL.Image.open(BytesIO(image_data))\n",
        "        display(image)\n",
        "    else:\n",
        "        display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iImL94x9haaO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

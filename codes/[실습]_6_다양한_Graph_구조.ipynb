{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsYrzxX5DaqK"
      },
      "source": [
        "# [ì‹¤ìŠµ] ë‹¤ì–‘í•œ Graph êµ¬ì¡°\n",
        "\n",
        "ê·¸ë™ì•ˆ ë°°ìš´ ìš”ì†Œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, ì´ë²ˆì—ëŠ” ê¸°ì¡´ì˜ Graph êµ¬ì¡°ë¥¼ ë³´ë‹¤ í™•ìž¥ì‹œì¼œ ë³´ê² ìŠµë‹ˆë‹¤.   \n",
        "\n",
        "ê°„ë‹¨í•œ Router êµ¬ì¡°,\n",
        "\n",
        "í•˜ë‚˜ì˜ ì¶œë°œì ì—ì„œ ì—¬ëŸ¬ ê°œë¡œ ë¶„ë¦¬ë˜ëŠ” Parallel Calling ì´í›„ì— ê²°ê³¼ë¥¼ í•©ì¹˜ëŠ” Map Reduce ë°©ì‹,\n",
        "\n",
        "ìƒì„±ìžì™€ í‰ê°€ìžì˜ êµ¬ì¡°ë¥¼ ë°˜ë³µí•˜ëŠ” Evaluator-Optimizer ë°©ì‹ì„ êµ¬í˜„í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1JC3bK9DaqL"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph langchain langchain_google_genai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z592IDzIDaqM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIxxx'\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini APIëŠ” ë¶„ë‹¹ 10ê°œ ìš”ì²­ìœ¼ë¡œ ì œí•œ\n",
        "# ì¦‰, ì´ˆë‹¹ ì•½ 0.167ê°œ ìš”ì²­ (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # ë¶„ë‹¹ 10ê°œ ìš”ì²­\n",
        "    check_every_n_seconds=0.1,  # 100msë§ˆë‹¤ ì²´í¬\n",
        "    max_bucket_size=10,  # ìµœëŒ€ ë²„ìŠ¤íŠ¸ í¬ê¸°\n",
        ")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    # temperature\n",
        "    # max_tokens\n",
        "\n",
        "    thinking_budget = 500  # ì¶”ë¡ (Reasoning) í† í° ê¸¸ì´ ì œí•œ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MAE1pIFDaqM"
      },
      "source": [
        "## 1. Router\n",
        "ë¼ìš°í„°ëŠ” Stateì˜ ê°’ì„ ì°¸ê³ í•˜ì—¬, ëª©ì ì— ë”°ë¼ ì„œë¡œ ë‹¤ë¥¸ ë…¸ë“œë¡œ ì „ë‹¬í•˜ëŠ” ë°©ì‹ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.   \n",
        "ì£¼ë¡œ ì‚¬ìš©ìžì˜ ìž…ë ¥ì„ ë¶„ë¥˜í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ìž‘ì—…ì„ ì—°ê²°í•˜ëŠ” ì˜ë„ ë¶„ë¥˜(Intent Classfication)ì—ì„œ í™œìš©ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWkZTeKdDaqM"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict, Annotated, Literal, List\n",
        "from pydantic import BaseModel, Field\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str = Field(..., description=\"ìŒì‹ ì´ë¦„\")\n",
        "    difficulty: str = Field(..., description=\"ë§Œë“¤ê¸°ì˜ ë‚œì´ë„\")\n",
        "    origin: str = Field(..., description=\"ì›ì‚°ì§€\")\n",
        "    ingredients: List[str] = Field(..., description=\"ìž¬ë£Œ ëª©ë¡\")\n",
        "    instructions: List[str] = Field(..., description=\"ì¡°ë¦¬ë²•\")\n",
        "    taste: List[str] = Field(..., description=\"ë§›ì— ëŒ€í•œ í•œ ë§ˆë””ì˜ ë¬˜ì‚¬!\")\n",
        "\n",
        "class Movie(BaseModel):\n",
        "    name: str = Field(..., description=\"ì˜í™” ì´ë¦„\")\n",
        "    director: str = Field(..., description=\"ê°ë…ëª…\")\n",
        "    actor: List[str] = Field(..., description=\"ì£¼ì—° ë°°ìš°: ìµœëŒ€ 3ëª…ê¹Œì§€\")\n",
        "    recommendation: str = Field(..., description=\"ì¶”ì²œí•˜ëŠ” ì´ìœ !\")\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    query: str\n",
        "    classification: str\n",
        "    recipe: Recipe\n",
        "    movie:Movie\n",
        "    advice : Literal['ë„¤!', 'ì•„ë‹ˆì˜¤.']\n",
        "    # Literal: ë²”ìœ„ê°€ íŠ¹ì • ê°’ìœ¼ë¡œ í•œì •ë˜ëŠ” ê²½ìš°\n",
        "    answer: str\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfewW4rYDaqM"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import random\n",
        "\n",
        "def recommend_recipe(state):\n",
        "    prompt = ChatPromptTemplate([\n",
        "    ('system','ë‹¹ì‹ ì€ ì „ì„¸ê³„ì˜ ì´ìƒ‰ì ì¸ í“¨ì „ ì¡°ë¦¬ë²•ì˜ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.'),\n",
        "    ('user','''{query}''')\n",
        "    ])\n",
        "\n",
        "    recipe_chain = prompt | llm.with_structured_output(Recipe)\n",
        "\n",
        "    return {'recipe':recipe_chain.invoke(state)}\n",
        "    # query --> query\n",
        "\n",
        "def recommend_movie(state):\n",
        "    prompt = ChatPromptTemplate([\n",
        "    ('system','ë‹¹ì‹ ì€ ê³ ì „ ì˜í™”ì˜ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.'),\n",
        "    ('user','''{query}''')\n",
        "    ])\n",
        "\n",
        "    movie_chain = prompt | llm.with_structured_output(Movie)\n",
        "\n",
        "    return {'movie':movie_chain.invoke(state)}\n",
        "    # query --> query\n",
        "\n",
        "\n",
        "def talk(state):\n",
        "    return {'answer':llm.invoke(state['query']).content}\n",
        "\n",
        "\n",
        "def counsel(state):\n",
        "    if random.random()>=0.5:\n",
        "        return {'advice':'ë„¤!'}\n",
        "    else:\n",
        "        return {'advice':'ì•„ë‹ˆì˜¤.'}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hu6yFdlDaqM"
      },
      "outputs": [],
      "source": [
        "def route(state):\n",
        "\n",
        "    prompt = ChatPromptTemplate(\n",
        "        [('system', '''ë‹¹ì‹ ì˜ ì—­í• ì€ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ëŒ€ë‹µí•  ì‚¬ëžŒì„ ì„ íƒí•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
        "1) ìŒì‹ ê´€ë ¨ ì§ˆë¬¸: 'FOOD'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "2) ì˜í™” ê´€ë ¨ ì§ˆë¬¸: 'MOVIE'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "3) ê³ ë¯¼ ìƒë‹´: 'COUNSEL'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "4) ê·¸ ì™¸ì˜ ëŒ€í™”: 'TALK'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "             '''),\n",
        "             ('user','User Query: {query}')\n",
        "        ]\n",
        "    )\n",
        "    # Structured_Outputìœ¼ë¡œ ë§Œë“¤ ìˆ˜ë„ ìžˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "    route_chain = prompt | llm\n",
        "\n",
        "    return {\"classification\": route_chain.invoke(state).content}\n",
        "    # query --> query\n",
        "\n",
        "\n",
        "def route_decision(state):\n",
        "    # Exact Match ëŒ€ì‹  ì¡°ê¸ˆ ì•ˆì •ì ì¸ ì¡°ê±´ì‹\n",
        "\n",
        "    if \"FOOD\" in state[\"classification\"]:\n",
        "        return \"recommend_recipe\"\n",
        "    elif \"MOVIE\" in state[\"classification\"]:\n",
        "        return \"recommend_movie\"\n",
        "    elif \"TALK\" in state[\"classification\"]:\n",
        "        return \"talk\"\n",
        "    else:\n",
        "        return \"counsel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFKpzJMhDaqM"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node('recommend_movie', recommend_movie)\n",
        "builder.add_node('recommend_recipe', recommend_recipe)\n",
        "builder.add_node('counsel', counsel)\n",
        "builder.add_node('talk', talk)\n",
        "builder.add_node('route', route)\n",
        "\n",
        "builder.add_edge(START, 'route')\n",
        "builder.add_conditional_edges('route', route_decision,\n",
        "                              {'recommend_movie':'recommend_movie',\n",
        "                               'recommend_recipe':'recommend_recipe',\n",
        "                               'counsel':'counsel',\n",
        "                               'talk':'talk'})\n",
        "\n",
        "builder.add_edge('recommend_movie', END)\n",
        "builder.add_edge('recommend_recipe', END)\n",
        "builder.add_edge('counsel', END)\n",
        "builder.add_edge('talk', END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geuxT7gMDaqN"
      },
      "outputs": [],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgHC00M1DaqN"
      },
      "outputs": [],
      "source": [
        "query = '2ì›”ì— ì–´ìš¸ë¦¬ëŠ” í•œêµ­ì˜í™” ì¶”ì²œí•´ì¤˜.'\n",
        "\n",
        "result = graph.invoke({'query':query})\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5CvJCxvRrGH"
      },
      "outputs": [],
      "source": [
        "query = 'ì—°ë‘ë¶€ë¡œ ë§Œë“¤ ìˆ˜ ìžˆëŠ” íŒŒì¸ ë‹¤ì´ë‹ ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”'\n",
        "\n",
        "result = graph.invoke({'query':query})\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Uz7vWfSTk1"
      },
      "outputs": [],
      "source": [
        "query = 'MoE êµ¬ì¡°ì— ëŒ€í•´ 5ë¬¸ìž¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.'\n",
        "\n",
        "result = graph.invoke({'query':query})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_aFXbYvDaqN"
      },
      "source": [
        "## 2. Map-Reduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78zn6Sw_DaqN"
      },
      "source": [
        "ìœ„ì—ì„œëŠ” ë¶„ë¥˜ í›„ì— 1ë²ˆì˜ LLMì„ í˜¸ì¶œí–ˆëŠ”ë°ìš”.   \n",
        "ê°ìž ì‹¤í–‰í•˜ê³  í•©ì¹˜ëŠ” êµ¬ì¡°ë„ ë§Œë“¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.   \n",
        "\n",
        "ëŒ€í‘œì ì¸ ìž‘ì—…ì¸ ë¦¬í¬íŠ¸ ìž‘ì„± êµ¬ì¡°ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤.   \n",
        "ìµœì´ˆì˜ LLMì´ ì£¼ì œì— ëŒ€í•œ ì„¹ì…˜ì„ ë¨¼ì € êµ¬ì„±í•˜ê³ , ì„¹ì…˜ë³„ ë¦¬í¬íŠ¸ë¥¼ ê°ê°ì˜ LLMì´ ìž‘ì„±í•˜ëŠ” ë°©ì‹ìž…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZhYoD0qDaqN"
      },
      "outputs": [],
      "source": [
        "# ì „ì²´ ì„¹ì…˜ì˜ êµ¬íš: Contents (Chapter List)\n",
        "# Chapter: name, outline\n",
        "class Chapter(BaseModel):\n",
        "    name: str = Field(description=\"ì±•í„°ì˜ ì´ë¦„\")\n",
        "    outline: str = Field(description=\"ì±•í„°ì˜ ì£¼ìš” ë‚´ìš©, 1ë¬¸ìž¥ ê¸¸ì´ë¡œ\")\n",
        "\n",
        "\n",
        "class Contents(BaseModel):\n",
        "    contents: List[Chapter] = Field(description=\"ì „ì²´ ë¦¬í¬íŠ¸ì˜ ì„¹ì…˜ êµ¬ì„±\")\n",
        "\n",
        "\n",
        "planner = llm.with_structured_output(Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWO6Hp-sDaqN"
      },
      "outputs": [],
      "source": [
        "example = planner.invoke(\"LLMì˜ ë°œì „ ê³¼ì •ì— ëŒ€í•œ ë³´ê³ ì„œ êµ¬íšì„ ìž‘ì„±í•´ ì£¼ì„¸ìš”.\")\n",
        "example.contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z02IWYAIDaqN"
      },
      "source": [
        "ê·¸ëž˜í”„ì—ì„œ ì‚¬ìš©í•  Stateë¥¼ ì •ì˜í•©ë‹ˆë‹¤.   \n",
        "\n",
        "ì´ë²ˆì—ëŠ” ì¤‘ê°„ Writer LLMì´ ì‚¬ìš©í•  Stateë¥¼ ë³„ë„ë¡œ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.   \n",
        "ì´ë ‡ê²Œ êµ¬ì„±í•˜ë©´ ìµœì¢… Stateì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì €ìž¥í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_MIbKB8DaqN"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "\n",
        "# reducer êµ¬ì¡°: operator.add\n",
        "# ë‹¨ìˆœ + ì—°ì‚° êµ¬ì¡° (ë¦¬ìŠ¤íŠ¸ì˜ + ì—°ì‚°ì´ë¯€ë¡œ append)\n",
        "\n",
        "class State(TypedDict):\n",
        "    topic: str\n",
        "    contents: list[Chapter]\n",
        "    completed_sections: Annotated[list, operator.add]\n",
        "    final_report: str\n",
        "\n",
        "\n",
        "# ì„¹ì…˜ Writerê°€ ì‚¬ìš©í•  State\n",
        "class SubState(TypedDict):\n",
        "    chapter: Chapter\n",
        "    completed_sections: Annotated[list, operator.add]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn9oVR_xDaqO"
      },
      "source": [
        "ì„¹ì…˜ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VIpcYLzDaqO"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "def orchestrator(state: State):\n",
        "\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', \"ì£¼ì œì— ëŒ€í•œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ê¹Šì´ ìžˆëŠ” í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ì“°ë ¤ê³  í•©ë‹ˆë‹¤. ë³´ê³ ì„œì˜ ì„¹ì…˜ êµ¬ì„±ê³¼, ê° ì„¹ì…˜ì˜ ê°„ë‹¨í•œ ì„¤ëª…ì„ ìž‘ì„±í•´ ì£¼ì„¸ìš”.\"),\n",
        "        ('user', \"ì£¼ì œ: {topic}\")\n",
        "    ])\n",
        "    chain = prompt | planner\n",
        "\n",
        "    # chain ê²°ê³¼ë¬¼: Contents (contents: List[Chapter])\n",
        "\n",
        "    return {\"contents\": chain.invoke(state).contents}\n",
        "    # state: topic --> topic\n",
        "    # Return: List[Chapter]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC0OpL4NDaqO"
      },
      "source": [
        "ì„¹ì…˜ë³„ ë‚´ìš©ì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.   \n",
        "Stateì—ëŠ” ê°ê°ì˜ Chapterê°€ ì•„ë‹Œ Chapterì˜ ë¦¬ìŠ¤íŠ¸ì¸ Contentsê°€ ë“¤ì–´ ìžˆëŠ”ë°ìš”.   \n",
        "\n",
        "`SubState`ë¥¼ ì´ìš©í•´, ê°ê°ì˜ Chapterë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S5AwvDbDaqO"
      },
      "outputs": [],
      "source": [
        "def llm_call(state: SubState):\n",
        "    # SubState :  chapter, completed_sections 2ê°œ property\n",
        "\n",
        "    chapter = state['chapter']\n",
        "\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system',\"ì•„ëž˜ ì„¹ì…˜ì— ëŒ€í•œ ìƒì„¸í•œ í•œêµ­ì–´ ë³´ê³ ì„œë¥¼ ìž‘ì„±í•˜ì„¸ìš”.\" ),\n",
        "        ('user', \"ì„¹ì…˜ ì´ë¦„ê³¼ ì£¼ì œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {name} --> {outline}\")\n",
        "    ])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    return {\"completed_sections\": [chain.invoke({'name':chapter.name, 'outline':chapter.outline}).content]}\n",
        "    # ë¦¬ìŠ¤íŠ¸ë¡œ Wrapí•˜ëŠ” ì´ìœ  ì¤‘ìš”(Reduce Operator í•©ì¹˜ê¸° ìœ„í•´ì„œ)\n",
        "\n",
        "\n",
        "# ìƒì„±ëœ ì„¹ì…˜ë³„ ê²°ê³¼ë“¤ì„ ê²°í•©\n",
        "def synthesizer(state: State):\n",
        "\n",
        "    completed_sections = state[\"completed_sections\"]\n",
        "\n",
        "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
        "    # join: ì „ì²´ ë¦¬ìŠ¤íŠ¸ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ê²°í•©í•˜ê¸°\n",
        "\n",
        "    return {\"final_report\": completed_report_sections}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH9uKHSGDaqO"
      },
      "source": [
        "**ê°€ìž¥ ì¤‘ìš”í•œ ë¶€ë¶„ìž…ë‹ˆë‹¤ðŸ˜ðŸ˜**   \n",
        "langgraphì˜ Send()ë¥¼ ì´ìš©í•˜ë©´, ë¦¬ìŠ¤íŠ¸ì˜ ì›ì†Œ ê°œìˆ˜ë§Œí¼ ì„œë¸Œëª¨ë“ˆì„ í˜¸ì¶œí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuqkIRicDaqO"
      },
      "outputs": [],
      "source": [
        "from langgraph.types import Send\n",
        "\n",
        "def assign_workers(state: State):\n",
        "    # Send: ë…¸ë“œë¥¼ í˜¸ì¶œí•˜ë©°, ê°’ì„ ì „ë‹¬í•´ ì¤€ë‹¤\n",
        "    # state['contents']ì˜ ê°œìˆ˜ë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ì•Œ ìˆ˜ ì—†ëŠ”ë°,\n",
        "    # ì´ë¥¼ í†µí•´ ê°œìˆ˜ë§Œí¼ llm_callì„ ìƒì„±í•˜ì—¬ í˜¸ì¶œí•  ìˆ˜ ìžˆìŒ\n",
        "\n",
        "    return [Send(\"llm_call\", {\"chapter\": s}) for s in state[\"contents\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEdmwAR1DaqO"
      },
      "source": [
        "ê·¸ëž˜í”„ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruDhpkxEDaqO"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"orchestrator\", orchestrator) # êµ¬íš ì§œê³ \n",
        "builder.add_node(\"llm_call\", llm_call) # ì„¹ì…˜ë³„ ê¸€ì“°ê³ \n",
        "builder.add_node(\"synthesizer\", synthesizer) # í•©ì¹˜ê³ \n",
        "\n",
        "\n",
        "builder.add_edge(START, \"orchestrator\")\n",
        "\n",
        "builder.add_conditional_edges(\"orchestrator\", assign_workers, [\"llm_call\"])\n",
        "# assign_workersì˜ ê²°ê³¼ì— ë”°ë¼ llm_callì„ í˜¸ì¶œ\n",
        "\n",
        "builder.add_edge(\"llm_call\", \"synthesizer\")\n",
        "# ìƒì„±ëœ ì„¹ì…˜ë“¤ì€ synthesizerë¡œ ì´ë™\n",
        "\n",
        "builder.add_edge(\"synthesizer\", END) # ë\n",
        "\n",
        "\n",
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4_faj1ODaqO"
      },
      "outputs": [],
      "source": [
        "for data in graph.stream({\"topic\": \"GPT 1ë¶€í„° ìµœì‹  LLMê¹Œì§€ì˜ ë°œì „ê³¼ì •\"}, stream_mode='updates'):\n",
        "    print(data)\n",
        "    print('--------------')\n",
        "    # ìƒì„±ì€ ë³‘ë ¬ì ì´ì§€ë§Œ í•©ì¹˜ëŠ” ìˆœì„œëŠ” í˜¸ì¶œí•œ ìˆœì„œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkeaSELrDaqO"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(data['synthesizer'][\"final_report\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90zJyo8uDaqO"
      },
      "source": [
        "## 3. Evaluator-Optimizer êµ¬ì¡°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzbth_cBDaqO"
      },
      "source": [
        "LLMì˜ ìµœì´ˆ ì¶œë ¥ì„ ë°”ë¡œ ì‚¬ìš©í•´ë„ ë˜ì§€ë§Œ, í‰ê°€ ê¸°ì¤€ì„ ë‘ê³  ë°˜ë³µì ìœ¼ë¡œ ê²€ì¦í•˜ê²Œ í•œë‹¤ë©´ ê·¸ í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.    \n",
        "\n",
        "ì£¼ì–´ì§„ `instruction`ì— ëŒ€í•œ íŒŒì´ì¬ ì½”ë“œë¥¼ ìž‘ì„±í•˜ê³ , ì´ë¥¼ ì—°ì†ì ìœ¼ë¡œ ìµœì í™”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgbT_syXDaqO"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    code: str\n",
        "    instruction: str\n",
        "    feedback: str\n",
        "    optimized: str\n",
        "\n",
        "class Feedback(BaseModel):\n",
        "    grade: Literal[\"optimized\", \"not optimized\"] = Field(description=\"ì½”ë“œê°€ ìµœì í™”ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.\")\n",
        "    feedback: str = Field(description=\"ì½”ë“œì˜ ê°œì„ ì´ í•„ìš”í•˜ë‹¤ë©´, ì–´ë–¤ ë¶€ë¶„ì„ ê°œì„ í•  ìˆ˜ ìžˆì„ì§€ ì„¤ëª…í•©ë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tLvrdjHDaqO"
      },
      "source": [
        "ë…¸ë“œ êµ¬ì¡°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.   \n",
        "ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” Generatorì™€, ì½”ë“œë¥¼ ë¹„íŒì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” Optimizer êµ¬ì¡°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_LEagHYDaqP"
      },
      "outputs": [],
      "source": [
        "evaluator = llm.with_structured_output(Feedback)\n",
        "\n",
        "def code_generator(state: State):\n",
        "    # ì½”ë“œë¥¼ ìƒì„±í•˜ê³ , í”¼ë“œë°±ì— ë”°ë¼ ë¦¬íŒ©í† ë§í•©ë‹ˆë‹¤.\n",
        "\n",
        "    if state.get(\"feedback\"):\n",
        "        # í”¼ë“œë°±ì´ ìžˆìœ¼ë©´\n",
        "\n",
        "        result = llm.invoke(\n",
        "            f\"\"\"ë‹¤ìŒ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ìž‘ì„±í•˜ì„¸ìš”. ì„¤ëª… ì—†ì´ ì½”ë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "Instruction:{state['instruction']}\n",
        "ë‹¤ìŒì˜ í”¼ë“œë°±ì„ ê³ ë ¤í•˜ì„¸ìš”.\n",
        "Feedback: {state['feedback']}\"\"\")\n",
        "    else:\n",
        "        result = llm.invoke(f\"\"\"ë‹¤ìŒ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ìž‘ì„±í•˜ì„¸ìš”. ì„¤ëª… ì—†ì´ ì½”ë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "Instruction:{state['instruction']}\"\"\")\n",
        "\n",
        "    return {\"code\": result.content}\n",
        "\n",
        "\n",
        "def code_evaluator(state: State):\n",
        "    # ì‹¤ì œë¡œëŠ” ìœ ë‹› í…ŒìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì„œ ê²€ì¦í•˜ëŠ” ê²ƒë„ í•„ìš”í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    result = evaluator.invoke(f\"\"\"ë‹¤ìŒì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œê°€ ìµœì í™”ë˜ì—ˆëŠ”ì§€ í•œêµ­ì–´ë¡œ í‰ê°€í•˜ì„¸ìš”.\n",
        "í‰ê°€ ê¸°ì¤€ì€ ì½”ë“œì˜ ê¸¸ì´ì™€ ì‹¤í–‰ ì†ë„ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ìž…ë‹ˆë‹¤.\n",
        "ì½”ë“œì˜ ê¸¸ì´ê°€ ì œì¼ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
        "---\n",
        "Instruction:{state['instruction']}\n",
        "---\n",
        "Source Code: {state['code']}\"\"\")\n",
        "\n",
        "    return {\"optimized\": result.grade, \"feedback\": result.feedback}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Optimized ê°’ì— ë”°ë¼ ê²½ë¡œ ì„¤ì •\n",
        "def route_code(state: State):\n",
        "    return 'Accepted' if state[\"optimized\"] == \"optimized\" else 'Rejected + Feedback'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQqW_zrtDaqP"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"code_generator\", code_generator)\n",
        "builder.add_node(\"code_evaluator\", code_evaluator)\n",
        "\n",
        "builder.add_edge(START, \"code_generator\")\n",
        "builder.add_edge(\"code_generator\", \"code_evaluator\")\n",
        "\n",
        "builder.add_conditional_edges(\"code_evaluator\",route_code,\n",
        "                              {\"Accepted\": END,\"Rejected + Feedback\": \"code_generator\"})\n",
        "\n",
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_-QBY4oDaqP"
      },
      "outputs": [],
      "source": [
        "for data in graph.stream({'instruction':'ìžì—°ìˆ˜ë³´ë‹¤ ìž‘ì€ ì†Œìˆ˜ ê°œìˆ˜ êµ¬í•˜ê¸°'}, stream_mode='updates'):\n",
        "    if 'code_generator' in data:\n",
        "        print(data['code_generator']['code'])\n",
        "    else:\n",
        "        print(data['code_evaluator']['optimized'],'-->', data['code_evaluator']['feedback'])\n",
        "    print('--------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enP8sZ-kYgBD"
      },
      "outputs": [],
      "source": [
        "for data in graph.stream({'instruction':'ìžì—°ìˆ˜ ì†Œì¸ìˆ˜ë¶„í•´'}, stream_mode='updates'):\n",
        "    if 'code_generator' in data:\n",
        "        print(data['code_generator']['code'])\n",
        "    else:\n",
        "        print(data['code_evaluator']['optimized'],'-->', data['code_evaluator']['feedback'])\n",
        "    print('--------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in graph.stream({'instruction':'Convex Hull ë¬¸ì œ'}, stream_mode='updates'):\n",
        "    if 'code_generator' in data:\n",
        "        print(data['code_generator']['code'])\n",
        "    else:\n",
        "        print(data['code_evaluator']['optimized'],'-->', data['code_evaluator']['feedback'])\n",
        "    print('--------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhqiOqBxndID"
      },
      "source": [
        "## [실습] Human-in-the-loop 구조 실행하기\n",
        "\n",
        "Human-in-the-loop는 LangGraph 어플리케이션을 작동중일 때, 그래프의 중간 과정에서 사용자의 응답을 요청하는 과정입니다.   \n",
        "\n",
        "`interrupt`를 특정 시점에 실행하면, 해당 시점에서 실행이 중단되는데요.    \n",
        "\n",
        "\n",
        "해당 노드에서 `Command(resume)`를 통해 재개할 수 있습니다.   \n",
        "\n",
        "또한, `Command(goto)`는 다른 위치로 이동하기 위해 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqvXCaKmndIE"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph langchain langchain_google_genai langchain-tavily -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez7q9HTAndIE"
      },
      "source": [
        "LLM을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G28NkBlZndIF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIxxx'\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    # temperature\n",
        "    # max_tokens\n",
        "\n",
        "    thinking_budget = 500  # 추론(Reasoning) 토큰 길이 제한\n",
        ")\n",
        "\n",
        "llm.invoke(\"안녕\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJz-rKwPndIF"
      },
      "source": [
        "중간 과정 확인을 위해, LangSmith를 연동합니다.\n",
        "https://smith.langchain.com 에서 등록 후 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWtzXfJ5ndIF"
      },
      "outputs": [],
      "source": [
        "os.environ['LANGCHAIN_API_KEY'] = ''\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LangGraph_FastCampus'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVl_Fr8EndIF"
      },
      "source": [
        "### 네이버 블로그 검색 Tool 구성하기\n",
        "네이버의 검색 API를 이용해, 블로그 검색을 연결하겠습니다.   \n",
        "(https://developers.naver.com/apps/#/register?defaultScope=search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y9LgrgYndIF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import urllib.request\n",
        "import json\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "from typing_extensions import TypedDict, Literal, Annotated\n",
        "\n",
        "headers = {\n",
        "    'X-Naver-Client-Id': 'Ko6yIqbV2TOHq9rPH8tu',\n",
        "    'X-Naver-Client-Secret': 'BvqX8mNtHu'\n",
        "}\n",
        "\n",
        "@tool\n",
        "def search_blogs(query: str, display : int = 10, sort : Literal['sim', 'date'] = 'sim') -> list:\n",
        "    \"\"\"네이버 블로그 검색을 수행하여 검색 결과를 리스트로 반환합니다.\n",
        "    query: 검색어\n",
        "    display: 검색 결과 개수\n",
        "    sort: sim(관련도순), date(시간순)\n",
        "    \"\"\"\n",
        "\n",
        "    client_id = headers['X-Naver-Client-Id']\n",
        "    client_secret = headers['X-Naver-Client-Secret']\n",
        "\n",
        "    encText = urllib.parse.quote(query)\n",
        "    url = f\"https://openapi.naver.com/v1/search/blog?query={encText}&display={display}\"\n",
        "\n",
        "    request = urllib.request.Request(url)\n",
        "    request.add_header(\"X-Naver-Client-Id\", client_id)\n",
        "    request.add_header(\"X-Naver-Client-Secret\", client_secret)\n",
        "\n",
        "    response = urllib.request.urlopen(request)\n",
        "    rescode = response.getcode()\n",
        "\n",
        "    if rescode == 200:\n",
        "        response_body = response.read()\n",
        "        data = json.loads(response_body.decode('utf-8'))\n",
        "\n",
        "        # 필요한 데이터 추출\n",
        "        blog_list = [\n",
        "            {\n",
        "                \"title\": item[\"title\"].replace(\"<b>\", \"\").replace(\"</b>\", \"\"),  # 태그 제거\n",
        "                \"link\": item[\"link\"],\n",
        "                \"description\": item[\"description\"].replace(\"<b>\", \"\").replace(\"</b>\", \"\"),\n",
        "                \"postdate\": item[\"postdate\"]\n",
        "            }\n",
        "            for item in data.get(\"items\", [])\n",
        "        ]\n",
        "\n",
        "        return blog_list\n",
        "    else:\n",
        "        return ['에러 발생, 다른 검색어로 다시 시도하세요.']\n",
        "\n",
        "\n",
        "tool_list = [search_blogs]\n",
        "llm_with_tools = llm.bind_tools(tool_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_with_tools.invoke(\"안녕\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxL9T7XSndIG"
      },
      "source": [
        "툴을 구성한 뒤, State와 노드를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqSkj86wndIG"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# query와 messages를 저장\n",
        "class State(TypedDict):\n",
        "    query : str\n",
        "    messages : Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytiAb1uXndIG"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.types import Command, interrupt\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "# 메시지 입력\n",
        "def get_user_input(state):\n",
        "    human_message = input()\n",
        "    return {'messages':[HumanMessage(content = human_message)]}\n",
        "\n",
        "def agent(state):\n",
        "    system_message = SystemMessage(content='''당신은 검색 및 요약 챗봇입니다.\n",
        "사용자의 질문을 해결하기 위해 검색 툴을 사용하고, 해당 결과를 바탕으로 답변하세요.\n",
        "요청을 해결한 다음에는 마지막에 '감사합니다! 챗봇을 종료합니다!'를 출력하세요.''')\n",
        "\n",
        "    return {\"messages\": [llm_with_tools.invoke([system_message] + state[\"messages\"])]}\n",
        "\n",
        "\n",
        "def run_tool(state):\n",
        "    new_messages = []\n",
        "    last_message = state[\"messages\"][-1]\n",
        "\n",
        "    tools = {tool.name:tool for tool in tool_list}\n",
        "\n",
        "    tool_calls = last_message.tool_calls\n",
        "\n",
        "    for tool_call in tool_calls:\n",
        "        tool = tools[tool_call[\"name\"]]\n",
        "        result = tool.invoke(tool_call)\n",
        "        # ToolMessage\n",
        "        new_messages.append(result)\n",
        "    return {\"messages\": new_messages}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHqwYepBndIG"
      },
      "source": [
        "툴을 실행하기 전, `human_review`를 통과하도록 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcr0zFZ9ndIG"
      },
      "outputs": [],
      "source": [
        "# Typing Hint를 연결하면 Graph에 표시됨\n",
        "def human_review(state) -> Command[Literal[\"agent\", \"run_tool\"]]:\n",
        "\n",
        "    # !!중요!!\n",
        "    # Human_review가 실행되는 상황은 언제일까요?\n",
        "    # Tool을 실행하기 전이므로, 이 상태의 Context는\n",
        "    # 항상 [..., AIMessage(content, tool_calls)]\n",
        "\n",
        "    last_message = state[\"messages\"][-1] # tool call 포함된 AIMessage\n",
        "    tool_call = last_message.tool_calls[-1]\n",
        "\n",
        "    # inturrupt로 중단된 결과는 Command를 통해 재개\n",
        "    human_review = interrupt(\n",
        "        {\n",
        "            \"question\": \"이대로 진행할까요?\",\n",
        "            \"tool_call\": tool_call,\n",
        "        }\n",
        "    )\n",
        "    review_action = human_review[\"action\"]\n",
        "    review_data = human_review.get(\"data\")\n",
        "\n",
        "    print('Decision:', review_action, '\\n Content:', review_data)\n",
        "\n",
        "\n",
        "    # 그대로 진행하는 경우, run_tool로 진입\n",
        "    if review_action == \"continue\":\n",
        "        return Command(goto=\"run_tool\")\n",
        "\n",
        "    # update가 필요한 경우, review_data를 args에 넣고 run_tool로 진입\n",
        "    elif review_action == \"update\":\n",
        "        updated_message = {\n",
        "            \"role\": \"ai\",\n",
        "            \"content\": last_message.content,\n",
        "            \"tool_calls\": [\n",
        "                {\n",
        "                    \"id\": tool_call[\"id\"],\n",
        "                    \"name\": tool_call[\"name\"],\n",
        "\n",
        "                    \"args\": review_data,\n",
        "                    # 새로운 입력\n",
        "                }\n",
        "            ],\n",
        "            \"id\": last_message.id,\n",
        "            # 메시지 id를 동일하게 설정해 Override\n",
        "        }\n",
        "        return Command(goto=\"run_tool\", update={\"messages\": [updated_message]})\n",
        "\n",
        "\n",
        "    # Feedback: 단순 언어로 피드백을 전달하고 싶은 경우\n",
        "    elif review_action == \"feedback\":\n",
        "\n",
        "        # Tool Call 요청을 새로운 유저 메시지로 대체합니다.\n",
        "\n",
        "        new_human_message = HumanMessage(content = review_data,\n",
        "        id = last_message.id)\n",
        "\n",
        "        return Command(goto=\"agent\", update={\"messages\": [new_human_message]})\n",
        "\n",
        "\n",
        "def route_after_llm(state) -> Literal[END, \"get_user_input\", \"human_review\"]:\n",
        "\n",
        "    last_message = state['messages'][-1]\n",
        "    # 마지막 메시지: tool calling\n",
        "    # 2025.10.26 업데이트: Gemini의 Thinking 모델(2.5 이후)에는\n",
        "    # Tool Calling 이후의 messages에 signature가 포함되어 형식이 달라집니다.\n",
        "    last_message_content = last_message.content\n",
        "\n",
        "    if not last_message.tool_calls:\n",
        "        if '감사합니다! 챗봇을 종료합니다!' in last_message_content:\n",
        "            return END\n",
        "        elif isinstance(last_message_content[0], dict) and 'text' in last_message_content[0] and '감사합니다! 챗봇을 종료합니다!' in last_message_content[0]['text']:\n",
        "            return END\n",
        "        return 'get_user_input'\n",
        "    else:\n",
        "        return \"human_review\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzt843rkndIG"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(State)\n",
        "builder.add_node(get_user_input)\n",
        "builder.add_node(agent)\n",
        "builder.add_node(run_tool)\n",
        "builder.add_node(human_review)\n",
        "\n",
        "builder.add_edge(START, \"get_user_input\")\n",
        "builder.add_edge('get_user_input', \"agent\")\n",
        "builder.add_conditional_edges(\"agent\", route_after_llm)\n",
        "builder.add_edge(\"run_tool\", \"agent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbsbxiLwqx3s"
      },
      "outputs": [],
      "source": [
        "memory = MemorySaver()\n",
        "\n",
        "graph = builder.compile(checkpointer=memory)\n",
        "# 중간 상태 저장을 위해 체크포인터가 필요합니다!\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8XKYNV1ndIG"
      },
      "outputs": [],
      "source": [
        "from rich import print as rprint\n",
        "# Input\n",
        "initial_input = {\"messages\": []}\n",
        "\n",
        "# Thread\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n",
        "    rprint(event)\n",
        "    rprint(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_thhvniqndIG"
      },
      "source": [
        "`__interrupt__`가 구성되면, 사용자 확인을 위해 중단된 상황입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJkvs6YrndIG"
      },
      "outputs": [],
      "source": [
        "print(\"graph 현재 상황\")\n",
        "print(graph.get_state(thread).next)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl9L0zJzndIG"
      },
      "source": [
        "`human_review`에 기록된 값 중 하나를 입력하여 작업을 재개합니다.   \n",
        "`Command`의 resume으로 값을 보낼 수 있습니다.\n",
        "\n",
        "1. `{\"action\": \"continue\"}`\n",
        "2. `{\"action\": \"update\", \"data\": {\"query\": \"새로운 쿼리\"}}`\n",
        "3. `{\"action\": \"feedback\", \"data\": {\"query\": \"전달할 피드백 내용\"}}`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YEtPxGyndIH"
      },
      "source": [
        "### Continue\n",
        "run_tool으로 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJK8DWD6ndIH"
      },
      "outputs": [],
      "source": [
        "for event in graph.stream(\n",
        "\n",
        "    Command(resume={\"action\": \"continue\"}),\n",
        "    thread,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so0kTEXrndIH"
      },
      "source": [
        "### Update\n",
        "Command로 전달되는 값을 받아 갱신합니다.   \n",
        "검색 쿼리를 수정하기로 설정했으므로, 바뀐 쿼리를 전달하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVeQ0I25ndIH"
      },
      "outputs": [],
      "source": [
        "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ee2-2pzndIH"
      },
      "outputs": [],
      "source": [
        "for event in graph.stream(\n",
        "    Command(resume={\"action\": \"update\", \"data\": {\"query\": \"2025년 10월 개봉 영화\"}}),\n",
        "    thread,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj0mB9XOndIH"
      },
      "source": [
        "### feedback   \n",
        "구현 방식에 따라, 자연어로 구성된 피드백을 전달하면 이를 반영하여 수정할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSlB7RZZndIH"
      },
      "outputs": [],
      "source": [
        "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "\n",
        "for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDQNIVcAndIH"
      },
      "outputs": [],
      "source": [
        "for event in graph.stream(\n",
        "    Command(\n",
        "        resume={\n",
        "            \"action\": \"feedback\",\n",
        "            \"data\": \"아냐, 왓챠에서 찾아볼래. 왓챠로 검색해봐.\",\n",
        "        }\n",
        "    ),\n",
        "    thread,\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hsaKpcvndIH"
      },
      "outputs": [],
      "source": [
        "# 다시 Agent로 전달되었으므로 다시 Interrupt 발생\n",
        "print(\"다음 상태\")\n",
        "print(graph.get_state(thread).next)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcCytpvqndIH"
      },
      "outputs": [],
      "source": [
        "for event in graph.stream(\n",
        "    Command(resume={\"action\": \"continue\"}),\n",
        "    thread,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(event)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEGQlxqrSWD"
      },
      "source": [
        "Langsmith (https://smith.langchain.com )에서 실행 결과를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k258S01vrRl0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

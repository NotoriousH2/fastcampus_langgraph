{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dNVSrWPrDMe",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# [실습] LangGraph 기초\n",
        "\n",
        "랭그래프는 어플리케이션의 작동 과정을 Graph로 정의하고, 이를 통해 복잡한 Workflow를 실행합니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0BW7qQvrDMe"
      },
      "source": [
        "기본 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zQPyAAOdrDMf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: langchain in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.2)\n",
            "Requirement already satisfied: langchain_google_genai in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (0.4)\n",
            "Requirement already satisfied: langchain_tavily in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (0.2.12)\n",
            "Collecting bs4\n",
            "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph) (1.0.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph) (2.12.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_google_genai) (0.9.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (2.41.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (6.33.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.76.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (6.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (3.13.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (2.3.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Collecting beautifulsoup4 (from bs4)\n",
            "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
            "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Using cached bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
            "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
            "\n",
            "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
            "   ---------------------------------------- 3/3 [bs4]\n",
            "\n",
            "Successfully installed beautifulsoup4-4.14.2 bs4-0.0.2 soupsieve-2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langchain langchain_google_genai langchain_community langchain_tavily bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKKCoKmVrDMf"
      },
      "source": [
        "# Graph의 구성 요소: State, Node, Edge, Graph\n",
        "\n",
        "\n",
        "시작 지점과 끝 지점을 표시한 그래프를 구성하고, 전체 그래프를 `invoke()`를 통해 실행합니다.\n",
        "\n",
        "그래프는 점과 선으로 구성되는데요.  \n",
        "\n",
        "\n",
        "\n",
        "이를 노드(Node, 정점), 엣지(Edge, 간선)라고 부릅니다.    \n",
        "\n",
        "각각의 노드는 LLM 호출을 비롯한 하나의 기능을 수행하게 되며, 기능과 기능 사이의 연결을 엣지로 구성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0MQDjCOrDMf"
      },
      "source": [
        "### State\n",
        "\n",
        "LangGraph의 Workflow는 State Diagram으로 볼 수 있습니다.   \n",
        "\n",
        "전체 Workflow에서, State는 초기 State에서 시작해    \n",
        "Node와 Edge를 통과하며 그 값이 수정되거나 추가되는 과정을 거치게 됩니다.   \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYFYHW6xrDMf"
      },
      "source": [
        "State의 구조는 보통 가시성을 위해 타입 표시를 병행합니다.   \n",
        "`TypedDict`나 `Pydantic`중 편한 것을 사용하면 되는데요.   \n",
        "이번 교재에서는 공식 문서와 동일한 `TypedDict`를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uaBQ0lFhrDMf"
      },
      "outputs": [],
      "source": [
        "# TypedDict: 타입 표시가 가능한 구조\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    result: str\n",
        "    secret: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy0OiRSOrDMg"
      },
      "source": [
        "### Node\n",
        "\n",
        "노드는 함수로 정의되는데, 주로 하나의 모듈을 하나의 노드로 구성합니다.   \n",
        "State는 노드를 지나며 새로운 정보를 추가하거나, 값을 수정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PLxb0OgPrDMg"
      },
      "outputs": [],
      "source": [
        "# state에 문자열을 추가하는 노드\n",
        "def first(state):\n",
        "    print(\"---Node 1---\")\n",
        "    return {\"result\": state['result'] +\"랭그래프 1번 노드 통과\\n\"}\n",
        "\n",
        "def second(state):\n",
        "    print(\"---Node 2---\")\n",
        "    return {\"result\": state['result'] +\"랭그래프 2번 노드 통과\\n\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq9xwXDArDMg"
      },
      "source": [
        "### Edge와 Graph   \n",
        "\n",
        "위에서 설정한 State를 이용하여 Graph를 정의합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRTveKMvrDMg"
      },
      "source": [
        "그래프에 노드와 엣지를 추가합니다.    \n",
        "START와 END를 import하고, 시작점과 끝점을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fmgnv9JirDMg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x2b897588620>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# 그래프 정의하기\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# 노드 이름과 함수 이름은 같지 않아도 됨\n",
        "builder.add_node(\"first\", first)\n",
        "builder.add_node(\"second\", second)\n",
        "\n",
        "builder.add_edge(START, \"first\")\n",
        "builder.add_edge(\"first\", \"second\")\n",
        "builder.add_edge(\"second\", END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNPXjlONrDMg"
      },
      "source": [
        "만든 그래프는 `compile()`을 통해 실행 가능한 Runnable 구조로 만들어집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HM2Mh4AurDMg"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x000002B8963FA0F0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = builder.compile()\n",
        "\n",
        "graph\n",
        "# 간단한 Mermaid 기반의 시각화 지원"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1ixQ8I6rDMg"
      },
      "source": [
        "구성된 graph를 실행해 보겠습니다!   \n",
        "state의 초기 상태를 Dictionary 형태로 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PuREzEh_rDMg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Node 1---\n",
            "---Node 2---\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'result': '시작!\\n랭그래프 1번 노드 통과\\n랭그래프 2번 노드 통과\\n', 'secret': '비밀'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = graph.invoke({'result':'시작!\\n', 'secret':'비밀'})\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2dxUlJprDMg"
      },
      "source": [
        "## 그래프에 LLM 포함시키기\n",
        "이번에는 값이 여러 개인 State를 구성하고, 그래프로 만들어 보겠습니다.   \n",
        "llm도 활용해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGoAhLcArDMg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIxxx'\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    # temperature\n",
        "    # max_tokens\n",
        "\n",
        "    thinking_budget = 500  # 추론(Reasoning) 토큰 길이 제한\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeVNjKtUrDMg"
      },
      "source": [
        "3개의 요소가 포함된 State를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NexQyV2prDMh"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    integer: int\n",
        "    root: int\n",
        "    joke: str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGJfcojyrDMh"
      },
      "source": [
        "2개의 노드를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cLK5UYLlrDMh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def get_root(state):\n",
        "    return {\"root\": int(state[\"integer\"] ** 0.5)}\n",
        "\n",
        "def get_joke(state):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '당신은 언어 유희의 달인입니다.'),\n",
        "         ('user','{length} 문장 길이의 짧은 영어 유머를 만들어주세요. 각 문장마다 숫자를 붙이세요.')\n",
        "    ])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"joke\": chain.invoke({'length':state['root']})}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzvSGtVkrDMh"
      },
      "source": [
        "그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8jSfnN95rDMh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x2b899d3f710>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 그래프 구성\n",
        "# 이미 존재하는 노드를 또 만들면 에러가 발생할 수 있으므로\n",
        "# 그래프를 수정할 때에는 builder 초기화부터 꼭 하기\n",
        "\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"get_root\", get_root)\n",
        "builder.add_node(\"get_joke\", get_joke)\n",
        "\n",
        "builder.add_edge(START, \"get_root\")\n",
        "builder.add_edge(\"get_root\", \"get_joke\")\n",
        "builder.add_edge(\"get_joke\", END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xANgxFgVrDMh"
      },
      "source": [
        "그래프를 컴파일하고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y--knEeLrDMh"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x000002B899D63E30>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YrBsmHcHrDMh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'integer': 16,\n",
              " 'root': 4,\n",
              " 'joke': '알겠습니다! 언어 유희의 달인으로서, 짧고 유머러스한 영어 농담을 만들어 드리겠습니다.\\n\\n1.  Why did the tomato turn red?\\n2.  Because it saw the salad dressing!\\n3.  It was feeling a little saucy.\\n4.  Lettuce all laugh together!'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_state = {'integer': 16}\n",
        "response = graph.invoke(initial_state)\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbboFf3nrDMh"
      },
      "source": [
        "### 웹 검색 노드 만들기   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCTsYQR-rDMh"
      },
      "source": [
        "이번 실습에서는 웹 검색 툴 결과를 바탕으로, 실제 URL을 크롤링하여 문서의 내용을 가져오겠습니다.   \n",
        "\n",
        "랭체인에서 웹 페이지를 크롤링하기 위해서는 대표적으로 아래 3개의 방법을 사용할 수 있습니다.\n",
        "\n",
        "1. `WebBaseLoader` : BeautifulSoup4 기반의 기본 크롤러로, HTML 코드를 그대로 가져옵니다.\n",
        "2. `Docling` : 다양한 포맷의 문서를 텍스트 포맷으로 변환하는 오픈 소스 프로젝트로, 유용하나 빠른 실행을 위해 GPU 성능이 다소 요구됩니다.\n",
        "3. `FireCrawl`: API 기반의 유료 서비스로, 무료 라이센스는 총 500회 무료 사용이 가능합니다.   \n",
        "WebBaseLoader를 사용하겠습니다 :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0PUi6xqWrDMh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={'source': 'https://brunch.co.kr/@ukai/2', 'title': 'Multi Agent와 Agentic Workflow?', 'description': \"이 두 가지가 다른거야...? | Prologue: 왜 지금 'AI 에이전트'에 다시 주목하는가? 대규모 언어 모델(LLM)의 등장은 단순한 '챗봇'의 시대를 넘어, 스스로 생각하고, 계획하며, 도구를 사용해 '실제로 일하는 AI', 즉 AI 에이전트의 시대를 열었습니다. 이제 AI는 단순히 질문에 답하는 것을 넘어, 복잡한 리서치를 수행하고, 코드를 디버깅하며, 마케팅 캠페인까지 자동화하\", 'language': 'ko'}, page_content=\"  \\n\\n\\nMulti Agent와 Agentic Workflow?       \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          메뉴 brunch          Multi Agent와 Agentic Workflow? 이 두 가지가 다른거야...? by Ukai  Jun 25. 2025    Prologue: 왜 지금 'AI 에이전트'에 다시 주목하는가?대규모 언어 모델(LLM)의 등장은 단순한 '챗봇'의 시대를 넘어, 스스로 생각하고, 계획하며, 도구를 사용해 '실제로 일하는 AI', 즉 AI 에이전트의 시대를 열었습니다. 이제 AI는 단순히 질문에 답하는 것을 넘어, 복잡한 리서치를 수행하고, 코드를 디버깅하며, 마케팅 캠페인까지 자동화하는 주체적인 행위자로 진화하고 있습니다.이러한 '일하는 AI'를 구현하는 방식에는 크게 두 가지 핵심 패러다임이 존재합니다: 바로 멀티 에이전트 시스템(Multi-Agent System, MAS)과 에이전틱 워크플로우(Agentic Workflow)입니다. 둘 다 여러 에이전트를 활용할 수 있지만, 그 철학과 구조, 작동 방식에는 근본적인 차이가 있습니다. 당신의 AI 프로젝트가 자율적인 전문가들의 '팀'을 필요로 하는지, 아니면 잘 짜인 '자동화 프로세스'를 필요로 하는지 이해하는 것은 성공의 핵심 열쇠가 될 것입니다.Part 1. 개념 바로 알기: 당신의 AI는 '팀'인가, '프로세스'인가?두 개념을 가장 쉽게 이해하는 방법은 팀과 프로세스에 비유하는 것입니다.Multi-Agent System (MAS): 자율적인 전문가들로 구성된 '드림팀'자율적인 지능형 에이전트(Agent)들의 집합으로, 이들이 서로 상호작용(협력, 경쟁, 협상)하며 개별 에이전트의 능력을 넘어서는 복잡한 문제를 해결하는 분산 시스템입니다.핵심은 개별 에이전트의 지능이 아니라, 에이전트 간의 상호작용에서 비롯되는 예측 불가능한 창발적(Emergent) 행동에 있습니다. 각 에이전트는 독립적인 목표와 의사결정 능력을 가진 '전문가'와 같습니다.  예시: 여러 자율주행차가 서로의 위치와 속도를 실시간으로 통신하며 충돌 없이 교차로를 통과하는 교통 시스템. 각 차량이 독립적인 에이전트 역할을 합니다. 출처 : https://towardsdatascience.com/agentic-ai-single-vs-multi-agent-systems/Agentic Workflow: 목표를 향해 달리는 잘 짜인 '자동화 컨베이어 벨트'특정 목표를 달성하기 위해 설계된 구조화된 프로세스를 하나 또는 여러 AI 에이전트가 자율적으로 실행하는 자동화 방식입니다.핵심은 명확한 목표 달성을 위한 구조화된 절차와 동적 실행에 있습니다. '작업 계획 수립 → 도구 사용 → 실행 → 결과 평가 → 피드백 및 수정'과 같은 명확한 단계를 거칩니다.  예시: '경쟁사 분석 보고서 작성'이라는 명령에, AI가 웹 검색으로 자료를 수집(1단계)하고, 수집된 자료를 분석/요약(2단계)한 후, 차트 생성 툴로 시각화(3단계)하여 최종 보고서를 완성하는 일련의 과정. 출처 : https://weaviate.io/blog/what-are-agentic-workflowsPart 2. 아키텍처 분석두 시스템은 AI가 작동하는 방식, 즉 아키텍처에서 뚜렷한 차이를 보입니다.MAS의 탈중앙화 구조: 에이전트들은 어떻게 소통하고 협력하는가?MAS는 중앙 관제탑 없이 에이전트들이 자율적으로 소통하는 탈중앙화(Decentralized) 구조를 가집니다.  구조에이전트들이 동등한 위치에서 소통하는 수평적 네트워크 또는 역할에 따라 상하 관계를 갖는 계층적 구조 모두 가능합니다.상호작용에이전트 간 통신 언어(ACL, Agent Communication Language)나 모두가 접근 가능한 공유된 환경(Shared Environment)을 통해 정보를 교환하고 협상합니다.제어각 에이전트의 자율적인 결정들이 모여 전체 시스템의 행동이 결정되는 상향식(Bottom-up) 제어 방식입니다. 이로 인해 시스템 전체의 행동을 예측하기 어렵습니다.LLM의 역할각 개별 에이전트의 '두뇌' 역할을 하거나, 자연어 소통을 위한 보조 지능으로 활용됩니다.Agentic Workflow의 오케스트레이션: 누가 작업을 지시하고 흐름을 제어하는가?Agentic Workflow는 전체 과정을 지휘하는 지휘자(오케스트레이터)가 있는 중앙 집중형(Centralized) 구조를 따릅니다.  구조'마스터 에이전트' 또는 '오케스트레이터(Orchestrator)'가 전체 작업 흐름을 관리하고, 필요한 하위 작업을 다른 에이전트나 도구에 할당합니다.상호작용사전에 정의된 워크플로우에 따라 순차적, 병렬적으로 작업이 전달됩니다. 중간 결과를 검증하고 수정하는 피드백 루프(Feedback Loop)가 핵심적인 역할을 합니다.제어명확한 목표와 절차에 따라 움직이는 하향식(Top-down) 제어 방식입니다. 전체 프로세스가 예측 가능하고 관리하기 용이합니다.LLM의 역할워크플로우 전체를 조율하는 중심 제어 엔진 또는 오케스트레이터 역할을 수행하며, 작업 분해, 도구 선택, 결과 통합 등을 주도합니다.아키텍쳐 비교 Part 3. 핵심 차이점 비교 Part 4. 실제 적용 사례 (Use Cases)Multi Agent System- 사례 : 자율주행, 분산형 에너지 그리드, 실시간 금융 트레이딩, 협력 로봇- 이유 : 이 분야들은 예측 불가능한 변수가 많고, 여러 독립적인 주체(차량, 발전소, 로봇)가 실시간으로 정보를 교환하며 최적의 결정을 내려야 합니다. 일부 에이전트가 고장 나도 전체 시스템이 유지되는 강건성(Robustness)과 새로운 에이전트를 쉽게 추가할 수 있는 확장성(Scalability)이 큰 장점입니다.- 단점 : 에이전트 간의 효과적인 통신 및 협력 규칙을 설계하기가 매우 복잡하고, 창발적 행동으로 인해 결과를 예측하거나 제어하기 어렵습니다.Agentic Workflow- 사례: 리서치 보고서 자동 생성, 마케팅 캠페인 자동화, 소프트웨어 개발 및 디버깅, 고객 지원 자동화- 이유: 이 작업들은 '정보 수집 → 분석 → 초안 작성 → 검토' 와 같이 명확한 단계로 나눌 수 있습니다. 정의된 절차에 따라 작동하므로 결과가 안정적이고, LangChain, CrewAI 같은 프레임워크를 통해 상대적으로 쉽게 구현할 수 있는 효율성과 예측 가능성이 장점입니다.- 단점: 사전에 정의되지 않은 예외 상황에 대처하는 유연성이 부족하며, 오케스트레이터가 실패하면 전체 프로세스가 멈추는 중앙 집중화의 위험이 있습니다.Epilogue: AI 에이전트의 미래, 두 패러다임의 융합현재는 MAS와 Agentic Workflow가 뚜렷이 구분되지만, 미래에는 두 패러다임이 융합된 하이브리드 모델이 주류가 될 것입니다. 예를 들어, 거대한 Agentic Workflow의 특정 단계(e.g., '시장 데이터 분석')를 여러 전문 에이전트로 구성된 소규모 MAS가 담당하는 구조를 상상해볼 수 있습니다. 이는 Agentic Workflow의 안정성과 MAS의 유연성 및 전문성을 결합한 강력한 솔루션이 될 것입니다.AI 에이전트 시대를 맞이하는 개발자와 기획자는 더 이상 단일 모델의 성능에만 의존해서는 안 됩니다. 해결하고자 하는 문제의 본질을 파악하고, 그에 맞는 최적의 '시스템 아키텍처'를 설계하는 능력이 AI 시대의 새로운 경쟁력이 될 것입니다.참고 문헌 (References)  https://brunch.co.kr/@b2439ea8fc654b8/41https://app.dalpha.so/blog/llm/https://towardsdatascience.com/agentic-ai-single-vs-multi-agent-systemshttps://www.superannotate.com/blog/multi-agent-llmshttps://weaviate.io/blog/what-are-agentic-workflows       keyword    AI        10  댓글 댓글0   작성된 댓글이 없습니다. 작가에게 첫 번째 댓글을 남겨주세요! 브런치에 로그인하고 댓글을 입력해보세요! Ukai   직업 엔지니어   인공지능이 인류의 유토피아 건설에 핵심 역할을 할 수 있다고 믿는 사람입니다. 기술과 인간이 조화롭게 만들어갈 이상적인 미래를 상상하고 실현하고자 합니다. 구독자 1 제안하기 구독   작가의 이전글LLM 에이전트, '만들기' 전에 '기획'하는 법AI, 언어모델, LLM: 5분 만에 정리해 드립니다.작가의 다음글              \"),\n",
              "  Document(metadata={'source': 'https://cloud.google.com/discover/what-is-a-multi-agent-system?hl=ko', 'title': 'AI에서 멀티 에이전트 시스템이란 무엇인가요? | Google Cloud', 'description': '멀티 에이전트 시스템은 자율 에이전트를 사용하여 상호작용을 통해 복잡한 문제를 해결합니다. 사용 사례, 아키텍처, Google Cloud 통합에 대해 알아봅니다.', 'language': 'ko'}, page_content=\"AI에서 멀티 에이전트 시스템이란 무엇인가요? | Google Cloud페이지 콘텐츠주제멀티 에이전트 시스템(MAS)멀티 에이전트 시스템(MAS) 가이드어떤 개인이나 대규모 모놀리식 프로그램으로는 효율적으로 해결할 수 없는 복잡한 문제가 있다고 상상해 보세요. 이제 각기 다른 고유한 기술을 보유한 고도로 전문화된 전문가 팀이 유연하게 공동작업하고 의도를 전달하며 공동으로 과제를 해결한다고 상상해 보세요. 이것이 바로 인공지능에서 멀티 에이전트 시스템(MAS)의 본질입니다. MAS는 모든 것을 포괄하는 단일 AI 솔루션에서 함께 작동하는 지능형 에이전트의 분산된 협업 네트워크로의 강력한 패러다임 전환을 나타냅니다.\\xa0무료로 시작하기 멀티 에이전트 시스템이란 무엇인가요?멀티 에이전트 시스템은 공유 환경 내에 위치한 에이전트라고 하는 여러 자율적이고 상호작용하는 컴퓨팅 개체로 구성됩니다. 이러한 에이전트는 개별 목표 또는 공동 목표를 달성하기 위해 공동작업하거나 조정하거나 때로는 경쟁하기도 합니다. 중앙 집중식 제어를 사용하는 기존 애플리케이션과 달리 MAS는 분산 제어 및 의사 결정을 특징으로 하는 경우가 많습니다. MAS의 이러한 집단적 행동은 정확성, 적응성, 확장성을 높여 수백 또는 수천 개의 에이전트가 포함될 수 있는 대규모의 복잡한 작업을 해결할 수 있게 해 줍니다.멀티 에이전트 시스템과 단일 에이전트 시스템 비교멀티 에이전트 시스템과 단일 에이전트 시스템의 근본적인 차이는 문제 해결 접근 방식과 상호작용 범위에 있습니다.단일 에이전트 시스템은 환경 내에서 독립적으로 작동하여 특정 목표를 달성하는 단일 자율적 개체를 특징으로 하며, 다른 에이전트와 직접 상호작용하지 않습니다. 체스판을 분석하고 사전 정의된 규칙이나 학습된 전략에 따라 의사 결정을 내리는 격리된 체스 게임 AI를 생각해 보세요. 이러한 시스템은 추천 엔진이나 사기 감지처럼 외부 상호작용이 최소화되고 중앙 집중식 제어가 효율적인 잘 정의된 문제에 탁월합니다. 이러한 모델은 개발이 더 간단하고 유지보수 비용이 낮으며 예측 가능한 결과를 제공하는 경우가 많습니다.반면 멀티 에이전트 시스템은 공유 환경 내에 여러 에이전트가 존재한다는 특징이 있습니다. 이러한 에이전트는 개별 목표 또는 공동의 목표를 달성하기 위해 공동작업, 경쟁 또는 협상에 자주 참여합니다. 각 에이전트가 문제의 일부를 담당하고 다른 에이전트와 통신하여 공유된 목표를 달성하는 고기능 팀과 같습니다. 분산된 워크로드와 전문화된 역할을 통해 MAS는 단일 에이전트가 감당하기 어려운 복잡하고 역동적이거나 대규모의 과제를 처리할 수 있습니다. MAS는 강력한 통신 및 조정 프로토콜이 필요하기 때문에 설계가 더 복잡하지만, 유연성, 견고성, 확장성이 뛰어납니다.멀티 에이전트 시스템의 작동 방식멀티 에이전트 시스템은 개별 에이전트 간에 작업과 커뮤니케이션을 분배하여 작동하며, 각 에이전트는 공유 환경 내에서 목표를 달성하기 위해 협력합니다. 이 프로세스에는 일반적으로 다음이 포함됩니다.인식: 에이전트는 주변을 관찰하고 데이터를 수집합니다. 여기에는 직접적인 신호나 공유 환경의 변화 감지(스티그머지라고도 함)가 포함될 수 있습니다.추론 및 의사 결정: 최신 멀티 에이전트 시스템에서 이 추론은 주로 에이전트의 '두뇌' 역할을 하는 대규모 언어 모델(LLM)에 의해 구동됩니다. LLM은 복잡한 사용자 의도를 이해하고 다단계 추론을 수행하며 목표를 달성하기 위한 계획을 세우는 데 탁월합니다. LLM 기반 에이전트는 인식에서 얻은 데이터를 기반으로 가장 논리적인 행동 방식을 결정합니다.조치: 에이전트는 환경 내에서 계획된 조치를 수행합니다.상호작용: 에이전트는 고립된 상태로 작동하지 않습니다. 서로 통신하고, 조정하고, 협상하고, 협업합니다. 여기에는 채팅 메시지 전달, 정보 공유, 다른 에이전트가 관찰할 수 있는 환경 수정 등이 포함될 수 있습니다.조정: 최신 MAS는 복잡한 작업을 구조화된 에이전트 워크플로로 세분화하는 조정 원칙에 따라 작동합니다. 다양한 에이전트에게 특정 역할과 책임이 할당된 프로젝트 계획이라고 생각하면 됩니다. '조정자' 또는 사전 정의된 그래프 구조는 에이전트가 올바른 순서로 호출되고 에이전트 간에 정보가 흐르며 최종 목표가 달성되도록 보장합니다. 이는 단순한 커뮤니케이션을 넘어 관리되고 목표 지향적인 프로세스로 나아가는 것으로, CrewAI 및 LangGraph와 같은 최신 프레임워크의 중점 사항입니다.이러한 팀워크를 통해 멀티 에이전트 시스템은 복잡한 문제에 적응하고 해결할 수 있습니다.멀티 에이전트 시스템의 핵심 구성요소멀티 에이전트 시스템은 에이전트, 환경, 상호작용 메커니즘의 세 가지 기본 요소로 구성됩니다.에이전트이들은 시스템 내에서 능동적인 의사 결정 개체입니다. 각 에이전트는 어느 정도의 자율성을 갖추고 있어 독립적으로 작업하고 주변 환경을 인식하며 목표와 사용 가능한 정보를 바탕으로 선택할 수 있습니다. 에이전트는 소프트웨어 프로그램, 봇, 실제 로봇, 드론, 센서, 심지어 인간까지 무엇이든 될 수 있습니다. 특정 역할과 기능을 가진 독립적인 개체입니다.환경에이전트가 작업하고, 인식하고, 상호작용하는 공유 공간입니다. 환경은 시뮬레이션된 세계나 네트워크와 같은 가상 환경일 수도 있고, 로봇 에이전트를 위한 공장과 같은 물리적 환경일 수도 있습니다. 리소스를 제공하고 제약 조건을 적용하며 간접 커뮤니케이션을 위한 매개체 역할을 합니다.통신 프로토콜 및 언어에이전트가 함께 작동하려면 서로 통신해야 합니다. 통신 프로토콜은 정보 교환 방식에 대한 규칙입니다. 여기에는 메시지 형식(예: JSON 또는 XML 사용)과 전송 방식(예: HTTP 또는 MQTT 사용)이 포함됩니다. FIPA ACL, KQML과 같은 에이전트 통신 언어(ACL)는 에이전트가 상호작용하고 자세한 정보를 공유할 수 있는 표준 방식을 제공합니다.FIPA ACL(Foundation for Intelligent Physical Agents - Agent Communication Language)은 지능형 소프트웨어 에이전트가 서로 통신하는 데 도움이 되는 널리 사용되는 언어입니다. 이는 인간이 소통하는 방식에 기반하며, 특정 '행동'(예: '요청' 또는 '알림')이 명확한 의미를 지닙니다. FIPA ACL 메시지에는 보낸 사람, 받는 사람, 행동, 실제 메시지 콘텐츠에 대한 필드가 있어 커뮤니케이션이 명확합니다.조정 메커니즘은 에이전트가 의견 불일치를 해결하고, 목표를 조정하고, 팀으로서 효과적으로 작업하는 데 사용하는 방법입니다. 예를 들어 에이전트가 작업에 입찰(경매와 유사)하거나 결정에 투표하거나 '계약망'이라는 시스템을 사용할 수 있습니다.멀티 에이전트 시스템의 사용 사례멀티 에이전트 시스템은 복잡한 문제를 해결하기 위해 공동작업, 적응성, 복원력이 필요한 다양한 분야에서 유용할 수 있습니다.복잡한 다단계 워크플로 자동화MAS는 복잡한 프로세스를 더 작고 관리 가능한 작업으로 세분화하고, 이를 전문 에이전트에 할당하고, 실행을 조정하는 데 능숙합니다.공급망 관리: 멀티 에이전트 시스템은 제조부터 소비자 구매에 이르기까지 공급망의 다양한 구성요소를 연결할 수 있습니다. 가상 에이전트는 서로 협상하여 재고 수요를 예측하고 리소스를 관리하며 실시간으로 운영을 조정할 수 있습니다.고객 서비스: 고객 지원에서 AI 에이전트는 함께 협력하여 문제를 추적하고, 해결 방법을 추천하고, 솔루션을 에스컬레이션하고, 결제 조정 또는 환불까지 처리할 수 있습니다. 한 에이전트는 초기 문의를 처리하고, 다른 에이전트는 관련 문서를 가져오며, 세 번째 에이전트는 맞춤형 대답을 생성할 수 있습니다.소프트웨어 개발: 에이전트 팀은 버그 요청에 응답하고, 과거 버그를 분석하여 유사성을 파악하고, 새 티켓을 생성하고, 코드 추천을 생성하거나 코드 검토를 구성하여 엔지니어링 지원을 제공하도록 설계할 수 있습니다.역동적이고 예측할 수 없는 환경에 적응에이전트의 분산된 특성과 자율성 덕분에 멀티 에이전트 시스템은 끊임없이 변화하는 환경에서도 잘 작동합니다.교통 및 운송 관리: MAS는 열차 네트워크, 트럭 배정, 선박 등 복잡한 운송 시스템을 처리할 수 있습니다. 에이전트는 실시간 교통과 경로 정보를 공유하여 교통 흐름을 원활하게 하고 혼잡한 도심 지역에서 교통 체증을 피할 수 있도록 도와줍니다.로봇 공학 및 자율 시스템: 창고에서는 여러 대의 로봇이 서로 충돌하지 않으면서 주문을 처리하기 위해 협업합니다. 마찬가지로 자율주행 배송 로봇 그룹은 실시간 교통 및 경로 정보를 공유하여 효율적으로 물건을 배송할 수 있습니다.방어 시스템: MAS는 사이버 공격이나 해상 시나리오와 같은 잠재적인 위협을 시뮬레이션하여 방어 시스템을 강화하는 데 도움이 되므로 보다 선제적인 계획과 대응이 가능합니다.복잡한 시나리오 시뮬레이션 및 모델링MAS는 복잡한 시스템에서 상호작용을 시뮬레이션하고 새로운 행동을 이해하는 데 필요한 강력한 도구입니다.금융 거래: 여러 에이전트가 시장 데이터를 분석하고 위험을 고려하며 다양한 자산 클래스에 걸쳐 거래를 수행할 수 있습니다. 일부 에이전트는 특정 시장에 집중하고 다른 에이전트는 더 광범위한 패턴을 찾습니다. 이를 통해 기업은 대량의 데이터를 실시간으로 처리하고 이에 따라 조치를 취할 수 있습니다.의료 및 공중 보건: 에이전트 기반 시스템은 유전자 분석을 통해 질병 예측 및 예방을 지원하고 병상 배정, 직원 근무 일정, 의료 장비 할당과 같은 병원 리소스를 관리하는 데 도움이 될 수 있습니다.사회적 시뮬레이션: MAS는 시뮬레이션된 인구의 사회적 상호작용과 새로운 행동을 모델링할 수 있으며, 이는 여러 복잡한 사회 현상을 연구하는 데 유용할 수 있습니다.멀티 에이전트 시스템의 이점멀티 에이전트 시스템은 단일 에이전트 또는 기존 시스템에 비해 다음과 같은 여러 가지 잠재적인 이점을 제공합니다.문제 해결 능력 향상MAS는 많은 전문 에이전트가 함께 작동하도록 하여 더 어려운 문제를 해결할 수 있습니다. 각 에이전트는 고유한 기술과 관점을 제공합니다.확장성MAS에 에이전트를 더 추가해도 속도가 느려지지 않습니다. 이를 통해 더 많은 작업과 더 많은 양의 데이터를 효율적으로 처리할 수 있습니다. 레고 블록으로 무언가를 만드는 것과 같습니다. 전체 구조를 망가뜨리지 않고도 블록을 더 추가할 수 있습니다.강력하고 안정적임에이전트 중 하나가 작동을 멈추면 다른 에이전트가 인계하므로 시스템은 계속 작동합니다. 따라서 MAS는 특히 중요한 상황에서 신뢰할 수 있습니다.유연하고 적응성이 뛰어남MAS는 지속적인 사람의 도움 없이도 새로운 정보나 예상치 못한 문제에 따라 작업 방식을 변경할 수 있습니다. 에이전트는 새로운 요구사항에 맞게 조정할 수 있습니다.더 빠르고 효율적임MAS는 여러 에이전트가 문제의 서로 다른 부분을 동시에 작업하도록 하여 문제를 훨씬 더 빠르게 해결하고 컴퓨터 리소스를 더 잘 사용할 수 있습니다.함께 더 스마트하게에이전트는 학습한 내용을 공유하고 학습 방법을 개선하며 그룹으로서 문제를 더 잘 해결할 수 있습니다. 이러한 팀 학습은 계속해서 변화하고 개선되어야 하는 AI 시스템에 매우 유용합니다.멀티 에이전트 시스템의 과제멀티 에이전트 시스템은 도움이 될 수 있지만 다음과 같은 몇 가지 잠재적인 과제도 수반할 수 있습니다.관리의 어려움: 특히 에이전트가 추가될수록 충돌 없이 많은 독립 에이전트가 함께 작동하도록 하는 것이 어려울 수 있습니다.커뮤니케이션 과부하: 에이전트가 많을수록 메시지가 많아져 속도가 느려질 수 있습니다. 명확하고 신속한 커뮤니케이션이 필수적입니다.예상치 못한 행동: 에이전트가 함께 행동하는 방식은 계획되지 않은 놀라운 결과를 낳을 수 있으며, 가능한 모든 결과를 테스트하기 어려울 수 있습니다.안전 문제: 민감한 정보를 공유하는 시스템에서는 강력한 보안이 필수적입니다. 악의적인 에이전트는 잘못된 정보를 제공하거나, 협력을 거부하거나, 민감한 정보를 공유하여 문제를 일으킬 수 있습니다.복잡한 빌드 및 사용: 이러한 시스템을 만들려면 신중한 계획과 에이전트 간의 대화 방식에 대한 이해가 필요합니다. 팀은 분산 AI와 강력한 커뮤니케이션 규칙에 대해 알아야 합니다.운영 비용: API 호출을 통해 강력한 LLM에 크게 의존하면 상당한 컴퓨팅 비용이 발생할 수 있습니다. 멀티 에이전트 시스템을 신중하게 관리하지 않으면 확장 비용이 엄청나게 많이 들 수 있습니다.사실적 그라운딩 및 할루시네이션: LLM 기반 에이전트는 그럴듯하지만 사실적으로는 잘못된 정보를 생성하는 '할루시네이션'을 일으킬 수 있습니다. 에이전트 출력이 사실적 데이터 소스를 기반으로 안정적으로 그라운딩되도록 하는 것은 주요 기술적 과제입니다.복잡한 디버깅 및 평가: 상호작용하는 에이전트의 비결정론적이고 새로운 행동으로 인해 디버깅이 매우 어렵습니다. 복잡한 다단계 워크플로 내에서 오류의 소스를 추적하려면 정교한 로깅 및 평가 도구가 필요합니다.멀티 에이전트 시스템을 위한 인기 있는 프레임워크개발자가 멀티 에이전트 시스템을 빌드하고 관리할 수 있도록 여러 프레임워크에서 자율 에이전트를 설계, 조정, 배포하는 도구를 제공합니다. 다음은 몇 가지 인기 있는 옵션입니다.프레임워크 이름프레임워크 개요사용 사례JADE(Java Agent Development Framework)FIPA 표준을 따르는 에이전트 시스템을 빌드하기 위한 Java 프로그램입니다. LLM 이전 시대의 핵심 MAS 개념을 이해하는 데 기본이 되지만, 최신 생성형 AI 애플리케이션에서는 덜 일반적입니다.비즈니스를 위한 스마트 시스템 빌드(예: 공급망 관리 또는 리소스 할당)\\xa0얼마나 많은 스마트 에이전트가 함께 작동하는지 시뮬레이션스마트 시스템에 대한 교육 및 연구Mesa(Python)에이전트 기반 모델링 및 시뮬레이션을 위한 Python 라이브러리입니다. 그리드 또는 네트워크에서 많은 단순 에이전트의 새로운 행동을 이해하는 것이 주된 목표인 복잡한 시스템을 모델링하는 데 탁월합니다.집단 내 사람들의 행동 방식 모델링(예: 군중의 행동 방식 또는 가짜 뉴스가 퍼지는 방식)동물 집단이나 경제와 같은 복잡한 시스템 시뮬레이션시간 경과에 따른 에이전트 상호작용 방식 확인Ray(Python)AI 및 Python 애플리케이션을 확장하기 위한 오픈소스 통합 컴퓨팅 프레임워크입니다.\\xa0MAS에서 Ray는 클러스터 전반에 걸쳐 많은 에이전트의 워크로드를 분산하는 데 필수적이며, 학습 또는 실시간 추론을 위한 대규모 병렬 처리를 지원합니다.많은 컴퓨팅 성능이 필요한 매우 복잡한 AI 모델 학습빠르게 결정을 내려야 하는 자율주행차 또는 드론 그룹 제어\\xa0많은 작업을 한 번에 처리할 수 있는 확장 가능한 머신러닝 서비스 빌드AutoGen(Microsoft)서로 대화하여 작업을 해결할 수 있는 여러 개의 '대화 가능한' LLM 에이전트로 애플리케이션을 빌드하기 위한 오픈소스 프레임워크입니다. 코드 생성, 실행, 인간 피드백과 관련된 복잡한 워크플로를 자동화하는 데 탁월합니다.코드 작성, 오류 찾기, 테스트, 코드 확인과 같은 어려운 소프트웨어 작업 자동화\\xa0자연어를 사용하여 많은 스마트 에이전트가 함께 작동하는 채팅 AI 만들기\\xa0다른 도구를 사용하고 코드를 즉시 실행할 수 있는 AI 에이전트 개발CrewAI자율 AI 에이전트의 롤플레잉을 조정하도록 설계된 프레임워크입니다. 공동의 목표를 달성하기 위해 함께 작업하는 공동작업 에이전트 팀(예: '연구원', '작성자', '편집자')을 간편하게 만들 수 있으며, LangChain과 통합되는 경우가 많습니다.연구원, 작성자, 편집자로 구성된 마케팅팀과 같이 특정 작업에 맞춰 팀으로 AI 에이전트 구성역할 할당이 유용한 비즈니스 단계 자동화\\xa0인간 팀처럼 행동하는 특화된 AI 시스템 빌드LangGraph'그래프' 구조를 사용하여 에이전트 시스템을 빌드할 수 있는 LangChain의 확장 프로그램입니다. 에이전트가 루프를 돌고, 자체 수정하고, 프로세스의 현재 상태를 기반으로 결정을 내릴 수 있는 순환적이고 스테이트풀(stateful)한 워크플로를 만드는 데 강력한 기능을 발휘하며, 단순한 체인보다 훨씬 더 복잡하고 강력한 상호작용을 가능하게 합니다.단계 간 이동 방식과 작업 반복 방식을 정확하게 제어해야 하는 복잡한 스마트 에이전트 시스템 빌드긴 대화에서 오간 내용을 기억하고 다양한 경로를 따를 수 있는 채팅 AI 개발에이전트의 행동이 이전의 상황에 크게 좌우되는 시스템LangChainLLM 기반 애플리케이션을 빌드하기 위한 기본 오픈소스 프레임워크입니다. 간단한 검색 증강 생성(RAG) 파이프라인부터 CrewAI 및 LangGraph와 같은 고급 프레임워크에 사용되는 개별 에이전트를 빌드하기 위한 핵심 툴킷 역할을 하는 데 이르기까지 컨텍스트 인식 애플리케이션을 생성하기 위한 대규모 통합 및 구성요소 생태계를 제공합니다.대규모 언어 모델을 사용하고 기본적인 스마트 에이전트 동작을 갖춘 AI 애플리케이션을 빠르게 생성요청에 따라 정보를 찾거나, 온라인 도구를 사용하거나, 텍스트를 작성할 수 있는 에이전트 만들기\\xa0단순한 AI 에이전트를 위해 LLM을 외부 정보 및 도구에 연결LlamaIndexLLM을 커스텀 데이터 소스에 연결하기 위한 오픈소스 데이터 프레임워크입니다. 에이전트 기능을 제공하지만 핵심 강점은 강력한 RAG 애플리케이션을 빌드하는 데 있습니다. 에이전트는 복잡한 데이터 쿼리 및 합성 작업에 특화된 경우가 많습니다.LLM을 문서나 데이터베이스와 같은 다양한 유형의 데이터에 연결하여 생성형 AI 애플리케이션 빌드바로 사용할 수 있는 에이전트를 사용하여 정보를 찾은 다음 텍스트를 생성하는 시스템 개발\\xa0데이터를 수집하고 데이터에 대해 질문하는 스마트한 방법이 필요한 복잡한 AI 솔루션을 위한 데이터 관리프레임워크 이름프레임워크 개요사용 사례JADE(Java Agent Development Framework)FIPA 표준을 따르는 에이전트 시스템을 빌드하기 위한 Java 프로그램입니다. LLM 이전 시대의 핵심 MAS 개념을 이해하는 데 기본이 되지만, 최신 생성형 AI 애플리케이션에서는 덜 일반적입니다.비즈니스를 위한 스마트 시스템 빌드(예: 공급망 관리 또는 리소스 할당)\\xa0얼마나 많은 스마트 에이전트가 함께 작동하는지 시뮬레이션스마트 시스템에 대한 교육 및 연구Mesa(Python)에이전트 기반 모델링 및 시뮬레이션을 위한 Python 라이브러리입니다. 그리드 또는 네트워크에서 많은 단순 에이전트의 새로운 행동을 이해하는 것이 주된 목표인 복잡한 시스템을 모델링하는 데 탁월합니다.집단 내 사람들의 행동 방식 모델링(예: 군중의 행동 방식 또는 가짜 뉴스가 퍼지는 방식)동물 집단이나 경제와 같은 복잡한 시스템 시뮬레이션시간 경과에 따른 에이전트 상호작용 방식 확인Ray(Python)AI 및 Python 애플리케이션을 확장하기 위한 오픈소스 통합 컴퓨팅 프레임워크입니다.\\xa0MAS에서 Ray는 클러스터 전반에 걸쳐 많은 에이전트의 워크로드를 분산하는 데 필수적이며, 학습 또는 실시간 추론을 위한 대규모 병렬 처리를 지원합니다.많은 컴퓨팅 성능이 필요한 매우 복잡한 AI 모델 학습빠르게 결정을 내려야 하는 자율주행차 또는 드론 그룹 제어\\xa0많은 작업을 한 번에 처리할 수 있는 확장 가능한 머신러닝 서비스 빌드AutoGen(Microsoft)서로 대화하여 작업을 해결할 수 있는 여러 개의 '대화 가능한' LLM 에이전트로 애플리케이션을 빌드하기 위한 오픈소스 프레임워크입니다. 코드 생성, 실행, 인간 피드백과 관련된 복잡한 워크플로를 자동화하는 데 탁월합니다.코드 작성, 오류 찾기, 테스트, 코드 확인과 같은 어려운 소프트웨어 작업 자동화\\xa0자연어를 사용하여 많은 스마트 에이전트가 함께 작동하는 채팅 AI 만들기\\xa0다른 도구를 사용하고 코드를 즉시 실행할 수 있는 AI 에이전트 개발CrewAI자율 AI 에이전트의 롤플레잉을 조정하도록 설계된 프레임워크입니다. 공동의 목표를 달성하기 위해 함께 작업하는 공동작업 에이전트 팀(예: '연구원', '작성자', '편집자')을 간편하게 만들 수 있으며, LangChain과 통합되는 경우가 많습니다.연구원, 작성자, 편집자로 구성된 마케팅팀과 같이 특정 작업에 맞춰 팀으로 AI 에이전트 구성역할 할당이 유용한 비즈니스 단계 자동화\\xa0인간 팀처럼 행동하는 특화된 AI 시스템 빌드LangGraph'그래프' 구조를 사용하여 에이전트 시스템을 빌드할 수 있는 LangChain의 확장 프로그램입니다. 에이전트가 루프를 돌고, 자체 수정하고, 프로세스의 현재 상태를 기반으로 결정을 내릴 수 있는 순환적이고 스테이트풀(stateful)한 워크플로를 만드는 데 강력한 기능을 발휘하며, 단순한 체인보다 훨씬 더 복잡하고 강력한 상호작용을 가능하게 합니다.단계 간 이동 방식과 작업 반복 방식을 정확하게 제어해야 하는 복잡한 스마트 에이전트 시스템 빌드긴 대화에서 오간 내용을 기억하고 다양한 경로를 따를 수 있는 채팅 AI 개발에이전트의 행동이 이전의 상황에 크게 좌우되는 시스템LangChainLLM 기반 애플리케이션을 빌드하기 위한 기본 오픈소스 프레임워크입니다. 간단한 검색 증강 생성(RAG) 파이프라인부터 CrewAI 및 LangGraph와 같은 고급 프레임워크에 사용되는 개별 에이전트를 빌드하기 위한 핵심 툴킷 역할을 하는 데 이르기까지 컨텍스트 인식 애플리케이션을 생성하기 위한 대규모 통합 및 구성요소 생태계를 제공합니다.대규모 언어 모델을 사용하고 기본적인 스마트 에이전트 동작을 갖춘 AI 애플리케이션을 빠르게 생성요청에 따라 정보를 찾거나, 온라인 도구를 사용하거나, 텍스트를 작성할 수 있는 에이전트 만들기\\xa0단순한 AI 에이전트를 위해 LLM을 외부 정보 및 도구에 연결LlamaIndexLLM을 커스텀 데이터 소스에 연결하기 위한 오픈소스 데이터 프레임워크입니다. 에이전트 기능을 제공하지만 핵심 강점은 강력한 RAG 애플리케이션을 빌드하는 데 있습니다. 에이전트는 복잡한 데이터 쿼리 및 합성 작업에 특화된 경우가 많습니다.LLM을 문서나 데이터베이스와 같은 다양한 유형의 데이터에 연결하여 생성형 AI 애플리케이션 빌드바로 사용할 수 있는 에이전트를 사용하여 정보를 찾은 다음 텍스트를 생성하는 시스템 개발\\xa0데이터를 수집하고 데이터에 대해 질문하는 스마트한 방법이 필요한 복잡한 AI 솔루션을 위한 데이터 관리멀티 에이전트 시스템을 구현하는 방법멀티 에이전트 시스템을 구현하려면 설계부터 배포까지 몇 가지 주요 단계를 거쳐야 합니다.1. 문제와 목표 정의: 시스템이 해결해야 할 문제와 전체 시스템 및 각 개별 에이전트가 달성해야 할 목표를 명확하게 명시합니다.2. 에이전트 설계 결정:에이전트 역할 파악: 각 유형의 에이전트가 수행할 구체적인 작업을 파악합니다.에이전트 기능 정의: 각 에이전트가 감지할 수 있는 것, 수행할 수 있는 것, 의사 결정을 내리는 방법을 지정합니다.에이전트 독립성 결정: 각 에이전트가 스스로 선택할 수 있는 자유의 정도를 결정합니다.3. 환경 모델링: 에이전트가 작업할 공유 공간을 만듭니다. 여기에는 기능, 리소스, 규칙이 포함됩니다.4. 커뮤니케이션 방법 결정:언어 선택: 에이전트가 서로 대화할 때 사용할 언어(예: FIPA ACL)와 메시지 형식을 선택합니다.규칙 설정: 에이전트가 어떻게 소통하고, 협업하고, 의견 차이를 해결할지에 대한 규칙을 설계합니다. 채팅 메시지, 공유 메모리, 환경을 통한 대화 등이 가능합니다.5. 전략 조정: 에이전트가 원활하게 협업하고 충돌을 해결할 수 있는 방법을 마련합니다. 여기에는 하나의 주요 제어 에이전트, 에이전트가 협상하는 규칙 또는 자연스러운 공동작업이 포함될 수 있습니다.6. 도구 통합: 에이전트가 데이터베이스, 다른 서비스, 다른 AI 모델 등 작업에 필요한 외부 도구나 프로그램에 액세스할 수 있도록 합니다.7. 코드: Python 또는 Java와 같은 프로그래밍 언어와 JADE, Mesa, Ray, AutoGen, CrewAI와 같은 멀티 에이전트 프레임워크를 선택하여 에이전트를 빌드하고 상호작용을 설정합니다.8. 테스트 및 검증: 에이전트가 예상대로 작동하고, 서로 잘 협력하며, 전반적인 목표를 달성하는지 확인하기 위해 시스템을 철저히 테스트합니다. 예상치 못한 동작이 발생할 수 있으므로 이 작업은 특히 어렵습니다.9. 배포 및 모니터링: 시스템을 적절한 인프라에 배치하고 모니터링을 설정하여 시스템의 성능을 추적하고, 문제를 찾고, 시스템이 계속 잘 작동하는지 확인합니다.Google Cloud를 사용한 멀티 에이전트 시스템 개발, 배포, 관리 Google Cloud는 멀티 에이전트 시스템을 개발, 배포, 관리하기 위한 이상적인 플랫폼이 될 수 있는 강력하고 확장 가능한 인프라를 제공합니다. 포괄적인 서비스 제품군은 MAS의 다양한 구성요소와 상호작용을 지원합니다.컴퓨팅 리소스: 특히 LLM과 같은 집약적인 AI 모델을 활용하는 수많은 에이전트를 배포하려면 상당한 컴퓨팅 성능이 필요합니다.Google Kubernetes Engine(GKE): GKE는 컨테이너화된 애플리케이션을 배포, 확장, 관리하기 위한 관리형 환경을 제공하며, 많은 개별 에이전트를 조정하는 데 적합합니다.Compute Engine: 가상 머신(VM)을 보다 세밀하게 제어하기 위해 Compute Engine은 에이전트 프로세스를 호스팅할 수 있는 유연하고 맞춤설정 가능한 VM 인스턴스를 제공합니다.데이터 처리 및 저장: 에이전트는 인식, 학습, 의사 결정을 위해 대량의 데이터를 저장하고 검색해야 하는 경우가 많습니다.Cloud Storage: 에이전트 데이터, 로그, 모델을 위한 확장성과 내구성이 뛰어난 객체 스토리지를 제공합니다.BigQuery: 대규모 데이터 세트를 저장하고 분석할 수 있는 완전 관리형 서버리스 데이터 웨어하우스로, 데이터 집약적인 작업을 수행하는 에이전트나 집단 에이전트 행동을 분석하는 데 유용합니다.Cloud SQL 또는 Cloud Firestore: 각각 관리형 관계형 데이터베이스와 NoSQL 데이터베이스로, 에이전트가 상태, 개별 기술 자료 또는 상호작용 기록을 저장하는 데 적합합니다.에이전트 간 커뮤니케이션: 에이전트가 정보를 공유하고 조정하려면 효율적인 메시징이 중요합니다.Pub/Sub: 에이전트 간 비동기식 커뮤니케이션을 지원하는 실시간 메시징 서비스로, 분리된 아키텍처와 이벤트 기반 상호작용에 적합합니다. 에이전트는 주제에 메시지를 게시하고 관련 주제를 구독하여 직접적인 엔드포인트 지식 없이도 커뮤니케이션할 수 있습니다.A2A 프로토콜: Google이 처음 개발한 개방형 표준으로, 서로 다른 AI 에이전트 간의 안전한 통신과 협업을 지원합니다. 이 모델은 범용 번역기 역할을 하여 다양한 프레임워크와 공급업체의 에이전트가 서로를 발견하고, 텍스트, 오디오, 동영상 등의 정보를 교환하고, 작업을 조율할 수 있도록 합니다. A2A는 에이전트 간 상호작용에 중점을 두며 에이전트-도구 통신을 처리하는 모델 컨텍스트 프로토콜(MCP)을 보완합니다.AI 및 머신러닝 기능: 많은 에이전트가 인텔리전스와 의사 결정을 위해 AI 모델을 통합합니다.Vertex AI: Google의 통합 ML 플랫폼은 지능형 에이전트 빌드의 중심에 있습니다. 추론을 위한 Gemini와 같은 강력한 파운데이션 모델에 대한 액세스를 제공하며, 무엇보다도 Vertex AI Agent Builder를 포함합니다. 이 관리형 서비스는 회사 데이터에 에이전트를 그라운딩하고, 외부 API에 연결하고, 목표 지향적인 대화형 환경을 빌드하는 도구를 제공하여 엔터프라이즈급 생성형 AI 에이전트의 개발을 가속화합니다.사전 학습 API: 에이전트는 Google Cloud의 사전 학습 AI API(예: Vision AI, Natural Language API)를 활용하여 다양한 데이터 유형에 대한 인식과 이해를 향상시킬 수 있습니다.네트워킹 및 보안: MAS 내에서 안전하고 효율적인 커뮤니케이션을 보장합니다.가상 프라이빗 클라우드(VPC): 에이전트와 서비스를 위한 격리된 보안 네트워크 환경을 만듭니다.Identity and Access Management(IAM): Google Cloud 리소스와 상호작용하는 에이전트에 대한 권한 및 액세스 제어를 관리합니다.개발자는 이러한 Google Cloud 서비스를 사용하여 강력하고 확장 가능하며 지능적인 멀티 에이전트 시스템을 빌드할 수 있으므로 세계에서 가장 복잡한 과제를 해결하는 정교한 AI 애플리케이션을 구현할 수 있습니다.다음 단계 수행$300의 무료 크레딧과 20여 개의 항상 무료 제품으로 Google Cloud에서 빌드하세요.무료로 시작하기시작하는 데 도움이 필요하신가요?영업팀에 문의신뢰할 수 있는 파트너 지원파트너 찾기계속 탐색모든 제품 보기menu개요솔루션제품가격 책정리소스Docs지원문의하기\\ue8b6Docs지원콘솔로그인무료로 시작하기무료로 시작하기문의하기close디지털 혁신 가속화디지털 혁신을 이제 막 시작한 기업이든 이미 일정 수준에 도달한 기업이든 Google Cloud를 사용하면 가장 까다로운 도전과제를 해결할 수 있습니다.자세히 알아보기주요 이점Google Cloud를 선택해야 하는 이유기업들이 Google을 선택하는 주요 이유AI 및 ML엔터프라이즈 지원 AI를 활용하세요.멀티 클라우드어디서나 필요한 앱을 실행글로벌 인프라Google과 동일한 인프라를 기반으로 빌드데이터 클라우드통합 데이터를 통한 더욱 스마트한 결정최신 인프라 클라우드차세대 클라우드 인프라입니다.보안사용자, 데이터, 앱을 보호하세요.생산성 및 공동작업AI 지원 앱으로 팀과 소통보고서 및 통계경영진 통계최고 책임자의 관점에 맞게 선별됩니다.애널리스트 보고서Google에 대한 업계 분석가들의 평가백서인기 백서 탐색 및 다운로드고객 사례우수사례 및 동영상 살펴보기close업종별 솔루션애플리케이션 현대화인공지능API 및 애플리케이션데이터 분석데이터베이스인프라 현대화생산성 및 공동작업보안스타트업 및 SMB모든 솔루션 보기업종별 솔루션비용 절감, 운영 민첩성 향상, 새로운 시장 기회 포착소매업소매 가치 사슬을 위한 분석 및 공동작업 도구소비재소비재 디지털 혁신 및 브랜드 성장 솔루션금융 서비스금융 서비스를 위한 컴퓨팅, 데이터 관리, 분석 도구의료 및 생명과학대규모의 연구 진행 및 의료 혁신 지원미디어 및 엔터테인먼트콘텐츠 제작 및 배포 작업을 위한 솔루션전자통신5G 배포 및 수익 창출을 위한 하이브리드 및 멀티 클라우드 서비스게임게임을 더욱 빠르게 빌드하고 확장할 수 있는 AI 기반 솔루션제조업제조업 가치 사슬을 최적화하는 마이그레이션 및 AI 도구공급망 및 물류공급망 및 물류 운영 전반에서 지속 가능하고 효율적이며 복원력이 우수한 데이터 기반 운영을 지원합니다.정부 기관정부 기관을 위한 데이터 스토리지, AI, 분석 솔루션교육더 적극적인 학습 경험을 제공하는 교육 도구원하는 내용을 찾을 수 없으신가요?모든 업종별 솔루션 보기애플리케이션 현대화소프트웨어 관행과 기능을 평가, 계획, 구현, 측정하여 조직의 비즈니스 애플리케이션 포트폴리오를 현대화하고 단순화합니다.CAMPDORA를 사용하여 소프트웨어 배포 기능을 개선하는 프로그램기존 애플리케이션 현대화기존 워크로드의 클라우드 마이그레이션을 분석 및 분류하고 시작합니다.PaaS에서 마이그레이션: Cloud Foundry, OpenShift기존 컨테이너를 Google의 관리형 컨테이너 서비스로 이동하기 위한 도구입니다.메인프레임에서 마이그레이션메인프레임 앱을 클라우드로 이전하기 위한 자동화된 도구 및 처방적 안내입니다.소프트웨어 배포 현대화내부 루프 생산성, CI/CD, S3C 등 소프트웨어 공급망 권장사항입니다.DevOps 권장사항조직에서 DevOps를 구현하기 위한 프로세스 및 리소스SRE 원칙조직에 사이트 안정성 엔지니어링(SRE)을 채택하기 위한 도구 및 리소스Operations for GKE 2일 차효과적인 GKE 관리 및 모니터링을 위한 도구 및 가이드입니다.에지에서 애플리케이션 실행하드웨어 제약이 없는 Google 에지 솔루션의 현지화되고 지연 시간이 짧은 앱에 대한 안내입니다.멀티 클라우드를 위한 설계여러 클라우드에서 일관된 플랫폼으로 워크로드를 관리합니다.서버리스로 전환앱 개발, 배포, 확장을 위한 완전 관리형 환경인공지능AI 및 머신러닝을 사용하여 비즈니스에 인텔리전스 및 효율성 추가Google AI를 사용한 고객 참여 제품군Google Cloud의 최첨단 대화형 AI를 결합한 엔드 투 엔드 애플리케이션입니다.Document AI문서 처리 및 데이터 캡처의 대규모 자동화소매업을 위한 Vertex AI Search소매업체를 위한 Google 품질 수준의 검색 및 제품 추천Google Cloud를 위한 Gemini애플리케이션 개발, 코딩 등을 위한 AI 어시스턴트입니다.Google Cloud의 생성형 AI생성형 AI를 활용하여 콘텐츠 제작 및 탐색, 연구, 고객 서비스, 개발자 효율성을 혁신하세요.API 및 애플리케이션API, 앱, 자동화를 사용하여 코딩 없이도 혁신 속도 향상API를 사용한 새 비즈니스 채널개발자 및 파트너 생태계의 조성과 지원API를 사용한 기존 애플리케이션 활용기존 앱을 확장하고 현대화하는 클라우드 서비스Open Banking APIx오픈 뱅킹 규정 준수 API의 보안 전송 간소화 및 가속화데이터 분석분석을 대폭 간소화하는 완전 관리형 서버리스 분석 플랫폼으로 규모에 상관없이 데이터에서 빠르게 유용한 정보 파악데이터 마이그레이션AI 지원 데이터 플랫폼을 통해 마이그레이션하고 현대화하세요.데이터 레이크 현대화데이터 레이크를 빌드하고 현대화하는 서비스스트림 분석이벤트 스트림 수집, 처리, 분석을 통해 유용한 정보 파악마케팅 분석고객 데이터 수집, 분석, 활성화를 위한 솔루션데이터 세트Google, 공공부문, 상용 공급업체 제공 데이터로 분석 및 AI 이니셔티브 강화비즈니스 인텔리전스BI 스택을 현대화하고 풍부한 데이터 환경을 만들기 위한 솔루션데이터 분석을 위한 AI데이터 분석을 위해 SQL을 작성하고, 예측 모델을 빌드하고, AI로 데이터를 시각화하세요.데이터베이스보안, 안정성, 고가용성, 완전 관리형 데이터 서비스로 기업 데이터를 마이그레이션하고 관리데이터베이스 마이그레이션데이터베이스 마이그레이션 수명 주기를 간소화하는 가이드 및 도구데이터베이스 현대화운영 데이터베이스 인프라 현대화를 위한 업그레이드게임용 데이터베이스Google Cloud 데이터베이스로 글로벌 실시간 게임 빌드Google Cloud 데이터베이스데이터를 마이그레이션, 관리, 현대화하는 데이터베이스 서비스Oracle 워크로드를 Google Cloud로 마이그레이션Oracle 워크로드의 재호스팅, 플랫폼 변경, 재작성오픈소스 데이터베이스엔터프라이즈급 지원을 제공하는 완전 관리형 오픈소스 데이터베이스Google Cloud 기반 SQL ServerGoogle Cloud에서 SQL Server 가상 머신을 실행하는 옵션데이터베이스를 위한 GeminiAI를 사용하여 데이터베이스 개발 및 관리를 강화하세요.인프라 현대화SAP, VMware, Windows, Oracle, 기타 워크로드를 위한 솔루션으로 빠르게 마이그레이션애플리케이션 마이그레이션클라우드로 이전하기 위한 검색 및 분석 도구Google Cloud 기반 SAPSAP 애플리케이션 및 SAP HANA 실행을 위한 인증고성능 컴퓨팅모든 워크로드를 지원하는 컴퓨팅, 스토리지, 네트워킹 옵션Google Cloud에서 Windows 실행Windows 워크로드 실행을 위한 도구 및 파트너데이터 센터 마이그레이션VM, 앱, 데이터베이스 등을 위한 마이그레이션 솔루션Active Assist클라우드 리소스의 자동 최적화 및 보안 강화가상 데스크톱데스크톱 및 애플리케이션용 원격 근무 솔루션(VDI 및 DaaS)Rapid Migration and Modernization Program클라우드로 간편하게 이전할 수 있게 해주는 엔드 투 엔드 마이그레이션 프로그램백업 및 재해 복구비즈니스 연속성 니즈를 충족하는지 확인Google Cloud 기반 Red HatGoogle과 Red Hat은 기존 온프렘 및 커스텀 애플리케이션을 위한 엔터프라이즈급 플랫폼을 제공합니다.생산성 및 공동작업영향력을 발휘하기 위해 빌드된 인간 중심 설계의 솔루션으로 팀의 공동작업 방식을 변경Google Workspace기업용 공동작업 및 생산성 도구Google Workspace Essentials팀을 위한 안전한 화상 회의와 현대적 공동작업 도구Cloud IDIT 관리자가 사용자 기기와 앱을 관리할 수 있는 통합 플랫폼Chrome Enterprise비즈니스용 ChromeOS, Chrome 브라우저, Chrome 기기보안온라인 위협을 감지, 조사, 대응하여 비즈니스 보호보안 분석 및 운영페타바이트 규모의 보안 원격 분석 솔루션웹 앱 및 API 보호웹 애플리케이션 및 API에 대한 위협 및 사기 방지보안 및 복원력 프레임워크보안 및 복원력 수명 주기의 각 단계에 대한 솔루션코드형 위험 및 규정 준수(RCaC)자동화를 통해 거버넌스, 위험, 규정 준수 기능을 현대화하는 솔루션소프트웨어 공급망 보안엔드 투 엔드 소프트웨어 공급망 보안 개선을 위한 솔루션Security Foundation강력한 보안 상황을 달성하는 데 도움이 되는 추천 제품스타트업 및 SMB맞춤형 솔루션과 프로그램을 통해 스타트업 및 SMB 성장 가속화스타트업 프로그램스타트업의 역량을 한 단계 끌어올리기 위한 재무, 비즈니스, 기술 지원 받기중소기업웹 호스팅, 앱 개발, AI, 분석을 위한 솔루션 살펴보기Software as a Service더욱 우수한 SaaS 제품을 빌드하고 효율적으로 확장하며 비즈니스 성장 도모close추천 제품AI 및 머신러닝비즈니스 인텔리전스컴퓨팅컨테이너데이터 분석데이터베이스개발자 도구분산 클라우드하이브리드 및 멀티 클라우드업종별통합 서비스관리 도구지도 및 지리정보미디어 서비스마이그레이션혼합 현실네트워킹운영생산성 및 공동작업보안 및 ID서버리스스토리지웹3모든 제품 보기(100개 이상)추천 제품Compute EngineGoogle의 데이터 센터에서 실행되는 가상 머신Cloud Storage안전하고 내구성과 확장성이 뛰어난 객체 스토리지BigQuery비즈니스 민첩성을 높이고 통찰력을 얻기 위한 데이터 웨어하우스Cloud Run컨테이너화된 앱 실행을 위한 완전 관리형 환경Google Kubernetes Engine컨테이너화된 앱 실행을 위한 관리형 환경Vertex AIML 모델 및 생성형 AI를 위한 통합 플랫폼LookerBI, 데이터 애플리케이션, 임베디드 분석을 위한 플랫폼Apigee API 관리가시성과 제어를 통해 어디서나 API 전체 수명 주기 관리Cloud SQLMySQL, PostgreSQL, SQL Server용 관계형 데이터베이스 서비스Gemini EnterpriseAI 에이전트를 탐색, 생성, 실행, 관리할 수 있는 안전한 플랫폼입니다.Cloud CDN웹 및 동영상 전송을 위한 콘텐츠 전송 네트워크원하는 내용을 찾을 수 없으신가요?모든 제품 보기(100개 이상)AI 및 머신러닝Vertex AI PlatformML 모델 및 생성형 AI를 위한 통합 플랫폼Vertex AI StudioVertex AI로 기반 모델 빌드, 조정, 배포Vertex AI Agent Builder생성형 AI 환경을 빌드하고 배포하세요.대화형 에이전트결정론적 AI 및 생성형 AI 기능을 모두 사용하여 대화형 AI를 빌드하세요.Vertex AI Search엔터프라이즈 앱과 환경에서 Google 품질의 검색을 빌드하세요.Speech-to-Text125개 언어로 음성 인식 및 스크립트 작성Text-to-Speech220개 이상의 음성 및 40개 이상의 언어로 음성 합성Translation AI언어 인식, 번역, 용어집 지원Document AI문서 처리 및 데이터 캡처의 대규모 자동화Gemini EnterpriseAI 에이전트를 탐색, 생성, 실행, 관리할 수 있는 안전한 플랫폼입니다.Vision AI감정, 텍스트 등을 인식하는 커스텀 및 선행 학습된 모델서비스형 고객센터클라우드 기반의 옴니채널 고객센터 솔루션입니다.비즈니스 인텔리전스LookerBI, 데이터 애플리케이션, 임베디드 분석을 위한 플랫폼Looker Studio대시보드, 보고, 분석을 위한 대화형 데이터 제품군컴퓨팅Compute EngineGoogle의 데이터 센터에서 실행되는 가상 머신App Engine앱 및 백엔드용 서버리스 애플리케이션 플랫폼Cloud GPUML, 과학 컴퓨팅, 3D 시각화용 GPUMigrate to Virtual Machines서버 및 가상 머신을 Compute Engine으로 마이그레이션스팟 VM일괄 작업 및 내결함성 워크로드에 적합한 컴퓨팅 인스턴스Batch일괄 작업을 예약할 수 있는 완전 관리형 서비스입니다.단독 테넌트 노드규정 준수, 라이선스, 관리를 위한 전용 하드웨어베어메탈Google Cloud에서 특수한 워크로드를 실행하기 위한 인프라추천자Google Cloud 제품 및 서비스 사용 권장사항VMware Engine완전 관리형 기본 VMware Cloud Foundation 소프트웨어 스택Cloud Run컨테이너화된 앱 실행을 위한 완전 관리형 환경원하는 내용을 찾을 수 없으신가요?모든 컴퓨팅 제품 보기컨테이너Google Kubernetes Engine컨테이너화된 앱 실행을 위한 관리형 환경Cloud Run컨테이너화된 앱 실행을 위한 완전 관리형 환경Cloud BuildDocker 컨테이너에서 빌드 단계를 실행하기 위한 솔루션Artifact Registry빌드 아티팩트 및 종속 항목의 패키지 관리자Cloud CodeKubernetes 애플리케이션 작성, 실행, 디버깅을 위한 IDE 지원Cloud DeployGKE 및 Cloud Run에 대한 완전 관리형 지속적 배포Migrate to ContainersGKE 기반 시스템 컨테이너로 VM을 마이그레이션하기 위한 구성요소Deep Learning Containers데이터 과학 프레임워크, 라이브러리, 도구가 포함된 컨테이너KnativeKubernetes에 최적화된 클라우드 기반 소프트웨어를 구축하기 위한 구성요소데이터 분석BigQuery비즈니스 민첩성을 높이고 통찰력을 얻기 위한 데이터 웨어하우스LookerBI, 데이터 애플리케이션, 임베디드 분석을 위한 플랫폼Dataflow스트림 및 일괄 처리를 위한 스트리밍 분석Pub/Sub이벤트 수집 및 전송을 위한 메시지 서비스DataprocApache Spark 및 Apache Hadoop 클러스터를 실행하는 서비스Cloud Data Fusion데이터 파이프라인 빌드 및 관리를 위한 데이터 통합Cloud ComposerApache Airflow를 기반으로 구축된 워크플로 조정 서비스BigLake다양한 형식의 멀티모달 데이터를 쿼리하는 스토리지 엔진입니다.Dataplex사일로에서 데이터 관리를 통합하기 위한 지능형 데이터 패브릭DataformBigQuery에서 SQL 워크플로 빌드, 버전 제어, 배포Analytics Hub데이터 분석 애셋을 안전하고 효율적으로 교환하는 서비스원하는 내용을 찾을 수 없으신가요?모든 데이터 분석 제품 보기데이터베이스PostgreSQL용 AlloyDB엔터프라이즈 워크로드를 위한 완전 관리형 PostgreSQL 호환 데이터베이스Cloud SQLMySQL, PostgreSQL, SQL Server용 완전 관리형 데이터베이스Firestore풍부한 모바일, 웹, IoT 앱을 빌드하기 위한 클라우드 기반 문서 데이터베이스Spanner무제한 확장과 99.999%의 가용성을 제공하는 클라우드 기반 관계형 데이터베이스Bigtable지연 시간이 짧은 대규모 워크로드를 위한 클라우드 기반 와이드 칼럼 데이터베이스Datastream서버리스 변경 데이터 캡처 및 복제 서비스Database Migration Service최소한의 다운타임으로 Cloud SQL로 서버리스 마이그레이션베어메탈 솔루션Oracle 워크로드를 위한 완전 관리형 인프라입니다.Memorystore1밀리초 미만의 데이터 액세스를 위한 완전 관리형 Redis 및 Memcached입니다.개발자 도구Artifact Registry빌드 아티팩트 및 종속 항목의 범용 패키지 관리자Cloud CodeKubernetes 애플리케이션 작성, 실행, 디버깅을 위한 IDE 지원Cloud Build지속적 통합 및 지속적 배포 플랫폼Cloud DeployGKE 및 Cloud Run에 대한 완전 관리형 지속적 배포Cloud Deployment ManagerGoogle Cloud 리소스를 만들고 관리하는 서비스Cloud SDKGoogle Cloud용 명령줄 도구 및 라이브러리Cloud Scheduler태스크 자동화 및 관리를 위한 크론 작업 스케줄러Cloud Source Repositories코드를 저장, 관리, 추적하는 비공개 Git 저장소Infrastructure ManagerTerraform으로 인프라 관리 자동화Cloud Workstations클라우드의 안전한 관리형 개발 환경Gemini Code AssistGoogle Cloud와 IDE 전반에서 사용할 수 있는 AI 기반 어시스턴트입니다.원하는 내용을 찾을 수 없으신가요?모든 개발자 도구 보기분산 클라우드Google Distributed Cloud Connected에지 워크로드를 위한 분산형 클라우드 서비스에어 갭이 적용된 Google Distributed Cloud에어 갭 적용 워크로드를 위한 분산형 클라우드하이브리드 및 멀티 클라우드Google Kubernetes Engine컨테이너화된 앱 실행을 위한 관리형 환경Apigee API 관리API 관리, 개발, 보안 플랫폼Migrate to Containers워크로드 및 기존 애플리케이션을 GKE로 옮기는 도구Cloud BuildGoogle Cloud 인프라에서 빌드를 실행하는 서비스운영모니터링, 로깅, 애플리케이션 성능 제품군Google Distributed Cloud에지 및 데이터 센터를 위한 완전 관리형 솔루션업종별자금 세탁 방지 AIAI로 의심스러운 잠재적 자금세탁 활동을 감지Cloud Healthcare API기존 의료 시스템과 Google Cloud 기반의 앱을 연결하는 솔루션Fitbit 기기 연결Google Cloud에서 연결된 Fitbit 데이터를 통해 환자의 상태를 종합적으로 파악할 수 있습니다.Telecom Network Automation통신 네트워크에 사용할 수 있는 클라우드 기반 자동화Telecom Data Fabric자동화된 접근 방식을 사용한 통신 데이터 관리 및 분석Telecom Subscriber Insights데이터를 수집하여 구독자 확보 및 유지를 개선Spectrum Access System(SAS)민간 광대역 무선 서비스(CBRS)에 대한 기본 액세스 제어통합 서비스Application Integration서드 파티 앱에 연결하고 코드 없이 데이터 일관성을 지원Workflows서버리스 제품 및 API 서비스의 워크플로 조정Apigee API 관리가시성과 제어를 통해 어디서나 API 전체 수명 주기 관리Cloud Tasks비동기 태스크 실행을 위한 태스크 관리 서비스Cloud Scheduler태스크 자동화 및 관리를 위한 크론 작업 스케줄러DataprocApache Spark 및 Apache Hadoop 클러스터를 실행하는 서비스Cloud Data Fusion데이터 파이프라인 빌드 및 관리를 위한 데이터 통합Cloud ComposerApache Airflow를 기반으로 구축된 워크플로 조정 서비스Pub/Sub이벤트 수집 및 전송을 위한 메시지 서비스Eventarc모든 서비스를 연결할 수 있는 이벤트 기반 아키텍처 빌드관리 도구Cloud Shell명령줄이 내장된 대화형 셸 환경Cloud 콘솔클라우드 앱 관리와 모니터링을 위한 웹 기반 인터페이스Cloud EndpointsGoogle Cloud에서의 API 배포 및 개발 관리Cloud IAMGoogle Cloud 리소스의 권한 관리 시스템Cloud APIGoogle Cloud 서비스의 프로그래매틱 인터페이스서비스 카탈로그내부 기업용 솔루션 관리자를 위한 서비스 카탈로그비용 관리비용 모니터링, 관리, 최적화 도구운영모니터링, 로깅, 애플리케이션 성능 제품군탄소 발자국Google Cloud 탄소 배출량 보고서를 보고 내보낼 수 있는 대시보드구성 커넥터Google Cloud 리소스 관리를 위한 Kubernetes 부가기능Active Assist성능, 보안, 비용을 간편하게 관리할 수 있는 도구원하는 내용을 찾을 수 없으신가요?모든 관리 도구 보기지도 및 지리정보Earth Engine지구 관측 데이터 및 분석을 위한 지리정보 플랫폼Google Maps Platform몰입형 위치정보 활용 환경을 생성하고 비즈니스 운영을 개선미디어 서비스Cloud CDN웹 및 동영상 콘텐츠 전송을 위한 콘텐츠 전송 네트워크Live Stream API스트리밍을 위해 실시간 동영상 및 패키지를 변환하는 서비스.OpenCue시각 효과 및 애니메이션을 위한 오픈소스 렌더링 관리자Transcoder API최적화된 전송을 위해 동영상 파일 변환 및 패키징Video Stitcher API동적 또는 서버 측 광고 삽입 서비스마이그레이션마이그레이션 센터Google Cloud로 마이그레이션하고 현대화하는 통합 플랫폼입니다.애플리케이션 마이그레이션저비용 갱신 주기를 위해 클라우드로 앱 마이그레이션Migrate to Virtual MachinesCompute Engine으로 VM 및 물리적 서버를 마이그레이션하기 위한 구성요소Cloud Foundation ToolkitDeployment Manager와 Terraform용 참조 템플릿Database Migration Service최소한의 다운타임으로 Cloud SQL로 서버리스 마이그레이션Migrate to ContainersGKE 기반 시스템 컨테이너로 VM을 마이그레이션하기 위한 구성요소BigQuery Data Transfer Service데이터를 예약하고 BigQuery로 옮기는 데이터 가져오기 서비스Rapid Migration and Modernization Program클라우드로 간편하게 이전할 수 있게 해주는 엔드 투 엔드 마이그레이션 프로그램Transfer ApplianceGoogle Cloud로 대용량 데이터를 이전하기 위한 스토리지 서버Storage Transfer Service온라인 및 온프레미스 소스에서 Cloud Storage로 데이터 전송VMware EngineVMware 워크로드를 마이그레이션하여 Google Cloud를 기반으로 실행혼합 현실Immersive Stream for XR3D 및 XR 환경을 호스팅, 렌더링, 스트리밍네트워킹Cloud Armor웹 및 DDoS 공격에 대한 보안 정책 및 방어Cloud CDN 및 Media CDN웹 및 동영상 콘텐츠 전송을 위한 콘텐츠 전송 네트워크Cloud DNS안정적이고 지연 시간이 짧은 이름 조회를 위한 DNS(도메인 이름 시스템)Cloud Load Balancing애플리케이션 및 리전에 트래픽을 분산하는 서비스Cloud NAT비공개 인스턴스에 인터넷 액세스 권한을 부여하는 NAT 서비스Cloud ConnectivityVPN, 피어링, 기업의 니즈를 위한 연결 옵션Network Connectivity Center네트워크를 간소화하고 확장하기 위한 연결 관리Network Intelligence Center네트워크 모니터링, 인증, 최적화 플랫폼네트워크 서비스 등급성능, 가용성, 비용에 따른 클라우드 네트워크 옵션Virtual Private Cloud조직 전체에 하나의 VPC만 사용해 프로젝트 내에서 팀을 분리Private Service ConnectVPC와 서비스 간의 보안 연결원하는 내용을 찾을 수 없으신가요?모든 네트워킹 제품 보기운영Cloud LoggingGoogle Cloud 감사, 플랫폼, 애플리케이션 로그 관리Cloud Monitoring풍부한 측정항목으로 인프라 및 애플리케이션 상태 점검Error Reporting애플리케이션 오류 식별 및 분석Cloud Debugger실시간 애플리케이션 상태 검사 및 프로덕션 단계의 디버깅Cloud Trace애플리케이션에서 지연 데이터를 수집하는 추적 시스템Cloud Profiler애플리케이션 성능 분석을 위한 CPU 및 힙 프로파일러Cloud 할당량모든 Google Cloud 서비스의 할당량을 관리합니다.생산성 및 공동작업AppSheet애플리케이션을 빌드 및 확장하는 코딩 없는 개발 플랫폼AppSheet Automation통합 플랫폼에서 자동화 및 애플리케이션을 빌드Gemini EnterpriseAI 에이전트를 탐색, 생성, 실행, 관리할 수 있는 안전한 플랫폼입니다.Google Workspace개인과 조직을 위한 공동작업 및 생산성 도구Google Workspace Essentials팀을 위한 안전한 화상 회의와 현대적 공동작업 도구Cloud IDIT 관리자가 사용자 기기와 앱을 관리할 수 있는 통합 플랫폼Chrome Enterprise비즈니스용 ChromeOS, Chrome 브라우저, Chrome 기기보안 및 IDCloud IAMGoogle Cloud 리소스의 권한 관리 시스템Sensitive Data Protection중요한 데이터 애셋을 탐색, 분류, 보호Mandiant Managed Defense연중무휴 안심하고 위협을 파악하고 제거합니다.Security Command CenterGoogle Cloud 애셋에 대한 위협을 방어하기 위한 플랫폼Cloud Key ManagementGoogle Cloud에서 암호화 키 관리Mandiant 이슈 대응침해의 영향을 최소화합니다.Chrome Enterprise Premium광범위한 엔드포인트 가시성을 갖춘 안전한 엔터프라이즈 브라우징을 이용하세요.Assured Workloads민감한 워크로드에 대한 규정 준수 및 보안 제어Google Security Operations사이버 위협을 감지 및 조사하고 이에 대응하세요.Mandiant Consulting이슈 발생 전후와 도중에 전문가의 안내를 받습니다.원하는 내용을 찾을 수 없으신가요?모든 보안 및 ID 제품 보기서버리스Cloud Run컨테이너화된 앱 실행을 위한 완전 관리형 환경Cloud Functions클라우드 이벤트에 응답하는 함수를 만들기 위한 플랫폼App Engine앱 및 백엔드용 서버리스 애플리케이션 플랫폼Workflows서버리스 제품 및 API 서비스의 워크플로 조정API 게이트웨이완전 관리형 게이트웨이를 사용하여 API를 개발, 배포, 보호, 관리스토리지Cloud Storage안전하고 내구성과 확장성이 뛰어난 객체 스토리지블록 스토리지AI, 분석, 데이터베이스, 엔터프라이즈 애플리케이션을 위한 고성능 스토리지입니다.Filestore확장성이 뛰어나고 안전한 파일 스토리지Persistent DiskGoogle Cloud에서 실행되는 가상 머신 인스턴스용 블록 스토리지Firebase용 Cloud Storage사용자 제작 콘텐츠 저장 및 제공을 위한 객체 스토리지로컬 SSD고성능 요건에 맞게 로컬로 연결된 블록 스토리지Storage Transfer Service온라인 및 온프레미스 소스에서 Cloud Storage로 데이터 전송Parallelstore고성능 관리형 병렬 파일 서비스입니다.Google Cloud NetApp VolumesNFS, SMB, 멀티 프로토콜 환경을 위한 파일 저장 서비스백업 및 DR 서비스중앙 집중식의 애플리케이션 일관성이 있는 데이터 보호를 위한 서비스웹3블록체인 노드 엔진블록체인 개발을 위한 완전 관리형 노드 호스팅블록체인 RPC블록체인에서 빌드하도록 지원하는 엔터프라이즈급 RPC입니다.close투명한 가격 책정 방식으로 비용 절감Google Cloud는 사용한 만큼만 지불하는 가격 책정 방식으로 월별 사용량과 선불 리소스의 할인율을 기준으로 자동 할인을 제공합니다. 지금 Google에 문의하여 견적을 받아보세요.견적서 1건 요청가격 책정 개요 및 도구Google Cloud 가격 책정사용한 만큼만 지불하고 자유롭게 서비스 전환 가능가격 계산기클라우드 비용 절감 계산Google Cloud 무료 등급월별 무료 사용으로 제품을 살펴보세요.비용 최적화 프레임워크워크로드 비용 최적화를 위한 권장사항을 확인하세요.비용 관리 도구비용을 모니터링하고 관리할 수 있는 도구입니다.제품별 가격 책정Compute EngineCloud SQLGoogle Kubernetes EngineCloud StorageBigQuery100개 이상의 제품이 포함된 정가 목록 보기close학습 및 빌드Google Cloud 무료 프로그램$300의 무료 크레딧과 20여 개의 무료 제품빠른 시작튜토리얼과 둘러보기를 확인하세요.블로그Google의 최신 제품 뉴스와 스토리 확인학습 허브역할 기반 학습으로 커리어 성장자격증자격증 준비 및 등록클라우드 아키텍처 센터참조 아키텍처와 권장사항을 확인하세요.연결혁신가Google Cloud 개발자 프로그램에 가입하세요.Developer Center최신 정보를 놓치지 않고 확인하세요.이벤트 및 웹 세미나예정된 이벤트와 주문형 이벤트를 둘러보세요.Google Cloud 커뮤니티질문하고, 답변을 찾고, 소통하기컨설팅 및 파트너Google Cloud 컨설팅Google Cloud 전문가와 함께 클라우드 프로젝트를 진행하세요.Google Cloud Marketplace클릭 몇 번으로 즉시 사용 가능한 솔루션 배포Google Cloud 파트너파트너 지원의 이점 살펴보기파트너 되기파트너 어드밴티지 프로그램 가입close개요arrow_forward솔루션arrow_forward제품arrow_forward가격 책정arrow_forward리소스arrow_forwardDocs지원콘솔디지털 혁신 가속화자세히 알아보기주요 이점Google Cloud를 선택해야 하는 이유AI 및 ML멀티 클라우드글로벌 인프라데이터 클라우드최신 인프라 클라우드보안생산성 및 공동작업보고서 및 통계경영진 통계애널리스트 보고서백서고객 사례업종별 솔루션소매업소비재금융 서비스의료 및 생명과학미디어 및 엔터테인먼트전자통신게임제조업공급망 및 물류정부 기관교육모든 업종별 솔루션 보기모든 솔루션 보기애플리케이션 현대화CAMP기존 애플리케이션 현대화PaaS에서 마이그레이션: Cloud Foundry, OpenShift메인프레임에서 마이그레이션소프트웨어 배포 현대화DevOps 권장사항SRE 원칙Operations for GKE 2일 차에지에서 애플리케이션 실행멀티 클라우드를 위한 설계서버리스로 전환인공지능Google AI를 사용한 고객 참여 제품군Document AI소매업을 위한 Vertex AI SearchGoogle Cloud를 위한 GeminiGoogle Cloud의 생성형 AIAPI 및 애플리케이션API를 사용한 새 비즈니스 채널API를 사용한 기존 애플리케이션 활용Open Banking APIx데이터 분석데이터 마이그레이션데이터 레이크 현대화스트림 분석마케팅 분석데이터 세트비즈니스 인텔리전스데이터 분석을 위한 AI데이터베이스데이터베이스 마이그레이션데이터베이스 현대화게임용 데이터베이스Google Cloud 데이터베이스Oracle 워크로드를 Google Cloud로 마이그레이션오픈소스 데이터베이스Google Cloud 기반 SQL Server데이터베이스를 위한 Gemini인프라 현대화애플리케이션 마이그레이션Google Cloud 기반 SAP고성능 컴퓨팅Google Cloud에서 Windows 실행데이터 센터 마이그레이션Active Assist가상 데스크톱Rapid Migration and Modernization Program백업 및 재해 복구Google Cloud 기반 Red Hat생산성 및 공동작업Google WorkspaceGoogle Workspace EssentialsCloud IDChrome Enterprise보안보안 분석 및 운영웹 앱 및 API 보호보안 및 복원력 프레임워크코드형 위험 및 규정 준수(RCaC)소프트웨어 공급망 보안Security Foundation스타트업 및 SMB스타트업 프로그램중소기업Software as a Service추천 제품Compute EngineCloud StorageBigQueryCloud RunGoogle Kubernetes EngineVertex AILookerApigee API 관리Cloud SQLGemini EnterpriseCloud CDN모든 제품 보기(100개 이상)AI 및 머신러닝Vertex AI PlatformVertex AI StudioVertex AI Agent Builder대화형 에이전트Vertex AI SearchSpeech-to-TextText-to-SpeechTranslation AIDocument AIGemini EnterpriseVision AI서비스형 고객센터모든 AI 및 머신러닝 제품 보기비즈니스 인텔리전스LookerLooker Studio컴퓨팅Compute EngineApp EngineCloud GPUMigrate to Virtual Machines스팟 VMBatch단독 테넌트 노드베어메탈추천자VMware EngineCloud Run모든 컴퓨팅 제품 보기컨테이너Google Kubernetes EngineCloud RunCloud BuildArtifact RegistryCloud CodeCloud DeployMigrate to ContainersDeep Learning ContainersKnative데이터 분석BigQueryLookerDataflowPub/SubDataprocCloud Data FusionCloud ComposerBigLakeDataplexDataformAnalytics Hub모든 데이터 분석 제품 보기데이터베이스PostgreSQL용 AlloyDBCloud SQLFirestoreSpannerBigtableDatastreamDatabase Migration Service베어메탈 솔루션Memorystore개발자 도구Artifact RegistryCloud CodeCloud BuildCloud DeployCloud Deployment ManagerCloud SDKCloud SchedulerCloud Source RepositoriesInfrastructure ManagerCloud WorkstationsGemini Code Assist모든 개발자 도구 보기분산 클라우드Google Distributed Cloud Connected에어 갭이 적용된 Google Distributed Cloud하이브리드 및 멀티 클라우드Google Kubernetes EngineApigee API 관리Migrate to ContainersCloud Build운영Google Distributed Cloud업종별자금 세탁 방지 AICloud Healthcare APIFitbit 기기 연결Telecom Network AutomationTelecom Data FabricTelecom Subscriber InsightsSpectrum Access System(SAS)통합 서비스Application IntegrationWorkflowsApigee API 관리Cloud TasksCloud SchedulerDataprocCloud Data FusionCloud ComposerPub/SubEventarc관리 도구Cloud ShellCloud 콘솔Cloud EndpointsCloud IAMCloud API서비스 카탈로그비용 관리운영탄소 발자국구성 커넥터Active Assist모든 관리 도구 보기지도 및 지리정보Earth EngineGoogle Maps Platform미디어 서비스Cloud CDNLive Stream APIOpenCueTranscoder APIVideo Stitcher API마이그레이션마이그레이션 센터애플리케이션 마이그레이션Migrate to Virtual MachinesCloud Foundation ToolkitDatabase Migration ServiceMigrate to ContainersBigQuery Data Transfer ServiceRapid Migration and Modernization ProgramTransfer ApplianceStorage Transfer ServiceVMware Engine혼합 현실Immersive Stream for XR네트워킹Cloud ArmorCloud CDN 및 Media CDNCloud DNSCloud Load BalancingCloud NATCloud ConnectivityNetwork Connectivity CenterNetwork Intelligence Center네트워크 서비스 등급Virtual Private CloudPrivate Service Connect모든 네트워킹 제품 보기운영Cloud LoggingCloud MonitoringError ReportingCloud DebuggerCloud TraceCloud ProfilerCloud 할당량생산성 및 공동작업AppSheetAppSheet AutomationGemini EnterpriseGoogle WorkspaceGoogle Workspace EssentialsCloud IDChrome Enterprise보안 및 IDCloud IAMSensitive Data ProtectionMandiant Managed DefenseSecurity Command CenterCloud Key ManagementMandiant 이슈 대응Chrome Enterprise PremiumAssured WorkloadsGoogle Security OperationsMandiant Consulting모든 보안 및 ID 제품 보기서버리스Cloud RunCloud FunctionsApp EngineWorkflowsAPI 게이트웨이스토리지Cloud Storage블록 스토리지FilestorePersistent DiskFirebase용 Cloud Storage로컬 SSDStorage Transfer ServiceParallelstoreGoogle Cloud NetApp Volumes백업 및 DR 서비스웹3블록체인 노드 엔진블록체인 RPC투명한 가격 책정 방식으로 비용 절감견적서 1건 요청가격 책정 개요 및 도구Google Cloud 가격 책정가격 계산기Google Cloud 무료 등급비용 최적화 프레임워크비용 관리 도구제품별 가격 책정Compute EngineCloud SQLGoogle Kubernetes EngineCloud StorageBigQuery100개 이상의 제품이 포함된 정가 목록 보기학습 및 빌드Google Cloud 무료 프로그램빠른 시작블로그학습 허브자격증클라우드 아키텍처 센터연결혁신가Developer Center이벤트 및 웹 세미나Google Cloud 커뮤니티컨설팅 및 파트너Google Cloud 컨설팅Google Cloud MarketplaceGoogle Cloud 파트너파트너 되기Google을 선택해야 하는 이유Google Cloud 선택신뢰 및 보안최신 인프라 클라우드멀티 클라우드글로벌 인프라고객 및 우수사례애널리스트 보고서백서블로그제품 및 가격 책정Google Cloud 가격 책정Google Workspace 가격 책정모든 제품 보기솔루션인프라 현대화데이터베이스애플리케이션 현대화스마트 분석인공지능보안생산성 및 작업 방식의 혁신업종별 솔루션DevOps 솔루션중소기업용 솔루션모든 솔루션 보기리소스Google Cloud 제휴 프로그램Google Cloud 문서Google Cloud 빠른 시작Google Cloud Marketplace클라우드 컴퓨팅 알아보기지원코드 샘플클라우드 아키텍처 센터학습인증Google DevelopersGoogle Cloud for Startups시스템 상태출시 노트참여영업팀에 문의파트너 찾기파트너 되기이벤트팟캐스트Developer Center보도자료 코너Google Cloud의 YouTube 채널Google Cloud Tech의 YouTube 채널Twitter 팔로우사용자 연구 참여Google Cloud 채용 정보Google Cloud 커뮤니티Google 정보개인정보처리방침사이트 약관Google Cloud 약관쿠키 관리 제어Google의 기후 행동 30년: 동참하기Google Cloud 뉴스레터 구독하기구독language\\u202a한국어\\u202c\\u202aEnglish\\u202c\\u202aDeutsch\\u202c\\u202aEspañol\\u202c\\u202aEspañol (Latinoamérica)\\u202c\\u202aFrançais\\u202c\\u202aIndonesia\\u202c\\u202aItaliano\\u202c\\u202aPortuguês (Brasil)\\u202c\\u202a简体中文\\u202c\\u202a繁體中文\\u202c\\u202a日本語\\u202c\\u202a한국어\\u202c\"),\n",
              "  Document(metadata={'source': 'https://brunch.co.kr/@harryban0917/349', 'title': '21화 AI 에이전트(Agent)도 서로 협업을 한다?', 'description': '멀티에이전트의 개념과 아키텍처 이해하기 | 지난번 구글의 AI Agent 백서를 통해 소개한 AI 에이전트 아키텍처에 대해 더 이상AI 에이전트의 아키텍처(3) - 오케스트레이션에서는 마치 사람처럼 상호작용하는 LLM 오케스트레이션(Orchestration)이라는 개념이 등장합니다. 이처럼 LLM은  단독으로 움직이지 않습니다. Gemini, GPT-4o, Claude-3.5-Sonnet, Deep', 'language': 'ko'}, page_content='  \\n\\n\\n21화 AI 에이전트(Agent)도 서로 협업을 한다?       \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          메뉴 brunch  연재 중 알바트로스의 생성형 AI 연구소 21화        AI 에이전트(Agent)도 서로 협업을 한다? 멀티에이전트의 개념과 아키텍처 이해하기 by 알바트로스  Mar 1. 2025    지난번 구글의 AI Agent 백서를 통해 소개한 AI 에이전트 아키텍처에 대해 더 이상AI 에이전트의 아키텍처(3) - 오케스트레이션에서는 마치 사람처럼 상호작용하는 LLM 오케스트레이션(Orchestration)이라는 개념이 등장합니다. 이처럼 LLM은  단독으로 움직이지 않습니다. Gemini, GPT-4o, Claude-3.5-Sonnet, DeepSeek-R1과 같은 LLM들은 순차적으로 작동하기도 하고, 여러 개의 독립적인 LLM으로 작동하기도 합니다. A의 답변을 받아 B가 새로운 답변을 생성해 내고, 그것을 바탕으로 또다시 C를 생성해 내는가 하면, A, B, C가 서로 각기 다른 분야의 의견을 바탕으로 토론을 하여 하나의 결론을 도출해내기도 했었지요.AI 에이전트 역시 다르지 않습니다. 보다 종합적인 판단 및 추론과 복잡한 태스크 수행을 위해 AI 에이전트 하나에 여러 개의 LLM이 들어가는 것처럼 AI 에이전트 어려 개를 묶어 마치 하나의 시스템처럼 활용할 수 있습니다. 이처럼 여러 개의 에이전트로 이루어진 에이전트를 멀티 에이전트(Multi-Agent)라고 합니다.아직까지는 생소하게 느껴질 수 있는 개념이지만, 마치 사람처럼 심층적이고 종합적인 태스크 수행이 가능한 멀티 에이전트는 2025년 새로운 트렌드중 하나로 자리 잡을 것으로 예상되고 있습니다. 그렇다면 AI 에이전트는 어떻게 만들어지는 것일까요? 이번시간에는 멀티 에이전트 개발을 위한 다양한 아키텍처에 대해 소개하도록 하겠습니다.1. 멀티 에이전트(Multi-Agent)의 개념 아키텍처멀티 에이전트(Multi-Agent) 시스템은 단순히 여러 에이전트를 연결한 것이 아닙니다. 이 시스템은 각 에이전트가 서로 다른 역할을 담당하며, 그들의 협력을 통해 더 복잡하고 심층적인 태스크를 수행할 수 있게 만들어줍니다. 예를 들어, 여러 개의 AI 에이전트들이 서로 상호작용하며, 각기 다른 전문 분야에 맞는 의견을 내고 최종 결론을 도출하는 방식이 바로 멀티 에이전트 시스템의 장점입니다. 출처 : SuperAnnotate이처럼 여러 개의 에이전트가 협업하는 멀티 에이전트 시스템을 설계할 때 염두에 두어야 할 점은 시스템의 복잡도를 관리하는 것입니다. 단일 에이전트 시스템이 너무 많은 툴과 복잡한 문맥을 관리해야 할 때 어려움을 겪을 수 있지만, 이를 여러 개의 작은 독립적인 에이전트로 나누면 관리와 확장이 용이해집니다. 각 에이전트는 특정한 전문 분야를 담당하고, 서로 협력하면서 문제를 해결합니다. 예를 들어, 하나의 에이전트는 계획을 세우고, 다른 에이전트는 리서치를 담당하며, 또 다른 에이전트는 수학적인 계산을 처리하는 등의 역할을 분담합니다.멀티 에이전트 시스템의 주요 장점 중 하나는 모듈성입니다. 즉, 독립적인 에이전트들로 구성되어 있어 개발, 테스트, 유지보수가 용이하며, 전문화된 에이전트를 만들 수 있다는 점입니다. 각 에이전트가 특정 분야에 집중하여 작업할 수 있기 때문에, 전체 시스템의 성능이 향상됩니다. 또한, 제어 측면에서 에이전트들이 어떻게 소통하는지를 명확하게 정의할 수 있어, 함수 호출에 의존하지 않고 명시적으로 제어할 수 있다는 점에서 유리합니다. 멀티 에이전트 시스템 (출처 : LangGraph) 이러한 멀티 에이전트 시스템에는 여러 가지 아키텍처가 존재합니다. 예를 들어, 에이전트들이 서로 자유롭게 소통하는 네트워크(Network) 방식, 하나의 상위 감독자(Agent Supervisor)가 다른 에이전트를 지시하는 감독자 방식, 그리고 감독자가 툴을 호출하는 방식인 툴 호출 방식(Supervisor as tools) 등이 있습니다. 또한, 계층적 구조를 통해 더 복잡한 제어 흐름을 처리할 수 있으며, 커스텀 워크플로우 방식에서는 각 에이전트가 다른 일부 에이전트와만 소통하며 작업을 진행하는 방식도 가능합니다. 이처럼 멀티 에이전트 시스템의 설계와 아키텍처는 매우 다양하며, 각각의 상황에 맞는 최적의 구조를 선택하는 것이 중요합니다.2. 멀티 에이전트(Multi-Agent) 구현을 위한 프레임워크이러한 멀티에이전트를 구현하기 위한 프레임워크 역시 지난 시간 소개한 마이크로소프트 오토젠(Microsoft AutoGen)을 기반으로 개발된 오픈 소스 프레임워크인 마그네틱원(Magnetic-One)과 같은 프레임워크들은 이러한 멀티 에이전트 애플리케이션을 쉽게 개발할 수 있도록 지원하는 도구입니다.  이러한 프레임워크들은 에이전트들의 상호작용, 의사결정 과정 및 복잡한 태스크를 처리하는 데 유용한 도구들을 제공하지만, 활용하기 위해서는 먼저 멀티 에이전트의 개념과 아키텍처에 대한 이해가 선행되어야 합니다. 멀티 에이전트 시스템은 더 복잡하고 심층적인 문제 해결을 위한 강력한 방법론을 제공하며, 앞으로 2025년에는 AI 기술에서 중요한 트렌드로 자리 잡을 것으로 기대되는 만큼, 관련 개념을 배워두는 것이 매우 중요할 것입니다.       keyword    인공지능    챗GPT    AI           Brunch Book   토요일\\n연재\\n    연재 알바트로스의 생성형 AI 연구소           19   딥시크의 출현과 AI 에이전트       20   AI 에이전트 개발 프레임워크에는 어떤 것들이 있을까?       21   AI 에이전트(Agent)도 서로 협업을 한다?       22   중국의 완전 자율형 AI 에이전트 마누스 AI란?       23   SF 영화 속 AI 에이전트는 현실이 될까?       \\n전체 목차 보기\\n         18  댓글 댓글0   작성된 댓글이 없습니다. 작가에게 첫 번째 댓글을 남겨주세요! 브런치에 로그인하고 댓글을 입력해보세요! 알바트로스  IT 분야 크리에이터  직업 에세이스트   문과 출신으로 생성형 AI 엔지니어로 일하고 있습니다. 챗GPT와 같은 AI가 보다 더 사람의 말을 잘 알아듣고 생성할 수 있도록 연구하는 NLP(자연어처리) 분야에서 일합니다. 구독자 554 제안하기 구독  이전 20화AI 에이전트 개발 프레임워크에는 어떤 것들이 있을까?중국의 완전 자율형 AI 에이전트 마누스 AI란?다음 22화              '),\n",
              "  Document(metadata={'source': 'https://www.comworld.co.kr/news/articleView.html?idxno=51689', 'title': '[강좌]생성형 AI 시대의 에이전트, 멀티 에이전트, MCP 설계 전략 < 강좌 < 기사본문 - 컴퓨터월드', 'description': '[컴퓨터월드] 생성형 AI 붐과 ‘실행력 격차’대규모언어모델(LLM)을 앞세운 생성형 AI는 문서 요약, 이미지 자동 생성, 챗봇의 실시간 결제 지원처럼 일상 업무의 생산성을 급격히 끌어올리고 있다. 가트너는 2025년 보고서에서 산업별 50여 개 대표 활용 사례를 제시하며 ‘콘텐츠 작성뿐 아니라 공급망·R&D·고객 경험으로 빠르게 확대 중’이라고 평가했다[1].그러나 기업의 온도차는 뚜렷하다. 딜로이트가 2024년 말 공개한 ‘State of Generative AI’ 조사에 따르면 기업 절반 이상이 여전히 PoC-파일럿 단계에', 'language': 'ko'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[강좌]생성형 AI 시대의 에이전트, 멀티 에이전트, MCP 설계 전략 < 강좌 < 기사본문 - 컴퓨터월드\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n주요서비스 바로가기\\n본문 바로가기\\n매체정보 바로가기\\n로그인 바로가기\\n기사검색 바로가기\\n전체서비스 바로가기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n상단영역\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n전체메뉴\\n\\n\\n\\n\\n커버스토리\\n\\n\\n\\n\\n기획특집\\n\\n\\n\\n\\n이슈조명\\n\\n\\n\\n\\n인터뷰\\n\\n\\n\\n\\n구축사례\\n\\n\\n\\n\\n강좌\\n\\n\\n\\n\\n기고\\n\\n\\n\\n\\n솔루션 리뷰\\n\\n\\n\\n\\nIT산업20년전\\n\\n\\n\\n\\n특별부록\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n기사검색\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n00:00\\n\\n\\n\\n홈\\n로그인\\n회원가입\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n본문영역\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n이전 기사보기\\n다음 기사보기\\n\\n\\n\\n\\n[강좌]생성형 AI 시대의 에이전트, 멀티 에이전트, MCP 설계 전략\\n\\n\\n바로가기\\n복사하기\\n본문 글씨 줄이기\\n본문 글씨 키우기\\n\\n\\n\\n\\n\\n\\n스크롤 이동 상태바\\n\\n\\n\\n\\n\\n\\n\\n\\n현재위치\\n\\n\\xa0홈\\n강좌\\n\\n\\n[강좌]생성형 AI 시대의 에이전트, 멀티 에이전트, MCP 설계 전략\\n\\n\\n\\n\\n\\n기자명 \\r\\n\\t\\t\\t\\t\\t심정훈\\t\\t\\t\\t\\n 입력 2025.09.30 09:11\\n 댓글 0\\n\\n\\n\\n\\n바로가기\\n복사하기\\n본문 글씨 줄이기\\n본문 글씨 키우기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSNS 기사보내기\\n\\n페이스북(으)로 기사보내기\\n\\n\\n트위터(으)로 기사보내기\\n\\n\\n카카오톡(으)로 기사보내기\\n\\n\\nURL복사(으)로 기사보내기\\n\\n이메일(으)로 기사보내기\\n다른 공유 찾기\\n기사스크랩하기\\n \\n\\n\\n\\n이 기사를 공유합니다\\n\\n\\n\\n\\n페이스북(으)로 기사보내기\\n\\n\\n트위터(으)로 기사보내기\\n\\n\\n카카오톡(으)로 기사보내기\\n\\n\\nURL복사(으)로 기사보내기\\n\\n\\n\\n\\n\\n닫기\\n\\n\\n\\n\\n\\n\\n \\n아마존웹서비스 심정훈 솔루션즈 아키텍트\\n\\n\\n\\n\\n아마존웹서비스 심정훈 솔루션즈 아키텍트\\n\\n\\n[컴퓨터월드]\\xa0생성형 AI 붐과 ‘실행력 격차’\\n대규모언어모델(LLM)을 앞세운 생성형 AI는 문서 요약, 이미지 자동 생성, 챗봇의 실시간 결제 지원처럼 일상 업무의 생산성을 급격히 끌어올리고 있다. 가트너는 2025년 보고서에서 산업별 50여 개 대표 활용 사례를 제시하며 ‘콘텐츠 작성뿐 아니라 공급망·R&D·고객 경험으로 빠르게 확대 중’이라고 평가했다[1].\\n그러나 기업의 온도차는 뚜렷하다. 딜로이트가 2024년 말 공개한 ‘State of Generative AI’ 조사에 따르면 기업 절반 이상이 여전히 PoC-파일럿 단계에 머물러 있었고, ROI를 체감한 조직은 세 곳 중 한 곳에 그쳤다[2].\\n에어 캐나다(Air Canada) 웹 챗봇은 허위 할인 정보를 안내해 항공사가 배상 판결을 받으며 ‘AI 산출물에 대한 최종 책임은 기업에 있다’는 선례를 남기기도 했다[3]. 학계에서는 메타 분석의 경우 최신 모델조차 평균 1-3 %의 ‘환각(사실 오류)’을 보인다고 경고하고 있다[4].\\n이처럼 ‘콘텐츠 생성 능력’과 ‘업무 실행 능력’ 사이의 간극이 나타나자, 기업들은 생성형 AI를 진정한 업무 자동화로 연결할 돌파구를 찾고 있다. 단번에 해결책을 제시하기보다, 이 간극의 구조적 원인과 진화 과정을 추적한 뒤 최종 대안을 제시하고자 한다.\\r\\n\\xa0\\n생성형 AI의 개념과 한계\\n생성형 AI는 대규모 학습 데이터에서 추출한 확률 패턴을 바탕으로 새로운 텍스트·이미지·오디오·영상을 창출하는 기술이다. 대표적인 기반 모델(Foundation Model)로는 아마존웹서비스(AWS)의 ‘아마존 노바(Amazon Nova)’[5], 앤트로픽(Anthropic)의 ‘클로드(Claude)[6]’, 오픈AI(OpenAI)의 ‘GPT 시리즈’가 있으며, 이들 모델은 방대한 지식을 일반화해 다수의 도메인에서 범용적으로 활용되고 있다.\\n그러나 ‘콘텐츠를 잘 만드는 것’과 ‘업무를 끝까지 완수하는 것’ 사이에는 다음과 같은 구조적 제약이 존재한다.\\n\\n\\n생성형 AI의 세 가지 구조적 한계\\n\\n\\n위와 같은 문제를 해결하지 못한다면, 생성형 AI는 업무를 처리하거나, 정확한 답변을 하기 어려울 것이다. 이러한 한계를 완화하기 위해 역할별 전문 에이전트를 분업·협업 구조로 조직한 멀티 에이전트 시스템을 살펴본다.\\r\\n\\xa0\\n에이전트의 등장과 단일 에이전트의 한계\\n에이전트(Agent)는 생성형 AI 모델에 외부 도구 호출 기능을 결합해, ‘콘텐츠 생성, 행동 수행’까지 스스로 처리하도록 확장한 구조다.\\n\\n\\n에이전트의 특성\\n\\n\\n\\n\\n그림1. 리액트(ReAct) 에이전트 프레임워크 - ‘Thought-Action-Observation’ 루프.\\n\\n\\n<그림 1>은 리액트(ReAct) 에이전트가 한 건의 질문을 실제 답변으로 바꾸는 전체 경로를 압축해 보여주고 있다. 먼저 사용자의 질의(①)가 들어오면, 언어 모델은 이를 받아들이는 동시에 자신이 활용할 수 있는 계산기와 지식베이스 등 외부 도구 목록이 담긴 프롬프트(②)를 함께 참고한다.\\n그런 뒤 모델은 ‘생각-행동-관찰’ 절차를 반복하며 해결책을 좁혀 간다. 예컨대 계산이 필요하다고 판단되면 계산기를 호출하고(④), 계산 결과를 관찰한 뒤(⑤) 다음 단계로 나아가는 식이다. 이렇게 축적된 사고-과정 기록은 ‘Traces’ 영역에 남아 투명성을 확보한다.\\n최종적으로 모델이 충분한 근거를 확보했다고 판단하면 결과(⑥)를 정리해 사용자에게 반환한다. 요컨대 그림은 언어 모델의 추론 능력과 외부 시스템의 실행 능력이 하나의 피드백 루프로 결합돼 실제 업무를 자동화하는 과정을 직관적으로 설명해 준다.\\r\\n\\xa0\\n1) 초기형 단일 에이전트 - 짧은 체인의 장점\\n초기형 단일 에이전트는 1~2개의 툴만 호출하는 짧은 추론 체인(Reasoning chain)으로 설계된다. 예컨대 ‘휴가 기록 API 호출, 휴가 기능 수행’과 같은 <그림 2>의 흐름처럼 체인이 짧으면 △결정 확률이 높고 △오류 발생 지점이 명확하며 △출력이 짧아 수동·자동 검증과 재시도가 용이하다.\\n\\n\\n그림2. 초기 휴가 처리 에이전트 예시\\n\\n\\n\\n2) 복합·고도화 단일 에이전트 - 길어지는 체인의 함정\\n여러 도구를 순차·병렬로 엮고, 중간 결과를 피드백 루프로 재사용하면 체인 길이가 기하급수적으로 늘어난다 (그림 3 참조).\\n\\n\\n그림3. 고도화된 에이전트의 예시(복잡도 증가, 성공률 감소)\\n\\n\\n최근 아래와 같은 연구를 보면,\\n(1) 20단계 이상 필요한 트래블 플래너(Travel Planner) 벤치마크에서 GPT-4 단일 에이전트 성공률 0.6 %[7]\\n(2) 오토GPT 계열 실험에서는 무한 루프·잘못된 재귀 호출이 빈발[8]\\n사소한 오류가 다음 단계로 전파돼 환각-전파(hallucination propagation) 위험이 급증하고, 역할이 갈라질수록 작업 분기·롤백 관리가 어려워진다. 결과적으로 ‘기능 확장, 정확도 하락’이 명확한 상쇄 관계를 이룬다.\\r\\n\\xa0\\n3) 품질 저하를 막는 에이전트 설계 원칙\\n● 작업 분해 단계 최소화: 꼭 필요한 API·툴만 호출\\n● 중간 결과 자동 검증: 자기개선(Self-Refine), SAUP 등 불확실성 추적 기법 적용, 복합 체인 AUROC 등, 최대 20% 개선사례[9]\\n● 롤백·재시도 전략: 실패 단계만 부분 재실행, 무한 루프 감지\\n앞서 본 것과 같이 단일 에이전트가 복잡해지면 복잡한 업무를 처리하는 데 어려움이 있다는 것을 확인했다.\\n이러한 한계를 극복하기 위해 여러 전문 에이전트를 분업·협업시키는 멀티 에이전트 시스템으로 시야를 넓혀 보려고 한다.\\r\\n\\xa0\\n멀티 에이전트 시스템의 필요성\\n단일 에이전트는 짧은 추론체인, 단일 도구 호출에 최적화돼 있다. 그러나 휴가 관리, 급여 정산, 부재중 결재자 처리, 사규 확인과 같은 다중 API 호출·장기 플랜·실시간 의사결정이 겹치는 업무에서는 한계를 노출한다. 최근 오토젠(AutoGen) 벤치마크는 복수의 전문 에이전트를 투입할 경우 문제 해결률이 최대 22 % 향상된다고 보고했다[10].\\n\\n\\n멀티 에이전트 협업 패턴\\n\\n\\n설계 지침\\n● 역할 분리: 에이전트마다 단일 책임 원칙(SRP) 적용.\\n● 통신 프로토콜: JSON-RPC·gRPC 등 표준 메시지로 상호 호출.\\n● 공유 메모리 & 권한: 읽기/쓰기 범위·버전 관리 정책 명시.\\n● 컨플릭트 해소: 동시 업데이트 시 우선순위·락(lock) 전략 설계.\\n● 모니터링·테스트: 각 에이전트 성공률·지연·오류 유형을 독립 계측.\\n멀티 에이전트 구조는 전문성과 병렬 처리 효율을 높여 주지만, 그만큼 조정이 복잡해지고 권한·데이터 충돌 같은 새로운 위험도 수반한다.\\n이러한 협업 문제를 해소하기 위해 고안된 MCP(Model-Context-Protocol) 프레임워크를 살펴본다.\\r\\n\\xa0\\n왜 MCP인가? ― 멀티 에이전트의 난제와 해결 열쇠\\n멀티 에이전트 환경이 커질수록 데이터 충돌·버전 관리·권한 분리가 얽혀 ‘협력 피로도’가 폭증한다. 오토젠(AutoGen), 크루AI(CrewAI) 실험에서도 에이전트 수가 5개를 넘어가면 컨텍스트 전달 오류가 전체 실패의 60% 이상을 차지했다[11]. 이를 뿌리째 해결하려는 표준이 MCP(Model-Context-Protocol)다.\\nMCP는 다음의 요소로 구성된다.\\n● 모델(Model): 에이전트의 역할과 작업 방식을 정의하는 구조.\\n● 컨텍스트(Context): 에이전트 간 작업에 필요한 정보와 상태를 관리하고 공유하는 계층.\\n● 프로토콜(Protocol): 에이전트들이 표준화된 방식으로 상호작용할 수 있도록 규칙과 절차를 정의.\\nMCP를 실제로 구현하는 것은 매우 간단하다. 아마존 Q 디벨로퍼 CLI(Amazon Q Developer CLI)로 구현하는 법을 아래와 같이 확인할 수 있다. Q 디벨로퍼 CLI에 MCP 지원이 도입됨에 따라 MCP 서버 mcp.json 파일을 통해 설정할 수 있으며, 홈 디렉토리나 작업 공간 루트에 위치시킬 수 있다. 예를 들어 포스트그레SQL(PostgreSQL) MCP 서버를 설정하는 경우 다음과 같이 구성 및 결과를 확인할 수 있다[13].\\n\\n\\n포스트그레 SQL MCP JSON 설정 및 결과의 예\\n\\n\\n이와 같이 MCP를 구축하면 △일관된 데이터 관점에서 ‘한 번 연결, 어디서나 사용’이 가능하고 △플러그인형 확장을 통해 신규 에이전트를 모델에 선언만 하면 즉시 합류가 가능하다. 특히 △컨텍스트 레이어에서 접근 제어·감사 로그 자동 기록돼 보안·추적성 확보도 용이하다.\\n앤트로픽(Anthropic)은 자사 MCP 구현을 깃허브(GitHub) PR(Pull Request) 자동화에 적용해 리뷰 시간을 48% 단축했다고 보고했다[12]. 리플릿(Replit)도 MCP-호환 인터페이스를 공개하며 ‘코드·테스트·배포를 LLM-에이전트가 순전히 대화로 처리’하는 데모를 선보였다[14].\\r\\n\\xa0\\n에이전트, 멀티 에이전트, MCP: 전략적 통합 로드맵\\n● MVP - 단일 에이전트로 핵심 API 한두 개 자동화\\n● Scale-Up - 영역별 전문 에이전트 분업, Supervisor 패턴 도입\\n● Standardize - MCP로 모델·컨텍스트·프로토콜을 명세화\\n● Operate - 관측성(Observability)·A/B 실험·ROI 모니터링 체계 구축\\n생성형 AI는 이제 ‘콘텐츠 제작 도구’ 단계를 넘어, MCP로 표준화된 멀티 에이전트 자동화가 경쟁력을 가르는 시대로 접어들었다. 단일 멀티, MCP 로드맵을 선제적으로 수립하고, 조직 전반에 실험·배포 파이프라인을 마련한 기업만이 프로세스 혁신을 통해 비용 절감 및 신규 매출 창출의 선순환을 가져올 수 있다.\\n\\xa0\\n\\n레퍼런스\\xa0\\n\\n[1] Gartner - https://www.gartner.com/en/articles/generative-ai-use-cases\\n[2] Deloitte - https://www2.deloitte.com/content/dam/Deloitte/bo/Documents/consultoria/2025/state-of-gen-ai-report-wave-4.pdf\\n[3] The Guardian - https://www.theguardian.com/world/2024/feb/16/air-canada-chatbot-lawsuit\\n[4] arXiv HalluLens - https://arxiv.org/html/2504.17550v1\\n[5] Amazon Nova 소개 - https://aws.amazon.com/ai/generative-ai/nova/\\n[6] Anthropic Claude 모델 개요 - https://docs.anthropic.com/en/docs/about-claude/models/overview\\n[7] Riddle et al., \"Benchmarking LLM Agents on Multi-Step Travel-Planner Tasks,\" arXiv, 2025. https://arxiv.org/abs/2503.01234\\n[8] AutoGPT 무한 루프 사례 - https://github.com/Significant-Gravitas/Auto-GPT/issues/3644\\n[9] Zhang et al., \"SAUP: Uncertainty-Aware Self-Audit for Agent Chains,\" NeurIPS Workshops, 2025. https://openreview.net/forum?id=saup25\\n[10] Wu et al., \"AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,\" arXiv:2308.08155, 2024.\\n[11] Wu et al., \"AutoGen: Multi-Agent Conversation Framework,\" arXiv:2308.08155, 2024.\\n[12] Anthropic Blog, \"Introducing the Model-Context-Protocol (MCP),\" 2024. https://www.anthropic.com/news/model-context-protocol\\n[13] Amazon Q Developer CLI, 모델 컨텍스트 프로토콜(MCP) 지원 시작\\nhttps://aws.amazon.com/ko/blogs/korea/extend-the-amazon-q-developer-cli-with-mcp/\\n[14] Replit Engineering, \"MCP in Production: Automating Code Review with LLM Agents,\" 2025. https://blog.replit.com/mcp-code-review\\n[그림1] https://vishwasg.dev/blog/2024/12/20/understanding-and-building-react-agents/ \\n\\n\\n\\n\\n\\n\\n\\n\\n심정훈\\n@\\n\\n\\n\\n다른기사 보기 \\n\\n저작권자 © 컴퓨터월드 무단전재 및 재배포 금지\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n컴퓨터월드 추천기사\\n\\n\\n[커버스토리] 소버린 AI 시대, 데이터 주권 확보 첫걸음은 ‘국산 DBMS’\\n\\n\\n[커버스토리] 생성형 AI 시대, 오픈소스 생태계가 마주할 ‘도전’과 ‘기회’\\n\\n\\n[기획특집] 2025 제로 트러스트 시범사업 줌인\\n\\n\\n[기획특집] VM을 컨테이너처럼…가상화 시장 새로운 먹거리 ‘쿠베버트’ 주목\\n\\n\\n[기획특집] 금융권 제로 트러스트 확산의 열쇠, ‘자율보안’\\n\\n\\n[커버스토리] 인간에 한발 다가선 AI…멀티모달 지나 AGI 시대로\\n\\n\\n[기획특집] CSP 간 경쟁 심화되는 국내 클라우드 시장\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[특별부록] 2025 국산 정보보호 솔루션 구성도\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n댓글삭제\\n\\n\\t\\t\\t삭제한 댓글은 다시 복구할 수 없습니다.\\n\\t\\t\\t그래도 삭제하시겠습니까?\\n\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n비밀번호\\n\\n\\n\\n\\n\\n\\n\\n\\xa0삭제\\n\\n\\n\\n\\n\\n닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n기사 댓글\\n0 \\n댓글 접기\\n\\n\\n\\n\\n\\n로그인 후 이용 가능합니다.\\n\\n\\n\\n댓글 내용입력\\n\\n\\n0 / 400\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\xa0 \\n\\n비회원 로그인\\n\\n이름\\n\\n\\n\\n비밀번호\\n\\n\\n\\n\\n\\n\\n댓글 내용입력\\n\\n\\n0 / 400\\n\\xa0등록\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n댓글쓰기\\n\\n\\t\\t\\t\\t계정을 선택하시면 로그인·계정인증을 통해 댓글을 남기실 수 있습니다.\\n\\t\\t\\t\\n\\n\\n\\n\\n회원 로그인\\n비회원 글쓰기\\n\\n\\n\\n\\n\\n이름\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n비밀번호\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n자동등록방지\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\xa0확인\\n\\xa0취소\\n\\n\\n\\n\\n\\n\\n\\n로그인 옵션 창닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n주요기사\\n\\n\\n\\n\\n\\n[커버스토리] 보안 인력난 심화에 SOAR 도입 ‘확대일로’\\n\\n\\n\\n\\n\\n\\n\\n[지상중계] “사이버보안의 새 패러다임을 전망한다”\\n\\n\\n\\n\\n\\n\\n\\n[기획특집] 제조 현장 혁신의 열쇠, ‘피지컬 AI’\\n\\n\\n\\n\\n\\n\\n\\n[이슈조명] 끝없이 진화하는 SW 공급망 공격…보안 기업도 당했다\\n\\n\\n\\n\\n\\n\\n\\n[시장동향] ‘AI옵스’, 클라우드 파편화 시대 운영 혁신 전략으로 부상\\n\\n\\n\\n\\n\\n\\n\\n[인터뷰] “해외 30개국 진출 ‘아이피스캔’으로 K-보안의 글로벌 표준 꿈꾼다”\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n이달의 주요기사\\n\\n\\n\\n\\n\\n[커버스토리] 보안 인력난 심화에 SOAR 도입 ‘확대일로’\\n\\n\\n\\n\\n\\n\\n\\n[지상중계] “사이버보안의 새 패러다임을 전망한다”\\n\\n\\n\\n\\n\\n\\n\\n[기획특집] 제조 현장 혁신의 열쇠, ‘피지컬 AI’\\n\\n\\n\\n\\n\\n\\n\\n[이슈조명] 끝없이 진화하는 SW 공급망 공격…보안 기업도 당했다\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n인기기사\\n\\n\\n\\n1\\n[커버스토리] 보안 인력난 심화에 SOAR 도입 ‘확대일로’\\n\\n\\n\\n\\n2\\n[지상중계] “사이버보안의 새 패러다임을 전망한다”\\n\\n\\n\\n\\n3\\n[인터뷰] “스노우플레이크 기반 게임 이상 탐지 체계 ‘KARS’ 고도화”\\n\\n\\n\\n\\n4\\n[초점] 해커들 단골 침투 경로 된 VPN…ZTNA 및 SDP로 대체해야\\n\\n\\n\\n\\n5\\n[이슈조명] 끝없이 진화하는 SW 공급망 공격…보안 기업도 당했다\\n\\n\\n\\n\\n6\\n[전문가 기고] 진화하는 사이버 위협 속 기업이 선택해야 할 새로운 인증 전략\\n\\n\\n\\n\\n7\\n[취재.txt] ‘징벌적 과징금’ 엄포가 전환점 될까…보안 투자 확대 기대한다\\n\\n\\n\\n\\n8\\n[화제의 현장] “애플리케이션 개발부터 테스트까지 ‘AI 패스’로 전 과정 혁신”\\n\\n\\n\\n\\n9\\n[화제의 현장] “AI 이네이블과 에이전틱 AI로 거버넌스와 컴플라이언스 고도화”\\n\\n\\n\\n\\n10\\n[기획특집] 제조 현장 혁신의 열쇠, ‘피지컬 AI’\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n하단영역\\n\\n\\n\\n주요뉴스\\n\\n\\n\\n[인터뷰] “해외 30개국 진출 ‘아이피스캔’으로 K-보안의 글로벌 표준 꿈꾼다”\\n\\n\\n[인터뷰] “스노우플레이크 기반 게임 이상 탐지 체계 ‘KARS’ 고도화”\\n\\n\\n[인터뷰] “버추얼 트윈 시대, ‘시뮬리아’로 디지털 혁신 러닝메이트 될 것”\\n\\n\\n[초점] 해커들 단골 침투 경로 된 VPN…ZTNA 및 SDP로 대체해야\\n\\n\\n[초점] AI, 연구 활동 동반자인가 훼방꾼인가\\n\\n\\n\\n\\n\\n\\n실시간뉴스\\n\\n\\n\\n[커버스토리] 보안 인력난 심화에 SOAR 도입 ‘확대일로’\\n\\n\\n[지상중계] “사이버보안의 새 패러다임을 전망한다”\\n\\n\\n[기획특집] 제조 현장 혁신의 열쇠, ‘피지컬 AI’\\n\\n\\n[이슈조명] 끝없이 진화하는 SW 공급망 공격…보안 기업도 당했다\\n\\n\\n[시장동향] ‘AI옵스’, 클라우드 파편화 시대 운영 혁신 전략으로 부상\\n\\n\\n[인터뷰] “해외 30개국 진출 ‘아이피스캔’으로 K-보안의 글로벌 표준 꿈꾼다”\\n\\n\\n[인터뷰] “스노우플레이크 기반 게임 이상 탐지 체계 ‘KARS’ 고도화”\\n\\n\\n[인터뷰] “버추얼 트윈 시대, ‘시뮬리아’로 디지털 혁신 러닝메이트 될 것”\\n\\n\\n[초점] 해커들 단골 침투 경로 된 VPN…ZTNA 및 SDP로 대체해야\\n\\n\\n[초점] AI, 연구 활동 동반자인가 훼방꾼인가\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n하단메뉴\\n\\n매체소개\\n기사제보\\n광고문의\\n이용약관\\n개인정보처리방침\\n청소년보호정책\\n저작권보호정책\\n이메일무단수집거부\\n\\n\\n\\n\\n\\n\\n매체정보\\n\\n법인명 : 컴퓨터월드\\n서울특별시 금천구 가산디지털1로 181 (가산 더블유센터) 1713~1715호 \\n대표전화 : 02-2039-6160 \\n팩스 : 02-2039-6163\\n제호 : 컴퓨터월드\\n등록번호 : 금천 라 00077\\n발행일 : \\n등록일 : 2006-01-03\\n발행인 : 김용석\\n편집인 : 김선오\\n청소년보호책임자 : 김선오\\n\\n컴퓨터월드 모든 콘텐츠(기사)는 저작권법의 보호를 받는 바, 무단전재, 복사, 배포 등을 금합니다.\\n© 컴퓨터월드. All rights reserved.\\r\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n위로 \\n\\n\\n\\n\\n\\n전체메뉴\\n\\n\\n전체기사\\n\\n커버스토리\\n\\n\\n기획특집\\n\\n\\n이슈조명\\n\\n\\n인터뷰\\n\\n\\n구축사례\\n\\n\\n강좌\\n\\n\\n기고\\n\\n\\n솔루션 리뷰\\n\\n\\nIT산업20년전\\n\\n\\n특별부록\\n\\n\\n\\n\\n전체메뉴닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://www.salesforce.com/kr/agentforce/ai-agents/multi-agent-systems/', 'title': '멀티 에이전트 시스템이란 무엇인가요? | Salesforce', 'description': '멀티 에이전트 시스템은 문제를 해결하고, 결정을 최적화하며, 업무를 효율적으로 조정하기 위해 상호 작용하는 AI 기반 자율 에이전트 네트워크입니다.', 'language': 'ko'}, page_content='멀티 에이전트 시스템이란 무엇인가요? | Salesforce\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n사례 공유하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템 설명: 완벽 가이드\\n    \\n\\n\\n\\n\\n\\n\\n사례 공유하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Agentforce 체험하기\\n    \\n    \\n    \\n    \\n        \\n            \\n                \\n            \\n        \\n    \\n    \\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n모든 사람이 각자의 기술을 가지고 독립적으로 일하면서도 공통의 목표를 달성하기 위해 협력을 유지하는 팀을 떠올려 보세요. 이것이 멀티 에이전트 시스템(MAS)의 기본 개념입니다. MAS는 단일 AI에 의존하여 모든 것을 처리하는 대신, 여러 AI 에이전트를 한데 모아 협업하고 정보를 공유하므로 궁극적으로 더 스마트한 의사 결정을 내릴 수 있습니다.\\n이러한 접근 방식은 많은 산업을 혁신하고 있습니다. 공급망 최적화부터 자율 차량 관리 및 금융 거래 강화에 이르기까지, MAS는 효율성과 적응성 과제 모두를 해결하는 데 도움을 줄 수 있습니다. 아래에서는 멀티 에이전트 시스템의 작동 방식을 살펴보고 모범 사례와 이점을 검토합니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        단일 에이전트 시스템의 이해\\n    \\n\\n\\n\\n\\n멀티 에이전트 시스템으로 업그레이드하기 전에 한 걸음 물러나 단일 에이전트 시스템이 어떻게 작동하는지 살펴보는 것이 좋습니다. 에이전트는 일종의 AI 시스템으로, 인간 개입 없이 고객 문의를 이해하고 응답할 수 있습니다. 이러한 정보를 수집하면 에이전트는 특정 목표를 달성하기 위한 조치를 취합니다.\\n들어오는 서비스 요청을 관리하고, 긴급도에 따라 작업의 우선순위를 지정하고, 기록을 업데이트하거나 후속 조치를 예약하여 조치를 취하는 에이전트를 떠올려 보세요. 스크립트를 따르는 대신 실시간 데이터를 사용하여 상황에 맞는 의사 결정을 내립니다.\\n이러한 에이전트는 강력하지만 다른 에이전트와 상호 작용하여 인사이트를 공유하고 문제를 해결하지는 않습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템이란 무엇인가요?\\n    \\n\\n\\n\\n\\n멀티 에이전트 시스템은 모든 것을 처리하기 위해 단일 AI에 의존하는 대신 다른 접근 방식을 취합니다. 즉, 상호 작용하고 협업하여 문제를 해결하는 여러 지능형 에이전트를 사용합니다. 이러한 에이전트는 공유 환경 내에서 작업하여 정보를 교환하고 종합적인 의사 결정을 내립니다. 그 결과, 복잡한 업무를 단일 AI보다 더 잘 처리할 수 있는 더 효율적인 시스템이 탄생했습니다.\\n멀티 에이전트 시스템은 모든 의사 결정 권한을 한곳에 모으는 대신 여러 엔티티에서 인텔리전스를 공유합니다. 각 에이전트는 자체 목표와 의사 결정 프로세스를 가지고 있지만, 둥지를 짓는 개미 무리처럼 함께 작동합니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템의 특징\\n    \\n\\n\\n\\n\\nMAS가 기존 에이전틱 AI와 다른 점은 무엇인가요? 에이전트가 상호 작용하는 방식, 그리고 에이전트가 혼자서 할 수 있는 것보다 더 많은 인텔리전스를 함께 활용하는 방법이 핵심입니다. 에이전틱 성숙도가 높아지면 시스템이 워크플로 전반에서 협업하고 결과를 조정하는 에이전트 팀을 지원하기 시작합니다.\\n멀티 에이전트 시스템을 정의하는 요소는 다음과 같습니다.\\n\\n자율성: 각 에이전트는 자체 범위 내에서 독립적으로 작동합니다. 이들은 데이터를 수집하고 처리한 다음, 중앙 기관에 확인 받을 필요 없이 작업을 수행합니다.\\n조정: 에이전트는 동기화 상태를 유지합니다. 다른 에이전트가 수행하고 있는 작업에 따라 업데이트를 공유하고, 업무를 전달하고, 계획을 조정합니다.\\n상호 운용성: 성숙한 MAS는 A2A 및 MCP와 같은 표준화된 프로토콜을 지원하므로, 에이전트가 서로 다른 기능을 위해 구축되었더라도 서로를 이해할 수 있습니다.\\n확장성: 시스템을 확장해야 하는 경우, 에이전트를 더 추가하기만 하면 됩니다. MAS 아키텍처를 사용하면 모든 것을 처음부터 다시 작성하지 않고도 더 쉽게 성장할 수 있습니다.\\n전문화: 각 에이전트는 목적별로 제작됩니다. 하나는 일정 관리를 처리하고 다른 하나는 지원 사례를 해결할 수 있습니다. 이들은 함께 더 큰 과제를 해결할 수 있는 조정된 네트워크를 형성하기도 합니다.\\n\\n이러한 특성은 단일 에이전트가 혼자서는 대응할 수 없는 빠르게 변화하는 환경에서 MAS를 특히 강력하게 만듭니다. 에이전트 에코시스템이 성숙함에 따라 MAS는 차세대 AI 오케스트레이션을 위한 모델이 됩니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        단일 에이전트와 멀티 에이전트 시스템 비교: 주요 차이점\\n    \\n\\n\\n\\n\\n단일 에이전트와 멀티 에이전트 시스템의 가장 큰 차이점은 의사 결정 방식입니다. 단일 에이전트 시스템은 단독으로 작동합니다. 이들은 데이터를 수집하고 처리한 다음, 자체 규칙에 따라 조치를 취합니다. 이러한 설정은 긴급도에 따라 지원 티켓을 라우팅하거나 개인화된 고객 이메일 초안을 작성하는 등의 간단한 작업에 적합합니다.\\n하지만 어떤 문제는 하나의 시스템만으로 처리하기에는 너무 큽니다. 하나의 에이전트가 혼자 일하는 대신, MAS는 팀에 기반하여 실시간으로 커뮤니케이션하고, 업무를 공유하고, 적응합니다.\\n또한 MAS는 확장성이 더 우수합니다. 단일 에이전트 시스템은 속도가 느려지기 전에만 다량의 데이터를 처리할 수 있는 반면, MAS는 필요에 따라 새로운 에이전트를 추가할 수 있습니다. 따라서 에이전트 개발의 다음 단계에서는 에이전트가 궁극적으로 고객 지원, 일정 관리, 주문 처리와 같은 여러 도메인에서 협업할 수 있는 멀티 에이전트 조정을 목표로 합니다. 물론 에이전트가 많을수록 복잡성이 커지지만, 올바른 구조를 갖춘 MAS는 모든 것을 원활하게 운영할 수 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템의 이점\\n    \\n\\n\\n\\n\\n멀티 에이전트 시스템은 단일 에이전트 설정으로는 불가능한 일, 즉 분담하고 맡는 기능을 제공합니다. 다양한 에이전트에게 특정 역할을 할당함으로써 MAS는 더 복잡한 업무를 더 유연하게 처리할 수 있습니다. 에이전트는 정보를 전달하거나 다른 에이전트가 중단한 작업을 맡을 수 있습니다.\\n특히 조직이 도메인 전반에서 자동화를 목표로 함에 따라, 이러한 종류의 조정은 응답성이 더 높은 시스템에 대한 가능성을 열어줍니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        모듈성 및 확장성\\n    \\n\\n\\n\\n\\n멀티 에이전트 시스템의 가장 큰 강점 중 하나는 우수한 확장성입니다. 각 에이전트는 독립적으로 작동하므로 시스템 과부하 없이 새로운 에이전트를 추가할 수 있습니다. 따라서 MAS는 물류 등 수요가 변동하는 산업에 이상적입니다. 새로운 변수나 작업이 발생할 때마다 전체 시스템을 재설계하는 대신, 더 많은 에이전트를 추가하여 워크로드를 공유할 수 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        작업 체이닝 및 에이전트 핸드오프\\n    \\n\\n\\n\\n\\nMAS를 사용하면 모든 문제를 협력하여 해결하는 대신, 에이전트가 서로 업무를 핸드오프하는 순서를 설계할 수 있습니다. 공항에 내렸다고 가정해 보겠습니다. 이때 여행 도우미 에이전트가 자동으로 차량 공유 에이전트에게 차량 예약을 요청할 수 있습니다. 각 에이전트는 전문 분야에 집중하지만, 함께 원활한 경험을 제공할 수 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        적응성 개선\\n    \\n\\n\\n\\n\\n실제 환경은 예측하기 어렵지만, MAS 에이전트는 새로운 정보나 예상치 못한 중단에 따라 행동을 조정할 수 있습니다. 이러한 산업에서는 의사 결정이 빠르게 이루어져야 하며 상황은 항상 변화하고 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템에서 에이전트가 조정하는 방법\\n    \\n\\n\\n\\n\\n멀티 에이전트 시스템에서는 에이전트가 단순히 서로 밀접하게 작동하는 것으로는 충분하지 않습니다. 업무를 전달하고, 컨텍스트를 공유하고, 더 광범위한 결과를 향해 협력하는 등 조정이 필요합니다. 이러한 조정은 느슨한 도구 그룹과 완벽하게 기능하는 MAS를 구분하는 요소입니다.\\n에이전트 에코시스템이 성숙함에 따라, 이러한 조정은 다음과 같이 이루어집니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        체이닝 및 오케스트레이션\\n    \\n\\n\\n\\n\\n각 에이전트는 제품 질문에 답변하거나 후속 조치를 시작하는 등 특정 목적에 맞게 설계됩니다. 더불어 이러한 에이전트가 작업을 서로 핸드오프할 수 있게 되면 진정한 오케스트레이션이 실현됩니다. 한 에이전트가 작업을 완료하고 다음 에이전트에게 배턴을 넘겨 컨텍스트와 추진력을 유지합니다.\\n설정 에이전트가 서비스를 활성화한 다음 환영 에이전트에게 개인화된 이메일을 전송하도록 신호를 보내고, 이어서 교육 에이전트에게 해당 사용자에게 맞춤형 리소스를 제공하라고 알리는 온보딩 순서를 상상해 보세요. 각 에이전트는 독립적으로 작동하지만 동기화되어 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        공유 메모리 및 컨텍스트\\n    \\n\\n\\n\\n\\n에이전트가 원활하게 협업하려면 관련 컨텍스트를 유지하고 공유해야 합니다. 그렇지 않으면 각 상호 작용이 리셋됩니다. 에이전트 설계가 진행됨에 따라 시스템은 메모리를 지원하는 방향으로 진화하므로, 에이전트는 다른 에이전트가 중단한 부분을 선택하고 그에 따라 결정을 조정할 수 있습니다.\\n이를 통해 별개의 여러 파트에서 지원을 받더라도 \"시스템\" 전체에 응집력이 생기므로 더 원활한 경험을 제공할 수 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        협업을 위한 프로토콜\\n    \\n\\n\\n\\n\\n에이전트는 정보를 교환하는 공유된 방법 없이는 조정할 수 없습니다. 이 부분에서 상호 운용성 프로토콜이 필요합니다. 이 프로토콜은 에이전트가 커뮤니케이션하고, 컨텍스트를 공유하고, 업무를 원활하게 전달하는 데 필요한 구조를 제공합니다.\\nSalesforce는 멀티 에이전트 조정을 위해 설계된 두 가지 핵심 프로토콜을 지원합니다.\\n\\n모델 컨텍스트 프로토콜(MCP)은 에이전트가 더 광범위한 업무에 대한 인식을 유지할 수 있도록 도와줍니다. 또한 에이전트 간에 컨텍스트(예: 사용자 의도, 이전 단계 또는 시스템 상태)를 전달할 수 있도록 보장합니다.\\n에이전트 투 에이전트(A2A)를 통해 에이전트는 서로 실시간 업데이트나 작업 요청을 보낼 수 있으므로 중앙 시스템에 의존하지 않고도 협업할 수 있습니다.\\n\\n이러한 프로토콜을 사용하면 에이전트 네트워크를 더 쉽게 확장할 수 있으므로 각 에이전트가 자신의 역할에 집중하면서 더 크고 연결된 경험에 기여할 수 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템 개발의 과제\\n    \\n\\n\\n\\n\\n멀티 에이전트 시스템은 많은 가능성을 가지고 있지만, 이러한 잠재력을 실현하는 것은 한 가지 핵심 요소인 상호 운용성에 달려 있습니다. 에이전트가 협업하려면 컨텍스트를 유지하면서 소통하고 업무를 핸드오프할 수 있는 공유된 방법이 필요합니다. 그렇지 않으면 각 에이전트는 고립된 상태에서 작동하게 됩니다.\\n오늘날 MAS 개발의 가장 큰 장애물 중 하나는 일관된 표준이 없다는 점입니다. 많은 에이전트는 다양한 프레임워크, 언어 또는 작동 방식에 대한 가설을 사용하여 구축됩니다. 이러한 분열로 인해 에이전트를 공유 에코시스템에 연결하거나 효과적으로 체인화하기가 더 어려워집니다.\\nMCP 및 A2A와 같은 프로토콜은 에이전트 상호 작용을 위한 공통 기반을 구축하여 이를 해결하는 데 도움을 줍니다. 하지만 널리 도입되려면 시간이 걸립니다. 또한 개발자가 처음부터 상호 운용성을 염두에 두고 구축하는지 여부에 따라 달라집니다.\\nMAS가 점점 더 주류가 됨에 따라 표준화를 향한 더 강력한 추진력을 기대할 수 있습니다. 이는 구축의 주체가 누구인지와 관계없이 에이전트가 더 광범위하고 조정된 시스템의 일부로 작동할 수 있도록 보장하는 유일한 방법입니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템 도입을 위한 모범 사례\\n    \\n\\n\\n\\n\\n처음부터 완벽히 오케스트레이션된 MAS로 시작할 필요는 없습니다. 개별 에이전트부터 시작하여 시간이 지남에 따라 조정을 확장하면서 점진적으로 구축하세요.\\nMAS를 시작할 때 다음 단계로 성장하는 방법은 다음과 같습니다.\\n\\n소규모로 시작하고 집중하세요: 구체적이고 반복 가능한 업무를 처리하는 에이전트로 시작하세요. 명확한 목표와 좁은 범위는 에이전트가 더 쉽게 테스트하고 개선할 수 있게 해줍니다.\\n공유 프로토콜을 사용하세요: MCP 및 A2A와 같은 상호 운용성 표준을 조기에 도입하세요. 아직 에이전트를 체인화하고 있지 않더라도 일반적인 프로토콜을 사용하면 나중에 더 원활하게 오케스트레이션할 수 있습니다.\\n지속적으로 개선하세요: 에이전트 네트워크를 확장할 때 피드백과 분석을 사용하여 행동을 다듬으세요. 에이전트 에코시스템은 더 많이 학습하고 연결할수록 더 스마트해집니다.\\n\\n이러한 각 단계를 통해 지능형 에이전트가 함께 작동하여 더 빠르고 스마트한 결과를 제공하는 멀티 에이전트 시스템에 더 가까워질 수 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        멀티 에이전트 시스템(MAS) FAQ\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    AI의 멀티 에이전트 시스템이란 무엇인가요?\\n                    \\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n멀티 에이전트 시스템(MAS)은 상호 작용하는 여러 지능형 에이전트로 구성된 컴퓨팅 시스템으로, 각각 특정 기능과 목표를 가지고 있으며, 복잡한 문제를 해결하기 위해 협업합니다.\\n\\n\\n\\n\\n\\n\\n\\n                    MAS의 개별 에이전트는 어떻게 상호 작용하나요? \\n                    \\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\nMAS의 에이전트는 통신 프로토콜을 통해 상호 작용하고, 정보를 공유하고, 업무를 협상하고, 작업을 조정하여 집단 또는 개별 목표를 달성합니다.\\n\\n\\n\\n\\n\\n\\n\\n                    멀티 에이전트 시스템의 이점은 무엇인가요? \\n                    \\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n이점으로는 복잡한 작업을 위한 문제 해결 기능 개선, 견고성 및 내결함성 향상, 확장성 개선, 개별 에이전트의 특성화된 전문 지식 활용 능력 등이 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n                    멀티 에이전트 시스템은 어떤 애플리케이션에서 사용되나요? \\n                    \\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n해당 애플리케이션에는 공급망 최적화, 스마트 그리드, 트래픽 관리, 스웜 로보틱스, 금융 거래, 및 복잡한 고객 서비스 에코시스템 등이 포함됩니다.\\n\\n\\n\\n\\n\\n\\n\\n                    멀티 에이전트 시스템은 작업 분배를 어떻게 처리하나요? \\n                    \\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n작업은 에이전트의 역량, 현재 워크로드, 전체 시스템의 목표에 따라 에이전트에게 분배되며, 협상 및 동적 할당이 수반되는 경우도 많습니다.\\n\\n\\n\\n\\n\\n\\n\\n                    멀티 에이전트 시스템 설계와 관련된 과제는 무엇인가요? \\n                    \\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n과제로는 효과적인 통신 프로토콜 설계, 에이전트 간의 조정 및 협업 보장, 잠재적인 충돌 관리, 시스템 전반의 성능 평가 등이 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n                    MAS에서 조정 메커니즘의 역할은 무엇인가요? \\n                    \\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n다중 에이전트 시스템에서 조정 메커니즘은 여러 자율 에이전트가 효율적으로 협력하고, 상호 작용을 관리하고, 공통적 또는 개별적 목표를 달성할 수 있게 해주는 방법 또는 프로토콜입니다. 조정 메커니즘에는 협상, 경매 기반 할당 또는 중앙 집중식 플랜과 같은 기술이 포함될 수 있으며, 이는 에이전트가 작업을 동기화하고, 충돌을 해결하고, 공동의 성과를 최적화하는 데 도움을 줍니다. 이러한 메커니즘은 에이전트가 시스템 내에서 응집력 있고 효율적으로 작동하도록 하는 데 매우 중요합니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        AI 에이전트에 대해 자세히 알아보고 비즈니스에 어떤 도움을 줄 수 있는지 알아보세요.\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuide\\n\\n\\n\\n    추론, 주제, 명령 및 작업에 대한 Agentforce 가이드.\\n    \\n\\n\\n\\n\\n\\n\\n\\n    가이드 읽기\\n    \\n    \\n    \\n    \\n        \\n            \\n        \\n    \\n    \\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticle\\n\\n\\n\\n    에이전트 AI란 무엇인가요?\\n    \\n\\n\\n\\n\\n\\n\\n\\n    문서 읽기\\n    \\n    \\n    \\n    \\n        \\n            \\n        \\n    \\n    \\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticle\\n\\n\\n\\n    AI 에이전트 구축 방법\\n    \\n\\n\\n\\n\\n\\n\\n\\n    문서 읽기\\n    \\n    \\n    \\n    \\n        \\n            \\n        \\n    \\n    \\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBlog\\n\\n\\n\\n    LLM과 Copilot만으로는 문제를 해결할 수 없습니다. 엔터프라이즈 AI를 잘못 이용하고 있는 이유\\n    \\n\\n\\n\\n\\n\\n\\n\\n    블로그 읽기\\n    \\n    \\n    \\n    \\n        \\n            \\n        \\n    \\n    \\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        Agentforce 제품을 사용해 비즈니스를 성장시킬 준비가 되셨나요?\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        담당자에게 문의하세요.\\n    \\n\\n\\n\\n비즈니스 요구 사항에 대해 알려주시면 해답을 찾도록 도와드리겠습니다.\\n\\n\\n\\n\\n\\n    문의하기\\n    \\n    \\n    \\n    \\n        \\n            \\n                \\n            \\n        \\n    \\n    \\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        전문가의 안내를 받으세요.\\n    \\n\\n\\n\\n속도, 자신감, 측정 가능 ROI로 Agentforce를 시작하세요.\\n\\n\\n\\n\\n\\n    방법 보기\\n    \\n    \\n    \\n    \\n        \\n            \\n        \\n    \\n    \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.environ['TAVILY_API_KEY'] = 'tvly-xxxx'\n",
        "os.environ['USER_AGENT'] = 'MyAgent'\n",
        "\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "def tavily_search(State):\n",
        "    tavily_search = TavilySearch(max_results=5)\n",
        "\n",
        "    # 검색 결과 수집\n",
        "    search_results = tavily_search.invoke({'query': State['query']})['results']\n",
        "    # search_results : url, Content 형식의 Dict List Return\n",
        "\n",
        "    # URL 리스트 추출 (PDF 주소는 제외)\n",
        "    urls = [result['url'] for result in search_results if 'pdf' not in result['url']]\n",
        "\n",
        "\n",
        "    try:\n",
        "        loader = WebBaseLoader(urls)\n",
        "    except:\n",
        "        loader = WebBaseLoader(urls, requests_kwargs={'verify':False})\n",
        "\n",
        "    documents = loader.load()\n",
        "    return {'context': documents}\n",
        "\n",
        "result = tavily_search({'query': '멀티 에이전트 구조'})\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "v2BswHqhrDMh"
      },
      "outputs": [],
      "source": [
        "def get_query(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "         ('user','''{question}에 답변하기 위해\n",
        "인터넷 검색을 사용하려고 합니다.\n",
        "적절한 검색어 쿼리를 하나만 출력하세요.\n",
        "쿼리만 출력하세요.''')\n",
        "    ])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"query\": chain.invoke(State)}\n",
        "    # State를 모두 입력해도, Prompt Template에 포함된 입력변수만 전달\n",
        "\n",
        "\n",
        "def answer_question(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
        "다음의 Context를 이용하여 Question에 답변하세요.\n",
        "정확한 답변을 제공하세요.\n",
        "만약 모든 Context를 다 확인해도 정보가 없다면,\n",
        "\"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.'''),\n",
        "\n",
        "        ('user', '''Context: {context}\n",
        "---\n",
        "Question: {question}''')])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"answer\": chain.invoke(State)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scIrzxLMrDMi"
      },
      "source": [
        "State를 만들고, 그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oUzOx5WrrDMi"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    question : str # 유저의 질문\n",
        "    query: str # 질문에서 파생된 검색어\n",
        "    answer: str # 답변\n",
        "    context: str # 검색 결과\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-taG6FMMrDMi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x2b89b16f710>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 그래프 구성\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"get_query\", get_query)\n",
        "builder.add_node(\"tavily_search\", tavily_search)\n",
        "builder.add_node(\"answer_question\", answer_question)\n",
        "\n",
        "builder.add_edge(START, \"get_query\")\n",
        "builder.add_edge(\"get_query\", \"tavily_search\")\n",
        "builder.add_edge(\"tavily_search\", \"answer_question\")\n",
        "builder.add_edge(\"answer_question\", END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xUUJS6x9rDMi"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x000002B89B2F1E20>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6u2IrFvkrDMi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Qwen 3 Omni 는 어떤 모델이야?',\n",
              " 'query': 'Qwen 3 Omni',\n",
              " 'answer': 'Qwen3-Omni는 텍스트, 이미지, 오디오, 비디오를 처리할 수 있는 다중 모달(multimodal) 모델입니다. 이 모델은 엔드투엔드(end-to-end) 다국어 옴니 모델로, 텍스트와 자연스러운 음성으로 실시간 스트리밍 응답을 제공합니다.\\n\\n주요 특징은 다음과 같습니다:\\n*   **다중 모달 처리**: 텍스트, 이미지, 오디오, 비디오 등 다양한 형태의 데이터를 처리합니다.\\n*   **실시간 응답**: 텍스트 및 자연스러운 음성으로 실시간 스트리밍 응답을 제공합니다.\\n*   **다국어 지원**: 119개 언어로 텍스트 상호작용을 지원하며, 19개 언어로 음성 이해, 10개 언어로 음성 생성을 지원합니다.\\n*   **아키텍처**: Thinker-Talker MoE 아키텍처를 채택하여 텍스트, 이미지, 오디오, 비디오 전반에 걸쳐 인식과 생성을 통합합니다.\\n*   **성능**: 단일 모달 모델과 비교하여 성능 저하 없이 텍스트, 이미지, 오디오, 비디오에서 최첨단 성능을 유지하며, 특히 오디오 작업에서 뛰어난 성능을 보입니다. (36개 오디오 및 오디오-시각 벤치마크 중 32개에서 오픈소스 SOTA, 22개에서 전체 SOTA 달성)',\n",
              " 'context': [Document(metadata={'source': 'https://qwen.ai/blog?id=65f766fc2dcba7905c1cb69cc4cab90e94126bf4&from=research.latest-advancements-list', 'title': 'Qwen', 'description': 'Qwen Chat offers comprehensive functionality spanning chatbot, image and video understanding, image generation, document processing, web search integration, tool utilization, and artifacts.', 'language': 'No language found.'}, page_content='\\nQwen'),\n",
              "  Document(metadata={'source': 'https://www.reddit.com/r/LocalLLaMA/comments/1nqg5q3/whats_your_experience_with_qwen3omni_so_far/', 'title': 'Reddit - The heart of the internet', 'language': 'en-US'}, page_content='\\n\\n\\n\\nReddit - The heart of the internet\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen menu\\n\\nOpen navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nGo to Reddit Home\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n\\nA chip\\n\\n\\n\\n\\n\\n\\n\\n\\nA close button\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLog In\\n\\nLog in to Reddit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExpand user menu\\nOpen settings menu\\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Go to LocalLLaMA\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nr/LocalLLaMA\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nhttps://x.com/localllamasub\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n              Subreddit to discuss AI & Llama, the large language model created by Meta AI. \\n            \\n\\n\\n\\n\\n\\n\\nMembers\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n•\\n\\n\\n\\n\\n\\n\\nBalance-\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n       What’s your experience with Qwen3-Omni so far? \\n\\n\\n\\n\\n\\n\\n    Discussion\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Qwen3-Omni is now out for a few days, what’s your experience with it so far? And what are you using it for?\\n    \\n\\n      Qwen3-Omni is the natively end-to-end multilingual omni model. It processes text, images, audio, and video, and delivers real-time streaming responses in both text and natural speech. We introduce several upgrades to improve performance and efficiency.\\n    \\n\\n\\n\\n      Blog: https://qwen.ai/blog?id=65f766fc2dcba7905c1cb69cc4cab90e94126bf4\\n\\n\\n\\n      Weights: https://huggingface.co/collections/Qwen/qwen3-omni-68d100a86cd0906843ceccbe\\n\\n\\n\\n      Paper: https://arxiv.org/abs/2509.17765\\n\\n\\n\\n\\n\\n\\n      Read more\\n       \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Share \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNew to Reddit?\\n          \\n\\n                  Create your account and connect with a world of communities.\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n        Continue with Email\\n      \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n              Continue With Phone Number\\n            \\n\\n\\n\\n\\n\\nBy continuing, you agree to our\\nUser Agreement\\nand acknowledge that you understand the\\nPrivacy Policy.\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nhttps://x.com/localllamasub\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n Public\\n   Anyone can view, post, and comment to this community\\n\\n0\\n0\\n\\n\\n\\n\\n\\nReddit Rules\\n\\n\\n\\nPrivacy Policy\\n\\n\\n\\nUser Agreement\\n\\n\\n\\nAccessibility\\n\\n\\nReddit, Inc. © 2025. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\nExpand Navigation\\n\\n\\n\\n\\n\\n\\n\\n\\nCollapse Navigation\\n\\n\\n\\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://arxiv.org/abs/2509.17765', 'title': '[2509.17765] Qwen3-Omni Technical Report', 'description': 'Abstract page for arXiv paper 2509.17765: Qwen3-Omni Technical Report', 'language': 'en'}, page_content=\"\\n\\n [2509.17765] Qwen3-Omni Technical Report\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHappy Open Access Week from arXiv!\\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\\n\\n\\nDonate!\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\\nDonate\\n\\n\\n\\n\\n\\n > cs > arXiv:2509.17765\\n  \\n\\n\\n\\n\\n\\n\\n\\nHelp | Advanced Search\\n\\n\\n\\n\\nAll fields\\nTitle\\nAuthor\\nAbstract\\nComments\\nJournal reference\\nACM classification\\nMSC classification\\nReport number\\narXiv identifier\\nDOI\\nORCID\\narXiv author ID\\nHelp pages\\nFull text\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nopen search\\n\\n\\n\\n\\n\\n\\nGO\\n\\n\\n\\nopen navigation menu\\n\\n\\nquick links\\n\\nLogin\\nHelp Pages\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputer Science > Computation and Language\\n\\n\\narXiv:2509.17765 (cs)\\n    \\n\\n\\n\\n\\n  [Submitted on 22 Sep 2025]\\nTitle:Qwen3-Omni Technical Report\\nAuthors:Jin Xu, Zhifang Guo, Hangrui Hu, Yunfei Chu, Xiong Wang, Jinzheng He, Yuxuan Wang, Xian Shi, Ting He, Xinfa Zhu, Yuanjun Lv, Yongqi Wang, Dake Guo, He Wang, Linhan Ma, Pei Zhang, Xinyu Zhang, Hongkun Hao, Zishan Guo, Baosong Yang, Bin Zhang, Ziyang Ma, Xipin Wei, Shuai Bai, Keqin Chen, Xuejing Liu, Peng Wang, Mingkun Yang, Dayiheng Liu, Xingzhang Ren, Bo Zheng, Rui Men, Fan Zhou, Bowen Yu, Jianxin Yang, Le Yu, Jingren Zhou, Junyang Lin View a PDF of the paper titled Qwen3-Omni Technical Report, by Jin Xu and 37 other authors\\nView PDF\\nHTML (experimental)\\n\\nAbstract:We present Qwen3-Omni, a single multimodal model that, for the first time, maintains state-of-the-art performance across text, image, audio, and video without any degradation relative to single-modal counterparts. Qwen3-Omni matches the performance of same-sized single-modal models within the Qwen series and excels particularly on audio tasks. Across 36 audio and audio-visual benchmarks, Qwen3-Omni achieves open-source SOTA on 32 benchmarks and overall SOTA on 22, outperforming strong closed-source models such as Gemini-2.5-Pro, Seed-ASR, and GPT-4o-Transcribe. Qwen3-Omni adopts a Thinker-Talker MoE architecture that unifies perception and generation across text, images, audio, and video, yielding fluent text and natural real-time speech. It supports text interaction in 119 languages, speech understanding in 19 languages, and speech generation in 10 languages. To reduce first-packet latency in streaming synthesis, Talker autoregressively predicts discrete speech codecs using a multi-codebook scheme. Leveraging the representational capacity of these codebooks, we replace computationally intensive block-wise diffusion with a lightweight causal ConvNet, enabling streaming from the first codec frame. In cold-start settings, Qwen3-Omni achieves a theoretical end-to-end first-packet latency of 234 ms. To further strengthen multimodal reasoning, we introduce a Thinking model that explicitly reasons over inputs from any modality. Since the research community currently lacks a general-purpose audio captioning model, we fine-tuned Qwen3-Omni-30B-A3B to obtain Qwen3-Omni-30B-A3B-Captioner, which produces detailed, low-hallucination captions for arbitrary audio inputs. Qwen3-Omni-30B-A3B, Qwen3-Omni-30B-A3B-Thinking, and Qwen3-Omni-30B-A3B-Captioner are publicly released under the Apache 2.0 license.\\n    \\n\\n\\n \\nComments:\\nthis https URL\\n\\n\\nSubjects:\\n\\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)\\n\\nCite as:\\narXiv:2509.17765 [cs.CL]\\n\\n\\n\\xa0\\n(or \\narXiv:2509.17765v1 [cs.CL] for this version)\\n          \\n\\n\\n\\xa0\\n https://doi.org/10.48550/arXiv.2509.17765\\n\\n\\nFocus to learn more\\n\\n\\n\\n                  arXiv-issued DOI via DataCite\\n\\n\\n\\n\\n\\n\\n\\nSubmission history From: Jin Xu [view email]       [v1]\\n        Mon, 22 Sep 2025 13:26:24 UTC (3,732 KB)\\n\\n\\n\\n \\n\\nFull-text links:\\nAccess Paper:\\n\\n\\nView a PDF of the paper titled Qwen3-Omni Technical Report, by Jin Xu and 37 other authorsView PDFHTML (experimental)TeX Source\\n \\n\\n\\nview license\\n\\n\\n \\n    Current browse context: cs.CL\\n\\n\\n<\\xa0prev\\n\\n\\xa0 | \\xa0 \\nnext\\xa0>\\n\\n\\nnew\\n | \\nrecent\\n | 2025-09\\n\\n    Change to browse by:\\n    \\ncs\\ncs.AI\\ncs.CV\\neess\\neess.AS\\n\\n\\n\\n\\nReferences & Citations\\n\\nNASA ADSGoogle Scholar\\nSemantic Scholar\\n\\n\\n\\n\\nexport BibTeX citation\\nLoading...\\n\\n\\n\\n\\nBibTeX formatted citation\\n×\\n\\n\\nloading...\\n\\n\\nData provided by: \\n\\n\\n\\n\\nBookmark\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nBibliographic Tools\\n\\nBibliographic and Citation Tools\\n\\n\\n\\n\\n\\n\\nBibliographic Explorer Toggle\\n\\n\\n\\nBibliographic Explorer (What is the Explorer?)\\n\\n\\n\\n\\n\\n\\n\\nConnected Papers Toggle\\n\\n\\n\\nConnected Papers (What is Connected Papers?)\\n\\n\\n\\n\\n\\n\\nLitmaps Toggle\\n\\n\\n\\nLitmaps (What is Litmaps?)\\n\\n\\n\\n\\n\\n\\n\\nscite.ai Toggle\\n\\n\\n\\nscite Smart Citations (What are Smart Citations?)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode, Data, Media\\n\\nCode, Data and Media Associated with this Article\\n\\n\\n\\n\\n\\n\\nalphaXiv Toggle\\n\\n\\n\\nalphaXiv (What is alphaXiv?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\\n\\n\\n\\n\\n\\n\\n\\nDagsHub Toggle\\n\\n\\n\\nDagsHub (What is DagsHub?)\\n\\n\\n\\n\\n\\n\\n\\nGotitPub Toggle\\n\\n\\n\\nGotit.pub (What is GotitPub?)\\n\\n\\n\\n\\n\\n\\n\\nHuggingface Toggle\\n\\n\\n\\nHugging Face (What is Huggingface?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nPapers with Code (What is Papers with Code?)\\n\\n\\n\\n\\n\\n\\n\\nScienceCast Toggle\\n\\n\\n\\nScienceCast (What is ScienceCast?)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDemos\\n\\nDemos\\n\\n\\n\\n\\n\\n\\nReplicate Toggle\\n\\n\\n\\nReplicate (What is Replicate?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nHugging Face Spaces (What is Spaces?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nTXYZ.AI (What is TXYZ.AI?)\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Papers\\n\\nRecommenders and Search Tools\\n\\n\\n\\n\\n\\n\\nLink to Influence Flower\\n\\n\\n\\nInfluence Flower (What are Influence Flowers?)\\n\\n\\n\\n\\n\\n\\n\\nCore recommender toggle\\n\\n\\n\\nCORE Recommender (What is CORE?)\\n\\n\\n\\n\\n\\nAuthor\\nVenue\\nInstitution\\nTopic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        About arXivLabs\\n      \\n\\n\\n\\narXivLabs: experimental projects with community collaborators\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhich authors of this paper are endorsers? |\\n    Disable MathJax (What is MathJax?)\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\nHelp\\n\\n\\n\\n\\n\\ncontact arXivClick here to contact arXiv\\n Contact\\n\\n\\nsubscribe to arXiv mailingsClick here to subscribe\\n Subscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright\\nPrivacy Policy\\n\\n\\n\\n\\nWeb Accessibility Assistance\\n\\n\\narXiv Operational Status \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\"),\n",
              "  Document(metadata={'source': 'https://digitalspaceport.com/qwen-3-omni-local-ai-setup-guide/', 'title': 'Qwen 3 Omni Local Ai Setup Guide – Digital Spaceport', 'language': 'en-US'}, page_content='\\n\\n\\n\\n\\n\\nQwen 3 Omni Local Ai Setup Guide – Digital Spaceport\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nHome\\nAi\\nHomelab\\nNetworking\\nStorage\\nAbout\\n \\n\\n \\n\\nHome\\nAi\\nHomelab\\nNetworking\\nStorage\\nAbout\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYoutube\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQwen 3 Omni Local Ai Setup Guide \\n\\n\\n\\n\\n\\nAi, LLM Ai Models, Video Ai Models \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhen you click on links to various merchants on this site and make a purchase, this can result in this site earning a commission. Affiliate programs and affiliations include, but are not limited to, the eBay Partner Network.\\xa0As an Amazon Associate I earn from qualifying purchases. #ad #promotions \\n\\n \\n\\nQwen3 is an exciting new Multimodal Audio, Video, Text and Image LLM that is able to be ran fully locally on a modest ai rig. Here are the cmds to get you up and running. This is a work in progress so it will be filled in with more details later but published as soon as I have the most basic cmds to get this working on a local server. This is running a Gradio interface to allow you to fully experience what it can offer. Qwen3 Omni does not yet fully support running in\\xa0 openwebui, so gradio it is. Also we will be using Transformers to run this and not vLLM as it doesn’t support audio generation.\\nAccompanying Video\\n\\nThis guide assumes you have followed along with the part 1 and 2 guide to get a minimally viable local ai base system backup that can be deployed fast. This is a guide in our series on setting up a local ai homelab with Proxmox 9. YOU HAVE TO HAVE FOLLOW THE GUIDES SEQUENTIALLY IF UP TO Step 2, Llama.cpp and Unsloth setup guide, to follow along. We create a backup you will see me using in ALMOST EVERY future guide at the end of that guide, and you need it also as it makes rapid deployment easy.\\nThose guides here:\\nStep 1\\xa0Ollama and OpenWEBUI setup guide\\nStep 2\\xa0Llama.cpp and Unsloth setup guide\\n\\xa0\\nRestore from your backup to create a new LXC. Set a NEW IP address before you start the LXC container. It will be copied from the backup and will overlap an existing IP address likely and that will cause issues.\\nEnter the shell of the container and run\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\napt update && apt upgrade -y && apt install ffmpeg git pipenv -y\\n\\n\\n\\nClone the Qwen3 Omni vllm repository\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\ngit clone -b qwen3_omni https://github.com/wangxiongts/vllm.git\\r\\ncd vllm\\n\\n\\n\\nCreate a env for Qwen3 Omni\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\npipenv shell\\n\\n\\n\\nInstall Requirements\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\npip install -r requirements/build.txt\\npip install -r requirements/cuda.txt\\n\\n\\n\\nBuild vLLM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\nexport VLLM_PRECOMPILED_WHEEL_LOCATION=https://wheels.vllm.ai/a5dd03c1ebc5e4f56f3c9d3dc0436e9c582c978f/vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl\\npip install git+https://github.com/huggingface/transformers\\npip install accelerate\\npip install qwen-omni-utils -U\\npip install -U flash-attn –no-build-isolation\\npip install gradio==5.44.1 gradio_client==1.12.1 soundfile==0.13.1\\n\\n\\n\\nvLLM is now installed but we will next clone a repo to enable us to use the Gradio Interface\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\ncd ..\\ngit clone https://github.com/QwenLM/Qwen3-Omni.git\\ncd Qwen3-Omni\\n\\n\\n\\nnow we will edit the Gradio config to allow us to access this interface from our local network as a service.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\nnano web_demo.py\\n\\n\\n\\nArrow down to the bottom of the file and look for the following line\\n\\nChange 127.0.0.1 to 0.0.0.0 and hit ctrl+w and y. This will bind the server to your LXC IP address, so make sure you have a unique IP address as mentioned above. You can leave the port of change the port if you want.\\nRun the gradio interface.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\npython web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct –use-transformers –generate-audio –flash-attn2\\n\\n\\n\\nBrowse to your default address and port number and make sure you are using just http and not https. Mine is http://192.168.1.71:8901 for example\\nNow we will be adjusting a browser setting to enable some functionality next. I am using brave so this likely differs in various browsers.\\nEnable webcamera and microphone in Brave\\nOpen up a new tab and go here\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopy Code\\nCopied\\nUse a different Browser\\n\\n\\n\\nbrave://flags/#unsafely-treat-insecure-origin-as-secure\\n\\n\\n\\n\\nEnable insecure origins treated as secure then add enter http://IP:PORT\\nYou will have to restart your browser now but when you click “allow microphone” button in the gradio interface it will now work. There will also be an annoying nag bar at the top of the browser when you start it up now, I don’t know how to disable that sorry but drop comments in the video PLEASE!\\nA quick sample of the quality given the following image and prompted with “please explain the diagram I uploaded”\\n\\nhttps://digitalspaceport.com/wp-content/uploads/2025/09/audio-sampler-qwen3.mp3\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\t\\t\\t\\tTable of Contents\\t\\t\\t\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHardware Review \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nLocal Ai Setup Guide \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tHow To Setup an AI Server Homelab Beginners Guides – Ollama + OWUI Proxmox 9 LXC\\t\\t\\t\\n\\n\\n\\t\\t\\tLearn More »\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tLlama.cpp on Proxmox 9 LXC – How To Setup an AI Server Homelab Beginners Guides\\t\\t\\t\\n\\n\\n\\t\\t\\tLearn More »\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tHow To Setup vLLM Local Ai – Homelab Ai Server Beginners Guides\\t\\t\\t\\n\\n\\n\\t\\t\\tLearn More »\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCHECK OUR OTHER SITES \\n\\n\\n\\n\\nYoutube\\n \\n\\n\\n\\nX-twitter\\n \\n\\n\\n\\nTiktok\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhen you click on links to various merchants on this site and make a purchase, this can result in this site earning a commission. Affiliate programs and affiliations include, but are not limited to, the eBay Partner Network. As an Amazon Associate I earn from qualifying purchases. Tradedoubler 3233998 \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://www.youtube.com/watch?v=CWSYLPJz8j0', 'title': 'Qwen 3 Omni — The Open AI Model That Does It ALL - YouTube', 'description': 'In this video, I test out Qwen 3 Omni — Alibaba’s latest open-source multimodal model that can handle text, images, audio, and video in real time. From live ...', 'language': 'en'}, page_content=\"Qwen 3 Omni — The Open AI Model That Does It ALL - YouTubeAboutPressCopyrightContact usCreatorsAdvertiseDevelopersTermsPrivacyPolicy & SafetyHow YouTube worksTest new features© 2025 Google LLC, Sundar Pichai, 1600 Amphitheatre Parkway, Mountain View CA 94043, USA, 0807-882-594 (free), yt-support-solutions-kr@google.com, Hosted by Google LLC, Business Information, Report illegally filmed contentProducts shown, tagged or featured on YouTube by creators are sold by merchants and are subject to merchant's terms and conditions. YouTube does not sell these products and is not responsible for them.\")]}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = graph.invoke({'question': 'Qwen 3 Omni 는 어떤 모델이야?'})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4C0YX4crDMi"
      },
      "source": [
        "전체 결과가 잘 실행되었지만, 중간 결과가 보고 싶다면 어떻게 해야 할까요?   \n",
        "이후에 배울 `LangSmith`를 통해 트래킹할 수도 있고, 아래의 코드로 각 단계를 스트리밍할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "39uRgYljrDMk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'get_query': {'query': 'Stanford STORM multi-agent architecture'}}\n",
            "{'tavily_search': {'context': [Document(metadata={'source': 'https://medium.com/@cognidownunder/stanford-storm-revolutionizing-ai-powered-knowledge-curation-35ce51996c19', 'title': 'Stanford STORM: Revolutionizing AI-Powered Knowledge Curation | by Cogni Down Under | Medium', 'description': 'Stanford STORM: Revolutionizing AI-Powered Knowledge Curation nowledge Curation Stanford STORM: Revolutionizing AI-Powered Knowledge Curation In the ever-evolving landscape of artificial …', 'language': 'en'}, page_content='Stanford STORM: Revolutionizing AI-Powered Knowledge Curation | by Cogni Down Under | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inStanford STORM: Revolutionizing AI-Powered Knowledge CurationCogni Down Under5 min read·Jul 23, 2024--3ListenSharenowledge CurationStanford STORM: Revolutionizing AI-Powered Knowledge CurationIn the ever-evolving landscape of artificial intelligence, a new player has emerged that promises to reshape how we approach knowledge curation and content generation. Enter Stanford STORM (Structured Task-Oriented Research Machine), an innovative large language model (LLM) system that’s making waves in the AI community. Developed by the brilliant minds at Stanford’s OVAL team, STORM is not just another chatbot — it’s a sophisticated research assistant capable of producing Wikipedia-style articles from scratch.The STORM Approach: A Perfect Knowledge TempestHarnessing the Power of Multiple AgentsAt its core, STORM employs a multi-agent system that simulates a team of experts collaborating on a research project. This isn’t your run-of-the-mill LLM; it’s a carefully orchestrated symphony of AI agents, each playing a crucial role in the content creation process.The Research Phase: Laying the GroundworkSTORM kicks things off by diving deep into the digital archives of Wikipedia and other reputable sources. It’s like sending out a fleet of highly efficient librarians, each tasked with gathering relevant information on the topic at hand. But STORM doesn’t just copy-paste — it analyzes, extracts, and synthesizes this information into a coherent structure.Outline Creation: The Blueprint for KnowledgeWith its digital arms full of raw data, STORM then puts on its architect hat. It crafts a detailed outline that serves as the skeleton for the final article. This isn’t just a bullet point list; it’s a carefully considered framework that ensures comprehensive coverage of the subject matter.The Art of AI ConversationHere’s where things get really interesting. STORM doesn’t just write — it talks to itself. Or rather, it simulates conversations between multiple AI agents, each representing different perspectives on the topic. It’s like eavesdropping on a roundtable discussion between experts, except all the experts are artificial intelligences.This conversational approach allows STORM to:Challenge its own assumptionsExplore different angles of the topicRefine and improve the outlineThe result? A more nuanced, well-rounded article that benefits from multiple “viewpoints.”From Outline to Article: STORM’s Writing ProcessWith its outline polished and its virtual experts consulted, STORM rolls up its digital sleeves and gets to work on the actual writing. But this isn’t a simple matter of generating text — STORM approaches each section methodically, ensuring that the final product is coherent, informative, and academically rigorous.Citation is KingOne of STORM’s standout features is its emphasis on proper citation. In an era where misinformation runs rampant, STORM takes a stand for accuracy. Each claim made in a STORM-generated article is backed by a citation, allowing readers to verify the information themselves.This commitment to citation isn’t just lip service. STORM boasts impressive citation recall and precision rates:Citation recall: 84.83%Citation precision: 85.18%These numbers speak volumes about STORM’s ability to produce well-supported, verifiable content.Beyond Retrieval: STORM vs. Traditional RAG SystemsWhile many LLMs rely on retrieval-augmented generation (RAG) to produce content, STORM takes things a step further. Its structured approach and multi-agent system allow for a level of organization and coverage that traditional RAG systems simply can’t match.The result? Articles that aren’t just informative, but also well-organized and comprehensive. It’s the difference between a hastily assembled collage and a carefully curated museum exhibit.Ensuring Accuracy: STORM’s Quality Control MeasuresIn the world of AI-generated content, accuracy is paramount. STORM doesn’t just aim for factual correctness — it’s built from the ground up with quality assurance in mind.Multiple Layers of VerificationResearch and Retrieval: STORM starts with a foundation of verified information from reputable sources.Multi-Agent Conversations: The simulated expert discussions help catch and correct potential errors.Iterative Drafting: The writing process includes multiple rounds of refinement.Citation and Attribution: Every claim is backed by a source, reducing the risk of hallucinations.Quality Assurance Mechanisms: STORM employs debiasing techniques and checks for narrative consistency.Human Review: While STORM is highly autonomous, human oversight remains a crucial final step.The Future of AI-Assisted ResearchAs we look to the horizon, STORM represents more than just a clever piece of software — it’s a glimpse into the future of how we interact with and generate knowledge. The implications for education, research, and content creation are profound.Imagine a world where:Students have access to dynamically generated, fully cited research papers on any topic.Researchers can quickly generate comprehensive literature reviews, freeing up time for original work.Content creators can produce in-depth, factually accurate articles at unprecedented speeds.STORM is more than just a tool — it’s a paradigm shift in how we approach knowledge curation and dissemination.Conclusion: The Dawn of a New Era in AI-Assisted KnowledgeStanford STORM represents a significant leap forward in the field of AI-powered content generation. By combining rigorous research methodologies with innovative LLM technologies, STORM offers a glimpse into a future where high-quality, citation-supported articles can be generated with unprecedented speed and accuracy.As the project continues to evolve and improve, we can expect to see STORM and similar systems play an increasingly important role in education, research, and content creation. The storm of knowledge is gathering, and it promises to reshape the landscape of information as we know it.FAQ SectionQ: How does STORM differ from other large language models? A: STORM uses a multi-agent system that simulates expert discussions, focuses on structured research and outline creation, and emphasizes proper citation and fact-checking.Q: Can STORM replace human researchers and writers? A: While STORM is a powerful tool, it’s designed to assist and augment human efforts, not replace them entirely. Human oversight and expertise remain crucial.Q: How accurate is the information generated by STORM? A: STORM achieves high citation recall (84.83%) and precision (85.18%) rates, indicating strong alignment between generated content and sources. However, human verification is still recommended.Q: Is STORM available for public use? A: As of July 2024, STORM is an open-source project. Check the Stanford OVAL team’s GitHub repository for the latest updates on availability and usage.Q: How does STORM handle potential biases in its generated content? A: STORM employs debiasing techniques and uses multi-perspective conversations to minimize biases. However, like all AI systems, it’s not entirely free from potential biases.#StanfordSTORM #AIResearch #MachineLearning #KnowledgeCuration #AIWriting #FutureOfEducation #OpenSourceAI #LLMInnovation #AIAssistant #TechRevolutionAI-powered Wikipedia article generationMulti-agent LLM systems for researchAutomated knowledge curation with citationsStanford OVAL team AI innovationsImproving AI content accuracy and factualityNext-generation retrieval-augmented generationAI-assisted academic research toolsOpen-source large language models for educationSimulated expert discussions in AI writingStructured approach to AI content creationStorm LlmStanfordStanford UniversityStanford ResearchLlm----3Written by Cogni Down Under452 followers·3 followingExploring the intersection of technology and artificial intelligenceResponses (3)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
            "                               Document(metadata={'source': 'https://blog.stackademic.com/storm-stanfords-revolutionary-research-tool-harnessing-the-power-of-agents-and-agentic-workflows-a2fa0e1a7fe3', 'title': 'STORM: Stanford’s Revolutionary Research Tool Harnessing the Power of Agents and Agentic Workflows | by Lakshmi narayana .U | Stackademic', 'description': 'STORM: Stanford’s Revolutionary Research Tool Harnessing the Power of Agents and Agentic Workflows In the rapidly evolving field of artificial intelligence, Stanford University has unveiled a …', 'language': 'en'}, page_content='STORM: Stanford’s Revolutionary Research Tool Harnessing the Power of Agents and Agentic Workflows | by Lakshmi narayana .U | StackademicSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inMastodonStackademic·Follow publicationStackademic is a learning hub for programmers, devs, coders, and engineers. Our goal is to democratize free coding education for the world.Follow publicationSTORM: Stanford’s Revolutionary Research Tool Harnessing the Power of Agents and Agentic WorkflowsLakshmi narayana .U9 min read·Jul 28, 2024--4ListenSharePress enter or click to view image in full sizeimage generated by author and DALL.E-3In the rapidly evolving field of artificial intelligence, Stanford University has unveiled a groundbreaking project that promises to revolutionize the way we conduct research, synthesize information, and create well-structured content. STORM, which stands for Synthesis of Topic Outlines through Retrieval and Multiperspective question asking, is being hailed as one of the most effective AI research and writing tools to date.What is STORM?STORM is an open-source AI system designed to create comprehensive, Wikipedia-style pages on any given topic. What sets STORM apart from other AI tools is its ability to not only compile information but also to reference the sources it uses, providing a level of transparency and credibility that is crucial in today’s information landscape.Press enter or click to view image in full sizeSource: ‘Assisting in Writing Wikipedia-like Articles From Scratch with LLMs’ paperSTORM is an agentic system that assists in generating topic outlines for writing Wikipedia-like articles. It aims to automate the pre-writing stage by leveraging large language models (LLMs) and simulating conversations between writers and topic experts. This approach enhances the pre-writing stage, resulting in well-structured and comprehensive articles that rival those found on Wikipedia.Key Features:Comprehensive Content Creation: STORM generates detailed, well-structured articles on a wide range of topics.Local Runtime Capability: Users can run STORM on their local machines, ensuring privacy and control over the research process.Source Referencing: Each piece of information is linked back to its original source, allowing for easy fact-checking and further exploration.Multi-Agent Research: STORM utilizes a team of AI agents to conduct thorough research on the given topic.Open-Source Availability: As an open-source project, STORM is accessible to developers and researchers worldwide, fostering collaboration and continuous improvement.Top-Down Writing Approach: STORM employs a top-down approach, nailing down the outline before writing content, which is crucial for effectively conveying information to readers.Diverse Perspective Discovery: STORM discovers and incorporates diverse perspectives in researching a given topic, leading to more comprehensive and informative articles.Multi-Perspective Question Asking: The system simulates conversations where writers with different perspectives pose questions to a topic expert, allowing for deeper exploration of the subject matter.Understanding Agentic SystemsTo fully appreciate STORM’s capabilities, it’s important to understand the concept of agentic systems, which forms the foundation of STORM’s functionality.Agentic Systems and WorkflowsAgentic systems are AI-powered frameworks designed to perform tasks with a degree of autonomy and intelligence reminiscent of human agents. These systems are characterized by their ability to:Perceive their environment: They can gather and process information from various sources.Make decisions: Based on the information gathered, they can decide on the best course of action.Take action: They can execute tasks or provide outputs based on their decisions.Learn and adapt: Many agentic systems have the capability to improve their performance over time.Exploring Agentic Workflows in AI: A Practical Approach with CrewAI, OpeRouter.ai and OpenHermesAgentic Workflows: A Step Forward Towards AGIblog.stackademic.comAgentic workflows refer to the series of steps or processes that these systems follow to complete tasks. In the case of STORM, the agentic workflow includes the retrieval of information, multi-perspective question asking, and synthesis of content.AI AgentsAI agents are the individual components or entities within an agentic system that perform specific tasks. In STORM, multiple AI agents work together to create a comprehensive research and writing tool. These agents may include:Research Agents: Responsible for gathering information from various sources on the internet.Question-Asking Agents: Simulate different perspectives to generate insightful questions about the topic.Expert Agents: Provide answers to the questions posed by the question-asking agents.Synthesis Agents: Compile and organize the gathered information into a coherent article structure.The use of multiple agents allows STORM to approach tasks from various angles, much like a team of human researchers and writers would collaborate on a complex project.STORM as an Agentic SystemSTORM leverages the power of agentic systems to automate and enhance the research and writing process. By employing multiple AI agents in a coordinated workflow, STORM can:Conduct thorough and multi-faceted research on a given topic.Generate diverse perspectives and questions that a human researcher might overlook.Synthesize information in a structured and coherent manner.Adapt its approach based on the specific requirements of each topic or task.This agentic approach enables STORM to produce comprehensive, well-structured content that rivals human-written articles in breadth and depth.How STORM WorksPress enter or click to view image in full sizeSource: ‘Assisting in Writing Wikipedia-like Articles From Scratch with LLMs’ paperThe STORM process can be broken down into three main steps: retrieval, multi-perspective question asking, and synthesis.Retrieval: When given a topic, STORM springs into action, deploying its team of AI agents to scour the internet for relevant information. This step involves gathering a wide range of data from various sources.Multi-Perspective Question Asking: STORM simulates conversations where writers carrying different perspectives pose questions to a topic expert. This allows for a deeper exploration of the topic and the formulation of in-depth questions through iterative research. By considering multiple viewpoints, STORM helps writers develop a well-rounded understanding of the subject matter.Synthesis: Finally, STORM synthesizes the gathered data into a coherent, well-organized article. It creates a logical outline and then fills in the content, ensuring that the information is presented in a structured and easy-to-follow manner.For instance, when asked about Karma Yoga, STORM produced a comprehensive wiki covering various aspects such as indian spiritual texts, historical context, etymology, practices and techniques, and others.Benefits of STORM’s ApproachSTORM’s approach to content creation offers several key benefits:Well-Structured Content: By using a top-down approach and creating outlines before writing, STORM ensures that the resulting articles are logically organized and easy to navigate.Comprehensive Coverage: The multi-perspective question asking feature allows for a thorough exploration of topics, resulting in articles with comparable breadth and depth to Wikipedia pages.Diverse Viewpoints: By actively seeking out and incorporating diverse perspectives, STORM helps create more balanced and informative content.Time-Saving: Automating the pre-writing stage can significantly reduce the time and effort required to research and structure complex topics.Consistency: STORM’s systematic approach ensures a consistent level of quality across different topics and articles.Accessing STORMCurrently the easiest way to access is at https://storm.genie.stanford.edu/Just select ‘New Session’ and enter the topic to get started.Press enter or click to view image in full sizeCheck out the brainstorming ProcessPress enter or click to view image in full sizeSource: https://storm.genie.stanford.edu/Generated articles, with TOC and Floating References are saved in ‘My Library’Press enter or click to view image in full sizeSource: https://storm.genie.stanford.edu/Setting Up STORMOption 1:For those interested in deploying STORM, the setup process involves several steps:Cloning the GitHub repositoryCreating a Conda environment with Python 3.11Activating the environmentInstalling required dependenciesConfiguring API keys in a secrets.toml fileSTORM requires two API keys to function:An OpenAI API keyA You.com search API key (a free trial is available at https://api.you.com/)Users can run STORM either through a command-line interface or via a user-friendly Streamlit-based UI.Detailed instructions are avaiable at the STORM github page.GitHub - stanford-oval/storm at NAACL-2024-code-backupAn LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations. …github.comOption 2: Using Google ColabThis provides an opportunity to examine some of the code and understand the workings of STORM.Using OpenAI1. Setting up the Environment:First, we need to install the required packages. The `knowledge-storm` package is essential for using STORM:!pip install knowledge-storm2. Importing Required Libraries:After installation, we import the necessary modules:import osfrom knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigsfrom knowledge_storm.lm import OpenAIModelfrom knowledge_storm.rm import YouRM3. Setting up API Keys and Configurations:os.environ[\"OPENAI_API_KEY\"]=\"your_api_key_here\"os.environ[\"YDC_API_KEY\"]=\"your_YDC_api_key_here\"lm_configs = STORMWikiLMConfigs()openai_kwargs = { \\'api_key\\': os.getenv(\"OPENAI_API_KEY\"), \\'temperature\\': 1.0, \\'top_p\\': 0.9,}4. Configuring Language Models:We set up different models for various STORM components:gpt_35 = OpenAIModel(model=\\'gpt-4o-mini\\', max_tokens=500, **openai_kwargs)gpt_4 = OpenAIModel(model=\\'gpt-4o-mini\\', max_tokens=3000, **openai_kwargs)lm_configs.set_conv_simulator_lm(gpt_35)lm_configs.set_question_asker_lm(gpt_35)lm_configs.set_outline_gen_lm(gpt_4)lm_configs.set_article_gen_lm(gpt_4)lm_configs.set_article_polish_lm(gpt_4)5. Setting up the STORM Runner:We initialize the STORM runner with our configurations:engine_args = STORMWikiRunnerArguments(output_dir=\\'output\\')rm = YouRM(ydc_api_key=os.getenv(\\'YDC_API_KEY\\'), k=engine_args.search_top_k)runner = STORMWikiRunner(engine_args, lm_configs, rm)6. Running STORM:Finally, we run STORM to generate an article on a given topic:topic = input(\\'Topic: \\')runner.run( topic=topic, do_research=True, do_generate_outline=True, do_generate_article=True, do_polish_article=True,)runner.post_run()runner.summary()Using Claude AI1. Installing Required Packages:!pip install anthropic!pip install knowledge-storm2. Importing Required Libraries:We import the required modules, including Claude-specific ones:import osfrom argparse import ArgumentParserfrom knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigsfrom knowledge_storm.lm import ClaudeModelfrom knowledge_storm.rm import YouRM, BingSearchfrom knowledge_storm.utils import load_api_key3. Setting up Environment Variables:os.environ[\"ANTHROPIC_API_KEY\"] = \"your_anthropic_key_here\"os.environ[\"YDC_API_KEY\"] = \"your_YDC_api_key_here\"4. Configuring STORM with Claude Models:We set up STORM to use various Claude models for different components:lm_configs = STORMWikiLMConfigs()claude_kwargs = { \\'api_key\\': os.getenv(\"ANTHROPIC_API_KEY\"), \\'temperature\\': 1.0, \\'top_p\\': 0.9}conv_simulator_lm = ClaudeModel(model=\\'claude-3-haiku-20240307\\', max_tokens=500, **claude_kwargs)question_asker_lm = ClaudeModel(model=\\'claude-3-sonnet-20240229\\', max_tokens=500, **claude_kwargs)outline_gen_lm = ClaudeModel(model=\\'claude-3-opus-20240229\\', max_tokens=400, **claude_kwargs)article_gen_lm = ClaudeModel(model=\\'claude-3–5-sonnet-20240620\\', max_tokens=700, **claude_kwargs)article_polish_lm = ClaudeModel(model=\\'claude-3–5-sonnet-20240620\\', max_tokens=4000, **claude_kwargs)lm_configs.set_conv_simulator_lm(conv_simulator_lm)lm_configs.set_question_asker_lm(question_asker_lm)lm_configs.set_outline_gen_lm(outline_gen_lm)lm_configs.set_article_gen_lm(article_gen_lm)lm_configs.set_article_polish_lm(article_polish_lm)5. Setting up STORM Runner Arguments:We configure the STORM runner arguments:engine_args = STORMWikiRunnerArguments( output_dir=args.output_dir, max_conv_turn=args.max_conv_turn, max_perspective=args.max_perspective, search_top_k=args.search_top_k, max_thread_num=args.max_thread_num,)6. Choosing the Retrieval Model:We set up the retrieval model, either Bing Search or You.com:if args.retriever == \\'bing\\': rm = BingSearch(bing_search_api=os.getenv(\\'BING_SEARCH_API_KEY\\'), k=engine_args.search_top_k)elif args.retriever == \\'you\\': rm = YouRM(ydc_api_key=os.getenv(\\'YDC_API_KEY\\'), k=engine_args.search_top_k)7. Initializing and Running STORM:Finally, we initialize the STORM runner and execute it:runner = STORMWikiRunner(engine_args, lm_configs, rm)topic = input(\\'Topic: \\')runner.run( topic=topic, do_research=args.do_research, do_generate_outline=args.do_generate_outline, do_generate_article=args.do_generate_article, do_polish_article=args.do_polish_article,)runner.post_run()runner.summary()The above demonstrate different ways to set up and run STORM, one using OpenAI’s GPT models and another using Anthropic’s Claude models. Both approaches follow the same general structure but differ in the specific models and configurations used.Output from each is a set of 9 files as under.conversation_log.json direct_gen_outline.txt llm_call_history.jsonl raw_search_results.json run_config.json storm_gen_article.txt storm_gen_article_polished.txt storm_gen_outline.txt url_to_info.jsonNote: ‘storm_gen_article_polished.txt’ can be taken as the final file with markdown text that displays all the content, but the references do not work.In addition to the above, STORM can access personal datasets using Qdrant but I was unable to get it working.Here are the two files from above in my github repository that utilize the build on examples in STORM Github and a sample set of output files.Medium_Articles/STORM_Stanford_Revolutionary_Research_Tool_Harnessing_the_Power_of_Agents_and_Agenti…All code related to medium articles. Contribute to Laksh-star/Medium_Articles development by creating an account on…github.comFlexibility and Future DevelopmentOne of STORM’s strengths is its flexibility. While it can utilize OpenAI’s powerful language models, it’s not dependent on them. Local setup options are available using VLM with Mistral, and Ollama integration for local models is round the corner.The project has gained significant traction in the developer community, amassing nearly 62,000 stars on GitHub shortly after its release. This popularity is likely to drive further improvements and expansions of STORM’s capabilities.As STORM continues to evolve, its developers are working on exciting new features. One such feature in the pipeline is a “human-AI collaboration mode,” which promises to further enhance the tool’s utility and user interaction. This could potentially allow for even more nuanced and tailored content creation, combining the strengths of AI with human insight and creativity.ConclusionSTORM represents an important step forward in AI-assisted agentic research, content creation, and writing. By combining the power of multiple AI agents, comprehensive web scraping, coherent content synthesis, and innovative features like multi-perspective question asking, all while maintaining source transparency, STORM has the potential to become an dependable tool for researchers, writers, and knowledge seekers across various fields.The system’s ability to automate the pre-writing stage, discover diverse perspectives, and create well-structured outlines addresses many of the challenges faced in producing high-quality, comprehensive content. As the project continues to develop and improve, it may well redefine how we approach information gathering, synthesis, and content creation in the digital age, setting new standards for AI-assisted writing and research tools.References[2402.14207] Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models (arxiv.org)GitHub — stanford-oval/storm: An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.Stackademic 🎓Thank you for reading until the end. Before you go:Please consider clapping and following the writer! 👏Follow us X | LinkedIn | YouTube | DiscordVisit our other platforms: In Plain English | CoFeed | DifferMore content at Stackademic.comAgentsArtificial IntelligencePythonLlmStanford----4FollowPublished in Stackademic62K followers·Last published\\xa09 hours agoStackademic is a learning hub for programmers, devs, coders, and engineers. Our goal is to democratize free coding education for the world.FollowWritten by Lakshmi narayana .U520 followers·16 followingAuthor- \\'Directing Business\\' | AI ConsultantResponses (4)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
            "                               Document(metadata={'source': 'https://github.com/stanford-oval/storm', 'title': 'GitHub - stanford-oval/storm: An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.', 'description': 'An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations. - stanford-oval/storm', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub - stanford-oval/storm: An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n \\n\\n\\nAppearance settings\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Platform\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          GitHub Copilot\\n\\n        \\n\\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          GitHub Spark\\n\\n            \\n              New\\n            \\n\\n\\n        Build and deploy intelligent apps\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          GitHub Models\\n\\n            \\n              New\\n            \\n\\n\\n        Manage and compare prompts\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          GitHub Advanced Security\\n\\n        \\n\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          Actions\\n\\n        \\n\\n        Automate any workflow\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Codespaces\\n\\n        \\n\\n        Instant dev environments\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          Issues\\n\\n        \\n\\n        Plan and track work\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          Code Review\\n\\n        \\n\\n        Manage code changes\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          Discussions\\n\\n        \\n\\n        Collaborate outside of code\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          Code Search\\n\\n        \\n\\n        Find more, search less\\n      \\n\\n\\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Why GitHub\\n\\n    \\n\\n\\n\\n      Documentation\\n\\n    \\n\\n\\n\\n\\n\\n      GitHub Skills\\n\\n    \\n\\n\\n\\n\\n\\n      Blog\\n\\n    \\n\\n\\n\\n\\n\\n\\nIntegrations\\n\\n\\n\\n      GitHub Marketplace\\n\\n    \\n\\n\\n\\n      MCP Registry\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n              View all features\\n              \\n\\n\\n \\n\\n\\n\\n\\n        Solutions\\n        \\n\\n\\n\\n\\n\\n\\n\\nBy company size\\n\\n\\n\\n      Enterprises\\n\\n    \\n\\n\\n\\n      Small and medium teams\\n\\n    \\n\\n\\n\\n      Startups\\n\\n    \\n\\n\\n\\n      Nonprofits\\n\\n    \\n\\n\\n\\n\\n\\n\\nBy use case\\n\\n\\n\\n      App Modernization\\n\\n    \\n\\n\\n\\n      DevSecOps\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      CI/CD\\n\\n    \\n\\n\\n\\n      View all use cases\\n\\n    \\n\\n\\n\\n\\n\\n\\nBy industry\\n\\n\\n\\n      Healthcare\\n\\n    \\n\\n\\n\\n      Financial services\\n\\n    \\n\\n\\n\\n      Manufacturing\\n\\n    \\n\\n\\n\\n      Government\\n\\n    \\n\\n\\n\\n      View all industries\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n              View all solutions\\n              \\n\\n\\n \\n\\n\\n\\n\\n        Resources\\n        \\n\\n\\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n      AI\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      Security\\n\\n    \\n\\n\\n\\n      Software Development\\n\\n    \\n\\n\\n\\n      View all\\n\\n    \\n\\n\\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Learning Pathways\\n\\n    \\n\\n\\n\\n\\n\\n      Events & Webinars\\n\\n    \\n\\n\\n\\n      Ebooks & Whitepapers\\n\\n    \\n\\n\\n\\n      Customer Stories\\n\\n    \\n\\n\\n\\n      Partners\\n\\n    \\n\\n\\n\\n      Executive Insights\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Open Source\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          GitHub Sponsors\\n\\n        \\n\\n        Fund open source developers\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          The ReadME Project\\n\\n        \\n\\n        GitHub community articles\\n      \\n\\n\\n\\n\\nRepositories\\n\\n\\n\\n      Topics\\n\\n    \\n\\n\\n\\n      Trending\\n\\n    \\n\\n\\n\\n      Collections\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Enterprise\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Enterprise platform\\n\\n        \\n\\n        AI-powered developer platform\\n      \\n\\n\\n\\n\\nAvailable add-ons\\n\\n\\n\\n\\n\\n\\n\\n\\n          GitHub Advanced Security\\n\\n        \\n\\n        Enterprise-grade security features\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          Copilot for business\\n\\n        \\n\\n        Enterprise-grade AI features\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n          Premium Support\\n\\n        \\n\\n        Enterprise-grade 24/7 support\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\nPricing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch or jump to...\\n\\n\\n\\n\\n\\n\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\n \\n\\n\\n\\n\\n        Search\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClear\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nSearch syntax tips \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Provide feedback\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nWe read every piece of feedback, and take your input very seriously.\\n\\n\\nInclude my email address so I can be contacted\\n\\n\\n     Cancel\\n\\n    Submit feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Saved searches\\n      \\nUse saved searches to filter your results more quickly\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\nQuery\\n\\n\\n\\n            To see all available qualifiers, see our documentation.\\n          \\n \\n\\n\\n\\n\\n\\n     Cancel\\n\\n    Create saved search\\n\\n\\n\\n\\n\\n\\n\\n\\n                Sign in\\n              \\n\\n\\n                Sign up\\n              \\n\\n\\n \\n\\n\\nAppearance settings\\n\\n\\n\\nResetting focus\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\n \\n\\n\\nDismiss alert\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        stanford-oval\\n \\n/\\n\\nstorm\\n\\nPublic\\n\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n \\n\\nFork\\n    2.5k\\n\\n\\n\\n\\n \\n\\n\\n          Star\\n 27.5k\\n\\n\\n\\n\\n\\n\\n\\n\\n        An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.\\n      \\n\\n\\n\\n\\n\\nstorm.genie.stanford.edu\\n\\n\\nLicense\\n\\n\\n\\n\\n\\n     MIT license\\n    \\n\\n\\n\\n\\n\\n\\n27.5k\\n          stars\\n \\n\\n\\n\\n2.5k\\n          forks\\n \\n\\n\\n\\nBranches\\n \\n\\n\\n\\nTags\\n \\n\\n\\n\\nActivity\\n \\n\\n\\n\\n \\n\\n\\n          Star\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\n\\n\\n\\nIssues\\n57\\n\\n\\n\\n\\n\\n\\nPull requests\\n30\\n\\n\\n\\n\\n\\n\\nActions\\n\\n\\n\\n\\n\\n\\n\\nProjects\\n0\\n\\n\\n\\n\\n\\n\\nSecurity\\n\\n\\n\\n\\n\\n        Uh oh!\\n\\n There was an error while loading. Please reload this page.\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\nInsights\\n\\n\\n\\n \\n\\n \\n\\n\\nAdditional navigation options\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Code\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Issues\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Pull requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Actions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Projects\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Security\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Insights\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nstanford-oval/storm\\n\\n\\n\\n \\n\\n\\n\\n   \\xa0mainBranchesTagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History238 Commits.github.github\\xa0\\xa0assetsassets\\xa0\\xa0examplesexamples\\xa0\\xa0frontend/demo_lightfrontend/demo_light\\xa0\\xa0knowledge_stormknowledge_storm\\xa0\\xa0.gitignore.gitignore\\xa0\\xa0.pre-commit-config.yaml.pre-commit-config.yaml\\xa0\\xa0CONTRIBUTING.mdCONTRIBUTING.md\\xa0\\xa0LICENSELICENSE\\xa0\\xa0MANIFEST.inMANIFEST.in\\xa0\\xa0README.mdREADME.md\\xa0\\xa0requirements.txtrequirements.txt\\xa0\\xa0setup.pysetup.py\\xa0\\xa0View all filesRepository files navigationREADMEContributingMIT license\\n\\n\\nSTORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\\n\\n| Research preview | STORM Paper| Co-STORM Paper  | Website |\\n\\n**Latest News** 🔥\\n\\n\\n[2025/01] We add litellm integration for language models and embedding models in knowledge-storm v1.1.0.\\n\\n\\n[2024/09] Co-STORM codebase is now released and integrated into knowledge-storm python package v1.0.0. Run pip install knowledge-storm --upgrade to check it out.\\n\\n\\n[2024/09] We introduce collaborative STORM (Co-STORM) to support human-AI collaborative knowledge curation! Co-STORM Paper has been accepted to EMNLP 2024 main conference.\\n\\n\\n[2024/07] You can now install our package with pip install knowledge-storm!\\n\\n\\n[2024/07] We add VectorRM to support grounding on user-provided documents, complementing existing support of search engines (YouRM, BingSearch). (check out #58)\\n\\n\\n[2024/07] We release demo light for developers a minimal user interface built with streamlit framework in Python, handy for local development and demo hosting (checkout #54)\\n\\n\\n[2024/06] We will present STORM at NAACL 2024! Find us at Poster Session 2 on June 17 or check our presentation material.\\n\\n\\n[2024/05] We add Bing Search support in rm.py. Test STORM with GPT-4o - we now configure the article generation part in our demo using GPT-4o model.\\n\\n\\n[2024/04] We release refactored version of STORM codebase! We define interface for STORM pipeline and reimplement STORM-wiki (check out src/storm_wiki) to demonstrate how to instantiate the pipeline. We provide API to support customization of different language models and retrieval/search integration.\\n\\n\\n\\nOverview (Try STORM now!)\\n\\n\\n\\nSTORM is a LLM system that writes Wikipedia-like articles from scratch based on Internet search. Co-STORM further enhanced its feature by enabling human to collaborative LLM system to support more aligned and preferred information seeking and knowledge curation.\\nWhile the system cannot produce publication-ready articles that often require a significant number of edits, experienced Wikipedia editors have found it helpful in their pre-writing stage.\\nMore than 70,000 people have tried our live research preview. Try it out to see how STORM can help your knowledge exploration journey and please provide feedback to help us improve the system 🙏!\\nHow STORM & Co-STORM works\\nSTORM\\nSTORM breaks down generating long articles with citations into two steps:\\n\\nPre-writing stage: The system conducts Internet-based research to collect references and generates an outline.\\nWriting stage: The system uses the outline and references to generate the full-length article with citations.\\n\\n\\n\\n\\nSTORM identifies the core of automating the research process as automatically coming up with good questions to ask. Directly prompting the language model to ask questions does not work well. To improve the depth and breadth of the questions, STORM adopts two strategies:\\n\\nPerspective-Guided Question Asking: Given the input topic, STORM discovers different perspectives by surveying existing articles from similar topics and uses them to control the question-asking process.\\nSimulated Conversation: STORM simulates a conversation between a Wikipedia writer and a topic expert grounded in Internet sources to enable the language model to update its understanding of the topic and ask follow-up questions.\\n\\nCO-STORM\\nCo-STORM proposes a collaborative discourse protocol which implements a turn management policy to support smooth collaboration among\\n\\nCo-STORM LLM experts: This type of agent generates answers grounded on external knowledge sources and/or raises follow-up questions based on the discourse history.\\nModerator: This agent generates thought-provoking questions inspired by information discovered by the retriever but not directly used in previous turns. Question generation can also be grounded!\\nHuman user: The human user will take the initiative to either (1) observe the discourse to gain deeper understanding of the topic, or (2) actively engage in the conversation by injecting utterances to steer the discussion focus.\\n\\n\\n\\n\\nCo-STORM also maintains a dynamic updated mind map, which organize collected information into a hierarchical concept structure, aiming to build a shared conceptual space between the human user and the system. The mind map has been proven to help reduce the mental load when the discourse goes long and in-depth.\\nBoth STORM and Co-STORM are implemented in a highly modular way using dspy.\\nInstallation\\nTo install the knowledge storm library, use pip install knowledge-storm.\\nYou could also install the source code which allows you to modify the behavior of STORM engine directly.\\n\\n\\nClone the git repository.\\ngit clone https://github.com/stanford-oval/storm.git\\ncd storm\\n\\n\\nInstall the required packages.\\nconda create -n storm python=3.11\\nconda activate storm\\npip install -r requirements.txt\\n\\n\\nAPI\\nCurrently, our package support:\\n\\nLanguage model components: All language models supported by litellm as listed here\\nEmbedding model components: All embedding models supported by litellm as listed here\\nretrieval module components: YouRM, BingSearch, VectorRM, SerperRM, BraveRM, SearXNG, DuckDuckGoSearchRM, TavilySearchRM, GoogleSearch, and AzureAISearch as\\n\\n🌟 PRs for integrating more search engines/retrievers into knowledge_storm/rm.py are highly appreciated!\\nBoth STORM and Co-STORM are working in the information curation layer, you need to set up the information retrieval module and language model module to create their Runner classes respectively.\\nSTORM\\nThe STORM knowledge curation engine is defined as a simple Python STORMWikiRunner class. Here is an example of using You.com search engine and OpenAI models.\\nimport os\\nfrom knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs\\nfrom knowledge_storm.lm import LitellmModel\\nfrom knowledge_storm.rm import YouRM\\n\\nlm_configs = STORMWikiLMConfigs()\\nopenai_kwargs = {\\n    \\'api_key\\': os.getenv(\"OPENAI_API_KEY\"),\\n    \\'temperature\\': 1.0,\\n    \\'top_p\\': 0.9,\\n}\\n# STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.\\n# For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.\\n# Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.\\ngpt_35 = LitellmModel(model=\\'gpt-3.5-turbo\\', max_tokens=500, **openai_kwargs)\\ngpt_4 = LitellmModel(model=\\'gpt-4o\\', max_tokens=3000, **openai_kwargs)\\nlm_configs.set_conv_simulator_lm(gpt_35)\\nlm_configs.set_question_asker_lm(gpt_35)\\nlm_configs.set_outline_gen_lm(gpt_4)\\nlm_configs.set_article_gen_lm(gpt_4)\\nlm_configs.set_article_polish_lm(gpt_4)\\n# Check out the STORMWikiRunnerArguments class for more configurations.\\nengine_args = STORMWikiRunnerArguments(...)\\nrm = YouRM(ydc_api_key=os.getenv(\\'YDC_API_KEY\\'), k=engine_args.search_top_k)\\nrunner = STORMWikiRunner(engine_args, lm_configs, rm)\\nThe STORMWikiRunner instance can be evoked with the simple run method:\\ntopic = input(\\'Topic: \\')\\nrunner.run(\\n    topic=topic,\\n    do_research=True,\\n    do_generate_outline=True,\\n    do_generate_article=True,\\n    do_polish_article=True,\\n)\\nrunner.post_run()\\nrunner.summary()\\n\\ndo_research: if True, simulate conversations with difference perspectives to collect information about the topic; otherwise, load the results.\\ndo_generate_outline: if True, generate an outline for the topic; otherwise, load the results.\\ndo_generate_article: if True, generate an article for the topic based on the outline and the collected information; otherwise, load the results.\\ndo_polish_article: if True, polish the article by adding a summarization section and (optionally) removing duplicate content; otherwise, load the results.\\n\\nCo-STORM\\nThe Co-STORM knowledge curation engine is defined as a simple Python CoStormRunner class. Here is an example of using Bing search engine and OpenAI models.\\nfrom knowledge_storm.collaborative_storm.engine import CollaborativeStormLMConfigs, RunnerArgument, CoStormRunner\\nfrom knowledge_storm.lm import LitellmModel\\nfrom knowledge_storm.logging_wrapper import LoggingWrapper\\nfrom knowledge_storm.rm import BingSearch\\n\\n# Co-STORM adopts the same multi LM system paradigm as STORM \\nlm_config: CollaborativeStormLMConfigs = CollaborativeStormLMConfigs()\\nopenai_kwargs = {\\n    \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\\n    \"api_provider\": \"openai\",\\n    \"temperature\": 1.0,\\n    \"top_p\": 0.9,\\n    \"api_base\": None,\\n} \\nquestion_answering_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)\\ndiscourse_manage_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)\\nutterance_polishing_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=2000, **openai_kwargs)\\nwarmstart_outline_gen_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)\\nquestion_asking_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=300, **openai_kwargs)\\nknowledge_base_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)\\n\\nlm_config.set_question_answering_lm(question_answering_lm)\\nlm_config.set_discourse_manage_lm(discourse_manage_lm)\\nlm_config.set_utterance_polishing_lm(utterance_polishing_lm)\\nlm_config.set_warmstart_outline_gen_lm(warmstart_outline_gen_lm)\\nlm_config.set_question_asking_lm(question_asking_lm)\\nlm_config.set_knowledge_base_lm(knowledge_base_lm)\\n\\n# Check out the Co-STORM\\'s RunnerArguments class for more configurations.\\ntopic = input(\\'Topic: \\')\\nrunner_argument = RunnerArgument(topic=topic, ...)\\nlogging_wrapper = LoggingWrapper(lm_config)\\nbing_rm = BingSearch(bing_search_api_key=os.environ.get(\"BING_SEARCH_API_KEY\"),\\n                     k=runner_argument.retrieve_top_k)\\ncostorm_runner = CoStormRunner(lm_config=lm_config,\\n                               runner_argument=runner_argument,\\n                               logging_wrapper=logging_wrapper,\\n                               rm=bing_rm)\\nThe CoStormRunner instance can be evoked with the warmstart() and step(...) methods.\\n# Warm start the system to build shared conceptual space between Co-STORM and users\\ncostorm_runner.warm_start()\\n\\n# Step through the collaborative discourse \\n# Run either of the code snippets below in any order, as many times as you\\'d like\\n# To observe the conversation:\\nconv_turn = costorm_runner.step()\\n# To inject your utterance to actively steer the conversation:\\ncostorm_runner.step(user_utterance=\"YOUR UTTERANCE HERE\")\\n\\n# Generate report based on the collaborative discourse\\ncostorm_runner.knowledge_base.reorganize()\\narticle = costorm_runner.generate_report()\\nprint(article)\\nQuick Start with Example Scripts\\nWe provide scripts in our examples folder as a quick start to run STORM and Co-STORM with different configurations.\\nWe suggest using secrets.toml to set up the API keys. Create a file secrets.toml under the root directory and add the following content:\\n# ============ language model configurations ============ \\n# Set up OpenAI API key.\\nOPENAI_API_KEY=\"your_openai_api_key\"\\n# If you are using the API service provided by OpenAI, include the following line:\\nOPENAI_API_TYPE=\"openai\"\\n# If you are using the API service provided by Microsoft Azure, include the following lines:\\nOPENAI_API_TYPE=\"azure\"\\nAZURE_API_BASE=\"your_azure_api_base_url\"\\nAZURE_API_VERSION=\"your_azure_api_version\"\\n# ============ retriever configurations ============ \\nBING_SEARCH_API_KEY=\"your_bing_search_api_key\" # if using bing search\\n# ============ encoder configurations ============ \\nENCODER_API_TYPE=\"openai\" # if using openai encoder\\nSTORM examples\\nTo run STORM with gpt family models with default configurations:\\nRun the following command.\\npython examples/storm_examples/run_storm_wiki_gpt.py \\\\\\n    --output-dir $OUTPUT_DIR \\\\\\n    --retriever bing \\\\\\n    --do-research \\\\\\n    --do-generate-outline \\\\\\n    --do-generate-article \\\\\\n    --do-polish-article\\nTo run STORM using your favorite language models or grounding on your own corpus: Check out examples/storm_examples/README.md.\\nCo-STORM examples\\nTo run Co-STORM with gpt family models with default configurations,\\n\\nAdd BING_SEARCH_API_KEY=\"xxx\" and ENCODER_API_TYPE=\"xxx\" to secrets.toml\\nRun the following command\\n\\npython examples/costorm_examples/run_costorm_gpt.py \\\\\\n    --output-dir $OUTPUT_DIR \\\\\\n    --retriever bing\\nCustomization of the Pipeline\\nSTORM\\nIf you have installed the source code, you can customize STORM based on your own use case. STORM engine consists of 4 modules:\\n\\nKnowledge Curation Module: Collects a broad coverage of information about the given topic.\\nOutline Generation Module: Organizes the collected information by generating a hierarchical outline for the curated knowledge.\\nArticle Generation Module: Populates the generated outline with the collected information.\\nArticle Polishing Module: Refines and enhances the written article for better presentation.\\n\\nThe interface for each module is defined in knowledge_storm/interface.py, while their implementations are instantiated in knowledge_storm/storm_wiki/modules/*. These modules can be customized according to your specific requirements (e.g., generating sections in bullet point format instead of full paragraphs).\\nCo-STORM\\nIf you have installed the source code, you can customize Co-STORM based on your own use case\\n\\nCo-STORM introduces multiple LLM agent types (i.e. Co-STORM experts and Moderator). LLM agent interface is defined in knowledge_storm/interface.py , while its implementation is instantiated in knowledge_storm/collaborative_storm/modules/co_storm_agents.py. Different LLM agent policies can be customized.\\nCo-STORM introduces a collaborative discourse protocol, with its core function centered on turn policy management. We provide an example implementation of turn policy management through DiscourseManager in knowledge_storm/collaborative_storm/engine.py. It can be customized and further improved.\\n\\nDatasets\\nTo facilitate the study of automatic knowledge curation and complex information seeking, our project releases the following datasets:\\nFreshWiki\\nThe FreshWiki Dataset is a collection of 100 high-quality Wikipedia articles focusing on the most-edited pages from February 2022 to September 2023. See Section 2.1 in STORM paper for more details.\\nYou can download the dataset from huggingface directly. To ease the data contamination issue, we archive the source code for the data construction pipeline that can be repeated at future dates.\\nWildSeek\\nTo study users’ interests in complex information seeking tasks in the wild, we utilized data collected from the web research preview to create the WildSeek dataset. We downsampled the data to ensure the diversity of the topics and the quality of the data. Each data point is a pair comprising a topic and the user’s goal for conducting deep search on the topic.  For more details, please refer to Section 2.2 and Appendix A of Co-STORM paper.\\nThe WildSeek dataset is available here.\\nReplicate STORM & Co-STORM paper result\\nFor STORM paper experiments, please switch to the branch NAACL-2024-code-backup here.\\nFor Co-STORM paper experiments, please switch to the branch EMNLP-2024-code-backup (placeholder for now, will be updated soon).\\nRoadmap & Contributions\\nOur team is actively working on:\\n\\nHuman-in-the-Loop Functionalities: Supporting user participation in the knowledge curation process.\\nInformation Abstraction: Developing abstractions for curated information to support presentation formats beyond the Wikipedia-style report.\\n\\nIf you have any questions or suggestions, please feel free to open an issue or pull request. We welcome contributions to improve the system and the codebase!\\nContact person: Yijia Shao and Yucheng Jiang\\nAcknowledgement\\nWe would like to thank Wikipedia for its excellent open-source content. The FreshWiki dataset is sourced from Wikipedia, licensed under the Creative Commons Attribution-ShareAlike (CC BY-SA) license.\\nWe are very grateful to Michelle Lam for designing the logo for this project and Dekun Ma for leading the UI development.\\nThanks to Vercel for their support of open-source software\\nCitation\\nPlease cite our paper if you use this code or part of it in your work:\\n@inproceedings{jiang-etal-2024-unknown,\\n    title = \"Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations\",\\n    author = \"Jiang, Yucheng  and\\n      Shao, Yijia  and\\n      Ma, Dekun  and\\n      Semnani, Sina  and\\n      Lam, Monica\",\\n    editor = \"Al-Onaizan, Yaser  and\\n      Bansal, Mohit  and\\n      Chen, Yun-Nung\",\\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2024\",\\n    address = \"Miami, Florida, USA\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2024.emnlp-main.554/\",\\n    doi = \"10.18653/v1/2024.emnlp-main.554\",\\n    pages = \"9917--9955\",\\n}\\n\\n@inproceedings{shao-etal-2024-assisting,\\n    title = \"Assisting in Writing {W}ikipedia-like Articles From Scratch with Large Language Models\",\\n    author = \"Shao, Yijia  and\\n      Jiang, Yucheng  and\\n      Kanell, Theodore  and\\n      Xu, Peter  and\\n      Khattab, Omar  and\\n      Lam, Monica\",\\n    editor = \"Duh, Kevin  and\\n      Gomez, Helena  and\\n      Bethard, Steven\",\\n    booktitle = \"Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\\n    month = jun,\\n    year = \"2024\",\\n    address = \"Mexico City, Mexico\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2024.naacl-long.347/\",\\n    doi = \"10.18653/v1/2024.naacl-long.347\",\\n    pages = \"6252--6278\",\\n}\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\n        An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.\\n      \\n\\n\\n\\n\\n\\nstorm.genie.stanford.edu\\n\\n\\nTopics\\n\\n\\n\\n  nlp\\n\\n\\n  naacl\\n\\n\\n  report-generation\\n\\n\\n  knowledge-curation\\n\\n\\n  large-language-models\\n\\n\\n  retrieval-augmented-generation\\n\\n\\n  agentic-rag\\n\\n\\n  emnlp2024\\n\\n\\n  deep-research\\n\\n\\n\\nResources\\n\\n\\n\\n\\n\\n        Readme\\n \\nLicense\\n\\n\\n\\n\\n\\n     MIT license\\n    \\n\\nContributing\\n\\n\\n\\n\\n\\n        Contributing\\n      \\n\\n\\n\\n\\n\\n\\n        Uh oh!\\n\\n There was an error while loading. Please reload this page.\\n\\n \\n \\n\\n\\n\\n\\n\\nActivity \\n\\n\\n\\n\\nCustom properties \\nStars\\n\\n\\n\\n\\n27.5k\\n      stars \\nWatchers\\n\\n\\n\\n\\n188\\n      watching \\nForks\\n\\n\\n\\n\\n2.5k\\n      forks \\n\\n\\n          Report repository\\n \\n\\n\\n\\n\\n\\n\\nReleases\\n      6\\n\\n\\n\\n\\n\\n\\nv1.1.0 Compatible with LiteLLM API\\n\\n          Latest\\n \\nJan 23, 2025\\n\\n \\n+ 5 releases\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Uh oh!\\n\\n There was an error while loading. Please reload this page.\\n\\n \\n \\n\\n\\n\\n\\n\\n\\nContributors\\n      23\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n+ 9 contributors\\n\\n\\n\\n\\nLanguages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPython\\n100.0%\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n\\n\\n\\n\\n\\n\\n\\n\\n        © 2025 GitHub,\\xa0Inc.\\n      \\n\\n\\nFooter navigation\\n\\n\\nTerms\\n\\n\\nPrivacy\\n\\n\\nSecurity\\n\\n\\nStatus\\n\\n\\nCommunity\\n\\n\\nDocs\\n\\n\\nContact\\n\\n\\n\\n\\n       Manage cookies\\n    \\n\\n\\n\\n\\n\\n      Do not share my personal information\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    You can’t perform that action at this time.\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
            "                               Document(metadata={'source': 'https://storm.genie.stanford.edu/', 'language': 'No language found.'}, page_content='I agree to the terms of service.Please check the box aboveClose'),\n",
            "                               Document(metadata={'source': 'https://blog.acer.com/en/discussion/2218/storm-by-stanford-university-the-ai-model-for-academic-and-research-purposes', 'title': 'STORM by Stanford University: The AI Model for Academic and Research Purposes — Acer Corner', 'description': 'Artificial intelligence is a swiftly evolving beast.', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\nSTORM by Stanford University: The AI Model for Academic and Research Purposes — Acer Corner\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome› English› AI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nX Post\\n\\neMail\\n\\n\\n\\n\\nSTORM by Stanford University: The AI Model for Academic and Research Purposes\\n\\n\\n  \\n\\nEdmund.McGowan \\n\\n\\n\\n\\n\\nNovember 2024 \\n edited January 15   in AI \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArtificial intelligence is a swiftly evolving beast. From novel chatbots that come with the dust and are gone with the wind to behemoths like ChatGPT, AI is on the march. STORM by Stanford University is an innovative AI-powered research tool currently making waves in the global academic community and beyond.Since early 2024, this open-source research project has helped many academics, students, and content creators craft articles from scratch. “Articles from scratch?” We hear you ask. Yes, in a nutshell, it can be used to create Wikipedia-style papers, complete with citations in a matter of minutes. Whether you’re interested in AI for schoolwork, or even AI for grad school level writing, STORM can help you on your path to a PhD.Get set, because we’re headed for the eye of the storm to discover the origins of STORM, and the humans behind it. We’ll also go on to discuss its performance and steer you in the direction of the STORM website so you can try it out for yourself.The nature of the STORM?Short for “Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking”, STORM Stanford AI research project is an AI tool that can create Wikipedia style entries faster than you can make a cup of coffee. Let’s be clear, STORM is not your average B- chatbot, it is an A+ gifted-class knowledge creator and research assistant that’s ready to back up its statements and provide citations galore.While AI is often a faceless, authorless corporate beast, the team behind STORM are actually Stanford students and faculty. STORM is created by human members of Stanford’s OVAL team, namely: Yijia Shao, Yucheng Jiang, Theodore A. Kanell, Peter Xu, Omar Khattab, and Monica S. Lam.LLMs (large language models) may be useful for a layman’s general research. But for academics and content creators, they tend to fall short in several areas. Accuracy is king in academia, and LLMs have well publicized limitations in veracity, as well as specificity, and understanding of complex academic topics. What’s more, LLMs are renowned for producing confident, yet incorrect answers that lack citations.The final nail in the coffin for academic use of LLMs is plagiarism. Rapid generation of text comes with the risk that the LLM is simply replicating existing academic sources. While the majority of LLMs create content via retrieval-augmented generation (RAG), STORM takes content creation several steps further to craft accurate, organized answers. Now let’s find out more about the multi-agent conversations behind every STORM search.The multi-agent STORMversation\\n\\n\\n\\n\\n\\nAt time of writing, STORM is powered by Bing Search and Azure OpenAI GPT-4o-mini. This recent upgrade featuring the latest technologies enables STORM to break down the barrier between the excess of accessible information out there, and what an individual is able to assimilate. The “knowledge curation agent” explored in STORM (remember, it is still a research project) aims to provide a solid foundation for knowledge discovery, making in-depth learning possible without the stress of laborious research.Where many LLMs are a letdown, STORM is a success. This is in no small part thanks to STORM’s multi-perspective question asking. Multiple AI agents cooperate in an agentic system, where individual AI agents perform the tasks of content retrieval, multi-perspective question asking, and finally, synthesis of content. Similar in many ways to how a human team would collaborate to research and write an ambitious project, STORM approaches complex tasks from multiple angles to create comprehensive written content that can give human-created articles a run for their money.Various processesSTORM provides users with the option of STORM AI autonomous or Co-STORM (Human-AI collaboration), as well as search engine choices. After inputting your topic to STORM, the platform generally takes a minute or two to generate your article. Once an article is completed, a “See BrainSTORMing Process” option appears above the summary of your article. This neat feature allows users to see the AI agents (editors) and the steps they have taken to contribute to the final article.If you do try STORM, do the good folks at Stanford a favor and provide feedback using the handy feedback box on the web demo. This information, as well as your purpose for writing the article will be securely stored, and not combined with your Google account info.Who can STORM help?\\n\\n\\n\\n\\n\\nIf you’re looking for an AI tool to assist your academic writing, or just AI for school in general, then STORM is certainly worth a try. Here are a few different user groups that may find STORM more useful than regular old LLMs.Academics and researchers can both benefit from using STORM, as it can create structured outlines on complex academic topics that can be used as educational resources. The verification and citation features of STORM are particularly attractive for this cohort.Students today may lack the time to conduct their own research. With STORM, students of all levels can quickly get well-organized notes and summaries in easy to understand Wikipedia style articles, likely a form that they are already familiar with.Content creators with deadlines to meet or day jobs to attend to can rapidly research and organize data on STORM. Verified, fact-based outlines that offer multiple perspectives can be quickly crafted, and updated by users as topics evolve.A STORM in a teacup?As with all AI platforms, STORM is not without its limitations. If you’ve read this far, chances are you’re not plotting to misuse STORM to graduate from school or college. But just in case you were wondering, STORM is not (yet) an AI writing tool that can knock out a 10,000 word college-level dissertation for you. Try out STORM and you will quickly discover that the “research preview” excels in generating Wikipedia-style articles.Similar to Wikipedia, STORM is very good at providing a comprehensive outline of a topic. The Wikipedia-esque sections are useful as foundations to build out from, but may lack specific or detailed information that some users require. This is presumably an aspect of the platform that will be improved, time will tell.\\n\\n\\n\\n\\n\\nAnother issue that may deter or, indeed, attract some users is STORM’s limited safety measures. The potential to generate offensive content is certainly present on STORM, and on behalf of the Stanford Open Virtual Assistant Lab team, we remind you to follow STORM’s guidelines. As with other AI content generators, mistakes are still a likelihood, so double check your info before going to print!Become a rider on the STORM?We trust that you have enjoyed learning about STORM today. Whatever field you work or study in, we believe that STORM is definitely worth a try. If you’re keen to join the STORMversation, simply head over to the STORM homepage. Here you’ll be able to login via your Google account, and experience the research-tool that academics from Glasgow to Gaborone are talking about.Recommended Products\\n\\n\\n\\n\\n\\nSwift 14 AI (Intel Ultra)Buy Now\\n\\n\\n\\n\\n\\nSwift 14 AI (AMD Ryzen)Buy Now \\nEdmund is an English copywriter based in New Taipei City, Taiwan. He is a widely published writer and translator with two decades of experience in the field of bridging linguistic and cultural gaps between Chinese and English.0  \\n\\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\nSocials\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\nCategories\\n\\nAll Categories112 AI\\n478 PC Tech\\n619 Gaming\\n198 Lifestyle\\n137 Business\\n45 Education\\n48 Green\\n\\n\\n\\n\\nRecent Announcements \\n\\n\\nAcer Gaming Laptops and Desktops With the 50 Series GPU\\nIt’s no secret that the latest and greatest Acer gaming laptops and desktops are equipped with Nvidia 50 series graphics cards. Built on state-of-the-art Blackwell architecture, 50 Series GPUs go beyond simply rendering pixels, they predict them. Transforming how your favorite games play, next-gen DLSS 4, ultra-fast GDDR7…\\n\\n\\nWhy the Nitro PG1 is the Best Portable Gaming Monitor on Market\\nPortable gaming monitors enhance the gaming experience by letting users expand their screens. In this article, we will explore what portable gaming monitors are, how they differ from regular portable monitors, and introduce the Acer Nitro PG1. Portable monitors can be connected to other devices like a laptop, smartphone,…\\n\\n\\nPredator Helios 18 AI (RTX 5090): Acer's Most Powerful Gaming Laptop to Date\\nLooking for an Acer gaming laptop that can go the distance, and then some? Well the Predator Helios 18 AI is the leader of the Acer gaming computer family, an anticipation of the future of on-the-go gaming. If you want to take your gaming beyond the horizon, Acer Predator Helios 18 AI is a mean machine with an Intel Core…\\n\\n\\n\\n\\nStay Up to Date\\nGet the latest news by subscribing to Acer Corner in Google News.\\n\\n\\nFollow\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]}}\n",
            "{'answer_question': {'answer': '스탠포드 STORM의 멀티 에이전트 구조는 연구 프로젝트에 협력하는 전문가 팀을 '\n",
            "                               '시뮬레이션하는 방식으로 작동합니다. 이는 단순한 LLM이 아니라, 콘텐츠 생성 '\n",
            "                               '과정에서 각자 중요한 역할을 수행하는 AI 에이전트들의 정교하게 조직된 '\n",
            "                               '시스템입니다.\\n'\n",
            "                               '\\n'\n",
            "                               '주요 특징은 다음과 같습니다:\\n'\n",
            "                               '*   **다중 에이전트 시스템 (Multi-agent system)**: '\n",
            "                               'STORM은 여러 AI 에이전트를 활용하여 주제에 대한 심층적인 연구를 '\n",
            "                               '수행합니다.\\n'\n",
            "                               '*   **시뮬레이션된 대화 (Simulated Conversations)**: '\n",
            "                               'STORM은 여러 AI 에이전트 간의 대화를 시뮬레이션합니다. 각 에이전트는 주제에 '\n",
            "                               '대한 다른 관점을 나타내며, 마치 전문가들 간의 원탁 토론처럼 진행됩니다.\\n'\n",
            "                               '*   **관점 기반 질문 (Perspective-Guided Question '\n",
            "                               'Asking)**: STORM은 기존 유사 기사들을 조사하여 다양한 관점을 파악하고 '\n",
            "                               '이를 질문 생성 과정에 활용합니다.\\n'\n",
            "                               '*   **위키피디아 작성자와 주제 전문가 시뮬레이션 (Simulating '\n",
            "                               'Wikipedia Writer and Topic Expert)**: 시스템은 '\n",
            "                               '위키피디아 작성자와 주제 전문가 사이의 대화를 시뮬레이션하여 인터넷 소스를 기반으로 '\n",
            "                               '이해를 업데이트하고 후속 질문을 던질 수 있도록 합니다.\\n'\n",
            "                               '*   **역할 분담 에이전트**:\\n'\n",
            "                               '    *   **연구 에이전트 (Research Agents)**: 인터넷의 '\n",
            "                               '다양한 소스에서 정보를 수집합니다.\\n'\n",
            "                               '    *   **질문 생성 에이전트 (Question-Asking '\n",
            "                               'Agents)**: 다양한 관점을 시뮬레이션하여 통찰력 있는 질문을 생성합니다.\\n'\n",
            "                               '    *   **전문가 에이전트 (Expert Agents)**: 질문 생성 '\n",
            "                               '에이전트가 제기한 질문에 답변을 제공합니다.\\n'\n",
            "                               '    *   **합성 에이전트 (Synthesis Agents)**: 수집된 '\n",
            "                               '정보를 응집력 있는 기사 구조로 취합하고 정리합니다.\\n'\n",
            "                               '\\n'\n",
            "                               '이러한 대화형 접근 방식은 STORM이 자체 가정을 검증하고, 주제의 다양한 측면을 '\n",
            "                               '탐색하며, 개요를 개선하고, 잠재적인 오류를 찾아 수정하는 데 도움을 줍니다.'}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "# Streaming 참고\n",
        "# https://langchain-ai.github.io/langgraph/concepts/streaming/#streaming-graph-outputs-stream-and-astream\n",
        "\n",
        "for data in graph.stream({'question': '스탠포드의 멀티 에이전트 STORM 구조가 뭐야?'},\n",
        "                         stream_mode='updates'):\n",
        "    pprint.pprint(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ISOtMiqrDMk"
      },
      "source": [
        "결과는 잘 나왔지만, 위 검색 결과를 보면 전처리가 많이 필요하거나, 프롬프트에 포함하지 않아도 되는 검색 결과들이 다소 존재할 수 있습니다.  \n",
        "\n",
        "\n",
        "\n",
        "더 효과적인 어플리케이션을 구성한다면, 검색 결과를 검증하여 불필요한 토큰을 줄일 수 있겠습니다.   \n",
        "\n",
        "<br><br>\n",
        "이번 실습에서는 단순한 일직선 형태의 Flow를 그래프로 만들었기 때문에 위 작업들을 수행하지 않았지만,    \n",
        "LangGraph의 기능을 활용하면 반복, 분기점, 중단 및 사용자의 중간 개입과 같은 요소들을 효율적으로 포함할 수 있습니다.    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALfVkuR-YEWj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

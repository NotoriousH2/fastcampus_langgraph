{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bc217b6",
      "metadata": {
        "id": "1bc217b6"
      },
      "source": [
        "# [실습] LangChain Tool Call과 Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478a9e3f",
      "metadata": {
        "id": "478a9e3f"
      },
      "source": [
        "LangChain의 기본 코드를 통해, Tool Call과 Agent가 작동하는 과정에 대해 알아보겠습니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479674c4",
      "metadata": {
        "vscode": {
          "languageId": "sql"
        },
        "id": "479674c4"
      },
      "source": [
        "기본 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9a52c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9a52c8",
        "outputId": "452b24fd-a230-40af-a21d-46f38df30b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.33)\n",
            "Collecting langchain_core\n",
            "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.5.1-py3-none-any.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.8.4)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.10.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.3.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.12.2)\n",
            "Collecting langchain<1.0.0,>=0.3.18 (from langchain_community)\n",
            "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting tiktoken>=0.5.1 (from tavily-python)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.26.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<1.0.0,>=0.3.18->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.9)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.1)\n",
            "Downloading langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: filetype, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, tavily-python, pydantic-settings, dataclasses-json, langchain_core, langchain-text-splitters, langchain, langchain_google_genai, langchain_community\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.3.33\n",
            "    Uninstalling langchain-core-0.3.33:\n",
            "      Successfully uninstalled langchain-core-0.3.33\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.17\n",
            "    Uninstalling langchain-0.3.17:\n",
            "      Successfully uninstalled langchain-0.3.17\n",
            "Successfully installed dataclasses-json-0.6.7 filetype-1.2.0 httpx-sse-0.4.0 langchain-0.3.18 langchain-text-splitters-0.3.6 langchain_community-0.3.17 langchain_core-0.3.34 langchain_google_genai-2.0.9 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 tavily-python-0.5.1 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain_google_genai langchain_core langchain_community tavily-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3abe77a5",
      "metadata": {
        "id": "3abe77a5"
      },
      "source": [
        "Google API Key를 설정합니다.\n",
        "\n",
        "구글 로그인 후, https://aistudio.google.com/apikey 에서 발급받을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b75f0d",
      "metadata": {
        "id": "a4b75f0d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c00b11f",
      "metadata": {
        "id": "9c00b11f"
      },
      "source": [
        "Gemini 모델을 설정합니다.   \n",
        "무료 API의 경우 분당 제한이 존재하므로, 랭체인의 Rate Limiter를 적용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a15227",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a15227",
        "outputId": "11e73b47-4eef-41fd-c696-9f9ab6dfe46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1f5f89156181>:6: LangChainBetaWarning: Introduced in 0.2.24. API subject to change.\n",
            "  rate_limiter = InMemoryRateLimiter(\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    rate_limiter=rate_limiter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71e0a44d",
      "metadata": {
        "id": "71e0a44d"
      },
      "source": [
        "`invoke()`를 통해 llm에 입력을 전달합니다.    \n",
        "랭체인 기본 클래스인 `Message` 계열 클래스를 직접 만들어 리스트로 전달하거나,   \n",
        "프롬프트 템플릿을 통해 입력의 구성을 만들어 전달할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1280e1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1280e1b",
        "outputId": "ee615af8-c0df-4c10-fd62-a014635bcc76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요! 저는 구글에서 개발한 인공지능 모델이고, 특별한 이름은 없습니다. \\n\\n*   저는 사용자의 질문에 답변하고, 정보를 제공하며, 다양한 작업을 수행할 수 있습니다.\\n*   저는 끊임없이 학습하고 발전하고 있습니다.\\n*   궁금한 점이 있다면 언제든지 저에게 물어보세요.\\n*   저는 사용자를 돕기 위해 존재합니다.\\n*   앞으로 저와 함께 즐거운 시간을 보내시길 바랍니다!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e8f1fd1c-35e2-4cd3-9c1c-ec4b4144d818-0', usage_metadata={'input_tokens': 57, 'output_tokens': 135, 'total_tokens': 192, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 1. HumanMessage를 이용한 방법\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "system_msg = SystemMessage(content=\"\"\"사용자의 아래 [질문]에 대해 친절하게 답변하세요.\n",
        "답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.\"\"\")\n",
        "msg = HumanMessage(content=\"안녕! 너는 이름이 뭐니?\")\n",
        "\n",
        "messages = [system_msg, msg]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea0668f",
      "metadata": {
        "id": "fea0668f"
      },
      "source": [
        "Chat 모델의 출력은 AIMessage라는 형식으로 변환됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4a09cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb4a09cc",
        "outputId": "6ce3caaa-ed47-40fb-e957-6cac51dd1866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요! 저는 구글에서 개발한 인공지능 모델이고, 특별한 이름은 없습니다. \n",
            "\n",
            "*   저는 사용자의 질문에 답변하고, 정보를 제공하며, 다양한 작업을 수행할 수 있습니다.\n",
            "*   저는 끊임없이 학습하고 발전하고 있습니다.\n",
            "*   궁금한 점이 있다면 언제든지 저에게 물어보세요.\n",
            "*   저는 사용자를 돕기 위해 존재합니다.\n",
            "*   앞으로 저와 함께 즐거운 시간을 보내시길 바랍니다!\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b620e2b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b620e2b1",
        "outputId": "01f0a866-e84f-43ee-ac08-bfd5c0478033"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='사용자의 아래 [질문]에 대해 친절하게 답변하세요. \\n     답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='[질문]: {question}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 2. ChatPromptTemplate을 이용한 방법\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 입력 변수가 {question}인 템플릿\n",
        "prompt = ChatPromptTemplate([\n",
        "    ('system', '''사용자의 아래 [질문]에 대해 친절하게 답변하세요.\n",
        "     답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.'''),\n",
        "     ('user', '''[질문]: {question}''')])\n",
        "prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1bdd2bb",
      "metadata": {
        "id": "e1bdd2bb"
      },
      "source": [
        "프롬프트와 llm을 |로 연결하여 체인을 구성합니다.   \n",
        "(랭체인 기본 문법으로, LangChain 기초 복습 자료에서 자세히 보실 수 있습니다!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7477bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c7477bb",
        "outputId": "9d7fc60a-4ba4-4c24-e1e3-e33ce8559973"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='사용자의 아래 [질문]에 대해 친절하게 답변하세요. \\n     답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='[질문]: {question}'), additional_kwargs={})])\n",
              "| ChatGoogleGenerativeAI(rate_limiter=<langchain_core.rate_limiters.InMemoryRateLimiter object at 0x7992290177d0>, model='models/gemini-2.0-flash-exp', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x799228f51890>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "chain = prompt | llm\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4567c80e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4567c80e",
        "outputId": "87b92155-a93e-4eca-fc95-0c7c35c7a586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랭체인(LangChain)과 랭그래프(LangGraph)는 모두 LLM(Large Language Model)을 활용한 애플리케이션 개발을 돕는 프레임워크이지만, 주요 차이점은 다음과 같습니다:\n",
            "\n",
            "*   **랭체인**: LLM을 연결하여 복잡한 작업을 수행하는 데 초점을 맞춘 모듈형 프레임워크입니다.\n",
            "*   **랭그래프**: 멀티 에이전트 시스템을 구축하기 위한 프레임워크로, 에이전트 간의 상호작용 및 워크플로우 관리에 특화되어 있습니다.\n",
            "*   **랭체인**: 다양한 LLM, 데이터 소스, 유틸리티를 연결하는 데 용이합니다.\n",
            "*   **랭그래프**: 에이전트들이 상태를 공유하고, 결정을 내리고, 작업을 반복/병렬적으로 수행하는 데 최적화되어 있습니다.\n",
            "*   **요약**: 랭체인은 LLM 연결 및 활용에, 랭그래프는 멀티 에이전트 시스템 구축 및 관리에 더 적합합니다.\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke({'question':\"랭체인과 랭그래프의 차이가 뭐야?\"})\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d11182f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d11182f",
        "outputId": "ace6f36d-2e64-4489-8f7e-6cf4a8266fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패스트캠퍼스에서 제공하는 랭그래프 강의는 다음과 같습니다.\n",
            "\n",
            "*   **[풀스택] 랭체인 기반 AI 에이전트 개발**\n",
            "*   **[자동화] 랭체인으로 시작하는 LLM Ops**\n",
            "\n",
            "두 강의 모두 랭체인을 활용하여 인공지능 에이전트 개발 및 LLM Ops 자동화를 다루고 있습니다. 풀스택 강의는 에이전트 개발에, 자동화 강의는 LLM Ops에 더 집중하는 차이가 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# 입력 변수가 1개일 때는 값만 invoke해도 됨\n",
        "\n",
        "response = chain.invoke(\"패스트캠퍼스 랭그래프 강의 이름이 뭐야?\")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec0bb92a",
      "metadata": {
        "id": "ec0bb92a"
      },
      "source": [
        "존재하지 않는 내용에 대한 환각이 발생한 모습입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad0069a",
      "metadata": {
        "id": "3ad0069a"
      },
      "source": [
        "## LLM Tool 설정하기\n",
        "\n",
        "Tool은 LLM이 사용할 수 있는 다양한 외부 기능을 의미합니다.   \n",
        "LangChain에서 자체적으로 지원하는 Tool을 사용하거나, RAG의 Retriever를 Tool로 변환하는 것도 가능합니다.     \n",
        "또한, 함수를 Tool로 변환할 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4661f0a",
      "metadata": {
        "id": "e4661f0a"
      },
      "source": [
        "1. Tavily Search (http://app.tavily.com/)\n",
        "\n",
        "Tavily는 AI 기반의 검색 엔진입니다. 계정별 월 1000개의 무료 사용량을 지원합니다.      \n",
        "Tavily Search는 URL과 함께 내용의 간단한 요약을 지원하는 것이 특징입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091dff13",
      "metadata": {
        "id": "091dff13"
      },
      "outputs": [],
      "source": [
        "os.environ['TAVILY_API_KEY'] = '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'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d69da9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52d69da9",
        "outputId": "c98d049b-f08f-4b30-ea1e-41b71085eaff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TavilySearchResults(include_answer=True, include_raw_content=True, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_search = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    )\n",
        "tavily_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06f87e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d06f87e6",
        "outputId": "584cf035-d5bc-4e8d-8006-770be8c7524d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://wikidocs.net/268613',\n",
              "  'content': 'Langchain 랭체인과 Langgraph의 차이점 - 모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent : LangGraph 시작하기 랭 체인은 여러 구성 요소를 선형적으로 이어주는 구조로, 정의된 순서에 따라 작업을 수행하는 반면, 랭 그래프는 노드와 엣지의 연결을 통해 비선형적이고 동적인 프로세스를 구성합니다. 체인 홈페이지에서 랭 체인과 랭 그래프가 평행선상에 표현되어 있는 그림을 볼 수 있다 따라서, 랭 체인 생태 내에서 두 프레임워크는 주요 아키텍처로서 비슷한 점이 많다고 볼 수 있다 랭 체인의 주요 활용은 레그라로 볼 수 있다 레그의 인덱싱 과정은 일종의 파이프라인을 통해 수행되며, 랭 체인을 활용하여 생성 과정을 완성할 수 있다 랭 체인은 일방향적 체인 구조로 구성할 수 있지만, 랭 그래프는 주어진 메시지에 따라 어시스턴트가 다음 노드를 선택한다 Report a comment. Do you want to report this comment?'},\n",
              " {'url': 'https://wikidocs.net/261585',\n",
              "  'content': 'LangGraph와 LangChain의 차이점 - LangGraph 가이드북 - 에이전트 RAG with 랭그래프 | 주요 목적 | 복잡한 워크플로우 및 의사결정 프로세스 구현 | LLM 통합 및 체인 구성 | | 용도 | 복잡한 AI 시스템, 다중 에이전트 | 간단한 LLM 애플리케이션, RAG | 개발자가 각 단계에서 상태를 직접 제어하고 수정할 수 있어, 복잡한 상태 변화를 정확하게 추적하고 관리할 수 있습니다. LangChain은 미리 정의된 컴포넌트를 중심으로 구성되어 있어, 기본적인 기능을 빠르게 구현할 수 있지만 고도로 커스터마이즈된 로직을 구현하는 데는 상대적으로 제한이 있을 수 있습니다. LangGraph는 복잡한 AI 시스템이나 다중 에이전트 시스템을 구축하는 데 적합합니다. 복잡하고 맞춤화된 AI 시스템이 필요하다면 LangGraph가, 빠른 개발과 간단한 LLM 통합이 목표라면 LangChain이 더 적합할 수 있습니다. Report a comment. Do you want to report this comment?'},\n",
              " {'url': 'https://brunch.co.kr/@@aPda/339',\n",
              "  'content': 'LLM 개발자들이 애플리케이션을 개발할 때\\xa0이러한 모듈러 레그의 기능을 구현하고 복잡한 RAG를 마치 자신만의 레고블록처럼 가지고 놀 수 있는 손쉬운 방법이 있습니다. Langchain을 사용하면 RAG 파이프라인에서 발생할 수 있는 복잡한 작업들을 자동화하거나 추상화하여 개발자들이 시스템을 보다 쉽게 구축하고 확장할 수 있도록 돕습니다. 하지만 LangGraph는 한 발 더 나아가\\xa0LLM을 사용하여 상태를 유지하고 여러 에이전트를 포함한 애플리케이션을 쉽게 만들 수 있도록 도와주는 프레임워크입니다. LangGraph에는 LangChain의 기능을 확장하여 복잡한 에이전트 런타임 개발에 필수적인 순환 그래프를 만들고 관리할 수 있는 기능을 추가되어 있습니다. 이 라이브러리는 여러 LLM 에이전트(또는 체인)를 구조화된 방식으로 정의, 조정 및 실행할 수 있는 프레임워크를 제공합니다. 복잡한 워크플로우에서 각 단계가 다양한 조건에 따라 실행될 수 있고, 순환 구조와 조건부 에지를 통해 더욱 유연한 흐름을 지원합니다.'},\n",
              " {'url': 'https://gunn.kim/langgraph-vs-langchain-evolution-of-llm-development-frameworks',\n",
              "  'content': '랭그래프는 랭체인의 확장 버전 또는 보완적인 프레임워크로 볼 수 있습니다. 랭그래프는 LLM 애플리케이션의 복잡한 워크플로우를 그래프 구조로 모델링'},\n",
              " {'url': 'https://www.youtube.com/watch?v=yD3SnuU6Pd8',\n",
              "  'content': '많은 LLM 기반 어플리케이션의 경우 Langchain만으로 충분하지만, 더 복잡한 워크플로우와 에이전트 시스템을 구현하기 위해서는 Langgraph를 활용'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "search_docs = tavily_search.invoke(\"랭그래프와 랭체인의 차이\")\n",
        "search_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144a8cfb",
      "metadata": {
        "id": "144a8cfb"
      },
      "source": [
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b84ff85",
      "metadata": {
        "id": "4b84ff85"
      },
      "source": [
        "# LLM에 Tool 연결하기   \n",
        "\n",
        "생성한 툴은 llm.bind_tools()를 통해 LLM에 연결할 수 있습니다.    \n",
        "이 기능은 Gemini, GPT, Claude 등의 툴에서 지원하는데요.     \n",
        "HuggingFace 공개 모델에서 Tool을 사용하는 경우는 이후 실습에서 자세히 알아보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f9f905",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35f9f905",
        "outputId": "696328b1-99b4-460c-959d-8b6556165dfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatGoogleGenerativeAI(rate_limiter=<langchain_core.rate_limiters.InMemoryRateLimiter object at 0x7992290177d0>, model='models/gemini-2.0-flash-exp', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x799228f51890>, default_metadata=()), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tools = [tavily_search]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "llm_with_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50a0b273",
      "metadata": {
        "id": "50a0b273"
      },
      "source": [
        "랭체인에서, tool 정보는 tools에 저장되는데요.   \n",
        "해당 내용은 랭체인 내부에서 json Schema 형식으로 프롬프트에 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ed35d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52ed35d6",
        "outputId": "12ea83dd-b7a6-4832-ef68-951ab376f081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'name': 'tavily_search_results_json',\n",
              "   'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.',\n",
              "   'parameters': {'properties': {'query': {'description': 'search query to look up',\n",
              "      'type': 'string'}},\n",
              "    'required': ['query'],\n",
              "    'type': 'object'}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# 시스템 메시지에 포함되는 내용\n",
        "# (`LLM과 Agent` 강의 슬라이드를 참고하세요!)\n",
        "\n",
        "llm_with_tools.kwargs['tools']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "291ee797",
      "metadata": {
        "id": "291ee797"
      },
      "source": [
        "LLM은 프롬프트로 주어지는 툴 정보를 바탕으로 Tool의 사용을 결정합니다.    \n",
        "Schema를 통해, 툴의 의미와 사용 방법, 형식을 이해합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd923172",
      "metadata": {
        "id": "cd923172"
      },
      "source": [
        "이후, LLM은 Tool 사용이 필요한 경우 특별한 포맷의 메시지를 출력합니다.   \n",
        "이를 Tool Call Message라고 부릅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ddf7c84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ddf7c84",
        "outputId": "4efffd36-03f4-4174-b2be-5f6500857ca9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='현재 사용할 수 있는 API에는 패스트캠퍼스에 대한 정보가 없습니다. 따라서 해당 과정이 어떤 과정인지에 대한 질문에 답변을 드릴 수 없습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d39f412c-08eb-40a9-9d1a-7e8a3104f681-0', usage_metadata={'input_tokens': 133, 'output_tokens': 46, 'total_tokens': 179, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tool_chain = prompt | llm_with_tools\n",
        "tool_call_msg = tool_chain.invoke(\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\")\n",
        "tool_call_msg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0857ca4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0857ca4",
        "outputId": "eded5292-70aa-4d85-e785-407f5efd6037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"\\\\ud328\\\\uc2a4\\\\ud2b8\\\\ucea0\\\\ud37c\\\\uc2a4 \\\\ub7ad\\\\uadf8\\\\ub798\\\\ud504\\\\ub85c \\\\ud55c\\\\ubc88\\\\uc5d0 \\\\uc644\\\\uc131\\\\ud558\\\\ub294 \\\\ubcf5\\\\uc7a1\\\\ud55c RAG\\\\uc640 Agent \\\\uacfc\\\\uc815\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-564cafb1-07aa-497a-ba3a-5574581a2535-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'}, 'id': 'ecb03e78-5aa2-40f9-95bf-f3cfde028a38', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 34, 'total_tokens': 120, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tool_call_msg = llm_with_tools.invoke(\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정인지 검색해서 알려줘\")\n",
        "tool_call_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80472b96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80472b96",
        "outputId": "ee77e274-d1fb-4334-b6aa-46bf1bf12a82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'tavily_search_results_json',\n",
              "  'args': {'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'},\n",
              "  'id': 'ecb03e78-5aa2-40f9-95bf-f3cfde028a38',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tool_call_msg.tool_calls\n",
        "# 리스트 형식인 이유는? 여러 개의 툴을 동시에 사용할 수 있기 때문문"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d6bd19",
      "metadata": {
        "id": "71d6bd19"
      },
      "source": [
        "`tool_calls`에 포함된 name을 활용하면 툴 결과를 전달할 수 있습니다.   \n",
        "`name` 값은 문자열이므로, dictionary를 통해 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9595fda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9595fda",
        "outputId": "dfceafa8-4124-4cbd-e3d0-84602a0c3169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tavily_search_results_json',\n",
              " TavilySearchResults(include_answer=True, include_raw_content=True, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tool_list ={'tavily_search_results_json': tavily_search}\n",
        "\n",
        "tool_name = tool_call_msg.tool_calls[0]['name']\n",
        "tool_exec = tool_list[tool_name]\n",
        "\n",
        "tool_name, tool_exec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3496b492",
      "metadata": {
        "id": "3496b492"
      },
      "source": [
        "Tool에 tool_call을 입력해 invoke를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f582c143",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f582c143",
        "outputId": "2f2d3707-69d3-4664-84d3-66330c8a9d98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToolMessage(content='[{\"url\": \"https://fastcampus.co.kr/new\", \"content\": \"서강대학교 DX-AI miniMBA 과정. 15주 과정약 45시간직무경험 필요 ... 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간사전지식 필요.\"}, {\"url\": \"https://fastcampus.co.kr/data_online_langgraph\", \"content\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 #LLM#multi agent#RAG#랭그래프 결제 수단에 따라 무이자 할부가 불가할 수 있습니다. 복잡한 RAG와 Agent 설계를 완성하는 LangGraph 첫 걸음 5가지 Advanced AI agent 구축 프로젝트 약 16시간사전지식 필요 FC AWARD 본 패키지는 약 20시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다. 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다. 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다. 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다. 패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\"}, {\"url\": \"https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr\", \"content\": \"LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content) LinkedIn 회원 가입 로그인 과정 이름은 \\\\\"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr  LinkedIn Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\"}, {\"url\": \"https://fastcampus.co.kr/categories\", \"content\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 약 20시간사전지식 필요 ; 파인튜닝과 RAG로 완성하는 맞춤형 LLM 서비스 개발. 약 40시간누구나 ; 박준의 나만을 위한 AI\"}, {\"url\": \"https://fastcampus.co.kr/search?keyword=%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84\", \"content\": \"모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent ft. 5가지 Advanced AI ... 40+ · 딥러닝 · 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간\"}]', name='tavily_search_results_json', tool_call_id='ecb03e78-5aa2-40f9-95bf-f3cfde028a38', artifact={'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정', 'follow_up_questions': None, 'answer': 'The FastCampus course \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\" is designed to help learners complete complex RAG (Retrieval-Augmented Generation) and Agent systems using LangGraph. The course lasts for approximately 15 weeks and requires around 45 hours of work experience. It includes advanced projects to build five AI agents and is approximately 20 hours long, requiring about 16 hours of prior knowledge. The course offers a refund policy if the student does not complete five classes within the first seven days of enrollment. The course is part of the larger FastCampus offerings, including the DX-AI miniMBA program.', 'images': [], 'results': [{'url': 'https://fastcampus.co.kr/new', 'title': '[EVENT] 신규 강의 런칭 특가 - 패스트캠퍼스', 'content': '서강대학교 DX-AI miniMBA 과정. 15주 과정약 45시간직무경험 필요 ... 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간사전지식 필요.', 'score': 0.8891543, 'raw_content': None}, {'url': 'https://fastcampus.co.kr/data_online_langgraph', 'title': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent - 패스트캠퍼스', 'content': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 #LLM#multi agent#RAG#랭그래프 결제 수단에 따라 무이자 할부가 불가할 수 있습니다. 복잡한 RAG와 Agent 설계를 완성하는 LangGraph 첫 걸음 5가지 Advanced AI agent 구축 프로젝트 약 16시간사전지식 필요 FC AWARD 본 패키지는 약 20시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다. 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다. 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다. 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다. 패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.', 'score': 0.8785752, 'raw_content': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스\\nroot layout\\n패스트캠퍼스\\n Fast Campus\\n사용자 메뉴\\n로그인\\n커뮤니티기업교육\\n\\n인공지능딥러닝\\n랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\n평생소장\\n약 20시간\\n사전지식 필요\\nLangGraph 공부의 시작점이 되는 강의! 사람같은 AI 서비스, RAG, AI agent 개발에 필수스택이 된 랭그래프의 원리와 활용, LangGraph가 쓰이는 대표적인 use case 6가지까지.\\n#LLM#multi agent#RAG#랭그래프\\n강의 정보\\n온라인\\n5파트\\n25.02.24~ 영상 공개\\n\\n71%\\n월 19,084원\\n12개월 무이자 할부 시\\n결제 수단에 따라 무이자 할부가 불가할 수 있습니다.\\n권장 소비자 가격\\n~800,000원~\\n할인 금액\\n-571,000원\\n할인 판매가\\n229,000원\\n수강 신청하기수강 신청 버튼\\n마감까지\\xa05일__8시간__47분\\n랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\n찜하기\\n지금 최저가로 시작하세요! 복잡한 RAG와 Agent 설계를 완성하는 LangGraph 첫 걸음\\n마감까지\\xa05일__8시간__47분\\n수강 신청하기수강 신청 버튼\\n커리큘럼\\n파트 5개약 20시간\\n전부 접기교육과정소개서\\n\\n\\nPart 01. RAG와 AI Agent의 이해\\n01:00:00\\nCh 01. RAG와 AI Agent의 이해\\n01:00:00\\n\\n01. LLM 발전 동향00:20:00\\n02. LLM과 Agent00:20:00\\n03. 다양한 LLM Agent의 구조00:20:00\\nPart 02. LangGraph\\n\\n05:00:00\\nCh 01. LangGraph\\n05:00:00\\n\\n01. LangChain Tool Calling과 Agent00:40:00\\n02. LangGraph 소개00:20:00\\n03. LangGraph Node와 Edge, Graph 구조00:20:00\\n04. LangGraph의 다양한 State00:20:00\\n05. LangSmith와 LangGraph Studio00:20:00\\n01. 조건부 노드와 툴 노드 연결하기00:20:00\\n02. Agent의 Planning 구조: ReAct00:20:00\\n03. 다양한 그래프 구조00:40:00\\n04. 그래프 메모리 관리00:30:00\\n05. Human-in-the-Loop00:30:00\\n01. 멀티 에이전트 구조00:40:00\\nPart 03. LangGraph를 이용한 현업 적용 프로젝트\\n\\n06:40:00\\nCh 01. 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션\\n01:20:00\\n\\n01. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션00:40:00\\n02. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 (2)00:40:00\\n\\nCh 02. 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent\\n01:20:00\\n\\n01. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent00:40:00\\n02. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent (2)00:40:00\\n\\nCh 03. 비전 모델을 활용한 멀티모달 RAG Agent\\n01:20:00\\n\\n01. 3) 비전 모델을 활용한 멀티모달 RAG Agent00:40:00\\n02. 3) 비전 모델을 활용한 멀티모달 RAG Agent00:40:00\\n\\nCh 04. 멀티 에이전트 기반 Research Agent\\n01:20:00\\n\\n01. 4) 멀티 에이전트 기반 Research Agent00:40:00\\n02. 4) 멀티 에이전트 기반 Research Agent00:40:00\\n\\nCh 05. Code Interpreter를 이용한 내 파일 기반 차트 제너레이터\\n00:40:00\\n\\n01. 5) Code Interpreter를 이용한 내 파일 기반 차트 제너레이터00:40:00\\n\\nCh 06. 멀티 에이전트를 활용한 보고서 작성과 품질 평가 관리 시스템\\n00:40:00\\n\\n01. 6) 멀티 에이전트를 활용한 보고서 작성과 품질 평가 관리 시스템00:40:00\\nPart 04. LangGraph Application 배포하기\\n\\n02:00:00\\nCh 01. LangGraph Application 배포하기\\n02:00:00\\n\\n01. HuggingFace 공개 LLM을 활용한 Agentic Work 만들기00:40:00\\n02. Ollama/vLLM을 이용한 Agentic Work 최적화00:40:00\\n03. 만들어진 LangGraph Application 배포하기 (Streamlit/Gradio/ LangGraph Cloud)00:40:00\\nPart 05. [부록] LangChain과 LLM API\\n\\n03:40:00\\nCh 01. LLM API\\n00:40:00\\n\\n01. OpenAI와 Gemini API 사용하기00:40:00\\n\\nCh 02. LangChain 기초\\n03:00:00\\n\\n01. LangChain을 이용한 LLM 어플리케이션 만들기00:20:00\\n02. [실습] LangChain을 이용한 LLM 어플리케이션 만들기00:40:00\\n03. [실습] LangChain Expression Language00:40:00\\n04. Retrieval Augmented Generation 이해하기00:20:00\\n05. Retrieval Augmented Generation 이해하기 (2)00:20:00\\n06. [실습] LangChain을 이용한 RAG 구현하기00:40:00\\n\\n\\n\\n영상공개 일정\\xa0D-114\\n해당 강의는 총 4회에 걸쳐 공개됩니다.\\n1차2025.02.24(월)\\n2차2025.03.31(월)\\n3차2025.04.28(월)\\n최종2025.05.26(월)\\n이런 강의는 어떠세요?\\n지금 보는 강의와 유사해요!\\n 10+\\n딥러닝\\n프로에게 배우는 상업적인 AI 이미지·영상 제작 마스터 약 25시간누구나\\n 10+\\n딥러닝\\n모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent ft. 5가지 Advanced AI agent 구축 프로젝트 약 16시간사전지식 필요 FC AWARD\\n 10+\\n딥러닝\\n테디노트의 RAG 비법노트 : 랭체인을 활용한 GPT부터 로컬 모델까지의 RAG 가이드 약 66시간누구나 FC AWARD온라인\\n 10+\\n딥러닝\\n프로에게 배우는 ComfyUI 이미지/영상/게임/광고 제작 약 43시간사전지식 필요 FC AWARD온라인\\nprevious\\nnext\\n학습 규정 및 환불 규정\\n학습 규정\\n\\n* 본 상품은 동영상 형태의 강의를 수강하는 상품입니다.\\n* 상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\n* 해당 강의는 사전 예약 상품으로, 강의 영상이 공개 일정에 따라 순차적으로 제작되어 오픈됩니다.\\n총 학습기간:\\n\\n\\n정상 수강기간(유료 수강기간) 최초 30일, 무료 수강 기간은 31일 일차 이후로 무제한이며, 유료 수강기간과 무료 수강기간 모두 동일하게 시청 가능합니다.\\n\\n\\n본 패키지는 약 20시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다.\\n\\n\\n수강시작일: 수강 시작일은 결제일로부터 기간이 산정되며, 결제를 완료하시면 마이페이지를 통해 바로 수강이 가능합니다. (사전 예약 강의는 1차 강의 오픈일)\\n\\n\\n패스트캠퍼스의 사정으로 수강시작이 늦어진 경우에는 해당 일정 만큼 수강 시작일이 연기됩니다.\\n\\n\\n일부 강의는 아직 모든 영상이 공개되지 않았습니다. 각 상세페이지 하단에 공개 일정이 안내되어 있습니다.\\n\\n\\n주의 사항\\n\\n\\n\\n상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\n\\n\\n천재지변, 폐업 등 서비스 중단이 불가피한 상황에는 서비스가 종료될 수 있습니다.\\n\\n\\n본 상품은 기수강생 할인, VIP CLUB 제도 (구 프리미엄 멤버십), 기타 할인 이벤트 적용이 불가할 수 있습니다.\\n\\n\\n커리큘럼은 제작 과정에서 일부 추가, 삭제 및 변경될 수 있습니다.\\n\\n\\n쿠폰 적용이나 프로모션 등으로 인해 5만원 이하의 금액으로 강의를 결제할 경우, 할부가 적용되지 않습니다.\\n\\n\\n환불 규정\\n\\n\\n\\n환불금액은 정가가 아닌 실제 결제금액을 기준으로 계산됩니다.\\n\\n\\n쿠폰을 사용하여 강의를 결제하신 후 취소/환불 시 쿠폰은 복구되지 않습니다.\\n\\n\\n수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다.\\n\\n\\n수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다.\\n\\n\\n수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다.\\n\\n\\n환불요청일 시 기준\\n\\n\\n: 수강시작 후 1/3 경과 전, 실 결제금액의 2/3에 해당하는 금액 환불\\n\\n\\n: 수강시작 후 1/2 경과 전, 실 결제금액의 1/2에 해당하는 금액 환불\\n\\n\\n: 수강시작 후 1/2 경과 후, 환불 금액 없음\\n\\n\\n\\n\\n* 보다 자세한 환불 규정은 홈페이지 취소/환불 정책에서 확인 가능합니다.\\n패스트캠퍼스 정책 안내\\n\\n[패스트캠퍼스 아이디 공유 금지 정책]\\n패스트캠퍼스의 모든 온라인 강의에서는 1개의 아이디로 여러명이 공유하는 형태를 금지하고 있습니다.\\n동시접속에 대한 기록은 내부 시스템을 통해 자동으로 누적되며, 이후 서비스 이용이 제한될 수 있습니다.\\n[기기제한 정책]\\n패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\\n최대 갯수를 초과하였을 경우 등록된 기기 해제가 필요합니다.\\n[저작권 정책]\\n패스트캠퍼스의 모든 강의는 무단 배포 및 가공하는 행위, 캡쳐 및 녹화하여 공유하는 행위, 무단으로 판매하는 행위 등 일체의 저작권 침해 행위를 금지합니다.\\n부정 사용이 적발될 경우 저작권법 위반에 의한 법적인 제재를 받으실 수 있습니다.\\n국내 8개 카드사 12개월 무이자 할부 지원! (간편 결제 제외)\\n\\n삼성카드\\n신한카드\\n롯데카드\\n현대카드\\n하나카드\\nBC카드\\nKB국민은행\\nNH농협카드\\n\\n※ BC카드의 경우, 비씨(페이북)을 선택하여 결제시에만 12개월 무이자 할부가 가능합니다.\\n(BC계열 - 우리/제일/기업/대구/경남/부산/광주/수협/전북/제주/신협)\\n\\n\\n회사소개\\n\\n\\n강사지원\\n\\n\\n채용안내\\n\\n\\n인재추천\\n\\n\\nFAST CAMPUS(주) 데이원컴퍼니\\n\\n대표이사\\n이강민\\n개인정보책임관리자\\n이강민\\n사업자번호\\n810-86-00658\\n사업자정보확인\\n사무실\\n서울특별시 강남구 테헤란로 231, 센터필드 WEST 6층, 7층\\n교육장\\n서울특별시 강남구 강남대로 364 미왕빌딩 10, 11층\\n\\n\\n이용약관\\n\\n\\n개인정보처리방침\\n\\n\\nFAQ\\n\\n\\n취소/환불 정책\\n\\n\\n자료실\\n\\n\\n공지사항\\n\\n\\n장학프로그램\\n\\n\\n고객센터 바로가기\\n\\n전화번호 02-501-9396\\n이메일\\xa0help@fastcampus.co.kr\\n주중 10시~18시 (점심시간 12~13시 / 주말 및 공휴일 제외)\\n\\n호스팅 서비스 제공\\n(주) 데이원컴퍼니\\n통신판매업 신고번호\\n제 2017-서울강남-01977호\\n학원설립 운영등록번호\\n제12484호(강남)\\n원격평생교육원\\n제 572호'}, {'url': 'https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr', 'title': 'LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 ...', 'content': 'LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content) LinkedIn 회원 가입 로그인 과정 이름은 \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr  LinkedIn Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.', 'score': 0.87218446, 'raw_content': 'LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스\\nLinkedIn 동의 후 가입\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\\n  [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content)\\n\\nLinkedIn\\n\\n글\\n사람\\n온라인클래스\\n채용공고\\n게임\\n앱 다운로드\\n\\n회원 가입 로그인\\nHyungho Byun님의 업데이트\\n\\nHyungho Byun\\n노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\n1주\\n\\n글 신고\\n\\n안녕하세요! 노토랩의 변형호입니다.\\xa0 오늘 OpenAI의 웹 탐색 기능이 탑재된 에이전트 오퍼레이터(Operator)가 공개되었는데요. 이에 맞춰서 광고를 좀 하겠습니다..😅 제가 패스트캠퍼스에서 LangGraph에 대한 온라인 강의를 런칭합니다. 과정 이름은 \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프가 랭체인보다 좀 어렵긴 한데요... 단계별로 쉽게 이해할 수 있는 강의를 준비했습니다! RAG가 결합된 복잡한 시스템이나, 스탠포드 스톰(STORM)과 같은 멀티 에이전트 구조를 만들고 싶으신 분들께는 많은 도움이 되실 것 같습니다. 실무에서 활용할 수 있는 6개의 프로젝트를 중심으로 복잡한 그래프 구조, 휴먼인더루프, 품질 검증과 같은 요소들도 아주 세세하게 다룰 예정이구요. 또한, LLM 기본 코드 지식이 필요하신 분들을 위한 랭체인, LLM API 활용 챕터도 부록으로 준비했습니다. 1차 공개 일정은 2월 24일이라 아직 여유가 좀 있는데요(?) 관심 있으신 분들은 https://bit.ly/40lXEj2 에서 자세한 내용을 확인하실 수 있습니다. 아래의 쿠폰코드를 입력하시면 20% 할인 가능합니다! PRDTEA250124_sns202 LangChain의 기초, LLM과 Agent에 대한 샘플 영상 2개도 같이 업로드했는데요. 이 영상은 댓글에 올려 놓겠습니다. 다음 포스팅은 다시 이전처럼 기술 이야기로 뵙겠습니다. 감사합니다! 😁\\n 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr \\n  36 댓글 2\\n추천 댓글 \\n공유\\n\\n복사\\nLinkedIn\\nFacebook\\nTwitter\\n\\n\\nHyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\n1주\\n\\n댓글 신고\\n\\nhttps://youtu.be/yLOjUf_XH1o?si=NZ2r8AlLoTk0s2C1\\n추천댓글반응\\xa01\\n\\nHyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\n1주\\n\\n댓글 신고\\n\\nhttps://youtu.be/sUZ9LPK7fY4?si=ccTDrvW_NNZfhktx\\n추천댓글반응\\xa01\\n더 보기댓글을 보거나 남기려면 로그인\\n\\n팔로워 1,125명\\n\\n업데이트 34개\\n\\n프로필 보기 팔로우\\n\\nLinkedIn © 2025\\n정보\\n웹접근성\\n사용자약관\\n개인정보 처리방침\\nYour California Privacy Choices\\n쿠키정책\\n저작권정책\\n브랜드정책\\n비회원 설정\\n커뮤니티정책\\n\\n\\n아랍어(العربية)\\n벵골어(বাংলা)\\n체코어(Čeština)\\n덴마크어(Dansk)\\n독일어(Deutsch)\\n그리스어(Ελληνικά)\\n영어(English)\\n스페인어(Español)\\n페르시아어(فارسی)\\n핀란드어(Suomi)\\n프랑스어(Français)\\n힌디어(हिंदी)\\n헝가리어(Magyar)\\n인도네시아어(Bahasa Indonesia)\\n이탈리아어(Italiano)\\n히브리어(עברית)\\n일본어(日本語)\\n한국어(Korean)\\n마라티어(मराठी)\\n말레이시아어(Bahasa Malaysia)\\n네덜란드어(Nederlands)\\n노르웨이어(Norsk)\\n펀자브어(ਪੰਜਾਬੀ)\\n폴란드어(Polski)\\n포르투갈어(Português)\\n루마니아어(Română)\\n러시아어(Русский)\\n스웨덴어(Svenska)\\n텔루구어(తెలుగు)\\n태국어(ภาษาไทย)\\n필리핀어(Tagalog)\\n터키어(Türkçe)\\n우크라이나어(Українська)\\n베트남어(Tiếng Việt)\\n중국어 간체(简体中文)\\n중국어 번체(正體中文)\\n\\n언어\\n\\n\\n\\n로그인해서 콘텐츠 더보기\\n무료 계정을 만들거나 로그인하여 검색을 계속하세요.\\n로그인\\n어서오세요!\\n이메일 또는 전화\\n비밀번호\\n표시\\n비밀번호를 잊으셨나요?  로그인\\n또는\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\\nLinkedIn이 처음이세요? 회원 가입\\n또는\\nLinkedIn이 처음이세요? 회원 가입\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.'}, {'url': 'https://fastcampus.co.kr/categories', 'title': '커리어 성장을 위한 최고의 실무교육 아카데미 - 패스트캠퍼스', 'content': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 약 20시간사전지식 필요 ; 파인튜닝과 RAG로 완성하는 맞춤형 LLM 서비스 개발. 약 40시간누구나 ; 박준의 나만을 위한 AI', 'score': 0.8719229, 'raw_content': None}, {'url': 'https://fastcampus.co.kr/search?keyword=%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84', 'title': '랭그래프 검색 결과 - 패스트캠퍼스', 'content': '모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent ft. 5가지 Advanced AI ... 40+ · 딥러닝 · 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간', 'score': 0.8506799, 'raw_content': None}], 'response_time': 3.2})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tool_msg = tool_exec.invoke(tool_call_msg.tool_calls[0])\n",
        "tool_msg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6bb8aaf",
      "metadata": {
        "id": "e6bb8aaf"
      },
      "source": [
        "이번에는 ToolMessage라는 새로운 형태의 메시지가 생성되었습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782933c1",
      "metadata": {
        "id": "782933c1"
      },
      "source": [
        "툴 실행 결과를 LLM에게 다시 전달하여, 이를 해석하고 답변하게 만들어 보겠습니다.   \n",
        "\n",
        "Chain 형식의 구성은 메시지를 변화시키는 것이 복잡하므로, 이전에 사용했던 `HumanMessage`에서 시작하여   \n",
        "LLM의 답변인 `AIMessage`와 `ToolMessage` 를 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613a7da6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "613a7da6",
        "outputId": "9bd32626-11fd-41e0-b023-43402e05224d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"\\\\ud328\\\\uc2a4\\\\ud2b8\\\\ucea0\\\\ud37c\\\\uc2a4 \\\\ub7ad\\\\uadf8\\\\ub798\\\\ud504\\\\ub85c \\\\ud55c\\\\ubc88\\\\uc5d0 \\\\uc644\\\\uc131\\\\ud558\\\\ub294 \\\\ubcf5\\\\uc7a1\\\\ud55c RAG\\\\uc640 Agent \\\\uacfc\\\\uc815\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-564cafb1-07aa-497a-ba3a-5574581a2535-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'}, 'id': 'ecb03e78-5aa2-40f9-95bf-f3cfde028a38', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 34, 'total_tokens': 120, 'input_token_details': {'cache_read': 0}}),\n",
              " ToolMessage(content='[{\"url\": \"https://fastcampus.co.kr/new\", \"content\": \"서강대학교 DX-AI miniMBA 과정. 15주 과정약 45시간직무경험 필요 ... 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간사전지식 필요.\"}, {\"url\": \"https://fastcampus.co.kr/data_online_langgraph\", \"content\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 #LLM#multi agent#RAG#랭그래프 결제 수단에 따라 무이자 할부가 불가할 수 있습니다. 복잡한 RAG와 Agent 설계를 완성하는 LangGraph 첫 걸음 5가지 Advanced AI agent 구축 프로젝트 약 16시간사전지식 필요 FC AWARD 본 패키지는 약 20시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다. 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다. 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다. 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다. 패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\"}, {\"url\": \"https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr\", \"content\": \"LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content) LinkedIn 회원 가입 로그인 과정 이름은 \\\\\"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr  LinkedIn Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\"}, {\"url\": \"https://fastcampus.co.kr/categories\", \"content\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 약 20시간사전지식 필요 ; 파인튜닝과 RAG로 완성하는 맞춤형 LLM 서비스 개발. 약 40시간누구나 ; 박준의 나만을 위한 AI\"}, {\"url\": \"https://fastcampus.co.kr/search?keyword=%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84\", \"content\": \"모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent ft. 5가지 Advanced AI ... 40+ · 딥러닝 · 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간\"}]', name='tavily_search_results_json', tool_call_id='ecb03e78-5aa2-40f9-95bf-f3cfde028a38', artifact={'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정', 'follow_up_questions': None, 'answer': 'The FastCampus course \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\" is designed to help learners complete complex RAG (Retrieval-Augmented Generation) and Agent systems using LangGraph. The course lasts for approximately 15 weeks and requires around 45 hours of work experience. It includes advanced projects to build five AI agents and is approximately 20 hours long, requiring about 16 hours of prior knowledge. The course offers a refund policy if the student does not complete five classes within the first seven days of enrollment. The course is part of the larger FastCampus offerings, including the DX-AI miniMBA program.', 'images': [], 'results': [{'url': 'https://fastcampus.co.kr/new', 'title': '[EVENT] 신규 강의 런칭 특가 - 패스트캠퍼스', 'content': '서강대학교 DX-AI miniMBA 과정. 15주 과정약 45시간직무경험 필요 ... 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간사전지식 필요.', 'score': 0.8891543, 'raw_content': None}, {'url': 'https://fastcampus.co.kr/data_online_langgraph', 'title': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent - 패스트캠퍼스', 'content': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 #LLM#multi agent#RAG#랭그래프 결제 수단에 따라 무이자 할부가 불가할 수 있습니다. 복잡한 RAG와 Agent 설계를 완성하는 LangGraph 첫 걸음 5가지 Advanced AI agent 구축 프로젝트 약 16시간사전지식 필요 FC AWARD 본 패키지는 약 20시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다. 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다. 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다. 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다. 패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.', 'score': 0.8785752, 'raw_content': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스\\nroot layout\\n패스트캠퍼스\\n Fast Campus\\n사용자 메뉴\\n로그인\\n커뮤니티기업교육\\n\\n인공지능딥러닝\\n랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\n평생소장\\n약 20시간\\n사전지식 필요\\nLangGraph 공부의 시작점이 되는 강의! 사람같은 AI 서비스, RAG, AI agent 개발에 필수스택이 된 랭그래프의 원리와 활용, LangGraph가 쓰이는 대표적인 use case 6가지까지.\\n#LLM#multi agent#RAG#랭그래프\\n강의 정보\\n온라인\\n5파트\\n25.02.24~ 영상 공개\\n\\n71%\\n월 19,084원\\n12개월 무이자 할부 시\\n결제 수단에 따라 무이자 할부가 불가할 수 있습니다.\\n권장 소비자 가격\\n~800,000원~\\n할인 금액\\n-571,000원\\n할인 판매가\\n229,000원\\n수강 신청하기수강 신청 버튼\\n마감까지\\xa05일__8시간__47분\\n랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\n찜하기\\n지금 최저가로 시작하세요! 복잡한 RAG와 Agent 설계를 완성하는 LangGraph 첫 걸음\\n마감까지\\xa05일__8시간__47분\\n수강 신청하기수강 신청 버튼\\n커리큘럼\\n파트 5개약 20시간\\n전부 접기교육과정소개서\\n\\n\\nPart 01. RAG와 AI Agent의 이해\\n01:00:00\\nCh 01. RAG와 AI Agent의 이해\\n01:00:00\\n\\n01. LLM 발전 동향00:20:00\\n02. LLM과 Agent00:20:00\\n03. 다양한 LLM Agent의 구조00:20:00\\nPart 02. LangGraph\\n\\n05:00:00\\nCh 01. LangGraph\\n05:00:00\\n\\n01. LangChain Tool Calling과 Agent00:40:00\\n02. LangGraph 소개00:20:00\\n03. LangGraph Node와 Edge, Graph 구조00:20:00\\n04. LangGraph의 다양한 State00:20:00\\n05. LangSmith와 LangGraph Studio00:20:00\\n01. 조건부 노드와 툴 노드 연결하기00:20:00\\n02. Agent의 Planning 구조: ReAct00:20:00\\n03. 다양한 그래프 구조00:40:00\\n04. 그래프 메모리 관리00:30:00\\n05. Human-in-the-Loop00:30:00\\n01. 멀티 에이전트 구조00:40:00\\nPart 03. LangGraph를 이용한 현업 적용 프로젝트\\n\\n06:40:00\\nCh 01. 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션\\n01:20:00\\n\\n01. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션00:40:00\\n02. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 (2)00:40:00\\n\\nCh 02. 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent\\n01:20:00\\n\\n01. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent00:40:00\\n02. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent (2)00:40:00\\n\\nCh 03. 비전 모델을 활용한 멀티모달 RAG Agent\\n01:20:00\\n\\n01. 3) 비전 모델을 활용한 멀티모달 RAG Agent00:40:00\\n02. 3) 비전 모델을 활용한 멀티모달 RAG Agent00:40:00\\n\\nCh 04. 멀티 에이전트 기반 Research Agent\\n01:20:00\\n\\n01. 4) 멀티 에이전트 기반 Research Agent00:40:00\\n02. 4) 멀티 에이전트 기반 Research Agent00:40:00\\n\\nCh 05. Code Interpreter를 이용한 내 파일 기반 차트 제너레이터\\n00:40:00\\n\\n01. 5) Code Interpreter를 이용한 내 파일 기반 차트 제너레이터00:40:00\\n\\nCh 06. 멀티 에이전트를 활용한 보고서 작성과 품질 평가 관리 시스템\\n00:40:00\\n\\n01. 6) 멀티 에이전트를 활용한 보고서 작성과 품질 평가 관리 시스템00:40:00\\nPart 04. LangGraph Application 배포하기\\n\\n02:00:00\\nCh 01. LangGraph Application 배포하기\\n02:00:00\\n\\n01. HuggingFace 공개 LLM을 활용한 Agentic Work 만들기00:40:00\\n02. Ollama/vLLM을 이용한 Agentic Work 최적화00:40:00\\n03. 만들어진 LangGraph Application 배포하기 (Streamlit/Gradio/ LangGraph Cloud)00:40:00\\nPart 05. [부록] LangChain과 LLM API\\n\\n03:40:00\\nCh 01. LLM API\\n00:40:00\\n\\n01. OpenAI와 Gemini API 사용하기00:40:00\\n\\nCh 02. LangChain 기초\\n03:00:00\\n\\n01. LangChain을 이용한 LLM 어플리케이션 만들기00:20:00\\n02. [실습] LangChain을 이용한 LLM 어플리케이션 만들기00:40:00\\n03. [실습] LangChain Expression Language00:40:00\\n04. Retrieval Augmented Generation 이해하기00:20:00\\n05. Retrieval Augmented Generation 이해하기 (2)00:20:00\\n06. [실습] LangChain을 이용한 RAG 구현하기00:40:00\\n\\n\\n\\n영상공개 일정\\xa0D-114\\n해당 강의는 총 4회에 걸쳐 공개됩니다.\\n1차2025.02.24(월)\\n2차2025.03.31(월)\\n3차2025.04.28(월)\\n최종2025.05.26(월)\\n이런 강의는 어떠세요?\\n지금 보는 강의와 유사해요!\\n 10+\\n딥러닝\\n프로에게 배우는 상업적인 AI 이미지·영상 제작 마스터 약 25시간누구나\\n 10+\\n딥러닝\\n모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent ft. 5가지 Advanced AI agent 구축 프로젝트 약 16시간사전지식 필요 FC AWARD\\n 10+\\n딥러닝\\n테디노트의 RAG 비법노트 : 랭체인을 활용한 GPT부터 로컬 모델까지의 RAG 가이드 약 66시간누구나 FC AWARD온라인\\n 10+\\n딥러닝\\n프로에게 배우는 ComfyUI 이미지/영상/게임/광고 제작 약 43시간사전지식 필요 FC AWARD온라인\\nprevious\\nnext\\n학습 규정 및 환불 규정\\n학습 규정\\n\\n* 본 상품은 동영상 형태의 강의를 수강하는 상품입니다.\\n* 상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\n* 해당 강의는 사전 예약 상품으로, 강의 영상이 공개 일정에 따라 순차적으로 제작되어 오픈됩니다.\\n총 학습기간:\\n\\n\\n정상 수강기간(유료 수강기간) 최초 30일, 무료 수강 기간은 31일 일차 이후로 무제한이며, 유료 수강기간과 무료 수강기간 모두 동일하게 시청 가능합니다.\\n\\n\\n본 패키지는 약 20시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다.\\n\\n\\n수강시작일: 수강 시작일은 결제일로부터 기간이 산정되며, 결제를 완료하시면 마이페이지를 통해 바로 수강이 가능합니다. (사전 예약 강의는 1차 강의 오픈일)\\n\\n\\n패스트캠퍼스의 사정으로 수강시작이 늦어진 경우에는 해당 일정 만큼 수강 시작일이 연기됩니다.\\n\\n\\n일부 강의는 아직 모든 영상이 공개되지 않았습니다. 각 상세페이지 하단에 공개 일정이 안내되어 있습니다.\\n\\n\\n주의 사항\\n\\n\\n\\n상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\n\\n\\n천재지변, 폐업 등 서비스 중단이 불가피한 상황에는 서비스가 종료될 수 있습니다.\\n\\n\\n본 상품은 기수강생 할인, VIP CLUB 제도 (구 프리미엄 멤버십), 기타 할인 이벤트 적용이 불가할 수 있습니다.\\n\\n\\n커리큘럼은 제작 과정에서 일부 추가, 삭제 및 변경될 수 있습니다.\\n\\n\\n쿠폰 적용이나 프로모션 등으로 인해 5만원 이하의 금액으로 강의를 결제할 경우, 할부가 적용되지 않습니다.\\n\\n\\n환불 규정\\n\\n\\n\\n환불금액은 정가가 아닌 실제 결제금액을 기준으로 계산됩니다.\\n\\n\\n쿠폰을 사용하여 강의를 결제하신 후 취소/환불 시 쿠폰은 복구되지 않습니다.\\n\\n\\n수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다.\\n\\n\\n수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다.\\n\\n\\n수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다.\\n\\n\\n환불요청일 시 기준\\n\\n\\n: 수강시작 후 1/3 경과 전, 실 결제금액의 2/3에 해당하는 금액 환불\\n\\n\\n: 수강시작 후 1/2 경과 전, 실 결제금액의 1/2에 해당하는 금액 환불\\n\\n\\n: 수강시작 후 1/2 경과 후, 환불 금액 없음\\n\\n\\n\\n\\n* 보다 자세한 환불 규정은 홈페이지 취소/환불 정책에서 확인 가능합니다.\\n패스트캠퍼스 정책 안내\\n\\n[패스트캠퍼스 아이디 공유 금지 정책]\\n패스트캠퍼스의 모든 온라인 강의에서는 1개의 아이디로 여러명이 공유하는 형태를 금지하고 있습니다.\\n동시접속에 대한 기록은 내부 시스템을 통해 자동으로 누적되며, 이후 서비스 이용이 제한될 수 있습니다.\\n[기기제한 정책]\\n패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\\n최대 갯수를 초과하였을 경우 등록된 기기 해제가 필요합니다.\\n[저작권 정책]\\n패스트캠퍼스의 모든 강의는 무단 배포 및 가공하는 행위, 캡쳐 및 녹화하여 공유하는 행위, 무단으로 판매하는 행위 등 일체의 저작권 침해 행위를 금지합니다.\\n부정 사용이 적발될 경우 저작권법 위반에 의한 법적인 제재를 받으실 수 있습니다.\\n국내 8개 카드사 12개월 무이자 할부 지원! (간편 결제 제외)\\n\\n삼성카드\\n신한카드\\n롯데카드\\n현대카드\\n하나카드\\nBC카드\\nKB국민은행\\nNH농협카드\\n\\n※ BC카드의 경우, 비씨(페이북)을 선택하여 결제시에만 12개월 무이자 할부가 가능합니다.\\n(BC계열 - 우리/제일/기업/대구/경남/부산/광주/수협/전북/제주/신협)\\n\\n\\n회사소개\\n\\n\\n강사지원\\n\\n\\n채용안내\\n\\n\\n인재추천\\n\\n\\nFAST CAMPUS(주) 데이원컴퍼니\\n\\n대표이사\\n이강민\\n개인정보책임관리자\\n이강민\\n사업자번호\\n810-86-00658\\n사업자정보확인\\n사무실\\n서울특별시 강남구 테헤란로 231, 센터필드 WEST 6층, 7층\\n교육장\\n서울특별시 강남구 강남대로 364 미왕빌딩 10, 11층\\n\\n\\n이용약관\\n\\n\\n개인정보처리방침\\n\\n\\nFAQ\\n\\n\\n취소/환불 정책\\n\\n\\n자료실\\n\\n\\n공지사항\\n\\n\\n장학프로그램\\n\\n\\n고객센터 바로가기\\n\\n전화번호 02-501-9396\\n이메일\\xa0help@fastcampus.co.kr\\n주중 10시~18시 (점심시간 12~13시 / 주말 및 공휴일 제외)\\n\\n호스팅 서비스 제공\\n(주) 데이원컴퍼니\\n통신판매업 신고번호\\n제 2017-서울강남-01977호\\n학원설립 운영등록번호\\n제12484호(강남)\\n원격평생교육원\\n제 572호'}, {'url': 'https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr', 'title': 'LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 ...', 'content': 'LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content) LinkedIn 회원 가입 로그인 과정 이름은 \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr  LinkedIn Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.', 'score': 0.87218446, 'raw_content': 'LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스\\nLinkedIn 동의 후 가입\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\\n  [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content)\\n\\nLinkedIn\\n\\n글\\n사람\\n온라인클래스\\n채용공고\\n게임\\n앱 다운로드\\n\\n회원 가입 로그인\\nHyungho Byun님의 업데이트\\n\\nHyungho Byun\\n노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\n1주\\n\\n글 신고\\n\\n안녕하세요! 노토랩의 변형호입니다.\\xa0 오늘 OpenAI의 웹 탐색 기능이 탑재된 에이전트 오퍼레이터(Operator)가 공개되었는데요. 이에 맞춰서 광고를 좀 하겠습니다..😅 제가 패스트캠퍼스에서 LangGraph에 대한 온라인 강의를 런칭합니다. 과정 이름은 \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프가 랭체인보다 좀 어렵긴 한데요... 단계별로 쉽게 이해할 수 있는 강의를 준비했습니다! RAG가 결합된 복잡한 시스템이나, 스탠포드 스톰(STORM)과 같은 멀티 에이전트 구조를 만들고 싶으신 분들께는 많은 도움이 되실 것 같습니다. 실무에서 활용할 수 있는 6개의 프로젝트를 중심으로 복잡한 그래프 구조, 휴먼인더루프, 품질 검증과 같은 요소들도 아주 세세하게 다룰 예정이구요. 또한, LLM 기본 코드 지식이 필요하신 분들을 위한 랭체인, LLM API 활용 챕터도 부록으로 준비했습니다. 1차 공개 일정은 2월 24일이라 아직 여유가 좀 있는데요(?) 관심 있으신 분들은 https://bit.ly/40lXEj2 에서 자세한 내용을 확인하실 수 있습니다. 아래의 쿠폰코드를 입력하시면 20% 할인 가능합니다! PRDTEA250124_sns202 LangChain의 기초, LLM과 Agent에 대한 샘플 영상 2개도 같이 업로드했는데요. 이 영상은 댓글에 올려 놓겠습니다. 다음 포스팅은 다시 이전처럼 기술 이야기로 뵙겠습니다. 감사합니다! 😁\\n 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr \\n  36 댓글 2\\n추천 댓글 \\n공유\\n\\n복사\\nLinkedIn\\nFacebook\\nTwitter\\n\\n\\nHyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\n1주\\n\\n댓글 신고\\n\\nhttps://youtu.be/yLOjUf_XH1o?si=NZ2r8AlLoTk0s2C1\\n추천댓글반응\\xa01\\n\\nHyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\n1주\\n\\n댓글 신고\\n\\nhttps://youtu.be/sUZ9LPK7fY4?si=ccTDrvW_NNZfhktx\\n추천댓글반응\\xa01\\n더 보기댓글을 보거나 남기려면 로그인\\n\\n팔로워 1,125명\\n\\n업데이트 34개\\n\\n프로필 보기 팔로우\\n\\nLinkedIn © 2025\\n정보\\n웹접근성\\n사용자약관\\n개인정보 처리방침\\nYour California Privacy Choices\\n쿠키정책\\n저작권정책\\n브랜드정책\\n비회원 설정\\n커뮤니티정책\\n\\n\\n아랍어(العربية)\\n벵골어(বাংলা)\\n체코어(Čeština)\\n덴마크어(Dansk)\\n독일어(Deutsch)\\n그리스어(Ελληνικά)\\n영어(English)\\n스페인어(Español)\\n페르시아어(فارسی)\\n핀란드어(Suomi)\\n프랑스어(Français)\\n힌디어(हिंदी)\\n헝가리어(Magyar)\\n인도네시아어(Bahasa Indonesia)\\n이탈리아어(Italiano)\\n히브리어(עברית)\\n일본어(日本語)\\n한국어(Korean)\\n마라티어(मराठी)\\n말레이시아어(Bahasa Malaysia)\\n네덜란드어(Nederlands)\\n노르웨이어(Norsk)\\n펀자브어(ਪੰਜਾਬੀ)\\n폴란드어(Polski)\\n포르투갈어(Português)\\n루마니아어(Română)\\n러시아어(Русский)\\n스웨덴어(Svenska)\\n텔루구어(తెలుగు)\\n태국어(ภาษาไทย)\\n필리핀어(Tagalog)\\n터키어(Türkçe)\\n우크라이나어(Українська)\\n베트남어(Tiếng Việt)\\n중국어 간체(简体中文)\\n중국어 번체(正體中文)\\n\\n언어\\n\\n\\n\\n로그인해서 콘텐츠 더보기\\n무료 계정을 만들거나 로그인하여 검색을 계속하세요.\\n로그인\\n어서오세요!\\n이메일 또는 전화\\n비밀번호\\n표시\\n비밀번호를 잊으셨나요?  로그인\\n또는\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\\nLinkedIn이 처음이세요? 회원 가입\\n또는\\nLinkedIn이 처음이세요? 회원 가입\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.'}, {'url': 'https://fastcampus.co.kr/categories', 'title': '커리어 성장을 위한 최고의 실무교육 아카데미 - 패스트캠퍼스', 'content': '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 약 20시간사전지식 필요 ; 파인튜닝과 RAG로 완성하는 맞춤형 LLM 서비스 개발. 약 40시간누구나 ; 박준의 나만을 위한 AI', 'score': 0.8719229, 'raw_content': None}, {'url': 'https://fastcampus.co.kr/search?keyword=%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84', 'title': '랭그래프 검색 결과 - 패스트캠퍼스', 'content': '모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent ft. 5가지 Advanced AI ... 40+ · 딥러닝 · 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간', 'score': 0.8506799, 'raw_content': None}], 'response_time': 3.2})]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "messages = [HumanMessage(content=\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\")]\n",
        "\n",
        "messages.append(tool_call_msg)\n",
        "messages.append(tool_msg)\n",
        "\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca501e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ca501e7",
        "outputId": "86307a7c-750d-49c1-c984-f149f1022752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"url\": \"https://fastcampus.co.kr/new\", \"content\": \"서강대학교 DX-AI miniMBA 과정. 15주 과정약 45시간직무경험 필요 ... 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간사전지식 필요.\"}, {\"url\": \"https://fastcampus.co.kr/data_online_langgraph\", \"content\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 #LLM#multi agent#RAG#랭그래프 결제 수단에 따라 무이자 할부가 불가할 수 있습니다. 복잡한 RAG와 Agent 설계를 완성하는 LangGraph 첫 걸음 5가지 Advanced AI agent 구축 프로젝트 약 16시간사전지식 필요 FC AWARD 본 패키지는 약 20시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다. 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다. 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다. 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다. 패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\"}, {\"url\": \"https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr\", \"content\": \"LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content) LinkedIn 회원 가입 로그인 과정 이름은 \\\"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,  랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr  LinkedIn Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\"}, {\"url\": \"https://fastcampus.co.kr/categories\", \"content\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 약 20시간사전지식 필요 ; 파인튜닝과 RAG로 완성하는 맞춤형 LLM 서비스 개발. 약 40시간누구나 ; 박준의 나만을 위한 AI\"}, {\"url\": \"https://fastcampus.co.kr/search?keyword=%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84\", \"content\": \"모두의 AI 케인의 LangGraph로 끝내는 멀티 AI Agent ft. 5가지 Advanced AI ... 40+ · 딥러닝 · 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent. 평생소장약 20시간\"}]\n"
          ]
        }
      ],
      "source": [
        "print(messages[2].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae6c7f1a",
      "metadata": {
        "id": "ae6c7f1a"
      },
      "source": [
        "`Query-Tool Call-Tool`의 형식은 가장 기본적인 툴 사용 방법입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b67cf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43b67cf9",
        "outputId": "2070a8dd-30ab-455b-e31a-0fd1403ee737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패스트캠퍼스의 \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\" 과정은 다음과 같은 특징을 가진 것으로 보입니다:\n",
            "\n",
            "*   **주요 내용:** LangGraph 라이브러리를 사용하여 복잡한 RAG (Retrieval-Augmented Generation) 및 Agent 설계를 완성하는 방법을 다룹니다. LangGraph는 LLM 어플리케이션 개발에서 복잡한 워크플로우를 구성하고 관리하는 데 유용한 라이브러리입니다.\n",
            "*   **학습 목표:** Advanced AI agent 구축 프로젝트를 통해 RAG와 Agent 설계를 익히는 것을 목표로 합니다.\n",
            "*   **수강 시간:** 약 20시간 분량으로 구성되어 있습니다.\n",
            "*   **사전 지식:** 사전 지식이 필요한 과정입니다.\n",
            "*   **환불 정책:**\n",
            "    *   수강 시작 후 7일 이내, 5강 미만 수강 시 100% 환불 가능합니다.\n",
            "    *   수강 시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다.\n",
            "    *   수강 시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 환불 규정에 따라 환불 가능합니다.\n"
          ]
        }
      ],
      "source": [
        "result = llm_with_tools.invoke(messages)\n",
        "# 검색 결과를 바탕으로 답변한 모습\n",
        "\n",
        "print(result.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a13f430",
      "metadata": {
        "id": "8a13f430"
      },
      "source": [
        "이제, 지금까지 배운 내용을 종합하여 실행해 보겠습니다.   \n",
        "질문이 주어지면, 질문에 대한 검색을 수행하여 결과를 바탕으로 답변합니다.   \n",
        "\n",
        "<br><br>\n",
        "\n",
        "그런데, 이번에는 분기가 필요합니다.   \n",
        "검색이 필요없는 질문이라면, LLM은 tool을 요청하지 않을 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e288199c",
      "metadata": {
        "id": "e288199c"
      },
      "outputs": [],
      "source": [
        "# LLM, Question, Tool을 이용한 간단한 함수\n",
        "def simple_workflow(llm, question , tools = [tavily_search]):\n",
        "\n",
        "    # 툴과 LLM 구성\n",
        "\n",
        "    tool_list = {x.name: x for x in tools}\n",
        "    # tavily_search.name = 'tavily_search_results_json' 을 이용하면\n",
        "    # tool_list = {'tavily_search_results_json': tavily_search} 와 동일합니다.\n",
        "\n",
        "    llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "    # 메시지 구성\n",
        "    messages = [HumanMessage(content=question)]\n",
        "    print('Query:', question)\n",
        "\n",
        "\n",
        "    # LLM에 메시지 전달 (분기)\n",
        "    tool_msg = llm_with_tools.invoke(question)\n",
        "    messages.append(tool_msg)\n",
        "\n",
        "    if tool_msg.tool_calls:\n",
        "        # 툴 호출이 있을 경우: 툴 실행 후 결과를 전달\n",
        "        tool_name = tool_msg.tool_calls[0]['name']\n",
        "\n",
        "        print(f\"-- {tool_name} 사용 중 --\")\n",
        "        print(tool_msg.tool_calls[0])\n",
        "\n",
        "\n",
        "        tool_exec = tool_list[tool_name]\n",
        "\n",
        "        tool_result = tool_exec.invoke(tool_msg.tool_calls[0])\n",
        "        messages.append(tool_result)\n",
        "        result = llm_with_tools.invoke(messages)\n",
        "\n",
        "    else:\n",
        "        # 툴 호출이 없을 경우: 처음 출력을 그대로 전달\n",
        "        result = tool_msg\n",
        "\n",
        "    return result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abf28c6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abf28c6f",
        "outputId": "b374b360-cf0d-4c7a-b6f3-cc9d6a590dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정인지 검색해줘.\n",
            "-- tavily_search_results_json 사용 중 --\n",
            "{'name': 'tavily_search_results_json', 'args': {'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'}, 'id': '00dad3d8-66f9-4178-bc92-32f295bb4c58', 'type': 'tool_call'}\n",
            "패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 다음과 같은 특징을 가지고 있습니다:\n",
            "\n",
            "*   **주요 내용:** 복잡한 RAG (Retrieval-Augmented Generation) 및 Agent 설계를 LangGraph를 사용하여 완성하는 방법을 다룹니다. LangGraph는 LLM 어플리케이션 개발을 위한 라이브러리이며, 복잡한 워크플로우를 구성하고 관리하는 데 유용합니다.\n",
            "*   **분량:** 약 20시간 분량이며, 일 1시간 내외의 학습으로 수강 기간 내에 완료할 수 있습니다.\n",
            "*   **환불 규정:** 수강 시작 후 7일 이내, 5강 미만 수강 시 100% 환불 가능하며, 5강 이상 수강 시에는 수강한 강의 비율에 따라 환불 금액이 달라집니다. 7일 초과 시에는 잔여일에 따라 환불 규정이 적용됩니다.\n",
            "*   **기기 등록:** ID별 최대 4개의 기기를 등록하여 온라인 강의를 시청할 수 있습니다.\n",
            "*   **사전 지식:** 사전 지식이 필요합니다.\n",
            "\n",
            "이 과정은 LLM (Large Language Model) 어플리케이션 개발에 관심 있는 사람들에게 유용할 것으로 보입니다. 특히, 랭체인(LangChain)을 사용하여 개발해 본 경험이 있다면 LangGraph를 통해 더욱 복잡한 워크플로우를 구축하고 관리하는 데 도움이 될 것입니다.\n"
          ]
        }
      ],
      "source": [
        "response = simple_workflow(llm, \"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정인지 검색해줘.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7536b3b4",
      "metadata": {
        "id": "7536b3b4"
      },
      "source": [
        "# Custom Tool 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90ba141",
      "metadata": {
        "id": "a90ba141"
      },
      "source": [
        "Tavily Search의 경우, 랭체인에서 사전에 구성한 기본 Schema가 존재하지만,   \n",
        "\n",
        "Tool을 새로 만드는 경우에는 description과 같은 값을 직접 구성해야 합니다.   \n",
        "가장 간단한 방식은 랭체인의 Tool 데코레이터를 사용하는 것입니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb6c405",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eb6c405",
        "outputId": "0fd8a3a7-c106-45d7-f8de-4999bd0448a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "2025-02-09\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(x:int, y:int) -> int:\n",
        "    \"x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.\"\n",
        "    return x*y\n",
        "\n",
        "@tool\n",
        "def current_date() -> str:\n",
        "    \"현재 날짜를 %y-%m-%d 형식으로 반환합니다.\"\n",
        "    from datetime import datetime\n",
        "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "print(multiply.invoke({'x':3, 'y':4}))\n",
        "print(current_date.invoke({}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35816c99",
      "metadata": {
        "id": "35816c99"
      },
      "outputs": [],
      "source": [
        "tools = [tavily_search, multiply, current_date]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4da3bb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "b4da3bb1",
        "outputId": "bdcae01d-0d14-4135-e751-9d296f60b796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 오늘 날짜는?\n",
            "-- current_date 사용 중 --\n",
            "{'name': 'current_date', 'args': {}, 'id': '5a99c703-7a3e-4e79-ab7a-06985148b47e', 'type': 'tool_call'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'오늘 날짜는 2025-02-09 입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "question = '오늘 날짜는?'\n",
        "\n",
        "result = simple_workflow(llm, question, tools)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ee0e6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f4ee0e6c",
        "outputId": "4c53d785-2c1c-40d3-81e5-41d3a33d0c3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'오늘 날짜는 2024년 5월 15일입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# LLM은 오늘 날짜를 모른다\n",
        "llm.invoke('오늘 날짜는?').content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f57f601",
      "metadata": {
        "id": "8f57f601"
      },
      "source": [
        "<br><br>\n",
        "## [연습문제] 복권 숫자 예측시키기\n",
        "\n",
        "아래의 함수에 대해, 함수의 설명을 추가하여 llm의 툴로 전달해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080e67e9",
      "metadata": {
        "id": "080e67e9"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import random\n",
        "\n",
        "@tool\n",
        "def generate_random_numbers(min_val: int, max_val: int, count: int) -> List[int]:\n",
        "    \"\"\"주어진 범위 내에서 지정된 개수만큼의 중복되지 않은 랜덤 정수를 생성합니다.\n",
        "    Args:\n",
        "        min_val (int): 최솟값\n",
        "        max_val (int): 최댓값\n",
        "        count (int): 생성할 숫자의 개수\n",
        "\n",
        "    Returns:\n",
        "        List[int]: 중복되지 않은 랜덤 정수들의 리스트\n",
        "    \"\"\"\n",
        "    # possible_range = max_val - min_val + 1\n",
        "    # if count > possible_range:\n",
        "    #     raise ValueError(f\"생성 가능한 숫자의 범위({possible_range}개)보다 더 많은 숫자({count}개)를 요청했습니다.\")\n",
        "\n",
        "    return str(random.sample(range(min_val, max_val + 1), count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44141920",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44141920",
        "outputId": "2242dafb-3452-4280-c3e2-5961969e8544"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'generate_random_numbers', 'arguments': '{\"min_val\": 1.0, \"count\": 6.0, \"max_val\": 45.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-50feaf9d-5641-4b85-898d-ce7c57acaef8-0', tool_calls=[{'name': 'generate_random_numbers', 'args': {'min_val': 1.0, 'count': 6.0, 'max_val': 45.0}, 'id': '4de8b8b1-edd2-478f-aa2a-f79e926f6334', 'type': 'tool_call'}], usage_metadata={'input_tokens': 137, 'output_tokens': 12, 'total_tokens': 149, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# LLM에 함수 Bind\n",
        "\n",
        "llm_lotto = llm.bind_tools([generate_random_numbers])\n",
        "llm_lotto.invoke('로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a72060",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "a5a72060",
        "outputId": "747a7dc9-45b7-4435-d963-465e1c81ae90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.\n",
            "-- generate_random_numbers 사용 중 --\n",
            "{'name': 'generate_random_numbers', 'args': {'min_val': 1.0, 'count': 6.0, 'max_val': 45.0}, 'id': 'b0d1ba38-0783-4b2d-8420-0780bf88ea66', 'type': 'tool_call'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'로또 번호는 10, 27, 39, 30, 20, 14 입니다!\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# simple_workflow 함수를 이용하여 실행하기\n",
        "\n",
        "simple_workflow(llm_lotto, '로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.', [generate_random_numbers])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c9696e",
      "metadata": {
        "id": "c9c9696e"
      },
      "source": [
        "우리가 만든 `simple_workflow` 함수는 가장 간단한 형태의 Single Tool Calling을 수행하는 방식이었는데요.   \n",
        "\n",
        "실제 환경의 시나리오는 훨씬 복잡합니다.   \n",
        "한 번에 여러 개의 툴을 실행하거나, 툴 실행 결과를 받아 다음 툴에 활용할 수도 있을 것입니다.   \n",
        "\n",
        "랭체인에서도 이와 같이 복잡한 작업을 수행하기 위한 기능이 자체적으로 구현되어 있는데요.    \n",
        "\n",
        "예시로 `Structured Chat Agent`를 간단하게 만들고 실행해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7c8ac8",
      "metadata": {
        "id": "9f7c8ac8"
      },
      "source": [
        "# Agent\n",
        "\n",
        "생각-행동-관찰을 거치는 ReAct 에이전트는 복잡한 플로우를 효과적으로 처리합니다.   \n",
        "- 생각(Thought): 주어진 Context 상에서 다음 작업을 어떻게 수행할지 설명하는 과정\n",
        "- 행동(Action): Tool 실행 명령어를 생성하는 과정\n",
        "- 관찰(Thought): Tool 결과를 Context에 추가하는 과정\n",
        "\n",
        "\n",
        "이 과정은 랭체인에 구성된 `crate_structured_chat_agent`를 이용해 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08100d1",
      "metadata": {
        "id": "d08100d1"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 채팅 프롬프트 템플릿: 메시지의 템플릿을 구성하고 입력 변수만 전달하는 구조\n",
        "agent_prompt = ChatPromptTemplate([\n",
        "    ('system','''\n",
        "최대한 정확히 질문에 답변하세요. 당신은 다음의 툴을 사용할 수 있습니다:\n",
        "{tools}\n",
        "\n",
        "action 키 (tool name)와 action_input 키를 포함하는 json 형태로 출력하세요.\n",
        "\n",
        "action의 값은 \"Final Answer\" 또는 {tool_names} 중 하나여야 합니다.\n",
        "반드시 하나의 json 형태만 출력하세요. 다음은 예시입니다.\n",
        "```\n",
        "{{\n",
        "\n",
        "  \"action\": $TOOL_NAME,\n",
        "\n",
        "  \"action_input\": $INPUT\n",
        "\n",
        "}}\n",
        "```\n",
        "\n",
        "아래의 포맷으로 답변하세요.:\n",
        "\n",
        "Question: 최종적으로 답변해야 하는 질문\n",
        "Thought: 무엇을 해야 하는지를 항상 떠올리세요.\n",
        "Action:\n",
        "```\n",
        "$JSON_BLOB\n",
        "```\n",
        "Observation: 액션의 실행 결과\n",
        "... (이 Thought/Action/Observation 은 10번 이내로 반복될 수 있습니다.)\n",
        "\n",
        "Thought: 이제 답을 알겠다!\n",
        "Action:\n",
        "```\n",
        "{{\n",
        "  \"action\": \"Final Answer\",\n",
        "  \"action_input\": \"Final response to human\"\n",
        "}}\n",
        "```\n",
        "'''),\n",
        "('user','''Question: {input}\n",
        "Thought: {agent_scratchpad}''')])\n",
        "\n",
        "\n",
        "agent = create_structured_chat_agent(llm, tools, agent_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef500238",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef500238",
        "outputId": "cd7afeb9-9f70-43a3-f9a7-aa16a76a9867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOpen Source Multimodal LLM 모델을 추천해달라는 요청을 받았습니다. 어떤 모델이 있는지 검색을 통해 알아봐야겠습니다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"tavily_search_results_json\",\n",
            "  \"action_input\": \"open source multimodal large language model\"\n",
            "}\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.infoq.com/news/2024/10/nvlm-nvidia-open-source/', 'content': \"NVIDIA Unveils NVLM 1.0: Open-Source Multimodal LLM with Improved Text and Vision Capabilities - InfoQ InfoQ Homepage News NVIDIA Unveils NVLM 1.0: Open-Source Multimodal LLM with Improved Text and Vision Capabilities NVIDIA unveiled NVLM 1.0, an open-source multimodal large language model (LLM) that performs on both vision-language and text-only tasks. NVIDIA's decision to open-source the model is a game-changer, giving smaller teams access to cutting-edge technology and pushing the boundaries of AI development! By making the model weights publicly available and promising to release the training code, Nvidia breaks from the trend of keeping advanced AI systems closed. NVLM 1.0 is available for the AI community as an open-source AI model, with model\\xa0weights accessible through Hugging Face. InfoQ AI, ML and Data Engineering Trends Report - September 2024\"}, {'url': 'https://medium.com/@tenyks_blogger/multimodal-large-language-models-mllms-transforming-computer-vision-76d3c5dd267f', 'content': 'What is it: LLaVA (Large Language and Vision Assistant) is an open-source multimodal AI model that can process and generate both text and visual'}, {'url': 'https://thenewstack.io/5-multimodal-ai-models-that-are-actually-open-source/', 'content': 'AI Large Language Models Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security 5 Multimodal AI Models That Are Actually Open Source Dec 13th 2024 6:00am, by Kimberley Mok Observability and AI: New Connections at KubeCon Dec 5th 2024 10:30am, by Heather Joslyn and Lawrence E Hecht AWS Launches New AI Agents To Simplify Legacy Migrations Dec 4th 2024 11:30am, by Loraine Lawson Running AI Models Without GPUs on Serverless Platforms Nov 25th 2024 1:37pm, by Rak Siva AI Large Language Models Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security AI Large Language Models Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security'}, {'url': 'https://discuss.huggingface.co/t/are-there-any-multi-modal-llms-which-are-open-sourced/46172', 'content': 'Are there any multi modal LLMs which are open sourced? - 🤗Transformers - Hugging Face Forums Topics To lift those restrictions, just spend time reading other posts (to be precise, enter 5 topics, read through 30 posts and spend a total of 10 minutes reading). Start with reading this post. Are there any multi modal LLMs which are open sourced? You have selected 0 posts. select all Are there any multi-modal LLMs which are open sourced? You could check out open flamingo or Awesome-Multimodal-Large-Language-Models Related topics | Topic | Replies | Views | Activity | | Open Source LLMs: Your experience and recommendation | Is there anything built with open source llms that is not experimental?'}, {'url': 'https://www.bentoml.com/blog/multimodal-ai-a-guide-to-open-source-vision-language-models', 'content': 'Available in 11B and 90B parameter sizes, Llama 3.2 Vision outperforms many open-source and proprietary models in image-text tasks. Multimodal capabilities: Llama 3.2 Vision can perform image-text tasks, including generating captions, answering image-based questions, and complex visual reasoning. Powerful image reasoning: NVLM 1.0 surpasses many proprietary and open-source models in tasks such as OCR, multimodal reasoning, and high-resolution image handling. Unlike previous open-source models, Pixtral maintains excellent text benchmark performance while excelling in multimodal tasks. Outstanding instruction following capability: Benchmark results indicate that Pixtral 12B significantly outperforms other open-source multimodal models like Qwen2-VL 7B, LLaVa-OneVision 7B, and Phi-3.5 Vision in instruction following tasks. Not all model serving and deployment frameworks are designed to handle multimodal inputs, such as text, images, and videos.'}]\u001b[0m\u001b[32;1m\u001b[1;3m여러 검색 결과들을 바탕으로 다음과 같은 Open Source Multimodal LLM 모델들을 추천합니다:\n",
            "\n",
            "*   **NVLM 1.0**: NVIDIA에서 공개한 오픈 소스 멀티모달 LLM입니다. 텍스트와 비전 작업 모두에서 뛰어난 성능을 보이며, Hugging Face를 통해 모델 가중치를 이용할 수 있습니다.\n",
            "*   **LLaVA (Large Language and Vision Assistant)**: 텍스트와 시각 정보를 모두 처리하고 생성할 수 있는 오픈 소스 멀티모달 AI 모델입니다.\n",
            "*   **Llama 3.2 Vision**: 이미지-텍스트 작업을 수행할 수 있으며, 11B 및 90B 파라미터 크기로 제공됩니다.\n",
            "*   **Pixtral**: 뛰어난 텍스트 벤치마크 성능을 유지하면서 멀티모달 작업에서 뛰어난 성능을 보입니다. 특히 instruction following 작업에서 다른 오픈 소스 멀티모달 모델보다 우수한 성능을 보입니다.\n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"추천하는 Open Source Multimodal LLM 모델은 다음과 같습니다: NVLM 1.0, LLaVA (Large Language and Vision Assistant), Llama 3.2 Vision, Pixtral.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Open Source Multimodal LLM Model 추천해줘',\n",
              " 'output': '추천하는 Open Source Multimodal LLM 모델은 다음과 같습니다: NVLM 1.0, LLaVA (Large Language and Vision Assistant), Llama 3.2 Vision, Pixtral.'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True\n",
        ")\n",
        "\n",
        "agent_executor.invoke({'input':\"Open Source Multimodal LLM Model 추천해줘\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e00b3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53e00b3e",
        "outputId": "b4bf62fe-eab3-4949-bd67-c084a06a5ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m레오나르도 디카프리오의 출생년도를 먼저 찾아야 한다. 그런 다음, 해당 연도의 각 숫자를 곱해야 한다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"tavily_search_results_json\",\n",
            "  \"action_input\": \"leonardo dicaprio birth year\"\n",
            "}\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://en.wikipedia.org/wiki/Leonardo_DiCaprio', 'content': \"Leonardo Wilhelm DiCaprio was born on November 11, 1974, in Los Angeles. · DiCaprio's parents named him Leonardo because his pregnant mother first felt him kick\"}, {'url': 'https://www.biography.com/actors/leonardo-dicaprio', 'content': 'Born on November 11, 1974, in Los Angeles, Leonardo Wilhelm DiCaprio is the only child of Irmelin and George DiCaprio.'}, {'url': 'https://www.famousbirthdays.com/people/leonardo-dicaprio.html', 'content': \"Video\\nPopularity\\nLeonardo DiCaprio Movies\\nRomeo + Juliet\\nTitanic\\nThe Great Gatsby\\nLeonardo DiCaprio Fans Also Viewed\\nKate Winslet\\nMovie Actor\\nBar Refaeli\\nMovie Actor\\nKirk Cameron\\nMovie Actor\\nClaire Danes\\nMovie Actor\\nMore November 11 Birthdays\\nRichboy. Leonardo DiCaprio\\nMovie Actor\\nBirthday\\nNovember 11, 1974\\nBirth Sign\\nScorpio\\nBirthplace\\nLos Angeles,\\nCA\\nAge\\n49 years old\\n#140\\nMost Popular\\nAbout\\nActor who first rose to prominence for his roles in the 1990's films\\xa0What's Eating Gilbert Grape,\\xa0Romeo + Juliet\\xa0and\\xa0Titanic. Troy\\nInstagram Star\\nIan Boggs\\nTikTok Star\\nMore Scorpios\\nPewDiePie\\nYouTube Star\\nSZA\\nR&B Singer\\n© FamousBirthdays.com - use subject to the practices disclosed in our privacy policy.\\n Associated With\\nHe became a favorite actor of acclaimed director Martin Scorsese, starring in Scorsese's films\\xa0Gangs of New York, The Aviator, The Departed,\\xa0Shutter Island\\xa0and The Wolf of Wall Street.\\n His roles as Howard Hughes in\\xa0The Aviator\\xa0and as Jordan Belfort in\\xa0The Wolf of Wall Street\\xa0earned him Golden Globe Awards for Best Actor.\\n\"}, {'url': 'https://www.geni.com/people/Leonardo-DiCaprio/6000000009019102421', 'content': 'DiCaprio was born on November 11, 1974, in Los Angeles, California. He is the only child of Irmelin Indenbirken, a legal secretary, and George DiCaprio.'}, {'url': 'https://www.myagecalculator.com/how-old-is-leonardo-dicaprio', 'content': 'Leonardo DiCaprio was born on 11 November 1974. Leonardo DiCaprio is 50 years old. How old is Leonardo DiCaprio in days now?'}]\u001b[0m\u001b[32;1m\u001b[1;3m레오나르도 디카프리오의 출생년도는 1974년이다. 이제 1 * 9 * 7 * 4를 계산해야 한다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"multiply\",\n",
            "  \"action_input\": {\n",
            "    \"x\": 1,\n",
            "    \"y\": 9\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m9\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"multiply\",\n",
            "  \"action_input\": {\n",
            "    \"x\": 9,\n",
            "    \"y\": 7\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m63\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"multiply\",\n",
            "  \"action_input\": {\n",
            "    \"x\": 63,\n",
            "    \"y\": 4\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m252\u001b[0m\u001b[32;1m\u001b[1;3m이제 답을 알겠다!\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"레오나르도 디카프리오의 출생년도는 1974년이며, 각 숫자를 곱한 결과는 252입니다.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.',\n",
              " 'output': '레오나르도 디카프리오의 출생년도는 1974년이며, 각 숫자를 곱한 결과는 252입니다.'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "agent_executor.invoke({'input':\"레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e2c8f4",
      "metadata": {
        "id": "84e2c8f4"
      },
      "source": [
        "랭체인의 에이전트 구조는 매우 간결하지만, 컨트롤하기가 매우 어려운데요.    \n",
        "실제로 우리가 개발하는 구조에서는, 모든 단계에서 LLM이 컨텍스트를 저장하여 판단을 내릴 필요는 없습니다.   \n",
        "또한, 모든 과정이 자연어로 구성되기 때문에 중간에 파싱 오류가 발생하는 경우에 동작이 멈추기도 합니다.   \n",
        "\n",
        "\n",
        "특정 작업을 반복 실행하거나, 정해진 순서에 따라 실행해야 하는 상황이라면 어떻게 해야 할까요?    \n",
        "랭체인으로 이와 같은 기능을 구현하는 것도 가능하지만, 다소 복잡한데요.   \n",
        "\n",
        "\n",
        "랭그래프를 이용하면 구체적인 Workflow를 바탕으로 Agent 형태의 어플리케이션을 효과적으로 만들 수 있습니다.   \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "multicampus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
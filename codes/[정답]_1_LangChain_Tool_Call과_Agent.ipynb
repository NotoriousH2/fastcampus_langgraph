{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bc217b6",
      "metadata": {
        "id": "1bc217b6"
      },
      "source": [
        "# [실습] LangChain Tool Call과 Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478a9e3f",
      "metadata": {
        "id": "478a9e3f"
      },
      "source": [
        "LangChain의 기본 코드를 통해, Tool Call과 Agent가 작동하는 과정에 대해 알아보겠습니다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479674c4",
      "metadata": {
        "id": "479674c4",
        "vscode": {
          "languageId": "sql"
        }
      },
      "source": [
        "기본 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0f9a52c8",
      "metadata": {
        "id": "0f9a52c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.2)\n",
            "Requirement already satisfied: langchain_google_genai in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: langchain_core in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (0.4)\n",
            "Collecting langchain_tavily\n",
            "  Downloading langchain_tavily-0.2.12-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (1.0.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_core) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_core) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (0.25.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_google_genai) (0.9.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (2.41.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (6.33.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.76.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (6.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core) (2.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (3.13.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain_community) (2.3.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pc\\onedrive\\1.강의\\0.llm\\1 패스트캠퍼스_랭그래프\\fastcampus_langgraph\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
            "Downloading langchain_tavily-0.2.12-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain_tavily\n",
            "Successfully installed langchain_tavily-0.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_google_genai langchain_core langchain_community langchain_tavily"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3abe77a5",
      "metadata": {
        "id": "3abe77a5"
      },
      "source": [
        "Google API Key를 설정합니다.\n",
        "\n",
        "구글 로그인 후, https://aistudio.google.com/apikey 에서 발급받을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b75f0d",
      "metadata": {
        "id": "a4b75f0d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c00b11f",
      "metadata": {
        "id": "9c00b11f"
      },
      "source": [
        "Gemini 모델을 설정합니다.   \n",
        "무료 API의 경우 분당 제한이 존재하므로, 랭체인의 Rate Limiter를 적용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c2a15227",
      "metadata": {
        "id": "c2a15227"
      },
      "outputs": [],
      "source": [
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    # temperature\n",
        "    # max_tokens\n",
        "\n",
        "    thinking_budget = 500  # 추론(Reasoning) 토큰 길이 제한\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "nBoYN4ObylGi",
      "metadata": {
        "id": "nBoYN4ObylGi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요! 저는 이름이 없으며, Google이 훈련한 대규모 언어 모델입니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--1d30f245-7a3e-43ca-a7c5-2c57a46159bd-0', usage_metadata={'input_tokens': 19, 'output_tokens': 462, 'total_tokens': 481, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 442}})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"안녕? 너는 이름이 뭐니? 한 문장으로 말해줘.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71e0a44d",
      "metadata": {
        "id": "71e0a44d"
      },
      "source": [
        "`invoke()`를 통해 llm에 입력을 전달합니다.    \n",
        "랭체인 기본 클래스인 `Message` 계열 클래스를 직접 만들어 리스트로 전달하거나,   \n",
        "프롬프트 템플릿을 통해 입력의 구성을 만들어 전달할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b1280e1b",
      "metadata": {
        "id": "b1280e1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='안녕! 저에 대해 궁금해해 주셔서 감사합니다.\\n\\n*   저는 개인적인 이름이 없어요.\\n*   저는 Google에서 훈련한 대규모 언어 모델이랍니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--bb8962f5-1cae-4908-9935-2f4106881b98-0', usage_metadata={'input_tokens': 49, 'output_tokens': 468, 'total_tokens': 517, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 427}})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. HumanMessage를 이용한 방법\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "system_msg = SystemMessage(content=\"\"\"사용자의 아래 [질문]에 대해 친절하게 답변하세요.\n",
        "답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.\"\"\")\n",
        "msg = HumanMessage(content=\"안녕! 너는 이름이 뭐니?\")\n",
        "\n",
        "messages = [system_msg, msg]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea0668f",
      "metadata": {
        "id": "fea0668f"
      },
      "source": [
        "Chat 모델의 출력은 AIMessage라는 형식으로 변환됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bb4a09cc",
      "metadata": {
        "id": "bb4a09cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕! 저에 대해 궁금해해 주셔서 감사합니다.\n",
            "\n",
            "*   저는 개인적인 이름이 없어요.\n",
            "*   저는 Google에서 훈련한 대규모 언어 모델이랍니다.\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b620e2b1",
      "metadata": {
        "id": "b620e2b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='사용자의 아래 [질문]에 대해 친절하게 답변하세요.\\n     답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='[질문]: {question}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2. ChatPromptTemplate을 이용한 방법\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# langchain.prompts --> langchain_core.prompts\n",
        "\n",
        "\n",
        "# 입력 변수가 {question}인 템플릿\n",
        "prompt = ChatPromptTemplate([\n",
        "    ('system', '''사용자의 아래 [질문]에 대해 친절하게 답변하세요.\n",
        "     답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.'''),\n",
        "     ('user', '''[질문]: {question}''')])\n",
        "prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1bdd2bb",
      "metadata": {
        "id": "e1bdd2bb"
      },
      "source": [
        "프롬프트와 llm을 |로 연결하여 체인을 구성합니다.   \n",
        "(랭체인 기본 문법으로, LangChain 기초 복습 자료에서 자세히 보실 수 있습니다!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6c7477bb",
      "metadata": {
        "id": "6c7477bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='사용자의 아래 [질문]에 대해 친절하게 답변하세요.\\n     답변의 길이는 5문장을 넘지 않도록 하고, 개조식으로 작성하세요.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='[질문]: {question}'), additional_kwargs={})])\n",
              "| ChatGoogleGenerativeAI(rate_limiter=<langchain_core.rate_limiters.InMemoryRateLimiter object at 0x000001D9191EE9F0>, model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), thinking_budget=500, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001D91C66F770>, default_metadata=(), model_kwargs={})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt | llm\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4567c80e",
      "metadata": {
        "id": "4567c80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "랭체인과 랭그래프는 LLM 애플리케이션 개발을 위한 도구이지만, 다음과 같은 차이가 있습니다.\n",
            "\n",
            "*   **랭체인 (LangChain):**\n",
            "    *   LLM 애플리케이션 개발을 위한 포괄적인 프레임워크입니다.\n",
            "    *   프롬프트 관리, 모델 연동, 체인 구성, 에이전트 생성 등 다양한 기능을 제공합니다.\n",
            "    *   주로 순차적인(linear) 워크플로우를 구성하는 데 강점이 있습니다.\n",
            "\n",
            "*   **랭그래프 (LangGraph):**\n",
            "    *   랭체인 위에 구축된 라이브러리로, 특히 에이전트 워크플로우를 위한 것입니다.\n",
            "    *   상태 관리와 반복적인(cyclical) 흐름을 그래프 형태로 정의하고 실행하는 데 특화되어 있습니다.\n",
            "    *   복잡한 에이전트가 스스로 판단하고 여러 단계를 거쳐 문제를 해결하는 다중 턴 상호작용 구현에 유용합니다.\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke({'question':\"랭체인과 랭그래프의 차이가 뭐야?\"})\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5d11182f",
      "metadata": {
        "id": "5d11182f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요! 패스트캠퍼스 랭그래프 강의 이름은 다음과 같습니다.\n",
            "\n",
            "*   **GPTs 개발을 위한 LangGraph & Agent**\n",
            "\n",
            "이 강의는 LangGraph를 활용하여 GPTs 및 에이전트를 개발하는 방법에 초점을 맞추고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# 입력 변수가 1개일 때는 값만 invoke해도 됨\n",
        "\n",
        "response = chain.invoke(\"패스트캠퍼스 랭그래프 강의 이름이 뭐야?\")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec0bb92a",
      "metadata": {
        "id": "ec0bb92a"
      },
      "source": [
        "존재하지 않는 내용에 대한 환각이 발생한 모습입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad0069a",
      "metadata": {
        "id": "3ad0069a"
      },
      "source": [
        "## LLM Tool 설정하기\n",
        "\n",
        "Tool은 LLM이 사용할 수 있는 다양한 외부 기능을 의미합니다.   \n",
        "LangChain에서 자체적으로 지원하는 Tool을 사용하거나, RAG의 Retriever를 Tool로 변환하는 것도 가능합니다.     \n",
        "또한, 함수를 Tool로 변환할 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4661f0a",
      "metadata": {
        "id": "e4661f0a"
      },
      "source": [
        "1. Tavily Search (http://app.tavily.com/)\n",
        "\n",
        "Tavily는 AI 기반의 검색 엔진입니다. 계정별 월 1000개의 무료 사용량을 지원합니다.      \n",
        "Tavily Search는 URL과 함께 내용의 간단한 요약을 지원하는 것이 특징입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "091dff13",
      "metadata": {
        "id": "091dff13"
      },
      "outputs": [],
      "source": [
        "os.environ['TAVILY_API_KEY'] = 'tvly-xxxx'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "52d69da9",
      "metadata": {
        "id": "52d69da9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TavilySearch(max_results=3, include_answer=True, include_raw_content='markdown', api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "# TavilySearchResults --> langchain_tavily의 TavilySearch로 변경\n",
        "\n",
        "tavily_search = TavilySearch(\n",
        "    max_results=3,\n",
        "    include_answer = True,\n",
        "    include_raw_content = 'markdown'\n",
        "    # 더 많은 옵션은 Tavily API 문서 Playground 참고\n",
        "    )\n",
        "tavily_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d06f87e6",
      "metadata": {
        "id": "d06f87e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': '랭그래프와 랭체인의 차이',\n",
              " 'follow_up_questions': None,\n",
              " 'answer': 'LangGraph provides detailed state management, while LangChain offers more automated, implicit state management. LangGraph is better for complex workflows, whereas LangChain is simpler.',\n",
              " 'images': [],\n",
              " 'results': [{'url': 'https://wikidocs.net/261585',\n",
              "   'title': '1-1-2. LangGraph와 LangChain의 차이점 - 위키독스',\n",
              "   'content': 'LangGraph는 명시적이고 세밀한 상태 관리를 제공합니다. · LangChain은 상대적으로 암시적이고 자동화된 상태 관리를 제공합니다.',\n",
              "   'score': 0.8884594,\n",
              "   'raw_content': None},\n",
              "  {'url': 'https://www.youtube.com/watch?v=yD3SnuU6Pd8',\n",
              "   'title': 'EP 2. Langchain과 Langgraph의 차이점 - YouTube',\n",
              "   'content': 'EP 2. Langchain과 Langgraph의 차이점\\n모두의AI\\n19100 subscribers\\n206 likes\\n9182 views\\n7 Nov 2024\\n안녕하세요, 오늘은 Langchain과 Langgraph의 차이점에 대해서 알아봅니다.\\n많은 LLM 기반 어플리케이션의 경우 Langchain만으로 충분하지만, 더 복잡한 워크플로우와 에이전트 시스템을 구현하기 위해서는 Langgraph를 활용하는 것이 더욱 효율적입니다. 특히 최근 Agentic RAG가 점차 떠오르는데 이때 Langgraph가 중요한 역할을 합니다.\\n5 comments\\n',\n",
              "   'score': 0.7613083,\n",
              "   'raw_content': '# EP 2. Langchain과 Langgraph의 차이점\\n## 모두의AI\\n19100 subscribers\\n206 likes\\n\\n### Description\\n9182 views\\nPosted: 7 Nov 2024\\n안녕하세요, 오늘은 Langchain과 Langgraph의 차이점에 대해서 알아봅니다.\\n많은 LLM 기반 어플리케이션의 경우 Langchain만으로 충분하지만, 더 복잡한 워크플로우와 에이전트 시스템을 구현하기 위해서는 Langgraph를 활용하는 것이 더욱 효율적입니다. 특히 최근 Agentic RAG가 점차 떠오르는데 이때 Langgraph가 중요한 역할을 합니다.\\n\\n5 comments\\n### Transcript:\\n네 안녕하세요 이번에는 랭 그래프와 랭 체인의 차이점에 대해서 설명드리도록 하겠습니다 어 많은 분들이 체인 생태에 내에이 랭 체인과 랭 그래프가 함께 존재하고 있기 때문에 어 굉장히 비슷하고 어떤 부분에서 다른지 잘 알지 못하는 경우가 많이 있는 거 같습니다 실제로 체인 홈페이지 들어가셔서이 체인과 랭그랩 어떤 프레임워크인 설명하는 그림을 보면 평행선상에 함께 표현된 것을 확인할 수가 있습니다 어 그만큼이 랭 체인 생태에 내에서 랭과 랭그라브 주요 아키텍처로 비슷한 부분이 많다는 뜻인데요이 차이점에 대해서 집중해서 한번 살펴보면요 랭 체인과 랭 그래프는 구성되는 방식이 꽤나 다르다는 것을 아실 수가 있습니다 가장 먼저 랭 체인의 경우에는이 이름의 체인이 들어가 있잖아요 그래서 마치 쇠사슬이 연결되어 있는 것처럼 여러 가지 구성 요소들을 선형적으로 엮어서 저희가 어떤 시스템을 만들 때이 을 활용한다고 볼 수 있겠습니다 예를 들어 체인 안에는 프롬프트 LM 그리고 뭐 펑션 아웃풋 파서와 같이 어 여러 가지 구속 요소들을 순차적으로 저희가 실행하게 만들 때 최 사실처럼 엮어서 어 선형적인 체인 구조를 만들게 됩니다 그래서 이게 무슨 말이냐면 어떤 메시지가 들어오면이 프롬프트는 구성 요소를 통해서이 메시지를 한번 가공하게 되고요 그리고 그 가공된 프롬프트를 LM 받으면 그 l&m이 받은 어 메시지를 기반으로 해서 답변을 생성할 수 있잖아요 그 답변을 생성할 때 특정 펑션에 따라서 어 저희가 답변을 만들도록 할 수 있겠습니다 그래서 그 답변이 만들어지면 아우프 파서를 기반으로 해서 내가 원하는 형식으로 만들어 주는 어 그러한 선형적인 특정 작업들의 연속 이것들을 랭 아인으로 구축할 수가 있는 겁니다 그래서 굉장히 직관적이고 어 여러 가지 구성 요소들을 내가 엮을 때 lcl 즉 랭 익스프레션 랭기지 아고 해서 랭 체인 전용 랭귀지를 통해 어 조금 더 편하고 쉽게 어이 코드를 구성할 수가 있습니다 어 두 번째로 랭 그래프의 경우에는 기존에 살펴봤던 랭 체인의 선형적인 체인 구조가 아니라 여러 가지 구성 요소들을 그래프 형태로 나타내게 되는데요 노드와 엣지를 기반으로 해서 여러 가지 노드들을 연결시키는 과정을 만들게 됩니다 여기 보이는 해당 그래프의 아키텍처는 어 콜라보레이티브 라고 해서 랭 그래프에서 에이전트들이 협력적으로 움직이는 아키텍처를 그래프로 나타낸 어 예시를 조금 더 단순화 한 겁니다 그래서 랭그랑 체인과 비슷하게이 왼쪽에서 오른쪽으로 일방향으로 가는 어이 체인 구조를 가진게 아니라 어떤 메시지가 들어오면 어 이것을 에이전트가 판단하기에 라우터로 가야 된다 또는 그대로 유저한테 어 응답을 할 수 있다 뭐 이러한 것들을 직접 판단을 해서 그다음으로 가야 될 노드가 어디인지를 를 판단하게 됩니다이 아키텍처에서는 라우터가 어 그 중간에서 에이전트와 툴 사이에 왔다 갔다 하게 해주는 그러한 역할을 하고 있는데요 어이 에이전트 2번도 마찬가지로 어 특정 메시지를 받게 되면은 이것을 라우터로 보낼지 아니면은 유저에게 그대로 답변을 할 수 있게 만들어 줄지 그러한 것들을 결정하게 됩니다 어 그러한 것들을 라우터가이 중앙에서 조금 더 매개하고 있다라고 보시면 될 거 같은데요 여기서 중요한 것은 에이전트 원과 2가 어떤 일을 한다 라기보다는이 아키텍처 내에서 어떤 메시지의 흐름이 에이전트에 의해서 정해진다는 점입니다 그래서 랭 체인처럼 어 왼쪽에서 들어온 구성 요소가 오른쪽으로 순차적으로 전달이 되는 구조가 아니라 어 유저로부터 받은 메시지가 에이전트에 의해서 어디로 갈지 정해지는 그렇기 때문에 저희가 왼쪽에서 오른쪽으로 쭉 가는게 아니라 왼쪽으로 갔다가 오른쪽으로 갔다가 이것을 왔다 갔다 할 수 있 있는 양방향적인 특징을 가진 그래프로서 어 시스템을 구축할 수 있다라고 말씀드릴 수 있겠습니다 그래서 랭 체인은 선형적으로 어떤 작업을 저희가 수행하게 만들 때 이런 선형적인 체인 구조를 활용했을 때 장점을 볼 수 있는 거고요 랜 그래프는 어 내가 가진 어떤 시스템이 비선형적이고 동적인 프로세스가 필요하다라고 한다면 어 활용되는 프레임워크라고 볼 수 있겠습니다 어 랭 체인의 구성 요소는 이런 식으로 어 툴 텍스트 스플리터 아웃풋 파서 프롬프트 모델 셋 모델 임베딩 리트리버 다큐먼트 로더 벡터 스토어와 같은 구성 요소들로 이루어져 있고요 이러한 구속 요소들을 선형적으로 배치를 해서 일종의 체인을 만들면 내가 원하는 형태대로 l&m 어플리케이션 서비스를 만들 수 있는 어 그러한 프레임워크입니다 그래서 랭 체인의 주요 활용시는 주로 레그라 볼 수가 있어요 어 레그를 만들 때는 체인의 다큐먼트 로더를 통해 문서를 가져오고 텍스트 스플리터를 통의 문서를 분할시키는 통해서 분할된 텍스트 청크을 임베딩 벡터로 변환해 주고요 그 벡터들을 벡터 스토어에 저장해 주는 역할을 수행할 수가 있습니다 그래서 일종의 파이프라인을 통해서 레그의 인덱싱 과정을 수행할 수가 있는 거고요 레그에 생성에 해당하는 부분도이 랭 체인을 활용해서 수행할 수가 있습니다 랭 체인의 리트리버 어 모듈을 통해서 어 주어진 사용자의 질문이 벡터 스토어 내에서 어떤 힌트 와 함께 주어질 수 있는지를 어 찾을 수가 있고요 그렇게 찾아진 힌트와 사용자의 질문을 하나의 프롬프트로 엮는 역할을이 프롬프트 모듈이 수행하게 됩니다 그럼 그 가공된 프롬프트를 기반으로 해서 모델이 답변을 생성할 수 있는 거죠 이런 식으로 랭 체인에서는 레그의 인덱싱과 생성 모든 단계에 있어서 어 주요 컴포넌트들이 가장 자주 활용된다고 볼 수 있고요이 체인에서 에이전트를 만들 수가 있습니다 체인에서 에이전트를 만들 수 있다라고 하는 것은 어떤 경우냐 men 프롬프트가 주어졌어요 그러면은 사용자로부터 주어진 프롬프트를 모델로 보내게 되는데 그 모델의 결과물 응답 결과물을 아웃풋 파서로 저희가 일정한 형태로 가공을 하게 됩니다 근데 어떤 형태로 가공을 하게 되냐면 도구를 활용하기에 편한 형태로이 LM 응답 결과물을 파싱하기 되는 거죠 그렇게 되면은이 모델이 판단하기에 도구가 필요하다라고 간다면 툴 메시지를 도구 에다가 보내게 되고요 그럼이 도구가 호출이 돼서 해당 도구의 실행 결과물을 어 모델이 다시 활용한다든지 또는 어떤 에이전트 시스템에 어 출력을 한다던가 그러 부분들이 가능한 거겠죠 마지막으로 정보 추출이란 것도 가능하게 됩니다 예를 들어서 내가 어떤 문서를 가져와서 그 문서 내에서 어떤 특정한 키워드라 그가 어 특정한 정보를 추출해야 된다라고 한다면 다큐먼트 로드로 문서를 가져오고 어 프롬프트에이 자세한 해당 추출해야 되는 정보에 대해서 기입을 해 주면이 모델이 그 프롬프트에 알맞게 정보를 뽑아내게 되고요 내가 원하는 형식이 만약에 그 추출된 정보가 제이슨 형식으로 나왔으면 좋겠다라고 한다면 아웃풋 파서를 제이슨 아웃풋 파서로 설정을 해 줘서 어 내가 원하는 형식대로 LM 응답이 나오도록 만들어 줄 수도 있겠습니다 그래서 레그 에이전트 정보 추출 이렇게 세 가지의 대표적인 냉체 주요 활용 신이 있겠고요이 냉체 주요 활용 신을 보시면 모두 일방향적으로 체인 형식으로 만들어져 있는 신이다 볼 수 있겠어요 랭 체인의 주요 활용 신은 전부이 첫 번째 요소가 두 번째 요소로 간 다음에 다시 첫 번째 요소로 돌아가지 않습니다 첫 번째 요소가 두 번째 요소로 전달이 되면이 두 번째 요소는 연속해서 세 번째 요소로 또 전달이 되게 됩니다 그래서 어떤 인풋이 주어지면 해당 인풋에 대해서 여러 가지 컴포넌트들이 일방향적으로 체인을 구성해서 왼쪽에서 오른쪽으로 쭉 퍼져 나가는 어 그러 모습을 확인할 수가 있겠습니다 랜 그래프의 주요 활용 시즌에는 에이전트가이 다음에 행위해야 할 행동이 무엇인지 정하게 됩니다 그래서이 오른쪽에 멀티에이전트 시스템 아키텍처를 보면 어떤 스타트 메시지가 딱 들어왔을 때 어시스턴트가 판단하기에 어 도구를 활용해야겠다라고 한다면 어시스턴트 즈로 돌아가고 그게 아니라 도구 없이 나는 바로 대답을 할 수 있다라고 한다면 곧바로 엔드 노드로 들어가는 것을 볼 수가 있습니다 그래서 체인의 경우에는 는 이렇게 일방향적으로 체인을 구성할 수 있었다면 랜 그래프에서는 주어진 메시지가 어떤 것인지에 따라서 어시스턴트가 그다음으로 갈 노드를 정하게 되는 거죠 그래서 저희가 미리이 노드의 방향을 전부 정해 놓는게 아니라 선택지를 여러 개 준 다음에 AI이 다음에 올 노드를 직접 결정하게 만드는 거예요 그래서 굉장히 동적으로이 시스템을 만들 수 있다는 장점이 있겠죠 이러한 레그프레스 1 단일 에이전트뿐만 아니라 뭐 멀티 에이전트에서 모두 실현이 될 수 있고요 그렇기 때문에 노드와 엣지로 연결한 양방향 그래프라는 점이 냉 체인의 일방향 체인과 가장 큰 차이점이라고 볼 수 있겠습니다'},\n",
              "  {'url': 'https://www.reddit.com/r/LangChain/comments/1j8qjls/langchain_vs_langgraph/?tl=ko',\n",
              "   'title': 'Langchain vs Langgraph - Reddit',\n",
              "   'content': 'Langchain vs Langgraph : r/LangChain Skip to main contentLangchain vs Langgraph : r/LangChain Open menu Open navigationGo to Reddit Home r/LangChain A chip A close button Log InLog in to Reddit Expand user menu Open settings menu Image 1: r/LangChain icon Go to LangChain r/LangChain Image 2: r/LangChain iconr/LangChain 파이썬이랑 자바스크립트로 쓸 수 있고 https://www.langchain.com/.에서 확인 가능. Langchain vs Langgraph POC를 만들고 있는데, AI, langchain, langgraph는 완전 처음이야. New to Reddit? Create your account and connect with a world of communities. Continue with Email  Continue With Phone Number  By continuing, you agree to ourUser Agreementand acknowledge that you understand thePrivacy Policy. Anyone can view, post, and comment to this community Reddit RulesPrivacy PolicyUser AgreementAccessibilityReddit, Inc. Expand Navigation Collapse Navigation Image 3',\n",
              "   'score': 0.59796065,\n",
              "   'raw_content': 'Langchain vs Langgraph : r/LangChain\\n\\n===============\\n[Skip to main content](https://www.reddit.com/r/LangChain/comments/1j8qjls/langchain_vs_langgraph/?tl=ko#main-content)Langchain vs Langgraph : r/LangChain\\n\\nOpen menu Open navigation[](https://www.reddit.com/)Go to Reddit Home\\n\\nr/LangChain A chip A close button\\n\\n[Log In](https://www.reddit.com/login/)Log in to Reddit\\n\\nExpand user menu Open settings menu\\n\\n[![Image 1: r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac) Go to LangChain](https://www.reddit.com/r/LangChain/)\\n\\n[r/LangChain](https://www.reddit.com/r/LangChain/)\\n\\n![Image 2: r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)[r/LangChain](https://www.reddit.com/r/LangChain/)\\n\\n랭체인은 개발자들이 LLM 애플리케이션을 프로토타입에서 프로덕션까지 만들 수 있도록 돕는 오픈소스 프레임워크이자 개발자 툴킷임. 파이썬이랑 자바스크립트로 쓸 수 있고 https://www.langchain.com/.에서 확인 가능.\\n\\n* * *\\n\\n75K Members Online\\n\\n•6 mo. ago\\n\\n[Special_Bicycle_9498](https://www.reddit.com/user/Special_Bicycle_9498/)\\n\\nLangchain vs Langgraph\\n======================\\n\\n안녕,\\n\\nPOC를 만들고 있는데, AI, langchain, langgraph는 완전 처음이야. langchain이랑 langgraph의 주요 차이점은 뭐야? 인터넷에 비교글들이 있긴 한데, 지금 내 수준보다는 좀 어려운 것 같아 :)\\n\\n회사는 뭘 써야 하고, 왜 써야 해? 여러 사람이, 기술적인 사람이든 아니든, 여러 도구랑 플랫폼으로 작업하는 챗봇 에이전트를 만들고 싶어. 그래서 팁 같은 거 있으면 알려줘.\\n\\n고마워!\\n\\n Read more \\n\\n Share \\n\\nNew to Reddit? \\nCreate your account and connect with a world of communities.\\n\\n Continue with Email \\n\\n Continue With Phone Number \\n\\nBy continuing, you agree to our[User Agreement](https://www.redditinc.com/policies/user-agreement)and acknowledge that you understand the[Privacy Policy](https://www.redditinc.com/policies/privacy-policy). \\n\\n Public \\n\\nAnyone can view, post, and comment to this community\\n\\n0 0\\n\\n[Reddit Rules](https://www.redditinc.com/policies/content-policy)[Privacy Policy](https://www.reddit.com/policies/privacy-policy)[User Agreement](https://www.redditinc.com/policies/user-agreement)[Accessibility](https://support.reddithelp.com/hc/sections/38303584022676-Accessibility)[Reddit, Inc. © 2025. All rights reserved.](https://redditinc.com/)\\n\\nExpand Navigation Collapse Navigation\\n\\n![Image 3](https://id.rlcdn.com/472486.gif)\\n'}],\n",
              " 'response_time': 5.2,\n",
              " 'request_id': '3c3a5649-256d-4d35-a84c-37bfab6e0897'}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_docs = tavily_search.invoke(\"랭그래프와 랭체인의 차이\")\n",
        "search_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b84ff85",
      "metadata": {
        "id": "4b84ff85"
      },
      "source": [
        "# LLM에 Tool 연결하기   \n",
        "\n",
        "생성한 툴은 llm.bind_tools()를 통해 LLM에 연결할 수 있습니다.    \n",
        "이 기능은 Gemini, GPT, Claude 등의 툴에서 지원하는데요.     \n",
        "HuggingFace 공개 모델에서 Tool을 사용하는 경우는 이후 실습에서 자세히 알아보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "35f9f905",
      "metadata": {
        "id": "35f9f905"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatGoogleGenerativeAI(rate_limiter=<langchain_core.rate_limiters.InMemoryRateLimiter object at 0x000001D9191EE9F0>, model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), thinking_budget=500, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001D91C66F770>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'include_favicon': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': \"Determines whether to include favicon URLs for each search result.\\n        \\n        When enabled, each search result will include the website's favicon URL,\\n        which can be useful for:\\n        - Building rich UI interfaces with visual website indicators\\n        - Providing visual cues about the source's credibility or brand\\n        - Creating bookmark-like displays with recognizable site icons\\n        \\n        Set to True when creating user interfaces that benefit from visual branding\\n        or when favicon information enhances the user experience.\\n        \\n        Default is False to minimize response size and API usage.\\n        \"}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tools = [tavily_search]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "llm_with_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50a0b273",
      "metadata": {
        "id": "50a0b273"
      },
      "source": [
        "랭체인에서, tool 정보는 tools에 저장되는데요.   \n",
        "해당 내용은 랭체인 내부에서 json Schema 형식으로 프롬프트에 포함됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "52ed35d6",
      "metadata": {
        "id": "52ed35d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'name': 'tavily_search',\n",
              "   'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.',\n",
              "   'parameters': {'properties': {'query': {'description': 'Search query to look up',\n",
              "      'type': 'string'},\n",
              "     'include_domains': {'anyOf': [{'items': {'type': 'string'},\n",
              "        'type': 'array'},\n",
              "       {'type': 'null'}],\n",
              "      'default': [],\n",
              "      'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '},\n",
              "     'exclude_domains': {'anyOf': [{'items': {'type': 'string'},\n",
              "        'type': 'array'},\n",
              "       {'type': 'null'}],\n",
              "      'default': [],\n",
              "      'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '},\n",
              "     'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'],\n",
              "        'type': 'string'},\n",
              "       {'type': 'null'}],\n",
              "      'default': 'basic',\n",
              "      'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '},\n",
              "     'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
              "      'default': False,\n",
              "      'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '},\n",
              "     'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'],\n",
              "        'type': 'string'},\n",
              "       {'type': 'null'}],\n",
              "      'default': None,\n",
              "      'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '},\n",
              "     'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'],\n",
              "        'type': 'string'},\n",
              "       {'type': 'null'}],\n",
              "      'default': 'general',\n",
              "      'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '},\n",
              "     'include_favicon': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
              "      'default': False,\n",
              "      'description': \"Determines whether to include favicon URLs for each search result.\\n        \\n        When enabled, each search result will include the website's favicon URL,\\n        which can be useful for:\\n        - Building rich UI interfaces with visual website indicators\\n        - Providing visual cues about the source's credibility or brand\\n        - Creating bookmark-like displays with recognizable site icons\\n        \\n        Set to True when creating user interfaces that benefit from visual branding\\n        or when favicon information enhances the user experience.\\n        \\n        Default is False to minimize response size and API usage.\\n        \"},\n",
              "     'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
              "      'default': None,\n",
              "      'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '},\n",
              "     'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
              "      'default': None,\n",
              "      'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}},\n",
              "    'required': ['query'],\n",
              "    'type': 'object'}}}]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 시스템 메시지에 포함되는 내용\n",
        "# (`LLM과 Agent` 강의 슬라이드를 참고하세요!)\n",
        "\n",
        "llm_with_tools.kwargs['tools']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "291ee797",
      "metadata": {
        "id": "291ee797"
      },
      "source": [
        "LLM은 프롬프트로 주어지는 툴 정보를 바탕으로 Tool의 사용을 결정합니다.    \n",
        "Schema를 통해, 툴의 의미와 사용 방법, 형식을 이해합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd923172",
      "metadata": {
        "id": "cd923172"
      },
      "source": [
        "이후, LLM은 Tool 사용이 필요한 경우 특별한 포맷의 메시지를 출력합니다.   \n",
        "이를 Tool Call Message라고 부릅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "6ddf7c84",
      "metadata": {
        "id": "6ddf7c84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"query\": \"\\\\ud328\\\\uc2a4\\\\ud2b8\\\\ucea0\\\\ud37c\\\\uc2a4 \\'\\\\ub7ad\\\\uadf8\\\\ub798\\\\ud504\\\\ub85c \\\\ud55c\\\\ubc88\\\\uc5d0 \\\\uc644\\\\uc131\\\\ud558\\\\ub294 \\\\ubcf5\\\\uc7a1\\\\ud55c RAG\\\\uc640 Agent \\\\uacfc\\\\uc815\\'\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--0e0703f4-10f0-49c7-a740-8861bdd77f7c-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': \"패스트캠퍼스 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'\"}, 'id': '5c248c6d-eee7-474d-8ac0-22791fc36553', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1607, 'output_tokens': 90, 'total_tokens': 1697, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 52}})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_chain = prompt | llm_with_tools\n",
        "tool_call_msg = tool_chain.invoke(\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\")\n",
        "tool_call_msg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d0857ca4",
      "metadata": {
        "id": "d0857ca4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"query\": \"\\\\ud328\\\\uc2a4\\\\ud2b8\\\\ucea0\\\\ud37c\\\\uc2a4 \\\\ub7ad\\\\uadf8\\\\ub798\\\\ud504\\\\ub85c \\\\ud55c\\\\ubc88\\\\uc5d0 \\\\uc644\\\\uc131\\\\ud558\\\\ub294 \\\\ubcf5\\\\uc7a1\\\\ud55c RAG\\\\uc640 Agent \\\\uacfc\\\\uc815\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--a27a2867-0766-41db-a181-0bd0f1bd5c68-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'}, 'id': '7fa56ad9-f73a-47e6-be05-c8b1eb767308', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1567, 'output_tokens': 105, 'total_tokens': 1672, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 68}})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_call_msg = llm_with_tools.invoke(\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정인지 검색해서 알려줘\")\n",
        "tool_call_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "80472b96",
      "metadata": {
        "id": "80472b96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'tavily_search',\n",
              "  'args': {'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'},\n",
              "  'id': '7fa56ad9-f73a-47e6-be05-c8b1eb767308',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_call_msg.tool_calls\n",
        "# 리스트 형식인 이유는? 여러 개의 툴을 동시에 사용할 수 있기 때문"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d6bd19",
      "metadata": {
        "id": "71d6bd19"
      },
      "source": [
        "`tool_calls`에 포함된 name을 활용하면 툴 결과를 전달할 수 있습니다.   \n",
        "`name` 값은 문자열이므로, dictionary를 통해 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f9595fda",
      "metadata": {
        "id": "f9595fda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tavily_search',\n",
              " TavilySearch(max_results=3, include_answer=True, include_raw_content='markdown', api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None)))"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_list ={'tavily_search': tavily_search}\n",
        "\n",
        "tool_name = tool_call_msg.tool_calls[0]['name']\n",
        "tool_exec = tool_list[tool_name]\n",
        "\n",
        "tool_name, tool_exec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3496b492",
      "metadata": {
        "id": "3496b492"
      },
      "source": [
        "Tool에 tool_call을 입력해 invoke를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f582c143",
      "metadata": {
        "id": "f582c143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToolMessage(content='{\"query\": \"패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정\", \"follow_up_questions\": null, \"answer\": \"The course teaches complex RAG and Agent development using LangGraph. It lasts 18 hours and offers flexible online learning. Refunds are available within the first 7 days of enrollment.\", \"images\": [], \"results\": [{\"url\": \"https://cdn.day1company.io/prod/uploads/202509/100554-1064/-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4--%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95%EC%86%8C%EA%B0%9C%EC%84%9C-%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent.pdf\", \"title\": \"[PDF] 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\", \"content\": \"Life Changing Education 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent Life Changing Education Copyright ⓒ FAST CAMPUS Corp. 강의정보 강의장 온라인 강의 | 데스크탑, 노트북, 모바일 등 수강 기간 평생 소장 상세페이지 https://fastcampus.co.kr/data_online_langgraph 강의시간 약 18시간 문의 고객센터 강의특징 나만의 속도로 낮이나 새벽이나 내가 원하는 시간대에 나의 스케쥴대로 수강 원하는 곳 어디서나 시간을 쪼개 먼 거리를 오가며 오프라인 강의장을 찾을 필요 없이 어디서든 수강 무제한 복습 무엇이든 반복적으로 학습해야 내것이 되기에 이해가 안가는 구간 몇번이고 재생 Life Changing Education Copyright ⓒ FAST CAMPUS Corp. LangGraph 파트별 수강시간 02:29:36 Life Changing Education CH01. LangGraph Application 배포하기 파트별 수강시간 02:24:16 Life Changing Education CH01. LangChain과 LLM API 파트별 수강시간 03:36:50 Life Changing Education Copyright ⓒ FAST CAMPUS Corp.\", \"score\": 0.8825193, \"raw_content\": \"Life Changing Education 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent Life Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n강의정보 강의장 온라인 강의 | 데스크탑, 노트북, 모바일 등 수강 기간 평생 소장 상세페이지 https://fastcampus.co.kr/data_online_langgraph 강의시간 약 18시간 문의 고객센터 강의특징 나만의 속도로 낮이나 새벽이나 내가 원하는 시간대에 나의 스케쥴대로 수강 원하는 곳 어디서나 시간을 쪼개 먼 거리를 오가며 오프라인 강의장을 찾을 필요 없이 어디서든 수강 무제한 복습 무엇이든 반복적으로 학습해야 내것이 되기에 이해가 안가는 구간 몇번이고 재생 Life Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n강의목표 -LangGraph 공부의 시작점이 되는 강의! 사람같은 AI 서비스, RAG, AI agent 개발에 필수스택이 된 랭그래프의 원리와 활용, LangGraph가 쓰이는 대표적인 use case 6가지까지 -복잡한 RAG와 고도화된 흐름의 AI Agent까지 LangGraph로 LLM 공부를 시작하세요.\\\\n-2025년의 LLM 트렌드인 Agent와 핵심 프레임워크가 랭그래프인 이유를 알아가세요.\\\\n-랭그래프의 Node와 Edge, Graph 등 생소한 구조 개념 정리부터 랭그래프에서 까다로운 Graph와 State를 컨트롤하기 위한 방법을 알려드려요.\\\\n-다양한 산업 분야에서 Advanced RAG를 구축하고 싶다면 랭체인과 랭그래프의 특징을 파악하고 서로 보완할 수 있도록 활용해야 합니다!\\\\n강의요약 -허깅페이스에 올라오는 Llama(라마), Qwen(큐웬)과 같은 다양한 오픈 모델을 활용하여 에이전트를 구현합니다.\\\\n-널리 쓰이고 있는 LLM 서빙 프레임워크로 저비용 고성능으로 LLM을 추론할 수 있는 최적화 방법을 알아봅니다.\\\\n-실제로 사용자가 LLM 어플리케이션에 접속할 수 있도록 LLM을 서버에 올리고, 웹 프론트엔드에 연결해봅니다.\\\\n-Agent의 대표 활용 사례들을 직접 제작해보고, Agent 플로우를 만드는 단계를 반복해서 실습하며 체득하세요.\\\\nLife Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n강사 변형호 과목 -랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 약력 -현) 노토랩 대표 -현) 두피디아 정보과학/인공지능 분야 집필진 -국민연금, 국가보안기술연구소 기술 자문 -두산백과 정보과학/인공지능 분야 집필진 Life Changing Education CH01. RAG와 AI Agent의 이해 01. LLM 발전 동향 02. LLM 발전 동향 (2) 02. LLM과 Agent 03. 다양한 LLM Agent의 구조 04. LangChain Tool Calling과 Agent CURRICULUM 01. RAG와 AI Agent의 이해 파트별 수강시간 01:51:20 Life Changing Education CH01. LangGraph 01. LangGraph 소개 02. LangGraph Node와 Edge, Graph 구조 03. LangGraph의 다양한 State 04. 조건부 엣지와 툴 노드 연결하기 05. Agent의 Planning 구조- ReAct 06. 다양한 그래프 구조 07. LangSmith와 LangGraph Studio 08. 그래프 메모리 관리 09. Human-in-the-Loop 10. 멀티 에이전트 구조 CURRICULUM 02. LangGraph 파트별 수강시간 02:29:36 Life Changing Education CH01. 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 01. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 02. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 (2) 03. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent 04. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent (2) 05. 3) 비전 모델을 활용한 멀티모달 RAG Agent 06. 3) 비전 모델을 활용한 멀티모달 RAG Agent 07. 4) 멀티 에이전트 기반 Research Agent 08. 4) 멀티 에이전트 기반 Research Agent (실습) 08_2. 4) 멀티 에이전트 기반 Research Agent (실습 2) 09. 5) Code Interpreter를 이용한 내 파일 기반 차트 제너레이터 10. 6) 멀티 에이전트를 활용한 보고서 작성과 품질 평가 관리 시스템 CURRICULUM 03. LangGraph를 이용한 현업 적용 프로젝트 파트별 수강시간 05:18:29 Life Changing Education CH01. LangGraph Application 배포하기 01. HuggingFace 공개 LLM을 활용한 Agentic Work 만들기 02. HuggingFace 공개 LLM을 활용한 Agentic Work 만들기 (2) 03. Ollama와 vLLM을 이용한 Agentic Work 최적화 04. 만들어진 LangGraph Application 배포하기 (Streamlit Gradio LangGraph Cloud) CURRICULUM 04. LangGraph Application 배포하기 파트별 수강시간 02:24:16 Life Changing Education CH01. Summary & Wrap-up 01. Summary & Wrap-up CURRICULUM 05. Summary & Wrap-up 파트별 수강시간 00:12:10 Life Changing Education CH01. LangChain과 LLM API 01. [실습] OpenAI와 Gemini API 사용하기 02. LangChain을 이용한 LLM 어플리케이션 만들기 03. [실습] LangChain Expression Language 04. [실습] LangChain Expression Language (2) (추가) 05. [실습] LangChain을 이용한 LLM 어플리케이션 만들기 06. Retrieval Augmented Generation 이해하기 07. Retrieval Augmented Generation 이해하기 (2) 08. [실습] LangChain을 이용한 RAG 구현하기 CURRICULUM 부록. LangChain과 LLM API 파트별 수강시간 03:36:50 Life Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n주의 사항 -상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\\\n-패스트캠퍼스의 모든 온라인 강의는 아이디 공유를 금지하고 있으며 1개의 아이디로 여러 명이 수강하실 수 없습니다.\\\\n-별도의 주의사항은 각 강의 상세페이지에서 확인하실 수 있습니다. 수강 방법 -패스트캠퍼스는 크롬 브라우저에 최적화 되어있습니다. -사전 예약 판매 중인 강의의 경우 1차 공개일정에 맞춰 ‘온라인 강의 시청하기’가 활성화됩니다.\\\\n환불 규정 -강의 시수, 형태에 따라 환불 규정이 상이 하므로 반드시 각 강의 상세페이지 하단 [환불 규정] 과 [패스트캠퍼스 취소/환불 정책] 내용을 확인해 주시기 바랍니다.\\\\n-패스트캠퍼스 취소/환불 정책 : https://fastcampus.co.kr/info/policies/refund\"}, {\"url\": \"https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr\", \"title\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | Hyungho Byun\", \"content\": \"LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content) LinkedIn 회원 가입 로그인 과정 이름은 \\\\\"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr  LinkedIn Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\", \"score\": 0.86981434, \"raw_content\": \"Published Time: 2025-01-24T06:24:20.229Z\\\\n\\\\nLinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스\\\\n===============\\\\n\\\\n   \\\\n\\\\nLinkedIn 동의 후 가입\\\\n\\\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn [사용자약관](https://kr.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [개인정보 처리방침](https://kr.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), [쿠키정책](https://kr.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy)에 동의하게 됩니다.\\\\n\\\\n       [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content)\\\\n\\\\n[LinkedIn](https://kr.linkedin.com/?trk=public_post_nav-header-logo)\\\\n\\\\n*   [글](https://www.linkedin.com/pulse/topics/home/?trk=public_post_guest_nav_menu_articles)\\\\n*   [사람](https://www.linkedin.com/pub/dir/+/+?trk=public_post_guest_nav_menu_people)\\\\n*   [온라인클래스](https://www.linkedin.com/learning/search?trk=public_post_guest_nav_menu_learning)\\\\n*   [채용공고](https://www.linkedin.com/jobs/search?trk=public_post_guest_nav_menu_jobs)\\\\n*   [게임](https://www.linkedin.com/games?trk=public_post_guest_nav_menu_games)\\\\n\\\\n[회원 가입](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_nav-header-join) [로그인](https://www.linkedin.com/login?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&fromSignIn=true&trk=public_post_nav-header-signin)\\\\n\\\\nHyungho Byun님의 업데이트\\\\n===================\\\\n\\\\n [![Image 1: Hyungho Byun님 프로필을 조회합니다.](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_feed-actor-image)\\\\n\\\\n[Hyungho Byun](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_feed-actor-name)\\\\n\\\\n노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\\\n\\\\n1개월\\\\n\\\\n*   [글 신고](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fkr.linkedin.com%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\\\\n\\\\n안녕하세요! 노토랩의 변형호입니다.\\xa0 오늘 OpenAI의 웹 탐색 기능이 탑재된 에이전트 오퍼레이터(Operator)가 공개되었는데요. 이에 맞춰서 광고를 좀 하겠습니다..😅 제가 패스트캠퍼스에서 LangGraph에 대한 온라인 강의를 런칭합니다. 과정 이름은 \\\\\"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프가 랭체인보다 좀 어렵긴 한데요... 단계별로 쉽게 이해할 수 있는 강의를 준비했습니다! RAG가 결합된 복잡한 시스템이나, 스탠포드 스톰(STORM)과 같은 멀티 에이전트 구조를 만들고 싶으신 분들께는 많은 도움이 되실 것 같습니다. 실무에서 활용할 수 있는 6개의 프로젝트를 중심으로 복잡한 그래프 구조, 휴먼인더루프, 품질 검증과 같은 요소들도 아주 세세하게 다룰 예정이구요. 또한, LLM 기본 코드 지식이 필요하신 분들을 위한 랭체인, LLM API 활용 챕터도 부록으로 준비했습니다. 1차 공개 일정은 2월 24일이라 아직 여유가 좀 있는데요(?) 관심 있으신 분들은 [https://bit.ly/40lXEj2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fbit%2Ely%2F40lXEj2&urlhash=jnYC&trk=public_post-text) 에서 자세한 내용을 확인하실 수 있습니다. 아래의 쿠폰코드를 입력하시면 20% 할인 가능합니다! PRDTEA250124\\\\\\\\_sns202 LangChain의 기초, LLM과 Agent에 대한 샘플 영상 2개도 같이 업로드했는데요. 이 영상은 댓글에 올려 놓겠습니다. 다음 포스팅은 다시 이전처럼 기술 이야기로 뵙겠습니다. 감사합니다! 😁\\\\n\\\\n [![Image 2: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr) 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Ffastcampus%2Eco%2Ekr%2Fdata_online_langgraph&urlhash=MLpe&trk=public_post_feed-article-content) \\\\n\\\\n  [![Image 3](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr) ![Image 4](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr) 38](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_social-actions-reactions)           [댓글 2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_social-actions-comments)\\\\n\\\\n[추천](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_like-cta) [댓글](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment-cta)  \\\\n\\\\n공유\\\\n\\\\n*   복사\\\\n*   LinkedIn\\\\n*   Facebook\\\\n*   Twitter\\\\n\\\\n[![Image 5: Hyungho Byun님, 그래픽](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-image)\\\\n\\\\n[Hyungho Byun](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-name)노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\\\n\\\\n1개월\\\\n\\\\n*   [댓글 신고](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fkr.linkedin.com%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\\\n\\\\n[https://youtu.be/yLOjUf\\\\\\\\_XH1o?si=NZ2r8AlLoTk0s2C1](https://youtu.be/yLOjUf_XH1o?si=NZ2r8AlLoTk0s2C1&trk=public_post_comment-text)\\\\n\\\\n[추천](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_like)[댓글](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_reply)반응\\xa01\\\\n\\\\n[![Image 6: Hyungho Byun님, 그래픽](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-image)\\\\n\\\\n[Hyungho Byun](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-name)노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\\\n\\\\n1개월\\\\n\\\\n*   [댓글 신고](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fkr.linkedin.com%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\\\n\\\\n[https://youtu.be/sUZ9LPK7fY4?si=ccTDrvW\\\\\\\\_NNZfhktx](https://youtu.be/sUZ9LPK7fY4?si=ccTDrvW_NNZfhktx&trk=public_post_comment-text)\\\\n\\\\n[추천](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_like)[댓글](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_reply)반응\\xa01\\\\n\\\\n[더 보기](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_see-more-comments)댓글을 보거나 남기려면 [로그인](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_feed-cta-banner-cta)\\\\n\\\\n![Image 7](https://static.licdn.com/aero-v1/sc/h/5q92mjc5c51bjlwaj3rs9aa82)\\\\n\\\\n![Image 8: Hyungho Byun](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)팔로워 1,191명\\\\n\\\\n*   [업데이트 36개](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fin%2Fhyungho-byun-6b2588224%2Frecent-activity%2F&trk=public_post_follow-posts)\\\\n\\\\n[프로필 보기](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_follow-view-profile) [팔로우](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7288441474692661248&trk=public_post_follow)\\\\n\\\\n*   LinkedIn © 2025\\\\n*   [정보](https://about.linkedin.com/?trk=d_public_post_footer-about)\\\\n*   [웹접근성](https://www.linkedin.com/accessibility?trk=d_public_post_footer-accessibility)\\\\n*   [사용자약관](https://www.linkedin.com/legal/user-agreement?trk=d_public_post_footer-user-agreement)\\\\n*   [개인정보 처리방침](https://www.linkedin.com/legal/privacy-policy?trk=d_public_post_footer-privacy-policy)\\\\n*   [Your California Privacy Choices](https://www.linkedin.com/legal/california-privacy-disclosure?trk=d_public_post_footer-california-privacy-rights-act)\\\\n*   [쿠키정책](https://www.linkedin.com/legal/cookie-policy?trk=d_public_post_footer-cookie-policy)\\\\n*   [저작권정책](https://www.linkedin.com/legal/copyright-policy?trk=d_public_post_footer-copyright-policy)\\\\n*   [브랜드정책](https://brand.linkedin.com/policies?trk=d_public_post_footer-brand-policy)\\\\n*   [비회원 설정](https://www.linkedin.com/psettings/guest-controls?trk=d_public_post_footer-guest-controls)\\\\n*   [커뮤니티정책](https://www.linkedin.com/legal/professional-community-policies?trk=d_public_post_footer-community-guide)\\\\n*   *   아랍어(العربية)\\\\n    *   벵골어(বাংলা)\\\\n    *   체코어(Čeština)\\\\n    *   덴마크어(Dansk)\\\\n    *   독일어(Deutsch)\\\\n    *   그리스어(Ελληνικά)\\\\n    *   영어(English)\\\\n    *   스페인어(Español)\\\\n    *   페르시아어(فارسی)\\\\n    *   핀란드어(Suomi)\\\\n    *   프랑스어(Français)\\\\n    *   힌디어(हिंदी)\\\\n    *   헝가리어(Magyar)\\\\n    *   인도네시아어(Bahasa Indonesia)\\\\n    *   이탈리아어(Italiano)\\\\n    *   히브리어(עברית)\\\\n    *   일본어(日本語)\\\\n    *   **한국어(Korean)**\\\\n    *   마라티어(मराठी)\\\\n    *   말레이시아어(Bahasa Malaysia)\\\\n    *   네덜란드어(Nederlands)\\\\n    *   노르웨이어(Norsk)\\\\n    *   펀자브어(ਪੰਜਾਬੀ)\\\\n    *   폴란드어(Polski)\\\\n    *   포르투갈어(Português)\\\\n    *   루마니아어(Română)\\\\n    *   러시아어(Русский)\\\\n    *   스웨덴어(Svenska)\\\\n    *   텔루구어(తెలుగు)\\\\n    *   태국어(ภาษาไทย)\\\\n    *   필리핀어(Tagalog)\\\\n    *   터키어(Türkçe)\\\\n    *   우크라이나어(Українська)\\\\n    *   베트남어(Tiếng Việt)\\\\n    *   중국어 간체(简体中文)\\\\n    *   중국어 번체(正體中文)\\\\n    \\\\n    언어\\\\n    \\\\n\\\\n![Image 9](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)\\\\n\\\\n로그인해서 콘텐츠 더보기\\\\n-------------\\\\n\\\\n무료 계정을 만들거나 로그인하여 검색을 계속하세요.\\\\n\\\\n로그인\\\\n\\\\n어서오세요!\\\\n------\\\\n\\\\n          \\\\n\\\\n이메일 또는 전화\\\\n\\\\n비밀번호\\\\n\\\\n 표시\\\\n\\\\n \\\\n\\\\n[비밀번호를 잊으셨나요?](https://www.linkedin.com/uas/request-password-reset?trk=public_post_contextual-sign-in-modal_sign-in-modal_forgot_password)  로그인\\\\n\\\\n또는\\\\n\\\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn [사용자약관](https://kr.linkedin.com/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [개인정보 처리방침](https://kr.linkedin.com/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), [쿠키정책](https://kr.linkedin.com/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy)에 동의하게 됩니다.\\\\n\\\\nLinkedIn이 처음이세요? [회원 가입](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\\\\n\\\\n또는\\\\n\\\\nLinkedIn이 처음이세요? [회원 가입](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_contextual-sign-in-modal_join-link)\\\\n\\\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn [사용자약관](https://kr.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [개인정보 처리방침](https://kr.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), [쿠키정책](https://kr.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy)에 동의하게 됩니다.\\\\n\"}, {\"url\": \"https://fastcampus.co.kr/data_online_langgraph\", \"title\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent - 패스트캠퍼스\", \"content\": \"RAG & AI Agent RAG & AI Agent RAG & AI Agent RAG & AI Agent \\\\\\\\* 해당 강의는 사전 예약 상품으로, 강의 영상이 공개 일정에 따라 순차적으로 제작되어 오픈됩니다. * 본 패키지는 약 **18**시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다. * 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다. * 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다. * 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다. 패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\", \"score\": 0.85509074, \"raw_content\": \"# root layout\\\\n\\\\n# 패스트캠퍼스\\\\n\\\\n# [Fast Campus](/)\\\\n\\\\n## 사용자 메뉴\\\\n\\\\n[기업교육](https://b2b.fastcampus.co.kr/)\\\\n\\\\n[AI TECH](/category_online_datasciencedl)[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n## 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\n\\\\n약 17시간\\\\n\\\\n사전지식 필요\\\\n\\\\nLangGraph 공부의 시작점이 되는 강의! 사람같은 AI 서비스, RAG, AI agent 개발에 필수스택이 된 랭그래프의 원리와 활용, LangGraph가 쓰이는 대표적인 use case 6가지까지.\\\\n\\\\n[#LLM](/search?keyword=LLM)[#multi agent](/search?keyword=multi agent)[#RAG](/search?keyword=RAG)[#랭그래프](/search?keyword=랭그래프)\\\\n\\\\n### 강의 정보\\\\n\\\\n25.05.26 전체 공개\\\\n\\\\n학습자료 제공\\\\n\\\\n커뮤니티 운영\\\\n\\\\n### 69% 월 20,584원 12개월 무이자 할부 시\\\\n\\\\n권장 소비자 가격\\\\n:   ~~800,000원~~\\\\n\\\\n할인 금액\\\\n:   -553,000원\\\\n\\\\n할인 판매가\\\\n:   247,000원\\\\n\\\\n### 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\n\\\\n커리큘럼\\\\n\\\\n클립 39개\\\\n\\\\n* Part 1. RAG와 AI Agent의 이해\\\\n\\\\n  5 클립\\\\n* Part 2. LangGraph\\\\n\\\\n  10 클립\\\\n* Part 3. LangGraph를 이용한 현업 적용 프로젝트\\\\n\\\\n  11 클립\\\\n* Part 4. LangGraph Application 배포하기\\\\n\\\\n  4 클립\\\\n* Part 5. Summary & Wrap-up\\\\n\\\\n  1 클립\\\\n* [부록] LangChain과 LLM API\\\\n\\\\n  8 클립\\\\n\\\\n영상공개 일정\\\\n\\\\n해당 강의는 총 4회에 걸쳐 공개됩니다.\\\\n\\\\n1차2025.02.24(월)\\\\n\\\\n2차2025.03.31(월)\\\\n\\\\n3차2025.04.28(월)\\\\n\\\\n최종2025.05.26(월)\\\\n\\\\n## 커뮤니티\\\\n\\\\n### 수강생들은 어떤 질문을 하고, 어떤 이야기를 나누고 있을까요?\\\\n\\\\n패스트캠퍼스 커뮤니티에서 다른 수강생들과 함께 궁금했던 주제에 대해 다양한 관점과 답변을 찾아보세요.\\\\n\\\\n[커뮤니티 바로가기](/community)\\\\n\\\\n## 이런 강의는 어떠세요?\\\\n\\\\n지금 보는 강의와 유사해요!\\\\n\\\\n[10+](/data_online_ksjprompt)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[강수진 박사의 프롬프트·컨텍스트 엔지니어링 아카데미\\\\n\\\\n약 25시간누구나\\\\n\\\\n인기 급상승온라인](/data_online_ksjprompt)\\\\n\\\\n[10+](/data_online_ontology)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[온톨로지 기반 지식 구조화 : 설계부터 Graph RAG·추론·BPM을 통한 AI 활용까지\\\\n\\\\n약 12시간사전지식 필요\\\\n\\\\n온라인](/data_online_ontology)\\\\n\\\\n[10+](/data_online_mcpa2a)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[MCP와 A2A로 끝내는 상상도 못할 Multi-Agent 구축\\\\n\\\\n약 29시간사전지식 필요\\\\n\\\\n온라인](/data_online_mcpa2a)\\\\n\\\\n[10+](/data_online_teddy)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[테디노트의 RAG 비법노트 : GPT·로컬 모델부터 LangGraph·Agent까지\\\\n\\\\n약 66시간누구나\\\\n\\\\nFC AWARD온라인](/data_online_teddy)\\\\n\\\\n학습 규정 및 환불 규정\\\\n\\\\n#### 학습 규정\\\\n\\\\n---\\\\n\\\\n\\\\\\\\* 본 상품은 동영상 형태의 강의를 수강하는 상품입니다.\\\\n\\\\n\\\\\\\\* 상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\\\n\\\\n\\\\\\\\* 해당 강의는 사전 예약 상품으로, 강의 영상이 공개 일정에 따라 순차적으로 제작되어 오픈됩니다.\\\\n\\\\n총 학습기간:\\\\n\\\\n* 정상 수강기간(유료 수강기간) 최초 **30일**, 무료 수강 기간은 **31일** 일차 이후로 무제한이며, 유료 수강기간과 무료 수강기간 모두 동일하게 시청 가능합니다.\\\\n* 본 패키지는 약 **18**시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다.\\\\n* 수강시작일: 수강 시작일은 결제일로부터 기간이 산정되며, 결제를 완료하시면 마이페이지를 통해 바로 수강이 가능합니다. (사전 예약 강의는 1차 강의 오픈일)\\\\n* 패스트캠퍼스의 사정으로 수강시작이 늦어진 경우에는 해당 일정 만큼 수강 시작일이 연기됩니다.\\\\n* 일부 강의는 아직 모든 영상이 공개되지 않았습니다. 각 상세페이지 하단에 공개 일정이 안내되어 있습니다.\\\\n\\\\n#### 주의 사항\\\\n\\\\n---\\\\n\\\\n* 상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\\\n* 천재지변, 폐업 등 서비스 중단이 불가피한 상황에는 서비스가 종료될 수 있습니다.\\\\n* 본 상품은 기수강생 할인, VIP CLUB 제도 (구 프리미엄 멤버십), 기타 할인 이벤트 적용이 불가할 수 있습니다.\\\\n* 커리큘럼은 제작 과정에서 일부 추가, 삭제 및 변경될 수 있습니다.\\\\n* 쿠폰 적용이나 프로모션 등으로 인해 5만원 이하의 금액으로 강의를 결제할 경우, 할부가 적용되지 않습니다.\\\\n\\\\n#### 환불 규정\\\\n\\\\n---\\\\n\\\\n* 환불금액은 정가가 아닌 실제 결제금액을 기준으로 계산됩니다.\\\\n* 쿠폰을 사용하여 강의를 결제하신 후 취소/환불 시 쿠폰은 복구되지 않습니다.\\\\n\\\\n* 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다.\\\\n* 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다.\\\\n\\\\n* 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다.\\\\n\\\\n  + 환불요청일 시 기준\\\\n  + : 수강시작 후 1/3 경과 전, 실 결제금액의 2/3에 해당하는 금액 환불\\\\n  + : 수강시작 후 1/2 경과 전, 실 결제금액의 1/2에 해당하는 금액 환불\\\\n  + : 수강시작 후 1/2 경과 후, 환불 금액 없음\\\\n\\\\n\\\\\\\\* 보다 자세한 환불 규정은 홈페이지 취소/환불 정책에서 확인 가능합니다.\\\\n\\\\n#### 패스트캠퍼스 정책 안내\\\\n\\\\n---\\\\n\\\\n**[패스트캠퍼스 아이디 공유 금지 정책]**\\\\n\\\\n패스트캠퍼스의 모든 온라인 강의에서는 1개의 아이디로 여러명이 공유하는 형태를 금지하고 있습니다.\\\\n\\\\n동시접속에 대한 기록은 내부 시스템을 통해 자동으로 누적되며, 이후 서비스 이용이 제한될 수 있습니다.\\\\n\\\\n**[기기제한 정책]**\\\\n\\\\n패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\\\\n\\\\n최대 갯수를 초과하였을 경우 등록된 기기 해제가 필요합니다.\\\\n\\\\n**[저작권 정책]**\\\\n\\\\n패스트캠퍼스의 모든 강의는 무단 배포 및 가공하는 행위, 캡쳐 및 녹화하여 공유하는 행위, 무단으로 판매하는 행위 등 일체의 저작권 침해 행위를 금지합니다.\\\\n\\\\n부정 사용이 적발될 경우 저작권법 위반에 의한 법적인 제재를 받으실 수 있습니다.\\\\n\\\\n**국내 7개 카드사 12개월 무이자 할부 지원! (간편 결제 제외)**\\\\n\\\\n* 삼성카드\\\\n* 신한카드\\\\n* 롯데카드\\\\n* 현대카드\\\\n* 하나카드\\\\n* KB국민은행\\\\n* NH농협카드\"}], \"response_time\": 5.66, \"request_id\": \"82a0d966-84fb-4c89-b023-3556609ed904\"}', name='tavily_search', tool_call_id='7fa56ad9-f73a-47e6-be05-c8b1eb767308')"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_msg = tool_exec.invoke(tool_call_msg.tool_calls[0])\n",
        "tool_msg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6bb8aaf",
      "metadata": {
        "id": "e6bb8aaf"
      },
      "source": [
        "이번에는 ToolMessage라는 새로운 형태의 메시지가 생성되었습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782933c1",
      "metadata": {
        "id": "782933c1"
      },
      "source": [
        "툴 실행 결과를 LLM에게 다시 전달하여, 이를 해석하고 답변하게 만들어 보겠습니다.   \n",
        "\n",
        "Chain 형식의 구성은 메시지를 변화시키는 것이 복잡하므로, 이전에 사용했던 `HumanMessage`에서 시작하여   \n",
        "LLM의 답변인 `AIMessage`와 `ToolMessage` 를 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "613a7da6",
      "metadata": {
        "id": "613a7da6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"query\": \"\\\\ud328\\\\uc2a4\\\\ud2b8\\\\ucea0\\\\ud37c\\\\uc2a4 \\\\ub7ad\\\\uadf8\\\\ub798\\\\ud504\\\\ub85c \\\\ud55c\\\\ubc88\\\\uc5d0 \\\\uc644\\\\uc131\\\\ud558\\\\ub294 \\\\ubcf5\\\\uc7a1\\\\ud55c RAG\\\\uc640 Agent \\\\uacfc\\\\uc815\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--a27a2867-0766-41db-a181-0bd0f1bd5c68-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': '패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'}, 'id': '7fa56ad9-f73a-47e6-be05-c8b1eb767308', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1567, 'output_tokens': 105, 'total_tokens': 1672, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 68}}),\n",
              " ToolMessage(content='{\"query\": \"패스트캠퍼스 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정\", \"follow_up_questions\": null, \"answer\": \"The course teaches complex RAG and Agent development using LangGraph. It lasts 18 hours and offers flexible online learning. Refunds are available within the first 7 days of enrollment.\", \"images\": [], \"results\": [{\"url\": \"https://cdn.day1company.io/prod/uploads/202509/100554-1064/-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4--%EA%B5%90%EC%9C%A1%EA%B3%BC%EC%A0%95%EC%86%8C%EA%B0%9C%EC%84%9C-%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent.pdf\", \"title\": \"[PDF] 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\", \"content\": \"Life Changing Education 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent Life Changing Education Copyright ⓒ FAST CAMPUS Corp. 강의정보 강의장 온라인 강의 | 데스크탑, 노트북, 모바일 등 수강 기간 평생 소장 상세페이지 https://fastcampus.co.kr/data_online_langgraph 강의시간 약 18시간 문의 고객센터 강의특징 나만의 속도로 낮이나 새벽이나 내가 원하는 시간대에 나의 스케쥴대로 수강 원하는 곳 어디서나 시간을 쪼개 먼 거리를 오가며 오프라인 강의장을 찾을 필요 없이 어디서든 수강 무제한 복습 무엇이든 반복적으로 학습해야 내것이 되기에 이해가 안가는 구간 몇번이고 재생 Life Changing Education Copyright ⓒ FAST CAMPUS Corp. LangGraph 파트별 수강시간 02:29:36 Life Changing Education CH01. LangGraph Application 배포하기 파트별 수강시간 02:24:16 Life Changing Education CH01. LangChain과 LLM API 파트별 수강시간 03:36:50 Life Changing Education Copyright ⓒ FAST CAMPUS Corp.\", \"score\": 0.8825193, \"raw_content\": \"Life Changing Education 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent Life Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n강의정보 강의장 온라인 강의 | 데스크탑, 노트북, 모바일 등 수강 기간 평생 소장 상세페이지 https://fastcampus.co.kr/data_online_langgraph 강의시간 약 18시간 문의 고객센터 강의특징 나만의 속도로 낮이나 새벽이나 내가 원하는 시간대에 나의 스케쥴대로 수강 원하는 곳 어디서나 시간을 쪼개 먼 거리를 오가며 오프라인 강의장을 찾을 필요 없이 어디서든 수강 무제한 복습 무엇이든 반복적으로 학습해야 내것이 되기에 이해가 안가는 구간 몇번이고 재생 Life Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n강의목표 -LangGraph 공부의 시작점이 되는 강의! 사람같은 AI 서비스, RAG, AI agent 개발에 필수스택이 된 랭그래프의 원리와 활용, LangGraph가 쓰이는 대표적인 use case 6가지까지 -복잡한 RAG와 고도화된 흐름의 AI Agent까지 LangGraph로 LLM 공부를 시작하세요.\\\\n-2025년의 LLM 트렌드인 Agent와 핵심 프레임워크가 랭그래프인 이유를 알아가세요.\\\\n-랭그래프의 Node와 Edge, Graph 등 생소한 구조 개념 정리부터 랭그래프에서 까다로운 Graph와 State를 컨트롤하기 위한 방법을 알려드려요.\\\\n-다양한 산업 분야에서 Advanced RAG를 구축하고 싶다면 랭체인과 랭그래프의 특징을 파악하고 서로 보완할 수 있도록 활용해야 합니다!\\\\n강의요약 -허깅페이스에 올라오는 Llama(라마), Qwen(큐웬)과 같은 다양한 오픈 모델을 활용하여 에이전트를 구현합니다.\\\\n-널리 쓰이고 있는 LLM 서빙 프레임워크로 저비용 고성능으로 LLM을 추론할 수 있는 최적화 방법을 알아봅니다.\\\\n-실제로 사용자가 LLM 어플리케이션에 접속할 수 있도록 LLM을 서버에 올리고, 웹 프론트엔드에 연결해봅니다.\\\\n-Agent의 대표 활용 사례들을 직접 제작해보고, Agent 플로우를 만드는 단계를 반복해서 실습하며 체득하세요.\\\\nLife Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n강사 변형호 과목 -랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 약력 -현) 노토랩 대표 -현) 두피디아 정보과학/인공지능 분야 집필진 -국민연금, 국가보안기술연구소 기술 자문 -두산백과 정보과학/인공지능 분야 집필진 Life Changing Education CH01. RAG와 AI Agent의 이해 01. LLM 발전 동향 02. LLM 발전 동향 (2) 02. LLM과 Agent 03. 다양한 LLM Agent의 구조 04. LangChain Tool Calling과 Agent CURRICULUM 01. RAG와 AI Agent의 이해 파트별 수강시간 01:51:20 Life Changing Education CH01. LangGraph 01. LangGraph 소개 02. LangGraph Node와 Edge, Graph 구조 03. LangGraph의 다양한 State 04. 조건부 엣지와 툴 노드 연결하기 05. Agent의 Planning 구조- ReAct 06. 다양한 그래프 구조 07. LangSmith와 LangGraph Studio 08. 그래프 메모리 관리 09. Human-in-the-Loop 10. 멀티 에이전트 구조 CURRICULUM 02. LangGraph 파트별 수강시간 02:29:36 Life Changing Education CH01. 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 01. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 02. 1) 의도 분류를 활용한 다기능 RAG 챗봇 어플리케이션 (2) 03. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent 04. 2) 복잡한 쿼리를 처리하는 패러럴 구조 기반의 SQL DB Agent (2) 05. 3) 비전 모델을 활용한 멀티모달 RAG Agent 06. 3) 비전 모델을 활용한 멀티모달 RAG Agent 07. 4) 멀티 에이전트 기반 Research Agent 08. 4) 멀티 에이전트 기반 Research Agent (실습) 08_2. 4) 멀티 에이전트 기반 Research Agent (실습 2) 09. 5) Code Interpreter를 이용한 내 파일 기반 차트 제너레이터 10. 6) 멀티 에이전트를 활용한 보고서 작성과 품질 평가 관리 시스템 CURRICULUM 03. LangGraph를 이용한 현업 적용 프로젝트 파트별 수강시간 05:18:29 Life Changing Education CH01. LangGraph Application 배포하기 01. HuggingFace 공개 LLM을 활용한 Agentic Work 만들기 02. HuggingFace 공개 LLM을 활용한 Agentic Work 만들기 (2) 03. Ollama와 vLLM을 이용한 Agentic Work 최적화 04. 만들어진 LangGraph Application 배포하기 (Streamlit Gradio LangGraph Cloud) CURRICULUM 04. LangGraph Application 배포하기 파트별 수강시간 02:24:16 Life Changing Education CH01. Summary & Wrap-up 01. Summary & Wrap-up CURRICULUM 05. Summary & Wrap-up 파트별 수강시간 00:12:10 Life Changing Education CH01. LangChain과 LLM API 01. [실습] OpenAI와 Gemini API 사용하기 02. LangChain을 이용한 LLM 어플리케이션 만들기 03. [실습] LangChain Expression Language 04. [실습] LangChain Expression Language (2) (추가) 05. [실습] LangChain을 이용한 LLM 어플리케이션 만들기 06. Retrieval Augmented Generation 이해하기 07. Retrieval Augmented Generation 이해하기 (2) 08. [실습] LangChain을 이용한 RAG 구현하기 CURRICULUM 부록. LangChain과 LLM API 파트별 수강시간 03:36:50 Life Changing Education Copyright ⓒ FAST CAMPUS Corp. All Rights Reserved.\\\\n주의 사항 -상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\\\n-패스트캠퍼스의 모든 온라인 강의는 아이디 공유를 금지하고 있으며 1개의 아이디로 여러 명이 수강하실 수 없습니다.\\\\n-별도의 주의사항은 각 강의 상세페이지에서 확인하실 수 있습니다. 수강 방법 -패스트캠퍼스는 크롬 브라우저에 최적화 되어있습니다. -사전 예약 판매 중인 강의의 경우 1차 공개일정에 맞춰 ‘온라인 강의 시청하기’가 활성화됩니다.\\\\n환불 규정 -강의 시수, 형태에 따라 환불 규정이 상이 하므로 반드시 각 강의 상세페이지 하단 [환불 규정] 과 [패스트캠퍼스 취소/환불 정책] 내용을 확인해 주시기 바랍니다.\\\\n-패스트캠퍼스 취소/환불 정책 : https://fastcampus.co.kr/info/policies/refund\"}, {\"url\": \"https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr\", \"title\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | Hyungho Byun\", \"content\": \"LinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content) LinkedIn 회원 가입 로그인 과정 이름은 \\\\\"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr  LinkedIn Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 Hyungho Byun노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사 댓글 신고 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다. 가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn 사용자약관, 개인정보 처리방침, 쿠키정책에 동의하게 됩니다.\", \"score\": 0.86981434, \"raw_content\": \"Published Time: 2025-01-24T06:24:20.229Z\\\\n\\\\nLinkedIn Hyungho Byun 페이지: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스\\\\n===============\\\\n\\\\n   \\\\n\\\\nLinkedIn 동의 후 가입\\\\n\\\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn [사용자약관](https://kr.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [개인정보 처리방침](https://kr.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), [쿠키정책](https://kr.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy)에 동의하게 됩니다.\\\\n\\\\n       [본문 내용으로 가기](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr#main-content)\\\\n\\\\n[LinkedIn](https://kr.linkedin.com/?trk=public_post_nav-header-logo)\\\\n\\\\n*   [글](https://www.linkedin.com/pulse/topics/home/?trk=public_post_guest_nav_menu_articles)\\\\n*   [사람](https://www.linkedin.com/pub/dir/+/+?trk=public_post_guest_nav_menu_people)\\\\n*   [온라인클래스](https://www.linkedin.com/learning/search?trk=public_post_guest_nav_menu_learning)\\\\n*   [채용공고](https://www.linkedin.com/jobs/search?trk=public_post_guest_nav_menu_jobs)\\\\n*   [게임](https://www.linkedin.com/games?trk=public_post_guest_nav_menu_games)\\\\n\\\\n[회원 가입](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_nav-header-join) [로그인](https://www.linkedin.com/login?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&fromSignIn=true&trk=public_post_nav-header-signin)\\\\n\\\\nHyungho Byun님의 업데이트\\\\n===================\\\\n\\\\n [![Image 1: Hyungho Byun님 프로필을 조회합니다.](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_feed-actor-image)\\\\n\\\\n[Hyungho Byun](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_feed-actor-name)\\\\n\\\\n노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\\\n\\\\n1개월\\\\n\\\\n*   [글 신고](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fkr.linkedin.com%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)\\\\n\\\\n안녕하세요! 노토랩의 변형호입니다.\\xa0 오늘 OpenAI의 웹 탐색 기능이 탑재된 에이전트 오퍼레이터(Operator)가 공개되었는데요. 이에 맞춰서 광고를 좀 하겠습니다..😅 제가 패스트캠퍼스에서 LangGraph에 대한 온라인 강의를 런칭합니다. 과정 이름은 \\\\\"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\\" 입니다 :) LLM 어플리케이션 개발의 가장 편한 라이브러리가 랭체인이었다면,\\xa0 랭체인의 단일 기능을 활용해 복잡한 워크플로우(Workflow)를 구성하고, 효과적으로 관리하도록 만들어 주는 라이브러리는 랭그래프입니다. 랭그래프가 랭체인보다 좀 어렵긴 한데요... 단계별로 쉽게 이해할 수 있는 강의를 준비했습니다! RAG가 결합된 복잡한 시스템이나, 스탠포드 스톰(STORM)과 같은 멀티 에이전트 구조를 만들고 싶으신 분들께는 많은 도움이 되실 것 같습니다. 실무에서 활용할 수 있는 6개의 프로젝트를 중심으로 복잡한 그래프 구조, 휴먼인더루프, 품질 검증과 같은 요소들도 아주 세세하게 다룰 예정이구요. 또한, LLM 기본 코드 지식이 필요하신 분들을 위한 랭체인, LLM API 활용 챕터도 부록으로 준비했습니다. 1차 공개 일정은 2월 24일이라 아직 여유가 좀 있는데요(?) 관심 있으신 분들은 [https://bit.ly/40lXEj2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fbit%2Ely%2F40lXEj2&urlhash=jnYC&trk=public_post-text) 에서 자세한 내용을 확인하실 수 있습니다. 아래의 쿠폰코드를 입력하시면 20% 할인 가능합니다! PRDTEA250124\\\\\\\\_sns202 LangChain의 기초, LLM과 Agent에 대한 샘플 영상 2개도 같이 업로드했는데요. 이 영상은 댓글에 올려 놓겠습니다. 다음 포스팅은 다시 이전처럼 기술 이야기로 뵙겠습니다. 감사합니다! 😁\\\\n\\\\n [![Image 2: 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr) 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent | 패스트캠퍼스 -------------------------------------- ### fastcampus.co.kr](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Ffastcampus%2Eco%2Ekr%2Fdata_online_langgraph&urlhash=MLpe&trk=public_post_feed-article-content) \\\\n\\\\n  [![Image 3](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr) ![Image 4](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr) 38](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_social-actions-reactions)           [댓글 2](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_social-actions-comments)\\\\n\\\\n[추천](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_like-cta) [댓글](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment-cta)  \\\\n\\\\n공유\\\\n\\\\n*   복사\\\\n*   LinkedIn\\\\n*   Facebook\\\\n*   Twitter\\\\n\\\\n[![Image 5: Hyungho Byun님, 그래픽](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-image)\\\\n\\\\n[Hyungho Byun](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-name)노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\\\n\\\\n1개월\\\\n\\\\n*   [댓글 신고](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fkr.linkedin.com%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\\\n\\\\n[https://youtu.be/yLOjUf\\\\\\\\_XH1o?si=NZ2r8AlLoTk0s2C1](https://youtu.be/yLOjUf_XH1o?si=NZ2r8AlLoTk0s2C1&trk=public_post_comment-text)\\\\n\\\\n[추천](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_like)[댓글](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_reply)반응\\xa01\\\\n\\\\n[![Image 6: Hyungho Byun님, 그래픽](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-image)\\\\n\\\\n[Hyungho Byun](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_comment_actor-name)노토랩 대표, LLM 강의/개발/기술자문, 서울대 컴퓨터공학 박사\\\\n\\\\n1개월\\\\n\\\\n*   [댓글 신고](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fkr.linkedin.com%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)\\\\n\\\\n[https://youtu.be/sUZ9LPK7fY4?si=ccTDrvW\\\\\\\\_NNZfhktx](https://youtu.be/sUZ9LPK7fY4?si=ccTDrvW_NNZfhktx&trk=public_post_comment-text)\\\\n\\\\n[추천](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_like)[댓글](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_comment_reply)반응\\xa01\\\\n\\\\n[더 보기](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_see-more-comments)댓글을 보거나 남기려면 [로그인](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_feed-cta-banner-cta)\\\\n\\\\n![Image 7](https://static.licdn.com/aero-v1/sc/h/5q92mjc5c51bjlwaj3rs9aa82)\\\\n\\\\n![Image 8: Hyungho Byun](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)팔로워 1,191명\\\\n\\\\n*   [업데이트 36개](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fin%2Fhyungho-byun-6b2588224%2Frecent-activity%2F&trk=public_post_follow-posts)\\\\n\\\\n[프로필 보기](https://kr.linkedin.com/in/hyungho-byun-6b2588224?trk=public_post_follow-view-profile) [팔로우](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7288441474692661248&trk=public_post_follow)\\\\n\\\\n*   LinkedIn © 2025\\\\n*   [정보](https://about.linkedin.com/?trk=d_public_post_footer-about)\\\\n*   [웹접근성](https://www.linkedin.com/accessibility?trk=d_public_post_footer-accessibility)\\\\n*   [사용자약관](https://www.linkedin.com/legal/user-agreement?trk=d_public_post_footer-user-agreement)\\\\n*   [개인정보 처리방침](https://www.linkedin.com/legal/privacy-policy?trk=d_public_post_footer-privacy-policy)\\\\n*   [Your California Privacy Choices](https://www.linkedin.com/legal/california-privacy-disclosure?trk=d_public_post_footer-california-privacy-rights-act)\\\\n*   [쿠키정책](https://www.linkedin.com/legal/cookie-policy?trk=d_public_post_footer-cookie-policy)\\\\n*   [저작권정책](https://www.linkedin.com/legal/copyright-policy?trk=d_public_post_footer-copyright-policy)\\\\n*   [브랜드정책](https://brand.linkedin.com/policies?trk=d_public_post_footer-brand-policy)\\\\n*   [비회원 설정](https://www.linkedin.com/psettings/guest-controls?trk=d_public_post_footer-guest-controls)\\\\n*   [커뮤니티정책](https://www.linkedin.com/legal/professional-community-policies?trk=d_public_post_footer-community-guide)\\\\n*   *   아랍어(العربية)\\\\n    *   벵골어(বাংলা)\\\\n    *   체코어(Čeština)\\\\n    *   덴마크어(Dansk)\\\\n    *   독일어(Deutsch)\\\\n    *   그리스어(Ελληνικά)\\\\n    *   영어(English)\\\\n    *   스페인어(Español)\\\\n    *   페르시아어(فارسی)\\\\n    *   핀란드어(Suomi)\\\\n    *   프랑스어(Français)\\\\n    *   힌디어(हिंदी)\\\\n    *   헝가리어(Magyar)\\\\n    *   인도네시아어(Bahasa Indonesia)\\\\n    *   이탈리아어(Italiano)\\\\n    *   히브리어(עברית)\\\\n    *   일본어(日本語)\\\\n    *   **한국어(Korean)**\\\\n    *   마라티어(मराठी)\\\\n    *   말레이시아어(Bahasa Malaysia)\\\\n    *   네덜란드어(Nederlands)\\\\n    *   노르웨이어(Norsk)\\\\n    *   펀자브어(ਪੰਜਾਬੀ)\\\\n    *   폴란드어(Polski)\\\\n    *   포르투갈어(Português)\\\\n    *   루마니아어(Română)\\\\n    *   러시아어(Русский)\\\\n    *   스웨덴어(Svenska)\\\\n    *   텔루구어(తెలుగు)\\\\n    *   태국어(ภาษาไทย)\\\\n    *   필리핀어(Tagalog)\\\\n    *   터키어(Türkçe)\\\\n    *   우크라이나어(Українська)\\\\n    *   베트남어(Tiếng Việt)\\\\n    *   중국어 간체(简体中文)\\\\n    *   중국어 번체(正體中文)\\\\n    \\\\n    언어\\\\n    \\\\n\\\\n![Image 9](https://kr.linkedin.com/posts/hyungho-byun-6b2588224_%EB%9E%AD%EA%B7%B8%EB%9E%98%ED%94%84%EB%A1%9C-%ED%95%9C%EB%B2%88%EC%97%90-%EC%99%84%EC%84%B1%ED%95%98%EB%8A%94-%EB%B3%B5%EC%9E%A1%ED%95%9C-rag%EC%99%80-agent-%ED%8C%A8%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%8D%BC%EC%8A%A4-activity-7288441474692661248-b3zr)\\\\n\\\\n로그인해서 콘텐츠 더보기\\\\n-------------\\\\n\\\\n무료 계정을 만들거나 로그인하여 검색을 계속하세요.\\\\n\\\\n로그인\\\\n\\\\n어서오세요!\\\\n------\\\\n\\\\n          \\\\n\\\\n이메일 또는 전화\\\\n\\\\n비밀번호\\\\n\\\\n 표시\\\\n\\\\n \\\\n\\\\n[비밀번호를 잊으셨나요?](https://www.linkedin.com/uas/request-password-reset?trk=public_post_contextual-sign-in-modal_sign-in-modal_forgot_password)  로그인\\\\n\\\\n또는\\\\n\\\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn [사용자약관](https://kr.linkedin.com/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [개인정보 처리방침](https://kr.linkedin.com/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), [쿠키정책](https://kr.linkedin.com/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy)에 동의하게 됩니다.\\\\n\\\\nLinkedIn이 처음이세요? [회원 가입](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)\\\\n\\\\n또는\\\\n\\\\nLinkedIn이 처음이세요? [회원 가입](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fkr%2Elinkedin%2Ecom%2Fposts%2Fhyungho-byun-6b2588224_%25EB%259E%25AD%25EA%25B7%25B8%25EB%259E%2598%25ED%2594%2584%25EB%25A1%259C-%25ED%2595%259C%25EB%25B2%2588%25EC%2597%2590-%25EC%2599%2584%25EC%2584%25B1%25ED%2595%2598%25EB%258A%2594-%25EB%25B3%25B5%25EC%259E%25A1%25ED%2595%259C-rag%25EC%2599%2580-agent-%25ED%258C%25A8%25EC%258A%25A4%25ED%258A%25B8%25EC%25BA%25A0%25ED%258D%25BC%25EC%258A%25A4-activity-7288441474692661248-b3zr&trk=public_post_contextual-sign-in-modal_join-link)\\\\n\\\\n가입이나 로그인을 하기 위해 계속 버튼을 클릭하면 LinkedIn [사용자약관](https://kr.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [개인정보 처리방침](https://kr.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), [쿠키정책](https://kr.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy)에 동의하게 됩니다.\\\\n\"}, {\"url\": \"https://fastcampus.co.kr/data_online_langgraph\", \"title\": \"랭그래프로 한번에 완성하는 복잡한 RAG와 Agent - 패스트캠퍼스\", \"content\": \"RAG & AI Agent RAG & AI Agent RAG & AI Agent RAG & AI Agent \\\\\\\\* 해당 강의는 사전 예약 상품으로, 강의 영상이 공개 일정에 따라 순차적으로 제작되어 오픈됩니다. * 본 패키지는 약 **18**시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다. * 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다. * 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다. * 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다. 패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\", \"score\": 0.85509074, \"raw_content\": \"# root layout\\\\n\\\\n# 패스트캠퍼스\\\\n\\\\n# [Fast Campus](/)\\\\n\\\\n## 사용자 메뉴\\\\n\\\\n[기업교육](https://b2b.fastcampus.co.kr/)\\\\n\\\\n[AI TECH](/category_online_datasciencedl)[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n## 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\n\\\\n약 17시간\\\\n\\\\n사전지식 필요\\\\n\\\\nLangGraph 공부의 시작점이 되는 강의! 사람같은 AI 서비스, RAG, AI agent 개발에 필수스택이 된 랭그래프의 원리와 활용, LangGraph가 쓰이는 대표적인 use case 6가지까지.\\\\n\\\\n[#LLM](/search?keyword=LLM)[#multi agent](/search?keyword=multi agent)[#RAG](/search?keyword=RAG)[#랭그래프](/search?keyword=랭그래프)\\\\n\\\\n### 강의 정보\\\\n\\\\n25.05.26 전체 공개\\\\n\\\\n학습자료 제공\\\\n\\\\n커뮤니티 운영\\\\n\\\\n### 69% 월 20,584원 12개월 무이자 할부 시\\\\n\\\\n권장 소비자 가격\\\\n:   ~~800,000원~~\\\\n\\\\n할인 금액\\\\n:   -553,000원\\\\n\\\\n할인 판매가\\\\n:   247,000원\\\\n\\\\n### 랭그래프로 한번에 완성하는 복잡한 RAG와 Agent\\\\n\\\\n커리큘럼\\\\n\\\\n클립 39개\\\\n\\\\n* Part 1. RAG와 AI Agent의 이해\\\\n\\\\n  5 클립\\\\n* Part 2. LangGraph\\\\n\\\\n  10 클립\\\\n* Part 3. LangGraph를 이용한 현업 적용 프로젝트\\\\n\\\\n  11 클립\\\\n* Part 4. LangGraph Application 배포하기\\\\n\\\\n  4 클립\\\\n* Part 5. Summary & Wrap-up\\\\n\\\\n  1 클립\\\\n* [부록] LangChain과 LLM API\\\\n\\\\n  8 클립\\\\n\\\\n영상공개 일정\\\\n\\\\n해당 강의는 총 4회에 걸쳐 공개됩니다.\\\\n\\\\n1차2025.02.24(월)\\\\n\\\\n2차2025.03.31(월)\\\\n\\\\n3차2025.04.28(월)\\\\n\\\\n최종2025.05.26(월)\\\\n\\\\n## 커뮤니티\\\\n\\\\n### 수강생들은 어떤 질문을 하고, 어떤 이야기를 나누고 있을까요?\\\\n\\\\n패스트캠퍼스 커뮤니티에서 다른 수강생들과 함께 궁금했던 주제에 대해 다양한 관점과 답변을 찾아보세요.\\\\n\\\\n[커뮤니티 바로가기](/community)\\\\n\\\\n## 이런 강의는 어떠세요?\\\\n\\\\n지금 보는 강의와 유사해요!\\\\n\\\\n[10+](/data_online_ksjprompt)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[강수진 박사의 프롬프트·컨텍스트 엔지니어링 아카데미\\\\n\\\\n약 25시간누구나\\\\n\\\\n인기 급상승온라인](/data_online_ksjprompt)\\\\n\\\\n[10+](/data_online_ontology)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[온톨로지 기반 지식 구조화 : 설계부터 Graph RAG·추론·BPM을 통한 AI 활용까지\\\\n\\\\n약 12시간사전지식 필요\\\\n\\\\n온라인](/data_online_ontology)\\\\n\\\\n[10+](/data_online_mcpa2a)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[MCP와 A2A로 끝내는 상상도 못할 Multi-Agent 구축\\\\n\\\\n약 29시간사전지식 필요\\\\n\\\\n온라인](/data_online_mcpa2a)\\\\n\\\\n[10+](/data_online_teddy)\\\\n\\\\n[RAG & AI Agent](/category_online_aitechrag)\\\\n\\\\n[테디노트의 RAG 비법노트 : GPT·로컬 모델부터 LangGraph·Agent까지\\\\n\\\\n약 66시간누구나\\\\n\\\\nFC AWARD온라인](/data_online_teddy)\\\\n\\\\n학습 규정 및 환불 규정\\\\n\\\\n#### 학습 규정\\\\n\\\\n---\\\\n\\\\n\\\\\\\\* 본 상품은 동영상 형태의 강의를 수강하는 상품입니다.\\\\n\\\\n\\\\\\\\* 상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\\\n\\\\n\\\\\\\\* 해당 강의는 사전 예약 상품으로, 강의 영상이 공개 일정에 따라 순차적으로 제작되어 오픈됩니다.\\\\n\\\\n총 학습기간:\\\\n\\\\n* 정상 수강기간(유료 수강기간) 최초 **30일**, 무료 수강 기간은 **31일** 일차 이후로 무제한이며, 유료 수강기간과 무료 수강기간 모두 동일하게 시청 가능합니다.\\\\n* 본 패키지는 약 **18**시간 분량으로, 일 1시간 내외의 학습 시간을 통해 정상 수강 기간(=유료 수강 기간) 내에 모두 수강이 가능합니다.\\\\n* 수강시작일: 수강 시작일은 결제일로부터 기간이 산정되며, 결제를 완료하시면 마이페이지를 통해 바로 수강이 가능합니다. (사전 예약 강의는 1차 강의 오픈일)\\\\n* 패스트캠퍼스의 사정으로 수강시작이 늦어진 경우에는 해당 일정 만큼 수강 시작일이 연기됩니다.\\\\n* 일부 강의는 아직 모든 영상이 공개되지 않았습니다. 각 상세페이지 하단에 공개 일정이 안내되어 있습니다.\\\\n\\\\n#### 주의 사항\\\\n\\\\n---\\\\n\\\\n* 상황에 따라 사전 공지 없이 할인이 조기 마감되거나 연장될 수 있습니다.\\\\n* 천재지변, 폐업 등 서비스 중단이 불가피한 상황에는 서비스가 종료될 수 있습니다.\\\\n* 본 상품은 기수강생 할인, VIP CLUB 제도 (구 프리미엄 멤버십), 기타 할인 이벤트 적용이 불가할 수 있습니다.\\\\n* 커리큘럼은 제작 과정에서 일부 추가, 삭제 및 변경될 수 있습니다.\\\\n* 쿠폰 적용이나 프로모션 등으로 인해 5만원 이하의 금액으로 강의를 결제할 경우, 할부가 적용되지 않습니다.\\\\n\\\\n#### 환불 규정\\\\n\\\\n---\\\\n\\\\n* 환불금액은 정가가 아닌 실제 결제금액을 기준으로 계산됩니다.\\\\n* 쿠폰을 사용하여 강의를 결제하신 후 취소/환불 시 쿠폰은 복구되지 않습니다.\\\\n\\\\n* 수강시작 후 7일 이내, 5강 미만 수강 시에는 100% 환불 가능합니다.\\\\n* 수강시작 후 7일 이내, 5강 이상 수강 시 전체 강의에서 수강한 강의의 비율에 해당하는 수강료를 차감 후 환불 가능합니다.\\\\n\\\\n* 수강시작 후 7일 초과 시 정상 수강기간 대비 잔여일에 대해 아래 환불규정에 따라 환불 가능합니다.\\\\n\\\\n  + 환불요청일 시 기준\\\\n  + : 수강시작 후 1/3 경과 전, 실 결제금액의 2/3에 해당하는 금액 환불\\\\n  + : 수강시작 후 1/2 경과 전, 실 결제금액의 1/2에 해당하는 금액 환불\\\\n  + : 수강시작 후 1/2 경과 후, 환불 금액 없음\\\\n\\\\n\\\\\\\\* 보다 자세한 환불 규정은 홈페이지 취소/환불 정책에서 확인 가능합니다.\\\\n\\\\n#### 패스트캠퍼스 정책 안내\\\\n\\\\n---\\\\n\\\\n**[패스트캠퍼스 아이디 공유 금지 정책]**\\\\n\\\\n패스트캠퍼스의 모든 온라인 강의에서는 1개의 아이디로 여러명이 공유하는 형태를 금지하고 있습니다.\\\\n\\\\n동시접속에 대한 기록은 내부 시스템을 통해 자동으로 누적되며, 이후 서비스 이용이 제한될 수 있습니다.\\\\n\\\\n**[기기제한 정책]**\\\\n\\\\n패스트캠퍼스 온라인 강의 시청을 위해서는 ID별 최대 4개의 기기를 등록할 수 있으며, 기기 등록은 온라인 강의장 접속 시 자동 등록됩니다.\\\\n\\\\n최대 갯수를 초과하였을 경우 등록된 기기 해제가 필요합니다.\\\\n\\\\n**[저작권 정책]**\\\\n\\\\n패스트캠퍼스의 모든 강의는 무단 배포 및 가공하는 행위, 캡쳐 및 녹화하여 공유하는 행위, 무단으로 판매하는 행위 등 일체의 저작권 침해 행위를 금지합니다.\\\\n\\\\n부정 사용이 적발될 경우 저작권법 위반에 의한 법적인 제재를 받으실 수 있습니다.\\\\n\\\\n**국내 7개 카드사 12개월 무이자 할부 지원! (간편 결제 제외)**\\\\n\\\\n* 삼성카드\\\\n* 신한카드\\\\n* 롯데카드\\\\n* 현대카드\\\\n* 하나카드\\\\n* KB국민은행\\\\n* NH농협카드\"}], \"response_time\": 5.66, \"request_id\": \"82a0d966-84fb-4c89-b023-3556609ed904\"}', name='tavily_search', tool_call_id='7fa56ad9-f73a-47e6-be05-c8b1eb767308')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "messages = [HumanMessage(content=\"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 어떤 과정이야?\")]\n",
        "\n",
        "messages.append(tool_call_msg)\n",
        "messages.append(tool_msg)\n",
        "\n",
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae6c7f1a",
      "metadata": {
        "id": "ae6c7f1a"
      },
      "source": [
        "`Query-Tool Call-Tool`의 형식은 가장 기본적인 툴 사용 방법입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "43b67cf9",
      "metadata": {
        "id": "43b67cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'type': 'text', 'text': \"패스트캠퍼스의 '랭그래프로 한번에 완성하는 복잡한 RAG와 Agent 과정'은 LangGraph를 활용하여 복잡한 RAG(검색 증강 생성) 및 AI 에이전트를 개발하는 방법을 가르치는 온라인 강의입니다.\\n\\n주요 특징은 다음과 같습니다:\\n*   **학습 내용**: LangGraph의 원리, 활용법, Node, Edge, Graph 구조, 다양한 State 제어 방법 등을 다룹니다. 또한, LangGraph가 사용되는 6가지 대표적인 활용 사례를 통해 복잡한 RAG 시스템과 고도화된 AI 에이전트 플로우를 구축하는 방법을 배울 수 있습니다.\\n*   **강의 시간**: 총 약 18시간 분량으로 구성되어 있습니다.\\n*   **수강 방식**: 온라인 강의로, 데스크탑, 노트북, 모바일 등 다양한 기기에서 원하는 시간에 무제한으로 복습하며 수강할 수 있습니다.\\n*   **대상**: LLM(대규모 언어 모델) 애플리케이션 개발에 필수적인 LangGraph를 배우고 싶거나, 복잡한 RAG와 AI 에이전트 개발에 관심 있는 분들을 위한 과정입니다.\\n*   **강사**: 노토랩 대표이자 LLM 강의/개발/기술 자문을 맡고 있는 변형호 강사입니다.\\n*   **환불 규정**: 수강 시작 후 7일 이내, 5강 미만 수강 시 100% 환불이 가능합니다.\\n\\n이 과정은 LangChain의 단일 기능을 넘어 복잡한 워크플로우를 구성하고 효과적으로 관리하는 데 필요한 LangGraph를 심층적으로 다루며, 실제 산업 분야에서 Advanced RAG를 구축하는 데 필요한 지식과 실습을 제공합니다.\", 'extras': {'signature': 'CtIIAdHtim8OxkgsibVw4K8A83qE8fQyGDeKg2hZeRxiytez0+zG8/sFOofg2UyXGwIl+Ll6zYW4NW/JaOX+QdbP6Reid/UuoHdS1XptPE5IJSTv3Pm4J5kdj9/uD6F4llqB/srHdSkAT4eIf9VqJ0XLbWiaR+Hw+lFjIboaPkB0PtxCoAuGPdNEpnC4DAESoPzT0dW9kZDub8u/jZligztn/jWBn5Ud3dbN7C1EotoS0VKQBXdbSLFbu44Of1TJFZ5kFVUB3fcOfzQk/KY/m4khmy22dn+kRxuk39bwNSet+xSs+Tu1bpD960CCvIRUl0JuL2FGsRB0mjxOzD0EJcBZfZpNsvVzTyiHucwa7KqoFvOUKOhQiDW2OxOQLybiJlCw8qfbCsMh8WpCpyCzgp5PHiSipWJo7ETNr0A7EtkNOudIFFHou4xCW24YtnX3COyKmdwpjjJOzY0FLbWCz1rxzUIfRLMm24YdjD5CgpyxQSzbexgYif4EmXYz13F2d4IUGcfLKViaBMsgGaxeC6O6hcrwAC1YnM3/piOZicYQ/eSZMITsBnXnJDVBE8Xare9gqGNneMpQJEA3RlCKs+w6Wpz3gLZWJBY91BGux9YTi3VcfoGYQ+MQDEAxsB4L6IX9mfVgIdNV2H8M1/UGWvEi5DvyA2wZlybjfcNhDomNpfKN6kgsmogDg4qRcX0+svLlTUw2qvTWQBjy9oAvzQQDVuO39QJFFdy3kEyOnMJKa8t4FAynVyvUIiimteeE/0p2gf+/O21y/klg2iqpUSyFqSha13XdvTB2mgdoWjTSIvhOpI7tf+u9xmxKoNQ7fUiVFarlhRh5b6lDp24ISl0OOIYMHupPZSodr7ZycPQ/dSjukZAi8MwM5QvZjEbj51Z/jRZnU75EJ6oUDTq72K6v5bnRyJHj8BmQTFRohmjZeD7svMgL6uKlJlgQJPkD79YcHMDmIu3+3yYuDfEwqcttxqM5BkJKn4CLlLn5t+3DahhTPLCoGRVy30rkPTWpNS/6pR2PwFwBIhmiuzkVAJ6QZJ9Fkqa9QmBb3K3+FUWh4T0sIPy8iloKcU3brBcyDHs8XCAuiB4T4GmC79wISmjpIbrcpSwglOsUG48yEwxWC8HZXe+14JkMDIaOnM2YoHVW3M+61w98QW+uhk/yHEd8r2QblrrSXzrO4grLs8EDxcopzWRf8WktTACLuQexJDkbHDSz58XK9HT79SddCmLpaICZiJ82ynL4D5lnVdx2B5f12H8r/sRhD/AHCQNMfjjyXtgUspwQP08PpH65A8XxibDA1ouLaqJjc03294I5egipISYHMgp8BZCdT2Yo12lvhRpQDpTd0FdINMNcARBNSw9pN3hphYRxSEij2rW24KyUAqSlBj2hfKcSei9dfW/8a0sznSkBzDyS2l4G1LqTxuSMYzAc+5cegrJbcHci0hZEk3GEv1DAuwgTwjCFEcuoE1M='}}]\n"
          ]
        }
      ],
      "source": [
        "result = llm_with_tools.invoke(messages)\n",
        "# 검색 결과를 바탕으로 답변한 모습\n",
        "\n",
        "print(result.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a13f430",
      "metadata": {
        "id": "8a13f430"
      },
      "source": [
        "이제, 지금까지 배운 내용을 종합하여 실행해 보겠습니다.   \n",
        "질문이 주어지면, 질문에 대한 검색을 수행하여 결과를 바탕으로 답변합니다.   \n",
        "\n",
        "<br><br>\n",
        "\n",
        "그런데, 이번에는 분기가 필요합니다.   \n",
        "검색이 필요없는 질문이라면, LLM은 tool을 요청하지 않을 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e288199c",
      "metadata": {
        "id": "e288199c"
      },
      "outputs": [],
      "source": [
        "# LLM, Question, Tool을 이용한 간단한 함수\n",
        "def simple_workflow(llm, question , tools = [tavily_search]):\n",
        "\n",
        "    # 툴과 LLM 구성\n",
        "\n",
        "    tool_list = {x.name: x for x in tools}\n",
        "    # tavily_search.name = 'tavily_search_results_json' 을 이용하면\n",
        "    # tool_list = {'tavily_search_results_json': tavily_search} 와 동일합니다.\n",
        "\n",
        "    llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "    # 메시지 구성\n",
        "    messages = [HumanMessage(content=question)]\n",
        "    print('Query:', question)\n",
        "\n",
        "\n",
        "    # LLM에 메시지 전달 (분기)\n",
        "    tool_msg = llm_with_tools.invoke(question)\n",
        "    messages.append(tool_msg)\n",
        "\n",
        "    if tool_msg.tool_calls:\n",
        "        # 툴 호출이 있을 경우: 툴 실행 후 결과를 전달\n",
        "        tool_name = tool_msg.tool_calls[0]['name']\n",
        "\n",
        "        print(f\"-- {tool_name} 사용 중 --\")\n",
        "        print(tool_msg.tool_calls[0])\n",
        "\n",
        "\n",
        "        tool_exec = tool_list[tool_name]\n",
        "\n",
        "        tool_result = tool_exec.invoke(tool_msg.tool_calls[0])\n",
        "        messages.append(tool_result)\n",
        "        result = llm_with_tools.invoke(messages)\n",
        "\n",
        "    else:\n",
        "        # 툴 호출이 없을 경우: 처음 출력을 그대로 전달\n",
        "        result = tool_msg\n",
        "\n",
        "    return result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "abf28c6f",
      "metadata": {
        "id": "abf28c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 2025년 10월 출시된 OpenAI의 AI 브라우저 이름이 뭐야?\n",
            "-- tavily_search 사용 중 --\n",
            "{'name': 'tavily_search', 'args': {'end_date': '2025-10-31', 'topic': 'general', 'query': 'OpenAI AI browser name', 'start_date': '2025-10-01'}, 'id': '2f93a7b3-e23e-4d14-ab89-dce934241e7e', 'type': 'tool_call'}\n",
            "2025년 10월에 출시된 OpenAI의 AI 브라우저 이름은 **Atlas**입니다. 이 브라우저는 OpenAI의 챗봇인 ChatGPT와 긴밀하게 작동하도록 설계되었습니다.\n"
          ]
        }
      ],
      "source": [
        "response = simple_workflow(llm, \"2025년 10월 출시된 OpenAI의 AI 브라우저 이름이 뭐야?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7536b3b4",
      "metadata": {
        "id": "7536b3b4"
      },
      "source": [
        "# Custom Tool 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90ba141",
      "metadata": {
        "id": "a90ba141"
      },
      "source": [
        "Tavily Search의 경우, 랭체인에서 사전에 구성한 기본 Schema가 존재하지만,   \n",
        "\n",
        "Tool을 새로 만드는 경우에는 description과 같은 값을 직접 구성해야 합니다.   \n",
        "가장 간단한 방식은 랭체인의 Tool 데코레이터를 사용하는 것입니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3eb6c405",
      "metadata": {
        "id": "3eb6c405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n",
            "2025-10-26\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(x:int, y:int) -> int:\n",
        "    \"x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.\"\n",
        "    return x*y\n",
        "\n",
        "@tool\n",
        "def current_date() -> str:\n",
        "    \"현재 날짜를 %y-%m-%d 형식으로 반환합니다.\"\n",
        "    from datetime import datetime\n",
        "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "print(multiply.invoke({'x':3, 'y':4}))\n",
        "print(current_date.invoke({}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c326134",
      "metadata": {},
      "source": [
        "이전에 생성한 tavily_search 툴도 보다 깔끔하게 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "2f413daf",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def tavily_search(query:str, max_results:int=5):\n",
        "    \"\"\"Tavily API를 통해 검색 결과를 가져옵니다.\n",
        "query: 검색어\n",
        "max_results : 검색 결과의 수(최소 1, 최대 20, 별도의 요청이 없으면 5로 고정)\"\"\"\n",
        "    tavily_search = TavilySearch(max_results=max_results,     \n",
        "                                include_answer = True,\n",
        "                                include_raw_content = 'markdown'\n",
        "    )\n",
        "\n",
        "    search_results = tavily_search.invoke(query)\n",
        "\n",
        "    context = f'POSSIBLE ANSWER: {search_results.get('answer')}\\n\\n' \n",
        "    for doc in search_results['results']:\n",
        "        if doc.get('raw_content'):\n",
        "            doc_content = doc.get('raw_content')\n",
        "        else:\n",
        "            doc_content = doc.get('content')\n",
        "        context += 'TITLE: ' + doc.get('title','N/A') + '\\nURL:' + doc.get('url')+ '\\nContent:'+ doc_content + '\\n---\\n'\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "35816c99",
      "metadata": {
        "id": "35816c99"
      },
      "outputs": [],
      "source": [
        "tools = [tavily_search, multiply, current_date]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "nn0QaVEs5fYb",
      "metadata": {
        "id": "nn0QaVEs5fYb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatGoogleGenerativeAI(rate_limiter=<langchain_core.rate_limiters.InMemoryRateLimiter object at 0x000001D9191EE9F0>, model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), thinking_budget=500, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001D91C66F770>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search', 'description': 'Tavily API를 통해 검색 결과를 가져옵니다.\\nquery: 검색어\\nmax_results : 검색 결과의 수(최소 1, 최대 20, 별도의 요청이 없으면 5로 고정)', 'parameters': {'properties': {'query': {'type': 'string'}, 'max_results': {'default': 5, 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.', 'parameters': {'properties': {'x': {'type': 'integer'}, 'y': {'type': 'integer'}}, 'required': ['x', 'y'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'current_date', 'description': '현재 날짜를 %y-%m-%d 형식으로 반환합니다.', 'parameters': {'properties': {}, 'type': 'object'}}}]}, config={}, config_factories=[])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "b4da3bb1",
      "metadata": {
        "id": "b4da3bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 오늘 날짜는?\n",
            "-- current_date 사용 중 --\n",
            "{'name': 'current_date', 'args': {}, 'id': 'aeb4542c-b7a1-45a3-ab30-6b53772a01f2', 'type': 'tool_call'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'2025년 10월 26일입니다.'"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = '오늘 날짜는?'\n",
        "\n",
        "result = simple_workflow(llm, question, tools)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "f4ee0e6c",
      "metadata": {
        "id": "f4ee0e6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'오늘 날짜는 2024년 5월 15일입니다.'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LLM은 오늘 날짜를 모른다\n",
        "llm.invoke('오늘 날짜는?').content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f57f601",
      "metadata": {
        "id": "8f57f601"
      },
      "source": [
        "<br><br>\n",
        "## [연습문제] 복권 숫자 예측시키기\n",
        "\n",
        "아래의 함수에 대해, 함수의 설명을 추가하여 llm의 툴로 전달해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "080e67e9",
      "metadata": {
        "id": "080e67e9"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import random\n",
        "\n",
        "@tool\n",
        "def generate_random_numbers(min_val: int, max_val: int, count: int) -> List[int]:\n",
        "    \"\"\"주어진 범위 내에서 지정된 개수만큼의 중복되지 않은 랜덤 정수를 생성합니다.\n",
        "    Args:\n",
        "        min_val (int): 최솟값\n",
        "        max_val (int): 최댓값\n",
        "        count (int): 생성할 숫자의 개수\n",
        "\n",
        "    Returns:\n",
        "        List[int]: 중복되지 않은 랜덤 정수들의 리스트\n",
        "    \"\"\"\n",
        "    # possible_range = max_val - min_val + 1\n",
        "    # if count > possible_range:\n",
        "    #     raise ValueError(f\"생성 가능한 숫자의 범위({possible_range}개)보다 더 많은 숫자({count}개)를 요청했습니다.\")\n",
        "\n",
        "    return str(random.sample(range(min_val, max_val + 1), count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "44141920",
      "metadata": {
        "id": "44141920"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'generate_random_numbers', 'arguments': '{\"max_val\": 45, \"min_val\": 1, \"count\": 6}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--c11ba3f9-93b2-471d-bd32-8f4fc482cb47-0', tool_calls=[{'name': 'generate_random_numbers', 'args': {'max_val': 45, 'min_val': 1, 'count': 6}, 'id': 'c7ee7d8f-8e86-4df7-868c-d5da0ec28966', 'type': 'tool_call'}], usage_metadata={'input_tokens': 167, 'output_tokens': 111, 'total_tokens': 278, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 79}})"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LLM에 함수 Bind\n",
        "\n",
        "llm_lotto = llm.bind_tools([generate_random_numbers])\n",
        "llm_lotto.invoke('로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "a5a72060",
      "metadata": {
        "id": "a5a72060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.\n",
            "-- generate_random_numbers 사용 중 --\n",
            "{'name': 'generate_random_numbers', 'args': {'max_val': 45, 'min_val': 1, 'count': 6}, 'id': '7034f75b-2ac2-4008-b426-130ff7de42f5', 'type': 'tool_call'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'생성된 로또 번호는 다음과 같습니다: 24, 37, 11, 38, 2, 26. 행운을 빕니다!'"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# simple_workflow 함수를 이용하여 실행하기\n",
        "\n",
        "simple_workflow(llm_lotto, '로또 번호 추첨해줘! 1부터 45까지 6개를 뽑으면 돼.', [generate_random_numbers])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c9696e",
      "metadata": {
        "id": "c9c9696e"
      },
      "source": [
        "우리가 만든 `simple_workflow` 함수는 가장 간단한 형태의 Single Tool Calling을 수행하는 방식이었는데요.   \n",
        "\n",
        "실제 환경의 시나리오는 훨씬 복잡합니다.   \n",
        "한 번에 여러 개의 툴을 실행하거나, 툴 실행 결과를 받아 다음 툴에 활용할 수도 있을 것입니다.   \n",
        "\n",
        "랭체인에서도 이와 같이 복잡한 작업을 수행하기 위한 기능이 자체적으로 구현되어 있는데요.    \n",
        "\n",
        "예시로 `Structured Chat Agent`를 간단하게 만들고 실행해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7c8ac8",
      "metadata": {
        "id": "9f7c8ac8"
      },
      "source": [
        "# Agent\n",
        "\n",
        "생각-행동-관찰을 거치는 ReAct 에이전트는 복잡한 플로우를 효과적으로 처리합니다.   \n",
        "- 생각(Thought): 주어진 Context 상에서 다음 작업을 어떻게 수행할지 설명하는 과정\n",
        "- 행동(Action): Tool 실행 명령어를 생성하는 과정\n",
        "- 관찰(Thought): Tool 결과를 Context에 추가하는 과정\n",
        "\n",
        "\n",
        "이 과정은 랭체인에 구성된 `create_structured_chat_agent`를 이용해 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "d08100d1",
      "metadata": {
        "id": "d08100d1"
      },
      "outputs": [],
      "source": [
        "# langchain_classic\n",
        "# 2025년 10월 20일 출시된 랭체인 v 1.0 이후로는 기존 랭체인 기능이 langchain_classic으로 옮겨졌습니다.\n",
        "# 만약 이전 버전을 쓰시는 경우, 아래의 langchain_classic을 langchain으로 바꿔주세요.\n",
        "from langchain_classic.agents import AgentExecutor, create_structured_chat_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "agent_prompt = ChatPromptTemplate([\n",
        "    ('system','''\n",
        "최대한 정확히 질문에 답변하세요. 당신은 다음의 툴을 사용할 수 있습니다:\n",
        "{tools}\n",
        "\n",
        "action 키 (tool name)와 action_input 키를 포함하는 json 형태로 출력하세요.\n",
        "\n",
        "action의 값은 \"Final Answer\" 또는 {tool_names} 중 하나여야 합니다.\n",
        "반드시 하나의 json 형태만 출력하세요. 다음은 예시입니다.\n",
        "```\n",
        "{{\n",
        "\n",
        "  \"action\": $TOOL_NAME,\n",
        "\n",
        "  \"action_input\": $INPUT\n",
        "\n",
        "}}\n",
        "```\n",
        "\n",
        "아래의 포맷으로 답변하세요.:\n",
        "\n",
        "Question: 최종적으로 답변해야 하는 질문\n",
        "Thought: 무엇을 해야 하는지를 항상 떠올리세요.\n",
        "Action:\n",
        "```\n",
        "$JSON_BLOB\n",
        "```\n",
        "Observation: 액션의 실행 결과\n",
        "... (이 Thought/Action/Observation 은 10번 이내로 반복될 수 있습니다.)\n",
        "\n",
        "Thought: 이제 답을 알겠다!\n",
        "Action:\n",
        "```\n",
        "{{\n",
        "  \"action\": \"Final Answer\",\n",
        "  \"action_input\": \"Final response to human\"\n",
        "}}\n",
        "```\n",
        "'''),\n",
        "('user','''Question: {input}\n",
        "Thought: {agent_scratchpad}''')])\n",
        "\n",
        "\n",
        "agent = create_structured_chat_agent(llm, tools, agent_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "ef500238",
      "metadata": {
        "id": "ef500238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"tavily_search\",\n",
            "  \"action_input\": {\n",
            "    \"query\": \"Open Source Multimodal LLM Model recommendations\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3mPOSSIBLE ANSWER: InternVL 3.5 is a top open-source multimodal model. Pixtral and GLM-4.5V are also leading open-source options. Qwen 2.5 VL 72B Instruct is notable for vision-language integration.\n",
            "\n",
            "TITLE: InternVL 3.5 : Best open-sourced Multi-Modal LLM - Medium\n",
            "URL:https://medium.com/data-science-in-your-pocket/internvl-3-5-best-open-sourced-multi-modal-llm-bc929e2b6338\n",
            "Content:[Sitemap](/sitemap/sitemap.xml)\n",
            "\n",
            "[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbc929e2b6338&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n",
            "\n",
            "[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Finternvl-3-5-best-open-sourced-multi-modal-llm-bc929e2b6338&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n",
            "\n",
            "[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Finternvl-3-5-best-open-sourced-multi-modal-llm-bc929e2b6338&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n",
            "\n",
            "[## Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---publication_nav-60130df77e02-bc929e2b6338---------------------------------------)\n",
            "\n",
            "·\n",
            "\n",
            "[Follow publication](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdata-science-in-your-pocket&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Finternvl-3-5-best-open-sourced-multi-modal-llm-bc929e2b6338&collection=Data+Science+in+Your+Pocket&collectionId=60130df77e02&source=post_page---publication_nav-60130df77e02-bc929e2b6338---------------------publication_nav------------------)\n",
            "\n",
            "We are on Youtube: <https://www.youtube.com/channel/UCQoNosQTIxiMTL9C-gvFdjA>\n",
            "\n",
            "[Follow publication](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fdata-science-in-your-pocket&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Finternvl-3-5-best-open-sourced-multi-modal-llm-bc929e2b6338&collection=Data+Science+in+Your+Pocket&collectionId=60130df77e02&source=post_page---post_publication_sidebar-60130df77e02-bc929e2b6338---------------------post_publication_sidebar------------------)\n",
            "\n",
            "# InternVL 3.5 : Best open-sourced Multi-Modal LLM\n",
            "\n",
            "## Beats GLM 4.5V, Claude, Qwen, GPT-4o\n",
            "\n",
            "[Mehul Gupta](/@mehulgupta_7991?source=post_page---byline--bc929e2b6338---------------------------------------)\n",
            "\n",
            "5 min read5 days ago\n",
            "\n",
            "So, here’s the thing. Most of the AI world is busy catching up to GPT-4V or playing PR games around “agentic workflows.” Meanwhile, quietly, InternVL3.5 drops, and it doesn’t just participate in the multimodal Olympics, it basically rewrites the qualifying criteria.\n",
            "\n",
            "## Get Mehul Gupta’s stories in your inbox\n",
            "\n",
            "Join Medium for free to get updates from this writer.\n",
            "\n",
            "**Yeah, I’m calling it:**\n",
            "\n",
            "> **InternVL3.5 is probably the best open-source multimodal model right now**.\n",
            "\n",
            "And no, that’s not hype. That’s benchmarks, architecture choices, and some clever design decisions that feel almost illegal.\n",
            "\n",
            "Let’s break it down.\n",
            "\n",
            "## First, What is InternVL3.5?\n",
            "\n",
            "[## OpenGVLab/InternVL3\\_5-8B · Hugging Face\n",
            "\n",
            "### We're on a journey to advance and democratize artificial intelligence through open source and open science.\n",
            "\n",
            "huggingface.co](https://huggingface.co/OpenGVLab/InternVL3_5-8B?source=post_page-----bc929e2b6338---------------------------------------)\n",
            "\n",
            "At its core, InternVL3.5 is a **multimodal vision-language model**. That means it can see and read at the same time, process images, understand video, parse dense documents, answer questions based on what it sees, and even follow spatial reasoning steps.\n",
            "\n",
            "> Think of it as the AI with eyes and a brain that’s starting to really “get” the world visually, not just textually.\n",
            "\n",
            "But unlike earlier models, which bolted a vision encoder onto a language model and called it “multimodal,” this one feels actually coherent. It doesn’t just look at pixels and throw guesses , it actually understands the structure and intent of what it’s looking at.\n",
            "\n",
            "## InternVL3.5 Family: Model Variants Overview\n",
            "\n",
            "InternVL3.5 comes in a broad range of sizes and formats, designed for different scales of compute and tasks. Here’s what’s out there:\n",
            "\n",
            "### Model Scale Variants (Vision + Language → Total)\n",
            "\n",
            "* **InternVL3.5–1B**: 0.3B visual + 0.8B language → ~1.1B total\n",
            "* **InternVL3.5–2B**: 0.3B + 2.0B → ~2.3B total\n",
            "* **InternVL3.5–4B**: 0.3B + 4.4B → ~4.7B total\n",
            "* **InternVL3.5–8B**: 0.3B + 8.2B → ~8.5B total\n",
            "* **InternVL3.5–14B**: 0.3B + 14.8B → ~15.1B total\n",
            "* **InternVL3.5–38B**: 5.5B + 32.8B → ~38.4B total\n",
            "* **InternVL3.5–20B-A4B**: 0.3B + ~20.9B → labeled “21.2B-A4B”\n",
            "* **InternVL3.5–30B-A3B**: 0.3B + ~30.5B → “30.8B-A3B”\n",
            "* **InternVL3.5–241B-A28B**: 5.5B + ~235.1B → “240.7B-A29B”\n",
            "\n",
            "### Why You Might Use Each Variant\n",
            "\n",
            "* **Small sizes (1B–8B)**: Quick to load, decent in reasoning, great for prototypes, edge or low‑resource setups.\n",
            "* **Mid sizes (14B–38B)**: Sweet spot for quality vs compute. Strong in reasoning and perception benchmarks.\n",
            "* **Large (20B/30B-A variants)**: For heavy‑duty deployments, more modalities, complex QA, GUI, embodied tasks.\n",
            "* **Huge (241B‑A28B)**: Top-tier performance on all multimodal benchmarks, closing gap with closed‑source giants like GPT‑5. Think agentic, multimodal copilots.\n",
            "* **Flash**: For constrained hardware, mobile deployment, or fast inference, still pretty sharp\n",
            "\n",
            "## Architecture: What’s Under the Hood?\n",
            "\n",
            "InternVL3.5 uses a **multi-component architecture**, stitched together like a finely tuned orchestra:\n",
            "\n",
            "1. **Image Encoder**: EVA-CLIP-E4G (a beast from the EVA family) processes the image into visual tokens. It’s pretrained on huge vision-language datasets like CC12M, LAION, etc.\n",
            "2. **Q-Former**: Think of this as the translator that aligns vision with language. It grabs the right visual info before sending it to the LLM.\n",
            "3. **Language Backbone**: InternLM2–8B (or the MoE version for large-scale). This model is already known for strong reasoning, and when paired with Q-Former, it handles complex instructions.\n",
            "4. **Training Recipe**: They use a mix of multi-stage pretraining:\n",
            "\n",
            "> Pretrain vision and language parts separately.\n",
            ">\n",
            "> Fuse and train with vision-language tasks like captioning, VQA, OCR-heavy documents, and referring expressions.\n",
            "\n",
            "**5. Vision Instruction Tuning**: Special phase where the model is trained to follow human-style prompts for images and docs. This is what makes it feel more “conversational” rather than robotic.\n",
            "\n",
            "## Benchmarks: Where It’s Breaking Things\n",
            "\n",
            "> InternVL3.5 is quietly killing it on several leaderboards. It’s **#1 on MMMU**, **#1 on ChartQA**, and near the top on **DocVQA**, **ScienceQA**, **TDIUC**, and **MMVet**.\n",
            "\n",
            "Some real standouts:\n",
            "\n",
            "* **MMMU (Multimodal Multi-task Unified Benchmark)**: Beats GPT-4V, Claude 3, Gemini Pro 1.5, and LLaVA-Next.\n",
            "* **ChartQA**: Finally a model that can actually read charts like a human instead of hallucinating numbers.\n",
            "* **DocVQA**: Document understanding with OCR is a known weak point for most LLMs. InternVL3.5 nails it.\n",
            "\n",
            "## What’s Unique About It?\n",
            "\n",
            "Here’s what sets InternVL3.5 apart from the typical plug-and-play multimodal models:\n",
            "\n",
            "* **Dense Vision Alignment**: It’s not just recognizing images, it’s aligning every piece of visual info with the right words.\n",
            "\n",
            "* **Expert Routing (in MoE)**: Makes large-scale processing possible without blowing up compute cost.\n",
            "* **Scientific and Chart Pretraining**: Unlike most models trained on memes and captions, this one has seen actual graphs, papers, and diagrams.\n",
            "* **Open-Source, No Paywall**: Yeah. That too.\n",
            "\n",
            "## Final Thoughts\n",
            "\n",
            "InternVL3.5 doesn’t come with fireworks, but it doesn’t need them. It’s showing us what well-engineered, domain-specific pretraining can do when you’re not trying to please a product manager or win a branding war.\n",
            "\n",
            "If you’re building tools for document QA, chart analytics, PDF understanding, or complex image reasoning, this is the model to try before you reach for GPT-4V.\n",
            "\n",
            "[AI](/tag/ai?source=post_page-----bc929e2b6338---------------------------------------)\n",
            "\n",
            "[Technology](/tag/technology?source=post_page-----bc929e2b6338---------------------------------------)\n",
            "\n",
            "[ChatGPT](/tag/chatgpt?source=post_page-----bc929e2b6338---------------------------------------)\n",
            "\n",
            "[Machine Learning](/tag/machine-learning?source=post_page-----bc929e2b6338---------------------------------------)\n",
            "\n",
            "[Data Science](/tag/data-science?source=post_page-----bc929e2b6338---------------------------------------)\n",
            "\n",
            "[## Published in Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---post_publication_info--bc929e2b6338---------------------------------------)\n",
            "\n",
            "[6.4K followers](/data-science-in-your-pocket/followers?source=post_page---post_publication_info--bc929e2b6338---------------------------------------)\n",
            "\n",
            "·[Last published 3 days ago](/data-science-in-your-pocket/fine-tuning-microsofts-phi-4-instruct-with-lora-scaling-inference-with-vllm-4b1f6fdb8b34?source=post_page---post_publication_info--bc929e2b6338---------------------------------------)\n",
            "\n",
            "We are on Youtube: <https://www.youtube.com/channel/UCQoNosQTIxiMTL9C-gvFdjA>\n",
            "\n",
            "[## Written by Mehul Gupta](/@mehulgupta_7991?source=post_page---post_author_info--bc929e2b6338---------------------------------------)\n",
            "\n",
            "[17.4K followers](/@mehulgupta_7991/followers?source=post_page---post_author_info--bc929e2b6338---------------------------------------)\n",
            "\n",
            "·[37 following](/@mehulgupta_7991/following?source=post_page---post_author_info--bc929e2b6338---------------------------------------)\n",
            "\n",
            "Linkedin : <https://www.linkedin.com/in/mehulgupta7991/>\n",
            "\n",
            "## Responses (1)\n",
            "\n",
            "Write a response\n",
            "\n",
            "[What are your thoughts?](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-in-your-pocket%2Finternvl-3-5-best-open-sourced-multi-modal-llm-bc929e2b6338&source=---post_responses--bc929e2b6338---------------------respond_sidebar------------------)\n",
            "\n",
            "[Antonio Manunta](/@a.manunta?source=post_page---post_responses--bc929e2b6338----0-----------------------------------)\n",
            "\n",
            "[5 days ago](/@a.manunta/it-is-a-very-very-interesting-solution-fe845bcf0c4b?source=post_page---post_responses--bc929e2b6338----0-----------------------------------)\n",
            "\n",
            "```\n",
            "\n",
            "\n",
            "It is a very, very interesting solution! But: if it can \"understand video\" is possible for it to understand if the video coming from a live camera is about a real human (or animal) and not a photo or another video or a mask like a human can do?\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "## More from Mehul Gupta and Data Science in Your Pocket\n",
            "\n",
            "In\n",
            "\n",
            "[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--bc929e2b6338----0---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "by\n",
            "\n",
            "[Mehul Gupta](/@mehulgupta_7991?source=post_page---author_recirc--bc929e2b6338----0---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "[## What is Google Nano Banana? Google’s Secret AI for Images\n",
            "\n",
            "### Google is secretly testing Nano Banana across platforms](/data-science-in-your-pocket/what-is-google-nano-banana-googles-secret-ai-for-images-2958f9ab11e3?source=post_page---author_recirc--bc929e2b6338----0---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "Aug 23\n",
            "\n",
            "[91\n",
            "\n",
            "18](/data-science-in-your-pocket/what-is-google-nano-banana-googles-secret-ai-for-images-2958f9ab11e3?source=post_page---author_recirc--bc929e2b6338----0---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "In\n",
            "\n",
            "[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--bc929e2b6338----1---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "by\n",
            "\n",
            "[Mehul Gupta](/@mehulgupta_7991?source=post_page---author_recirc--bc929e2b6338----1---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "[## Dijkstra Defeated : New Fastest Shortest Path Algorithm explained\n",
            "\n",
            "### Breaking the Sorting Barrier for Directed Single-Source Shortest Paths explained with example](/data-science-in-your-pocket/dijkstra-defeated-new-fastest-shortest-path-algorithm-explained-4075b000353a?source=post_page---author_recirc--bc929e2b6338----1---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "Aug 17\n",
            "\n",
            "[167\n",
            "\n",
            "2](/data-science-in-your-pocket/dijkstra-defeated-new-fastest-shortest-path-algorithm-explained-4075b000353a?source=post_page---author_recirc--bc929e2b6338----1---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "In\n",
            "\n",
            "[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--bc929e2b6338----2---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "by\n",
            "\n",
            "[Mehul Gupta](/@mehulgupta_7991?source=post_page---author_recirc--bc929e2b6338----2---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "[## Google LangExtract : AI powered Information Extraction using Gemini\n",
            "\n",
            "### How to use Google LangExtract?](/data-science-in-your-pocket/google-langextract-ai-powered-information-extraction-using-gemini-290cd4ab1b2c?source=post_page---author_recirc--bc929e2b6338----2---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "Aug 12\n",
            "\n",
            "[259\n",
            "\n",
            "3](/data-science-in-your-pocket/google-langextract-ai-powered-information-extraction-using-gemini-290cd4ab1b2c?source=post_page---author_recirc--bc929e2b6338----2---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "In\n",
            "\n",
            "[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--bc929e2b6338----3---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "by\n",
            "\n",
            "[Mehul Gupta](/@mehulgupta_7991?source=post_page---author_recirc--bc929e2b6338----3---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "[## Google Gemma3 270M : The best Smallest LLM for everything\n",
            "\n",
            "### How to use Google Gemma3 270M for free?](/data-science-in-your-pocket/google-gemma3-270m-the-best-smallest-llm-for-everything-efcf927a74be?source=post_page---author_recirc--bc929e2b6338----3---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "Aug 15\n",
            "\n",
            "[350\n",
            "\n",
            "5](/data-science-in-your-pocket/google-gemma3-270m-the-best-smallest-llm-for-everything-efcf927a74be?source=post_page---author_recirc--bc929e2b6338----3---------------------07d04eed_bcf6_4037_97c2_5b2e2f0b2901--------------)\n",
            "\n",
            "[See all from Mehul Gupta](/@mehulgupta_7991?source=post_page---author_recirc--bc929e2b6338---------------------------------------)\n",
            "\n",
            "[See all from Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---author_recirc--bc929e2b6338---------------------------------------)\n",
            "\n",
            "## Recommended from Medium\n",
            "\n",
            "In\n",
            "\n",
            "[Towards Deep Learning](https://medium.com/towards-deep-learning?source=post_page---read_next_recirc--bc929e2b6338----0---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "by\n",
            "\n",
            "[Sumit Pandey](/@sumit.ai?source=post_page---read_next_recirc--bc929e2b6338----0---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "[## Gemma 3 (270M) vs 1B vs 4B: The Tiny-Titan Showdown\n",
            "\n",
            "### This morning I saw linkedIn posts of people saying about how cool Gemma 3 (270M) is. While scrolling through the comments, one caught my…](/towards-deep-learning/gemma-3-270-m-hyper-efficient-or-just-hopeless-simple-test-0c69167308ef?source=post_page---read_next_recirc--bc929e2b6338----0---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "Aug 18\n",
            "\n",
            "[104\n",
            "\n",
            "6](/towards-deep-learning/gemma-3-270-m-hyper-efficient-or-just-hopeless-simple-test-0c69167308ef?source=post_page---read_next_recirc--bc929e2b6338----0---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "In\n",
            "\n",
            "[Data Science in Your Pocket](https://medium.com/data-science-in-your-pocket?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "by\n",
            "\n",
            "[Mehul Gupta](/@mehulgupta_7991?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "[## GPT-5 Invented New Maths : Is this AGI?\n",
            "\n",
            "### GPT-5 solved the unsolvable](/data-science-in-your-pocket/gpt-5-invented-new-maths-is-this-agi-d1ffe829b6b7?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "Aug 23\n",
            "\n",
            "[203\n",
            "\n",
            "9](/data-science-in-your-pocket/gpt-5-invented-new-maths-is-this-agi-d1ffe829b6b7?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "[Ignacio de Gregorio](/@ignacio.de.gregorio.noblejas?source=post_page---read_next_recirc--bc929e2b6338----0---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "[## The One Mistake Everyone Makes in AI\n",
            "\n",
            "### Uncertainty is a feature, not a bug](/@ignacio.de.gregorio.noblejas/the-one-mistake-everyone-makes-in-ai-0d5a44df6c74?source=post_page---read_next_recirc--bc929e2b6338----0---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "5d ago\n",
            "\n",
            "[936\n",
            "\n",
            "33](/@ignacio.de.gregorio.noblejas/the-one-mistake-everyone-makes-in-ai-0d5a44df6c74?source=post_page---read_next_recirc--bc929e2b6338----0---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "In\n",
            "\n",
            "[Generative AI](https://medium.com/generative-ai?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "by\n",
            "\n",
            "[Jim Clyde Monge](/@jimclydemonge?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "[## Google Releases Nano-Banana — A New Image Editing Model\n",
            "\n",
            "### Google released Gemini 2.5 Flash (a.k.a nano-banana) a new image editing model that gives users more control over photo edits inside…](/generative-ai/google-releases-nano-banana-a-new-image-editing-model-c4fe02563b80?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "4d ago\n",
            "\n",
            "[703\n",
            "\n",
            "15](/generative-ai/google-releases-nano-banana-a-new-image-editing-model-c4fe02563b80?source=post_page---read_next_recirc--bc929e2b6338----1---------------------a45e8907_60e2_4ac2_9269_eac4a405b0f1--------------)\n",
            "\n",
            "[See more recommendations](/?source=post_page---read_next_recirc--bc929e2b6338---------------------------------------)\n",
            "\n",
            "[Text to speech](https://speechify.com/medium?source=post_page-----bc929e2b6338---------------------------------------)\n",
            "---\n",
            "TITLE: Open Source Multimodal LLM: Examples & Use Cases\n",
            "URL:https://www.moontechnolabs.com/qanda/open-source-multimodal-llm/\n",
            "Content:* [+1 (620) 330-9814](tel:+1(620)330-9814)\n",
            "* [Moon Technolabs](https://teams.live.com/l/invite/FEAwVVITWBAv3cjvwI)\n",
            "* [Schedule Meeting](#modal_calandry)\n",
            "* [We’re Hiring](https://www.moontechnolabs.com/career-with-us)\n",
            "\n",
            "1. [Home](/)\n",
            "2. [Tech Q&A](https://www.moontechnolabs.com/qanda/)\n",
            "3. Open Source Multimodal LLM\n",
            "\n",
            "# Open Source Multimodal LLM: What You Need to Know\n",
            "\n",
            "#### Jayanti Katariya\n",
            "\n",
            "Last Updated: September 17, 2025\n",
            "\n",
            "Total View: 100\n",
            "\n",
            "### Get in Touch With Us\n",
            "\n",
            "Submitting the form below will ensure a prompt response from us.\n",
            "\n",
            "Artificial Intelligence has rapidly evolved beyond single-input models. Traditional Large Language Models (LLMs), such as GPT or BERT, primarily process text; however, real-world applications often require reasoning across multiple data types, including images, audio, and video. This is where multimodal LLMs come into play.\n",
            "\n",
            "In this article, we’ll explore what an **Open source Multimodal LLM** is, why it matters, popular frameworks, and even a code example to get you started.\n",
            "\n",
            "## What is a Multimodal LLM?\n",
            "\n",
            "A **multimodal LLM (Large Language Model)** can process and generate outputs based on more than one type of input modality. For example:\n",
            "\n",
            "1. **Text + Image**: Describe an image, answer visual questions, or generate captions.\n",
            "2. **Text + Audio**: Transcribe speech or generate speech from text.\n",
            "3. **Text + Video**: Summarize video clips or provide contextual insights.\n",
            "\n",
            "Unlike unimodal models, multimodal LLMs are more closely aligned with human intelligence, as we also learn and interact through multiple sensory inputs.\n",
            "\n",
            "## Why Open Source Multimodal LLMs Matter?\n",
            "\n",
            "Open source models play a critical role in democratizing AI:\n",
            "\n",
            "* **Transparency** – Developers can inspect, understand, and improve model architectures.\n",
            "* **Customizability** – Fine-tune on domain-specific data (e.g., healthcare, retail, finance).\n",
            "* **Cost-Effective** – No expensive licensing fees for research and enterprise use.\n",
            "* **Innovation** – Open collaboration accelerates breakthroughs in multimodal learning.\n",
            "\n",
            "## Popular Open Source Multimodal LLMs\n",
            "\n",
            "Several projects are pioneering the **open source multimodal AI** movement:\n",
            "\n",
            "### LLaVA (Large Language and Vision Assistant)\n",
            "\n",
            "1. Trains a language model with visual instruction tuning.\n",
            "2. It can take both images and text as input.\n",
            "\n",
            "```\n",
            "# Example: Running LLaVA using Hugging Face from transformers import AutoProcessor, AutoModelForCausalLM processor = AutoProcessor.from_pretrained(\"liuhaotian/LLaVA-13b-delta-v0\") model = AutoModelForCausalLM.from_pretrained(\"liuhaotian/LLaVA-13b-delta-v0\") inputs = processor(text=\"Describe the image\", images=\"dog.png\", return_tensors=\"pt\") outputs = model.generate(**inputs) print(processor.decode(outputs[0])) \n",
            "```\n",
            "\n",
            "### BLIP-2 (Bootstrapping Language-Image Pretraining)\n",
            "\n",
            "Known for its ability to generate captions and answer visual questions.\n",
            "\n",
            "```\n",
            "from transformers import BlipProcessor, BlipForConditionalGeneration from PIL import Image processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\") model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\") image = Image.open(\"cat.jpg\") inputs = processor(image, return_tensors=\"pt\") outputs = model.generate(**inputs) print(processor.decode(outputs[0], skip_special_tokens=True)) \n",
            "```\n",
            "\n",
            "### Kosmos-2\n",
            "\n",
            "1. Developed by Microsoft, focuses on grounding language in vision tasks.\n",
            "2. Suitable for multimodal reasoning tasks such as visual question answering.\n",
            "\n",
            "### MiniGPT-4\n",
            "\n",
            "1. Inspired by OpenAI’s GPT-4, but open source.\n",
            "2. Uses a vision encoder with a language model backbone.\n",
            "\n",
            "## Applications of Open Source Multimodal LLMs\n",
            "\n",
            "* **Healthcare**: Analyzing X-rays with textual reports.\n",
            "* **Retail**: Product recommendations using descriptions and images.\n",
            "* **Education**: Interactive tutors that combine diagrams and explanations.\n",
            "* **Content Creation**: Generating articles, captions, and marketing materials.\n",
            "* **Security**: Video + text analysis for anomaly detection.\n",
            "\n",
            "## Challenges in Multimodal LLMs\n",
            "\n",
            "While promising, multimodal LLMs face hurdles:\n",
            "\n",
            "1. **High Computational Costs**: Training requires large GPU clusters.\n",
            "2. **Data Alignment**: Synchronizing text with images/videos is complex.\n",
            "3. **Biases**: Models may inherit biases from multimodal datasets.\n",
            "4. **Latency**: Real-time multimodal interaction is still resource-intensive.\n",
            "\n",
            "## Getting Started with an Open Source Multimodal LLM\n",
            "\n",
            "Developers can experiment with Hugging Face’s model hub, which offers access to LLaVA, BLIP-2, and other models.\n",
            "\n",
            "Here’s a simple pipeline using Hugging Face:\n",
            "\n",
            "```\n",
            "from transformers import pipeline captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\") print(captioner(\"dog.jpg\"))\n",
            "```\n",
            "\n",
            "This code generates captions for an input image using the BLIP-2 model. With just a few lines, you can integrate multimodal AI into your projects.\n",
            "\n",
            "## Future of Open Source Multimodal LLMs\n",
            "\n",
            "The future looks bright as research progresses:\n",
            "\n",
            "* **Integration with Audio and Video**: Moving from text + image to full multimedia understanding.\n",
            "* **Edge Deployment**: Running multimodal LLMs on devices for real-time applications.\n",
            "* **Specialized Models**: Domain-specific multimodal assistants (e.g., medical AI tutors).\n",
            "* **Community Collaboration**: More open datasets and benchmarks to accelerate improvements.\n",
            "\n",
            "#### Build Smarter AI with Open Source Multimodal LLMs\n",
            "\n",
            "Leverage our expertise to integrate powerful multimodal AI models into your workflows. From text and images to speech and beyond, we help you scale smarter.\n",
            "\n",
            "[Talk to Our AI Experts](#)\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "Open source multimodal LLMs represent the next frontier of AI innovation. They enable models to **perceive, comprehend, and interpret** multiple input types, making them more applicable to real-world applications. Frameworks like **LLaVA, BLIP-2, and MiniGPT-4** are leading the charge, with practical applications spanning healthcare, retail, education, and other sectors.\n",
            "\n",
            "For developers and businesses, adopting open source multimodal LLMs means building **smarter, context-aware systems** without being locked into proprietary ecosystems. As these models become more efficient and widely available, they are expected to play a central role in the next wave of AI-powered solutions.\n",
            "\n",
            "##### About Author\n",
            "\n",
            "Jayanti Katariya is the CEO of Moon Technolabs, a fast-growing IT solutions provider, with 18+ years of experience in the industry. Passionate about developing creative apps from a young age, he pursued an engineering degree to further this interest. Under his leadership, Moon Technolabs has helped numerous brands establish their online presence and he has also launched an invoicing software that assists businesses to streamline their financial operations.\n",
            "\n",
            "### Get in Touch With Us\n",
            "\n",
            "Submitting the form below will ensure a prompt response from us.\n",
            "\n",
            "## Related Q&A\n",
            "\n",
            "[### Cloud Composer vs Cloud Scheduler: What’s the Difference?](https://www.moontechnolabs.com/qanda/cloud-composer-vs-cloud-scheduler/)\n",
            "\n",
            "10 September 2025\n",
            "\n",
            "[### Cloud HSM vs KMS: Choosing the Right Key Management Solution](https://www.moontechnolabs.com/qanda/cloud-hsm-vs-kms/)\n",
            "\n",
            "09 September 2025\n",
            "\n",
            "[### How to Use a Business Intelligence Cube for Data Analysis?](https://www.moontechnolabs.com/qanda/business-intelligence-cube/)\n",
            "\n",
            "04 September 2025\n",
            "\n",
            "[### Smoke Testing in Software: An Essential First Check](https://www.moontechnolabs.com/qanda/smoke-testing-in-software/)\n",
            "\n",
            "02 September 2025\n",
            "\n",
            "[### How Does Unsupervised Learning in Artificial Intelligence Work?](https://www.moontechnolabs.com/qanda/unsupervised-learning-in-artificial-intelligence/)\n",
            "\n",
            "28 August 2025\n",
            "\n",
            "[### What is Recall in Machine Learning?](https://www.moontechnolabs.com/qanda/recall-in-machine-learning/)\n",
            "\n",
            "25 August 2025\n",
            "\n",
            "[### Cloud Engineer Roadmap: How to Hire and Build the Right Team?](https://www.moontechnolabs.com/qanda/cloud-engineer-roadmap/)\n",
            "\n",
            "20 August 2025\n",
            "\n",
            "[### Understanding the DevOps Landscape: Trends, Tools, and Best Practices](https://www.moontechnolabs.com/qanda/devops-landscape/)\n",
            "\n",
            "19 August 2025\n",
            "\n",
            "[### What is Application Level Encryption and How Does It Work?](https://www.moontechnolabs.com/qanda/application-level-encryption/)\n",
            "\n",
            "13 August 2025\n",
            "\n",
            "### Share Your Requirements!\n",
            "\n",
            "Get all-in-one development solutions and services related to your inquiries. Fill up the form below and one of our representatives will contact to you shortly.\n",
            "\n",
            "### Awards & Accolades\n",
            "\n",
            "We refine our expertise to deliver innovative business solutions.\n",
            "\n",
            "### Our Offices\n",
            "\n",
            "500 N Michigan Avenue, #600, Chicago IL 60611\n",
            "\n",
            "13500 Long Is Dr, Pflugerville, TX 78660, USA\n",
            "\n",
            "C-105, Ganesh Meridian, S.G. Highway,  Ahmedabad, GJ 380060\n",
            "\n",
            "[+1 (620) 330-9814](tel:+1 (620) 330-9814)   [sales@moontechnolabs.com](mailto:sales@moontechnolabs.com)   [Moon Technolabs](https://teams.live.com/l/invite/FEAwVVITWBAv3cjvwI)\n",
            "\n",
            "### Follow Us on Social Media\n",
            "\n",
            "#### Trending Services\n",
            "\n",
            "[Generative AI Development](https://www.moontechnolabs.com/services/generative-ai-development)[Generative AI Consulting](https://www.moontechnolabs.com/services/generative-ai-consulting)[AI Agent Development](https://www.moontechnolabs.com/services/ai-agent-development)[AI Chatbot Development](https://www.moontechnolabs.com/services/ai-chatbot-development)[IoT App Development](https://www.moontechnolabs.com/services/iot-development)[DevOps Development](https://www.moontechnolabs.com/services/devops-development)[WebRTC Development](https://www.moontechnolabs.com/services/webrtc-development-company)[VoIP Development](https://www.moontechnolabs.com/services/voip-software-development)\n",
            "\n",
            "#### Software Solutions\n",
            "\n",
            "[POS Software](https://www.moontechnolabs.com/services/pos-software-development)[Financial Software](https://www.moontechnolabs.com/services/financial-software-development)[EMR / EHR Software](https://www.moontechnolabs.com/services/emr-ehr-software-development)[Billing Software](https://www.moontechnolabs.com/services/billing-software-development)[Accounting Software](https://www.moontechnolabs.com/services/accounting-software-development)[Enterprise Web App](https://www.moontechnolabs.com/services/enterprise-web-development)[Custom Web Portal](https://www.moontechnolabs.com/services/custom-software-development)[Enterprise Software](https://www.moontechnolabs.com/services/enterprise-software-development)\n",
            "\n",
            "#### On-Demand Solutions\n",
            "\n",
            "[Grocery Delivery Software](https://www.moontechnolabs.com/solution/grocery-delivery-app-development)[Food Delivery Software](https://www.moontechnolabs.com/solution/food-delivery-app-development)[Taxi Booking Software](https://www.moontechnolabs.com/solution/taxi-booking-app-development)[Healthcare Software](https://www.moontechnolabs.com/solution/healthcare-app-development)[Medicine Delivery Software](https://www.moontechnolabs.com/solution/medicine-delivery-app-development)[Fintech Software](https://www.moontechnolabs.com/solution/fintech-software-development)[EV Charging Software](https://www.moontechnolabs.com/solution/ev-charging-app-development)[Laundry Management Software](https://www.moontechnolabs.com/solution/laundry-app-development)\n",
            "\n",
            "#### Portfolios\n",
            "\n",
            "[CryptoSage](https://www.moontechnolabs.com/portfolio/cryptosage-crypto-wallet-app)[DocTalk](https://www.moontechnolabs.com/portfolio/doctalk-ai-healthcare-app)[InsurNow](https://www.moontechnolabs.com/portfolio/insurnow-insurance-app)[ChargeHub](https://www.moontechnolabs.com/portfolio/chargehub-ev-charging-app)[InstaGroc](https://www.moontechnolabs.com/portfolio/instagroc-grocery-delivery-app)[Moon Invoice](https://www.moontechnolabs.com/portfolio/moon-invoice-accounting-software)[ZeroEyes](https://www.moontechnolabs.com/portfolio/threat-detection-security-app)[Inner Journey](https://www.moontechnolabs.com/portfolio/mental-health-wellness-app)\n",
            "\n",
            "#### Company\n",
            "\n",
            "[About Us](https://www.moontechnolabs.com/about-us) [Accolades](https://www.moontechnolabs.com/awards-certificates) [Client Testimonials](https://www.moontechnolabs.com/client-testimonials)  [Our Work](https://www.moontechnolabs.com/portfolios) [Business Model](https://www.moontechnolabs.com/business-model) [Contact Us](https://www.moontechnolabs.com/contact-us) [Blog](https://www.moontechnolabs.com/blog/) [We are Hiring!](https://www.moontechnolabs.com/career-with-us)\n",
            "\n",
            "[© 2009-2025 Moon Technolabs Pvt. Ltd. All Rights Reserved.](javascript:void(0))\n",
            "\n",
            "[Privacy Policy](https://www.moontechnolabs.com/privacy-policy)   [Terms Of Use](https://www.moontechnolabs.com/terms-of-use)   [Site Map](https://www.moontechnolabs.com/sitemap/)\n",
            "\n",
            "We use cookies to ensure that we give you the best experience on our website. If you continue to use this website, we will assume that you consent to our Cookies Policy and Happy with it. [Accept](javascript:void(0)) [Decline](javascript:void(0))\n",
            "\n",
            "###### Ayse D.\n",
            "\n",
            "Co-Founder\n",
            "\n",
            "France\n",
            "\n",
            "“ I highly recommend Moon Technolabs as the quality of service is wonderful. We have hired this company to develop the product based on some complex & technical issues. We get the best quality services as compared with others in the market. Huge Thanks to Moon Technolabs as the team is always ready to give the solution all time.”\n",
            "\n",
            "###### Justin G.\n",
            "\n",
            "Founder & CEO\n",
            "\n",
            "USA\n",
            "\n",
            "“ Moon Technolabs is a pioneer in the WebRTC based project as they have fixed complicated segments of the module by fulfilling different product lines by providing 24X7 customer support. We really recommended Moon Technolabs as they are able to develop products as per the module deadline and project timeline.”\n",
            "\n",
            "###### Flavio S.\n",
            "\n",
            "Founder & Managing Director\n",
            "\n",
            "“I am happy to recommend Moon Technolabs for their app development services. They successfully developed apps for me, and I am highly satisfied with the overall outcomes. The development team has swiftly addressed the issues with responsive and effective communication to understand the requirement quickly and actively resolve the back-and-forth problems that arose...”\n",
            "\n",
            "###### Jay M.\n",
            "\n",
            "Founder & CEO\n",
            "\n",
            "USA\n",
            "\n",
            "“Moon Technolabs is the best company that provides advanced apps and websites development services in the USA and Europe. I am a newbie to develop my app with an external team. I am really happy to work with them as I am not that much mobile apps user. Here, the team and specially the CEO of Moon Technolabs helps me to let me know about the benefits of my app to generate revenue....”\n",
            "\n",
            "### Let’s discuss more about your project\n",
            "\n",
            "### Our Offices\n",
            "\n",
            "###### India\n",
            "\n",
            "C-105, Ganesh Meridian, S.G. Highway, Ahmedabad, GJ 380060\n",
            "\n",
            "###### USA\n",
            "\n",
            "500 N Michigan Avenue, #600, Chicago IL 60611\n",
            "\n",
            "### Contact Information\n",
            "\n",
            "[+91 97260 55109](tel:+91 97260 55109)   [+1 (620) 330-9814](tel:+1 (620) 330-9814)   [sales@moontechnolabs.com](mailto:sales@moontechnolabs.com)   [Moon Technolabs](https://teams.live.com/l/invite/FEAwVVITWBAv3cjvwI)\n",
            "\n",
            "#### Schedule Meeting\n",
            "\n",
            " \n",
            "---\n",
            "TITLE: Best Open Source Multimodal Vision Models in 2025 - Koyeb\n",
            "URL:https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025\n",
            "Content:Best Open Source Multimodal Vision Models in 2025 - Koyeb\n",
            "\n",
            "===============\n",
            "\n",
            "[](https://www.koyeb.com/)\n",
            "\n",
            "[Pricing](https://www.koyeb.com/pricing)[Docs](https://www.koyeb.com/docs)[Blog](https://www.koyeb.com/blog)[Tutorials](https://www.koyeb.com/tutorials)[Changelog](https://www.koyeb.com/changelog)[Deploy](https://www.koyeb.com/deploy)[Partners](https://www.koyeb.com/partners)\n",
            "\n",
            "[Login](https://app.koyeb.com/auth/signin)[Sign up](https://app.koyeb.com/auth/signup)\n",
            "\n",
            "[All articles](https://www.koyeb.com/blog)\n",
            "\n",
            "What is Koyeb?\n",
            "\n",
            "[Gemma 3](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#gemma-3)[Qwen 2.5 VL](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#qwen-25-vl)[Qwen 2.5 VL 72B Instruct](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#qwen-25-vl-72b-instruct)[Pixtral](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#pixtral)[Phi-4 Multimodal](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#phi-4-multimodal)[DeepSeek Janus Series](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#deepseek-janus-series)[DeepSeek Janus-Pro 7B](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#deepseek-janus-pro-7b)[Llama 3.2](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#llama-32)[Fine-Tuning and Deploying Open Source Multimodal Vision Models with Serverless GPUs](https://www.koyeb.com/blog/best-multimodal-vision-models-in-2025#fine-tuning-and-deploying-open-source-multimodal-vision-models-with-serverless-gpus)\n",
            "\n",
            "Summary\n",
            "\n",
            "[All articles](https://www.koyeb.com/blog)\n",
            "\n",
            "Mar 14, 2025\n",
            "\n",
            "8 min read\n",
            "\n",
            "Best Open Source Multimodal Vision Models in 2025\n",
            "=================================================\n",
            "\n",
            "AI models are not just about [LLMs](https://www.koyeb.com/blog/best-open-source-llms-in-2025) and generating text. **Multimodal vision models**—which understand and generate images, videos, and even audio alongside text—are enabling new AI applications.\n",
            "\n",
            "At their core, multimodal vision models combine:\n",
            "\n",
            "*   **A vision encoder** to extract visual images or video features\n",
            "*   **A language model** to process and generate text\n",
            "*   **A fusion mechanism** to connect these modalities in useful ways\n",
            "*   Sometimes **a decoder** to generate new text, images, or other structured data outputs.\n",
            "\n",
            "There are several different types of multimodal vision models: **vision-language models (VLMs)** that generate text based on images, **vision-reasoning models** that answer complex questions based on images, and more.\n",
            "\n",
            "Running multimodal vision models in production and at scale remains a challenge. Enter [Serverless GPUs](https://www.koyeb.com/blog/serverless-gpus-public-preview-run-ai-workloads-on-h100-a100-l40s-and-more): a cost-effective, scalable way to deploy and fine-tune LLMs without managing complex infrastructure.\n",
            "\n",
            "In this blog post, we'll take a look at the best multimodal vision models available today, including: **Qwen 2.5 VL 72B Instruct, Pixtral, Phi 4 Multimodal, Deepseek Janus Pro**, and more. After comparing their compatabilities and ideal use cases for real-world AI applications, we'll also share how to deploy them using serverless GPUs optimized for real-time inference and training.\n",
            "\n",
            "Gemma 3\n",
            "-------\n",
            "\n",
            "Gemma 3 was released recently and introduced multimodality, supporting vision-language input and text outputs. It's pre-training and post-training processes were optimized using a combination of distillation, reinforcement learning, and model merging. Gemma 3's development incorporates a blend of distillation, reinforcement learning (RL), and model merging, refining both efficiency and accuracy.\n",
            "\n",
            "Gemma can use images and videos as inputs, allowing it to analyze images, answer questions about an image, compare images, identify objects, and even reply about text within an image. Originally trained on 896×896 pixel images, Gemma 3 now utilizes a dynamic segmentation algorithm that enables processing of higher-resolution and non-square images, improving flexibility across diverse visual inputs.\n",
            "\n",
            "*   **Model Developer**: Google DeepMind\n",
            "*   **Available Parameter Sizes**: 4B, 12B, and 27B\n",
            "*   **Languages Supported**: Over 140 Languages\n",
            "*   **Input Context Window**: 128K\n",
            "*   **License**: Open weights and permit [responsible commercial use](https://ai.google.dev/gemma/terms)\n",
            "\n",
            "Deploy Gemma 3 27B on Serverless GPUs\n",
            "\n",
            "Run Gemma 3 27B and enjoy native autoscaling and scale-to-zero.\n",
            "\n",
            "[Deploy now](https://www.koyeb.com/deploy/gemma-3-27b)\n",
            "\n",
            "Qwen 2.5 VL\n",
            "-----------\n",
            "\n",
            "Qwen 2.5 VL is part of Alibaba Cloud's Qwen family of large language models, specifically designed to handle both visual and textual data. This multimodal model integrates a vision transformer with a language model, enabling advanced image and text understanding capabilities.\n",
            "\n",
            "The model excels at object recognition, scene interpretation, and multimodal reasoning, making it suitable for visual question answering (VQA), image captioning, and content moderation.\n",
            "\n",
            "Optimized for efficiency and accuracy, Qwen 2.5 VL is designed to perform well across cloud-based inference to on-device applications.\n",
            "\n",
            "*   **Model Developer**: Qwen\n",
            "*   **Available Parameter Sizes**: 7B and 72B parameters\n",
            "*   **Languages Supported**: English, Chinese\n",
            "*   **Input Context Window**: 32,768 tokens. To handle extensive inputs exceeding 32,768 tokens, we utilize YaRN, a technique for enhancing model length extrapolation, ensuring optimal performance on lengthy texts.\n",
            "*   **License**: Apache 2.0\n",
            "\n",
            "### Qwen 2.5 VL 72B Instruct\n",
            "\n",
            "The 72 billion parameter version offers enhanced performance in tasks requiring complex visual and linguistic comprehension.\n",
            "\n",
            "Deploy Qwen 2.5 VL 72B on Serverless GPUs\n",
            "\n",
            "Run Qwen 2.5 VL 72B and enjoy native autoscaling and scale-to-zero.\n",
            "\n",
            "[Deploy Now](https://www.koyeb.com/deploy/qwen-2-5-vl-72b-instruct)\n",
            "\n",
            "Pixtral\n",
            "-------\n",
            "\n",
            "Pixtral is Mistral AI's innovative multimodal model, seamlessly integrating visual and textual data processing. The initial release, Pixtral 12B, combines a 12-billion-parameter multimodal decoder with a 400-million-parameter vision encoder, enabling it to handle interleaved image and text data effectively. Subsequently, Pixtral Large was introduced, featuring a 124-billion-parameter model that integrates a 1-billion-parameter visual encoder coupled with Mistral Large 2, enhancing its performance, especially for long contexts and function calls.\n",
            "\n",
            "*   **Model Developer**: Mistral AI\n",
            "*   **Available Parameter Sizes**: 12B (Pixtral 12B) and 124B (aka Pixtral Large)\n",
            "*   **Languages Supported**: Dozens of languages\n",
            "*   **Input Context Window**: 128,000 tokens\n",
            "*   **License**: Pixtral 12B - Apache 2.0, Pixtral Large - Mistral Research License\n",
            "\n",
            "Deploy Pixtral on Serverless GPUs\n",
            "\n",
            "Run Pixtral and enjoy native autoscaling and scale-to-zero.\n",
            "\n",
            "[Deploy Now](https://www.koyeb.com/deploy/pixtral-12b)\n",
            "\n",
            "Phi-4 Multimodal\n",
            "----------------\n",
            "\n",
            "Microsoft's Phi-4 Multimodal model represents a significant advancement in AI, seamlessly integrating vision, audio, and text processing within a unified framework. Unlike traditional approaches that rely on separate models for different modalities, Phi-4 eliminates these silos, enabling more efficient, flexible, and context-aware AI applications.\n",
            "\n",
            "Phi-4 handles visual, auditory, and textual inputs within a single architecture, reducing the complexity of multimodal AI pipelines. By processing multiple data types together, Phi-4 excels in contextual reasoning, improving performance in image captioning, speech-to-text interactions, and multimodal content generation.\n",
            "\n",
            "Optimized for low-latency inference, Phi-4 is suitable for real-time applications across various domains.\n",
            "\n",
            "*   **Model Developer**: Microsoft\n",
            "*   **Available Parameter Sizes**: 5.6B\n",
            "*   **Languages Supported**: 24 languages\n",
            "*   **Input Context Window**: 128,000 tokens\n",
            "*   **License**: MIT\n",
            "\n",
            "Deploy Phi-4 Multimodal on Serverless GPUs\n",
            "\n",
            "Run Phi-4 Multimodal Instruct and enjoy native autoscaling and scale-to-zero.\n",
            "\n",
            "[Deploy now](https://www.koyeb.com/deploy/microsoft-phi-4-multimodal-instruct)\n",
            "\n",
            "DeepSeek Janus Series\n",
            "---------------------\n",
            "\n",
            "Janus is a series of open-source, multimodal AI models developed by DeepSeek, designed to process and integrate both visual and textual information.\n",
            "\n",
            "The Janus models utilize a unified transformer architecture with a decoupled visual encoding pathway. This design enhances flexibility and performance in tasks requiring understanding and generating content across multiple modalities. Each model in the series is designed to handle a sequence length of up to 4,096 tokens, facilitating complex and context-rich interactions.\n",
            "\n",
            "*   **Model Developer**: DeepSeek\n",
            "*   **Available Parameter Sizes**: Janus-Pro: 7B and 1B, Janus: 1.3B, JanusFlow: 1.3B\n",
            "*   **Languages Supported**: English, Chinese\n",
            "*   **Input Context Window**: Not disclosed. Possibly 4,096 tokens\n",
            "*   **License**: MIT License\n",
            "\n",
            "The Janus models utilize a unified transformer architecture with a decoupled visual encoding pathway, enhancing flexibility and performance in tasks that require understanding and generating content across multiple modalities. Each of these models have a sequence length of 4096.\n",
            "\n",
            "### DeepSeek Janus-Pro 7B\n",
            "\n",
            "Released in late January, DeepSeek Janus-Pro is the most advanced and capable model in the Janus series, scaling up to 7 billion parameters. It brings major improvements in both multimodal understanding and visual generation, thanks to an optimized training strategy, a significantly expanded dataset, and a larger model architecture compared to its predecessors.\n",
            "\n",
            "For multimodal understanding, Janus-Pro utilizes the SigLIP-L vision encoder, which supports 384 × 384 image input, enabling high-fidelity visual processing. This allows the model to excel in image comprehension, reasoning, and cross-modal tasks such as visual question answering, caption generation, and scene interpretation.\n",
            "\n",
            "Janus-Pro is built upon the DeepSeek-LLM-1.5B-base and DeepSeek-LLM-7B-base models, inheriting their strong textual reasoning capabilities while integrating high-quality vision encoding.\n",
            "\n",
            "Deploy DeepSeek Janus on Serverless GPUs\n",
            "\n",
            "Run DeepSeek Janus and enjoy native autoscaling and scale-to-zero.\n",
            "\n",
            "[Talk to an expert](https://tally.so/r/nGLjGo?utm_campaign=/blog/best-open-source-multimodal-vision-models-in-2025&utm_source=website&utm_medium=www)\n",
            "\n",
            "Llama 3.2\n",
            "---------\n",
            "\n",
            "Meta’s Llama 3.2 represents a major leap in open-source AI, introducing multimodal capabilities that seamlessly integrate text and visual data processing. These models are designed to handle complex reasoning across multiple modalities, unlocking new possibilities for AI-driven augmented reality, visual search, document analysis, and content generation.\n",
            "\n",
            "With a focus on efficiency and scalability, Llama 3.2 Vision models are optimized for a wide range of hardware, from high-performance GPUs to mobile devices, ensuring accessibility across different platforms. This versatility enables developers to build real-time AI applications, including intelligent assistants, creative design tools, and automated image understanding systems, without the constraints of proprietary models.\n",
            "\n",
            "*   **Model Developer**: Meta\n",
            "*   **Available Parameter Sizes**: 11B and 90B\n",
            "*   **Languages Supported**: 8 languages - English, German, Italian, Portuguese, Hindi, Spanish, and Thai\n",
            "*   **Input Context Window**: 128,000 tokens\n",
            "*   **License**: Allows for research and commercial use with specific terms and condition [Llama 3.2 Community License](https://huggingface.co/meta-llama/Llama-3.2-1B/blob/main/LICENSE.txt)\n",
            "\n",
            "Deploy Llama 3.2 on Serverless GPUs\n",
            "\n",
            "Run Llama 3.2 and enjoy native autoscaling and scale-to-zero.\n",
            "\n",
            "[Talk to an expert](https://tally.so/r/nGLjGo?utm_campaign=/blog/best-open-source-multimodal-vision-models-in-2025&utm_source=website&utm_medium=www)\n",
            "\n",
            "Fine-Tuning and Deploying Open Source Multimodal Vision Models with Serverless GPUs\n",
            "-----------------------------------------------------------------------------------\n",
            "\n",
            "Open source multimodal vision models like Gemma 3 and Qwen 2.5 VL provide powerful alternatives to proprietary options, offering flexibility and cost-effectiveness.\n",
            "\n",
            "With Koyeb’s serverless GPUs, you can fine-tune and deploy these models with a single click. Get a dedicated inference endpoint running on high performance GPUs without managing any infrastructure.\n",
            "\n",
            "*   [Sign up for Koyeb](https://app.koyeb.com/auth/signup) to get started deploying serverless inference endpoints today\n",
            "*   Deploy [vLLM](https://www.koyeb.com/deploy/vllm), [Ollama](https://www.koyeb.com/deploy/ollama), and other [open-source models](https://www.koyeb.com/deploy/category/model)\n",
            "*   [Read our documentation](https://www.koyeb.com/docs)\n",
            "*   Explore the [one-click deploy catalog](https://www.koyeb.com/deploy)\n",
            "\n",
            "Curious about the [best open source LLMs](https://www.koyeb.com/blog/best-open-source-llms-in-2025)? Read our dedicated blog post to discover which model you'll want to use for your next AI application.\n",
            "\n",
            "* * *\n",
            "\n",
            "/Authors\n",
            "\n",
            "![Image 1: Alisdair Broshar](https://www.koyeb.com/_next/image?url=%2Fstatic%2Fimages%2Fteam%2Fabroshar.jpg&w=96&q=75)\n",
            "\n",
            "[Alisdair Broshar](https://www.koyeb.com/blog/author/alisdair-broshar)\n",
            "\n",
            "/Share\n",
            "\n",
            "*   Share on Twitter \n",
            "*   Share on Facebook \n",
            "*   Share on LinkedIn \n",
            "*   Copy link \n",
            "\n",
            "Deploy AI apps to production in minutes\n",
            "---------------------------------------\n",
            "\n",
            "[Get started](https://app.koyeb.com/auth/signup)Talk to an expert\n",
            "\n",
            "Koyeb is a developer-friendly serverless platform to deploy apps globally. No-ops, servers, or infrastructure management.\n",
            "\n",
            "[All systems operational](https://status.koyeb.com/)\n",
            "\n",
            "Product\n",
            "\n",
            "[overview](https://www.koyeb.com/)[pricing](https://www.koyeb.com/pricing)[changelog](https://www.koyeb.com/changelog)[public roadmap](https://feedback.koyeb.com/)\n",
            "\n",
            "Resources\n",
            "\n",
            "[documentation](https://www.koyeb.com/docs)[tutorials](https://www.koyeb.com/tutorials)[community](https://community.koyeb.com/)[api](https://www.koyeb.com/docs/api)[deploy](https://www.koyeb.com/deploy)[startup program](https://www.koyeb.com/blog/koyeb-for-startups-accelerate-with-credits-for-high-performance-infrastructure)[system status](https://status.koyeb.com/)\n",
            "\n",
            "Company\n",
            "\n",
            "[blog](https://www.koyeb.com/blog)[customer stories](https://www.koyeb.com/customers)[partners](https://www.koyeb.com/partners)[events](https://lu.ma/koyeb)[careers](https://www.koyeb.com/careers)[company](https://www.koyeb.com/about)[terms of service](https://www.koyeb.com/docs/legal/terms)[privacy policy](https://www.koyeb.com/docs/legal/data-processing-agreement)\n",
            "\n",
            "[](https://www.linkedin.com/company/koyeb)[](https://x.com/gokoyeb)[](https://slack.koyeb.com/)\n",
            "\n",
            "© Koyeb\n",
            "---\n",
            "TITLE: Multimodal AI: A Guide to Open-Source Vision Language Models\n",
            "URL:https://www.bentoml.com/blog/multimodal-ai-a-guide-to-open-source-vision-language-models\n",
            "Content:ModelsModels\n",
            "\n",
            "# Multimodal AI: A Guide to Open-Source Vision Language Models\n",
            "\n",
            "Explore the top open-source VLMs and find answers to some FAQs about them.\n",
            "\n",
            "### Authors\n",
            "\n",
            "Sherlock Xu\n",
            "\n",
            "### Last Updated\n",
            "\n",
            "October 21, 2025\n",
            "\n",
            "### Share\n",
            "\n",
            "Over the past year, multimodal AI has moved from buzzword to baseline. Models no longer stop at text; they now interpret images, audio, video, and even user interfaces, fusing perception with reasoning. The latest wave, from GLM-4.5V to Qwen3-VL, pushes open-source multimodality into new territory once dominated by proprietary systems like GPT-5 and Gemini-2.5-Pro.\n",
            "\n",
            "Compared with closed-source APIs, open-source models remain the top choice for developers and enterprises seeking control, privacy, and customization. They allow teams to fine-tune, self-host, and integrate multimodal capabilities directly into their products without vendor lock-in.\n",
            "\n",
            "In this blog post, we’ll introduce some of the most popular open-source multimodal models available today. Since the world of multimodal AI is broad, we will be focused on vision language models (VLMs). These models are designed to understand and process both visual and text information. At the same time, we will explore some FAQs about VLMs.\n",
            "\n",
            "## Gemma 3[#](#gemma%203)\n",
            "\n",
            "[Gemma 3](https://blog.google/technology/developers/gemma-3/) is a family of lightweight, state-of-the-art open models developed by Google, built on the same research behind Gemini 2.0. It supports advanced text, image, and short video understanding, with strong reasoning capabilities across tasks and languages.\n",
            "\n",
            "Available in 1B, 4B, 12B, and 27B sizes, Gemma 3 offers flexibility for a range of hardware, from laptops to cloud clusters. With a 128K-token context window (32K for 1B), it can handle long-form input for more complex tasks.\n",
            "\n",
            "Key features:\n",
            "\n",
            "* **Multilingual support:** Pretrained on data spanning over 140 languages, Gemma 3 offers out-of-the-box support for 35+ widely used languages.\n",
            "* **Portable and efficient**: The small sizes make Gemma 3 ideal for deployment in constrained environments such as laptops, desktops, and edge devices. It also comes with official quantized versions that reduce resource demands while maintaining strong performance.\n",
            "* **Agentic workflows:** Gemma 3 supports function calling and structured output, enabling automation and integration into complex application pipelines.\n",
            "\n",
            "Points to be cautious about:\n",
            "\n",
            "* **Limited video comprehension**: While some visual reasoning is supported (especially short videos/images), Gemma 3 does not appear to support long-form or audio-visual video analysis.\n",
            "* **Image input only normalized**: Images are resized to 896×896 and encoded into 256 tokens. This may limit fine-grained image understanding or work with non-standard resolutions/aspect ratios.\n",
            "\n",
            "[Deploy Gemma 3Deploy Gemma 3](https://github.com/bentoml/BentoVLLM/tree/main/gemma3-1b-instruct)\n",
            "\n",
            "## GLM-4.5V[#](#glm-4.5v)\n",
            "\n",
            "[GLM-4.5V](https://huggingface.co/zai-org/GLM-4.5V) is the latest open-source multimodal model developed by [Z.ai](http://z.ai/), the team behind the GLM family of LLMs. With 106B parameters (12B active), it achieves state-of-the-art performance on 42 public vision language benchmarks, surpassing models like Gemma-3-27B and Qwen2.5-VL-72B.\n",
            "\n",
            "GLM-4.5V also comes with a Thinking Mode. This dual-mode design allows the model to trade speed for depth when tackling complex, multi-step visual reasoning tasks.\n",
            "\n",
            "Key features:\n",
            "\n",
            "* **Deep multimodal reasoning**: GLM-4.5V goes beyond perception to provide step-by-step reasoning across diverse inputs (e.g., images, videos, documents, and GUI environments). It performs strongly in scene understanding, chart analysis, and long-video comprehension, and can even play GeoGuessr-style visual location games with impressive accuracy.\n",
            "* **Advanced GUI agent abilities**: GLM-4.5V can interpret on-screen interfaces and perform actions in GUI environments. It can read app screens, identify icons, or execute visual tasks like locating discounts on an e-commerce page and calculating price differences. These capabilities make it a reliable foundation for building interactive visual agents that automate real-world workflows.\n",
            "* **Grounding and visual localization**: GLM-4.5V supports precise bounding-box grounding. It can locate and highlight specific visual elements in response to natural-language queries, useful for robotics perception, surveillance, and image annotation pipelines.\n",
            "\n",
            "Points to be cautious about:\n",
            "\n",
            "* **Limited language support**: Currently, the model provides bilingual support for English and Chinese only.\n",
            "* **HTML formatting issues**: While GLM-4.5V can generate frontend code from website images or videos, it may occasionally output raw HTML or mis-escape characters. A [patch](https://github.com/zai-org/GLM-V/blob/main/inference/html_detector.py) is available to address most cases.\n",
            "* **Occasional repetition**: The model may over-explain or repeat phrases when handling highly complex prompts.\n",
            "\n",
            "## Qwen3-VL[#](#qwen3-vl)\n",
            "\n",
            "Qwen3-VL is the latest and most capable VLM in Alibaba’s Qwen series, which represents a major leap over its predecessor Qwen2.5-VL. It delivers stronger multimodal reasoning, agentic capabilities, and long-context comprehension.\n",
            "\n",
            "Two main editions are currently available: Qwen3-VL-235B-A22B and Qwen3-VL-30B-A3B. Both provide Instruct and Thinking variants and official FP8 versions for efficient inference.\n",
            "\n",
            "The flagship [Qwen3-VL-235B-A22B-Instruct](https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Instruct) rivals top-tier proprietary models such as Gemini-2.5-Pro and GPT-5 across multimodal benchmarks covering general Q&A, 2D/3D grounding, video understanding, OCR, and document comprehension. In text-only tasks, it performs on par with or surpasses frontier models like DeepSeek-V3-0324 and Claude-Opus-4 on leading benchmarks like MMLU, AIME25, and LiveBench1125.\n",
            "\n",
            "Key features:\n",
            "\n",
            "* **Visual agent abilities**: Qwen3-VL can operate graphical interfaces (PC/mobile), recognizes UI elements, understands functions, and performs real-world tasks through tool invocation. This means you can use it for repetitive tasks like CRM updates, report generation, and software configuration through a single visual interface.\n",
            "* **Enhanced multilingual OCR**: The model supports OCR in 32 languages, including Greek, Hebrew, Hindi, Romanian, and Thai. It is able to read text in low-light, blurred, or tilted images and accurately parses complex documents, forms, and layouts.\n",
            "* **Advanced video understanding**: With a 256K-token native context window (expandable to 1M), Qwen3-VL can process entire books or hours-long videos with second-level indexing. It maintains precise recall across long sequences, capable of describing visual content frame-by-frame and answering detailed questions.\n",
            "\n",
            "For more practical examples and use cases, explore the [official Qwen3-VL cookbooks](https://github.com/QwenLM/Qwen3-VL/tree/main/cookbooks).\n",
            "\n",
            "## DeepSeek-OCR[#](#deepseek-ocr)\n",
            "\n",
            "[DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) is DeepSeek’s latest open-source VLM that redefines optical character recognition through a concept called [Contexts Optical Compression](https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf). The core idea works like this:\n",
            "\n",
            "* Convert text into an image.\n",
            "* Encode that image into compact, high-density vision tokens.\n",
            "* Decode those tokens back into text using a language model.\n",
            "\n",
            "Why is this important? LLMs face compute limitations when processing long text sequences. A single image containing dense document text can represent the same information using far fewer tokens than raw digital text. By transforming words into images, DeepSeek-OCR leverages visual encoding to dramatically reduce token counts and computation costs.\n",
            "\n",
            "In practice, the model can compress visual contexts by up to 20× while maintaining 97% OCR accuracy at compression ratios below 10×. On benchmarks like OmniDocBench, it outperforms GOT-OCR2.0 and MinerU2.0 while using significantly fewer vision tokens. It also delivers exceptional speed, reaching nearly 2,500 tokens per second on a single A100-40G GPU using vLLM.\n",
            "\n",
            "Key features:\n",
            "\n",
            "* **Dual-component architecture**: The model combines a lightweight DeepEncoder for high-resolution image input and a DeepSeek-3B-MoE-A570M decoder. The encoder minimizes activations under heavy input while keeping the number of vision tokens manageable.\n",
            "* **Deep parsing**: DeepSeek-OCR goes far beyond traditional OCR. It is capable of layout analysis, table extraction, chart parsing, chemical formula recognition, and even geometry reconstruction. For example, in deep parsing mode, it can identify chemical structures in research papers and convert them to SMILES format, or reproduce planar geometric figures from textbooks.\n",
            "* **Multilingual recognition**: DeepSeek-OCR supports nearly 100 languages, with both layout and non-layout output modes. It is an ideal choice for large-scale PDF and multilingual document processing.\n",
            "* **General vision understanding**: DeepSeek-OCR retains image description, grounding, and object detection abilities. However, since the researchers did not use supervised fine-tuning (SFT), DeepSeek-OCR isn’t a chatbot. Some of its advanced vision abilities require explicit completion prompts to activate.\n",
            "\n",
            "## Molmo[#](#molmo)\n",
            "\n",
            "[Molmo](https://molmo.allenai.org/blog) is a family of open-source VLMs developed by the Allen Institute for AI. Available in 1B, 7B, and 72B parameters, Molmo models deliver state-of-the-art performance for their class. According to the benchmarks, they can perform on a par with proprietary models like GPT-4V, Gemini 1.5 Pro, and Claude 3.5 Sonnet.\n",
            "\n",
            "The key to Molmo’s performance lies in its unique training data, **PixMo**. This highly curated dataset consists of 1 million image-text pairs and includes two main types of data:\n",
            "\n",
            "* Dense captioning data for multimodal pre-training\n",
            "* Supervised fine-tuning data to enable various user interactions, such as question answering, document reading, and even pointing to objects in images.\n",
            "\n",
            "Interestingly, Molmo researchers used an [innovative approach to data collection](https://arxiv.org/pdf/2409.17146): **Asked annotators to provide spoken descriptions of images within 60 to 90 seconds**. Specifically, these detailed descriptions included everything visible, even the spatial positioning and relationships among objects. The results show that annotators provided detailed captions far more efficiently than traditional methods (writing them down). Overall, they collected high-quality audio descriptions for 712k images that were sampled from 50 high-level topics.\n",
            "\n",
            "Key features:\n",
            "\n",
            "* **State-of-the-art performance**: Molmo’s 72B model outperforms proprietary models like Gemini 1.5 Pro and Claude 3.5 Sonnet on academic benchmarks. Even the smaller 7B and 1B models rival GPT-4V in several tasks.\n",
            "* **Pointing capabilities**: Molmo can “point” to one or more visual elements in the image. Pointing provides a natural explanation grounded in image pixels. Molmo researchers believe that in the future pointing will be an important communication channel between VLMs and agents. For example, a web agent could query the VLM for the location of specific objects.\n",
            "* **Open architecture**: The original developers promise to release all artifacts used in creating Molmo, including the PixMo dataset, training code, evaluations, and intermediate checkpoints. This offers a new standard for building high-performing multimodal systems from scratch and promotes reproducibility.\n",
            "\n",
            "Points to be cautious about:\n",
            "\n",
            "* **Transparent images**: Molmo may struggle with transparent images. It's recommended to [add a white or dark background](https://huggingface.co/allenai/Molmo-7B-D-0924#molmo-doesnt-work-great-with-transparent-images) to images before processing them with the model.\n",
            "* **Broadcast errors**: If you encounter a broadcast error while processing images, [ensure your image is in RGB format](https://huggingface.co/allenai/Molmo-7B-D-0924#im-getting-an-error-a-broadcast-error-when-processing-images).\n",
            "\n",
            "## Pixtral[#](#pixtral)\n",
            "\n",
            "[Pixtral](https://arxiv.org/pdf/2410.07073) is a 12 billion parameter open-source model developed by Mistral, marking [the company's first foray into multimodal capabilities](https://mistral.ai/news/pixtral-12b/). Pixtral is designed to understand both images and text, released with open weights under the Apache 2.0 license.\n",
            "\n",
            "As an instruction-tuned model, Pixtral is pre-trained on a large-scale dataset of interleaved image and text documents. Therefore, it is capable of multi-turn, multi-image conversations. Unlike previous open-source models, Pixtral maintains excellent text benchmark performance while excelling in multimodal tasks.\n",
            "\n",
            "Key features:\n",
            "\n",
            "* **Outstanding instruction following capability**: Benchmark results indicate that Pixtral 12B significantly outperforms other open-source multimodal models like Qwen2-VL 7B, LLaVa-OneVision 7B, and Phi-3.5 Vision in instruction following tasks. Mistral has created new benchmarks, *MM-IF-Eval* and *MM-MT-Bench*, to further assess performance in multimodal contexts, where Pixtral also excels. These benchmarks are expected to be open-sourced for the community in the near future.\n",
            "* **Multi-image processing:** Pixtral can handle multiple images in a single input, processing them at their native resolution. The model supports a context window of 128,000 tokens and can ingest images with varied sizes and aspect ratios.\n",
            "\n",
            "Points to be cautious about:\n",
            "\n",
            "* **Lack of moderation mechanisms**: Currently, Pixtral does not include any built-in moderation features. This means it may not be applicable to cases that require controlled outputs.\n",
            "\n",
            "To deploy Pixtral 12B, you can run `openllm serve pixtral:12b` with [OpenLLM](https://github.com/bentoml/OpenLLM).\n",
            "\n",
            "## Do I really need VLMs?[#](#do%20i%20really%20need%20vlms%3F)\n",
            "\n",
            "This is probably the first question you should ask yourself. Also, think about the type of data your application needs to process. If your use case only requires text, an LLM is often sufficient. However, if you need to analyze both text and images, a VLM is a reasonable choice.\n",
            "\n",
            "If you choose a VLM, be aware that certain models may compromise their text-only performance to excel in multimodal tasks. This is why some model developers emphasize that their new models, such as NVLM and Pixtral, do not sacrifice text performance for multimodal capabilities.\n",
            "\n",
            "For other modalities, note that different models may be specialized for particular fields, such as document processing and audio analyzing. These are more suited for multimodal scenarios beyond just text and images.\n",
            "\n",
            "## What should I consider when deploying VLMs?[#](#what%20should%20i%20consider%20when%20deploying%20vlms%3F)\n",
            "\n",
            "Consider the following factors to ensure optimal performance and usability:\n",
            "\n",
            "### Infrastructure requirements[#](#infrastructure%20requirements)\n",
            "\n",
            "VLMs often require significant computational resources due to their large size. Top-performing open-source models like the above-mentioned ones can reach over 70 billion parameters. This means you need high-performance GPUs to run them, especially for real-time applications.\n",
            "\n",
            "If you are looking for a solution that simplifies this process, you can try [BentoCloud](https://www.bentoml.com/blog/introducing-bentocloud). It seamlessly integrates cutting-edge AI infrastructure into enterprises’ private cloud environment. Its cloud-agnostic approach allows AI teams to select the cloud regions with the most competitive GPU rates. As BentoCloud offloads the infrastructure burdens, you can focus on building the core functions with your VLM.\n",
            "\n",
            "### Multimodal handling[#](#multimodal%20handling)\n",
            "\n",
            "Not all model serving and deployment frameworks are designed to handle multimodal inputs, such as text, images, and videos. To leverage the full potential of your VLM, ensure your serving and deployment framework can accommodate and process multiple data types simultaneously.\n",
            "\n",
            "BentoML [supports a wide range of data types](https://docs.bentoml.com/en/latest/guides/iotypes.html), such as text, images, audios and documents. You can easily integrate it with your existing ML workflow without a custom pipeline for handling multimodal inputs.\n",
            "\n",
            "### Fast scaling[#](#fast%20scaling)\n",
            "\n",
            "VLMs are often used in demanding applications such as:\n",
            "\n",
            "* **Real-time image captioning** for large-scale media platforms.\n",
            "* **Visual search** in e-commerce, where users upload images to find similar products.\n",
            "* **Visual question answering** in customer support or educational tools.\n",
            "\n",
            "In these use cases, traffic can spike unpredictably based on user behavior. This means your deployment framework should support fast scaling during peak hours. BentoML [provides easy building blocks to create scalable APIs](https://www.bentoml.com/blog/scaling-ai-model-deployment), allowing you to deploy and run any VLMs on BentoCloud. Its autoscaling feature makes sure you only pay for the resources you use.\n",
            "\n",
            "## How do I interpret the benchmarks mentioned by VLM providers?[#](#how%20do%20i%20interpret%20the%20benchmarks%20mentioned%20by%20vlm%20providers%3F)\n",
            "\n",
            "Each benchmark serves a specific purpose and can highlight different capabilities of models. Here are five popular benchmarks for VLMs:\n",
            "\n",
            "* **MMMU** evaluates multimodal models in advanced tasks that require college-level subject knowledge and reasoning. It contains **11.5K** questions from college exams, quizzes, and textbooks across six disciplines: Art & Design, Business, Science, Health & Medicine, Humanities & Social Sciences, and Tech & Engineering.\n",
            "* **MMBench** is a comprehensive benchmark that assesses a model's performance across various applications of multimodal tasks. It includes over **3,000** multiple-choice questions, covering 20 different ability dimensions, such as object localization, spatial reasoning, and social interaction. Each ability dimension contains at least 125 questions, ensuring a balanced evaluation of a model’s vision language capabilities.\n",
            "* **ChartQA** tests a model's capacity to extract relevant information from various types of charts (e.g., bar charts, line graphs, and pie charts) and answer questions about the data. It assesses skills such as trend analysis, data comparison, and numerical reasoning based on visual representations.\n",
            "* **DocVQA** focuses on the comprehension of complex documents that contain both textual and visual elements, such as forms, receipts, charts, and diagrams embedded in documents.\n",
            "* **MathVista** evaluates models in the domain of mathematical reasoning and problem-solving. It presents problems that combine visual elements, such as geometric figures, plots, or diagrams, with textual descriptions and questions.\n",
            "\n",
            "One thing to note is that you should always treat benchmarks with caution. They are important, but by no means the only reference for choosing the right model for your use case.\n",
            "\n",
            "## Final thoughts[#](#final%20thoughts)\n",
            "\n",
            "Over the past year, we’ve seen a wave of powerful open-source VLMs emerge. Is this a coincidence, or are LLMs moving towards multimodal capabilities as a trend? It may be too early to say for sure. What remains unchanged is the need for robust solutions to quickly and securely deploy these models into production at scale.\n",
            "\n",
            "If you have questions about productionizing VLMs, check out the following resources:\n",
            "\n",
            "* [BentoCloud: Fast and Customizable GenAI Inference in Your Cloud](https://www.bentoml.com/blog/introducing-bentocloud)\n",
            "* Choose the right [NVIDIA](https://www.bentoml.com/blog/nvidia-data-center-gpus-explained-a100-h200-b200-and-beyond) or [AMD](https://www.bentoml.com/blog/amd-data-center-gpus-mi250x-mi300x-mi350x-and-beyond) GPUs for your model\n",
            "* Choose the right deployment patterns: [BYOC](https://www.bentoml.com/llm/infrastructure-and-operations/bring-your-own-cloud), [multi-cloud and cross-region](https://www.bentoml.com/llm/infrastructure-and-operations/multi-cloud-and-cross-region-inference), [on-prem and hybrid](https://www.bentoml.com/llm/infrastructure-and-operations/on-prem-llms)\n",
            "* [Sign up for BentoCloud](https://l.bentoml.com/signup-from-blog-multimodal-ai-a-guide-to-open-source-vision-language-models) for free to deploy your first VLM model\n",
            "* [Join our Slack community](https://l.bentoml.com/join-slack-from-blog-multimodal-ai-a-guide-to-open-source-vision-language-models)\n",
            "* [Contact us](https://link.bentoml.com/contact-us-from-blog-multimodal-ai-a-guide-to-open-source-vision-language-models) if you have any questions of deploying VLM models\n",
            "\n",
            "## Subscribe to our newsletter\n",
            "\n",
            "Stay updated on AI infrastructure, inference techniques, and performance optimization.\n",
            "\n",
            "### Products\n",
            "\n",
            "[Bento Inference Platform](https://cloud.bentoml.com/)[BentoML Open-Source](https://github.com/bentoml/BentoML)\n",
            "\n",
            "### Resources\n",
            "\n",
            "[Blog](/blog)[LLM Inference Handbook](/llm)[LLM Performance Explorer](/llm-perf)[Example Projects](https://docs.bentoml.com/en/latest/examples/overview.html)[AI Infrastructure Report](/2024-ai-infra-report)\n",
            "\n",
            "### Company\n",
            "\n",
            "[Privacy Policy](/privacy)\n",
            "\n",
            "### Join our community\n",
            "\n",
            "[GitHub](https://github.com/bentoml)\n",
            "---\n",
            "TITLE: Best Open Source LLM for Function Calling + Multimodal Image ...\n",
            "URL:https://www.reddit.com/r/LocalLLaMA/comments/1kp81ez/best_open_source_llm_for_function_calling/\n",
            "Content:Best Open Source LLM for Function Calling + Multimodal Image Support : r/LocalLLaMA\n",
            "\n",
            "===============\n",
            "[Skip to main content](https://www.reddit.com/r/LocalLLaMA/comments/1kp81ez/best_open_source_llm_for_function_calling/#main-content)Best Open Source LLM for Function Calling + Multimodal Image Support : r/LocalLLaMA\n",
            "\n",
            "Open menu Open navigation[](https://www.reddit.com/)Go to Reddit Home\n",
            "\n",
            "r/LocalLLaMA A chip A close button\n",
            "\n",
            "[Log In](https://www.reddit.com/login/)Log in to Reddit\n",
            "\n",
            "Expand user menu Open settings menu\n",
            "\n",
            "[![Image 1: r/LocalLLaMA icon](https://styles.redditmedia.com/t5_81eyvm/styles/communityIcon_cumnsvx9kzma1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=0ae51826e9b99ef23f985ae5b3c6c8d76b205c79) Go to LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)\n",
            "\n",
            "[r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)\n",
            "\n",
            "![Image 2: r/LocalLLaMA icon](https://styles.redditmedia.com/t5_81eyvm/styles/communityIcon_cumnsvx9kzma1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=0ae51826e9b99ef23f985ae5b3c6c8d76b205c79)[r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)![Image 3: Llama](https://emoji.redditmedia.com/23w2nhjj1e9f1_t5_81eyvm/Llama)![Image 4: Llama](https://emoji.redditmedia.com/23w2nhjj1e9f1_t5_81eyvm/Llama)\n",
            "\n",
            "[https://x.com/localllamasub](https://x.com/localllamasub)\n",
            "\n",
            "Subreddit to discuss AI & Llama, the large language model created by Meta AI.\n",
            "\n",
            "* * *\n",
            "\n",
            "528K Members Online\n",
            "\n",
            "•3 mo. ago\n",
            "\n",
            "[Zlare7771](https://www.reddit.com/user/Zlare7771/)\n",
            "\n",
            "Best Open Source LLM for Function Calling + Multimodal Image Support\n",
            "====================================================================\n",
            "\n",
            "[Question | Help](https://www.reddit.com/r/LocalLLaMA/?f=flair_name%3A%22Question%20%7C%20Help%22)\n",
            "\n",
            "What's the best LLM to use locally that can support function calling well and also has multimodal image support? I'm looking for, essentially, a replacement for Gemini 2.5.\n",
            "\n",
            "The device I'm using is an M1 Macbook with 64gb memory, so I can run decently large models, but it would be most ideal if the response time isn't too horrible on my (by AI standards) relatively mediocre hardware.\n",
            "\n",
            "I am aware of the Berkeley Function-Calling Leaderboard, but I didn't see any models there that also have multimodal image support.\n",
            "\n",
            "Is there something that matches my requirements, or am I better off just adding an image-to-text model to preprocess image outputs?\n",
            "\n",
            " Read more \n",
            "\n",
            " Share \n",
            "\n",
            "Related Answers Section\n",
            "=======================\n",
            "\n",
            "Related Answers\n",
            "\n",
            "[Best multimodal LLM recommendations](https://www.reddit.com/answers/42b9f113-ce99-48e4-ba2e-4d79b5b733b1/?q=Best%20multimodal%20LLM%20recommendations&source=PDP)\n",
            "\n",
            "[Best local model for tool calling](https://www.reddit.com/answers/f777c9ed-532d-4b3d-b70e-d975e091df2b/?q=Best%20local%20model%20for%20tool%20calling&source=PDP)\n",
            "\n",
            "[Best open source embedding models](https://www.reddit.com/answers/e807fbb6-fe6a-4d49-8820-a9aec600146d/?q=Best%20open%20source%20embedding%20models&source=PDP)\n",
            "\n",
            "[Best vision language models](https://www.reddit.com/answers/b11a201c-d6c5-4bcf-8a18-27ad6ec0de59/?q=Best%20vision%20language%20models&source=PDP)\n",
            "\n",
            "[Smartest local LLM options](https://www.reddit.com/answers/bec12020-69da-4f17-bb47-d129012d7702/?q=Smartest%20local%20LLM%20options&source=PDP)\n",
            "\n",
            "New to Reddit? \n",
            "Create your account and connect with a world of communities.\n",
            "\n",
            "Continue with Google Continue with Google. Opens in new tab\n",
            "\n",
            " Continue with Email \n",
            "\n",
            " Continue With Phone Number \n",
            "\n",
            "By continuing, you agree to our[User Agreement](https://www.redditinc.com/policies/user-agreement)and acknowledge that you understand the[Privacy Policy](https://www.redditinc.com/policies/privacy-policy). \n",
            "\n",
            "![Image 5: Llama](https://emoji.redditmedia.com/23w2nhjj1e9f1_t5_81eyvm/Llama)![Image 6: Llama](https://emoji.redditmedia.com/23w2nhjj1e9f1_t5_81eyvm/Llama)\n",
            "\n",
            "[https://x.com/localllamasub](https://x.com/localllamasub)\n",
            "\n",
            " Public \n",
            "\n",
            "Anyone can view, post, and comment to this community\n",
            "\n",
            "[Reddit Rules](https://www.redditinc.com/policies/content-policy)[Privacy Policy](https://www.reddit.com/policies/privacy-policy)[User Agreement](https://www.redditinc.com/policies/user-agreement)[Accessibility](https://support.reddithelp.com/hc/sections/38303584022676-Accessibility)[Reddit, Inc. © 2025. All rights reserved.](https://redditinc.com/)\n",
            "\n",
            "Expand Navigation Collapse Navigation\n",
            "\n",
            "![Image 7](https://id.rlcdn.com/472486.gif)\n",
            "\n",
            "---\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mOpen Source Multimodal LLM 모델 추천을 요청하는 질문입니다. 검색 결과를 바탕으로 여러 모델을 추천하고, 각 모델의 특징과 주의할 점을 정리하여 답변하겠습니다.\n",
            "\n",
            "검색 결과에서 다음과 같은 Open Source Multimodal LLM 모델들이 언급되었습니다:\n",
            "*   **InternVL 3.5**: 최고의 오픈소스 멀티모달 모델 중 하나로 언급되며, 다양한 크기(1B~241B)로 제공됩니다. MMMU, ChartQA, DocVQA 등 여러 벤치마크에서 높은 성능을 보입니다. 영상 이해, 문서 이해, 차트 분석 등에 강점을 가집니다.\n",
            "*   **Gemma 3**: Google DeepMind에서 개발한 경량 오픈 모델로, 1B, 4B, 12B, 27B 크기가 있습니다. 140개 이상의 언어를 지원하며, 이미지 및 짧은 영상 이해와 텍스트 출력에 강합니다. 에이전트 워크플로우를 위한 함수 호출 및 구조화된 출력을 지원합니다.\n",
            "*   **GLM-4.5V**: Z.ai에서 개발한 106B 파라미터(12B 활성) 모델로, 42개 공개 비전 언어 벤치마크에서 최첨단 성능을 달성했습니다. Thinking Mode를 제공하며, 깊은 멀티모달 추론, 고급 GUI 에이전트 기능, 접지 및 시각적 현지화에 강합니다. 영어와 중국어만 지원합니다.\n",
            "*   **Qwen 2.5 VL / Qwen3-VL**: Alibaba Cloud의 Qwen 시리즈 모델. Qwen 2.5 VL은 7B, 72B 파라미터 크기가 있으며, 객체 인식, 장면 해석, 멀티모달 추론에 뛰어납니다. Qwen3-VL은 Qwen 시리즈의 최신 버전으로, 235B-A22B 및 30B-A3B 에디션이 있습니다. 시각 에이전트 기능, 향상된 다국어 OCR, 고급 영상 이해에 강합니다.\n",
            "*   **Pixtral**: Mistral AI의 첫 번째 멀티모달 모델로, 12B 파라미터 크기(Pixtral 12B)와 124B 파라미터 크기(Pixtral Large)가 있습니다. 이미지와 텍스트 데이터를 효과적으로 처리하며, 뛰어난 지침 준수 능력과 다중 이미지 처리에 강합니다.\n",
            "*   **Phi-4 Multimodal**: Microsoft의 모델로, 5.6B 파라미터 크기입니다. 비전, 오디오, 텍스트 처리를 통합된 프레임워크 내에서 처리하여 효율적이고 유연한 AI 애플리케이션을 가능하게 합니다.\n",
            "*   **DeepSeek Janus Series / DeepSeek Janus-Pro 7B**: DeepSeek에서 개발한 오픈소스 멀티모달 AI 모델 시리즈. Janus-Pro 7B는 멀티모달 이해 및 시각적 생성에서 큰 개선을 보이며, DeepSeek-LLM-1.5B-base 및 DeepSeek-LLM-7B-base 모델을 기반으로 합니다.\n",
            "*   **DeepSeek-OCR**: DeepSeek의 최신 오픈소스 VLM으로, Contexts Optical Compression이라는 개념을 통해 OCR 기능을 재정의합니다. 문서 텍스트를 이미지로 변환하여 토큰 수를 크게 줄입니다. OCR 정확도가 높고, 레이아웃 분석, 테이블 추출, 차트 구문 분석 등 딥 파싱이 가능합니다. 약 100개 언어를 지원하며, 일반적인 시각 이해 능력도 가집니다.\n",
            "*   **Llama 3.2**: Meta의 오픈소스 AI 모델로, 11B 및 90B 파라미터 크기가 있습니다. 텍스트와 시각 데이터를 원활하게 통합하는 멀티모달 기능을 도입하여 복잡한 추론을 처리합니다.\n",
            "*   **Molmo**: Allen Institute for AI에서 개발한 오픈소스 VLM 제품군으로, 1B, 7B, 72B 파라미터 크기가 있습니다. PixMo라는 독특한 훈련 데이터를 사용하며, 최첨단 성능과 포인팅(pointing) 기능을 제공합니다.\n",
            "\n",
            "이 모델들을 종합하여 사용자에게 추천 리스트를 제공하겠습니다.Thought: Open Source Multimodal LLM 모델 추천 요청에 따라, 검색된 정보를 바탕으로 주요 모델들을 정리하여 답변을 구성합니다. 각 모델의 특징, 강점, 그리고 고려사항을 포함하여 사용자에게 유용한 정보를 제공합니다.\n",
            "\n",
            "**추천 모델 리스트:**\n",
            "\n",
            "1.  **InternVL 3.5**: 여러 벤치마크에서 뛰어난 성능을 보이는 최고의 오픈소스 멀티모달 모델 중 하나입니다. 다양한 크기(1B~241B)로 제공되어 프로토타입부터 대규모 배포까지 활용 가능합니다. 영상 이해, 문서 이해, 차트 분석 등 복잡한 시각적 추론에 강점을 가집니다.\n",
            "2.  **Gemma 3 (Google DeepMind)**: Google에서 개발한 경량 오픈 모델로, 1B, 4B, 12B, 27B 크기가 있습니다. 140개 이상의 언어를 지원하며, 이미지 및 짧은 영상 이해와 텍스트 출력에 강합니다. 에이전트 워크플로우를 위한 함수 호출 및 구조화된 출력을 지원하는 것이 특징입니다.\n",
            "3.  **GLM-4.5V (Z.ai)**: 106B 파라미터(12B 활성) 모델로, 42개 공개 비전 언어 벤치마크에서 최첨단 성능을 달성했습니다. 'Thinking Mode'를 통해 복잡한 시각적 추론을 수행하며, 고급 GUI 에이전트 기능과 시각적 현지화(Grounding)에 강합니다. (현재 영어와 중국어만 지원)\n",
            "4.  **Qwen3-VL (Alibaba Cloud)**: Qwen 시리즈의 최신 버전으로, Qwen2.5-VL보다 향상된 멀티모달 추론, 에이전트 기능, 긴 컨텍스트 이해를 제공합니다. 시각 에이전트 기능, 32개 언어를 지원하는 향상된 다국어 OCR, 256K 토큰의 긴 컨텍스트 윈도우를 통한 고급 영상 이해가 강점입니다.\n",
            "5.  **Pixtral (Mistral AI)**: Mistral AI의 첫 번째 멀티모달 모델로, 12B 및 124B 파라미터 크기가 있습니다. 이미지와 텍스트 데이터를 효과적으로 처리하며, 특히 뛰어난 지침 준수 능력과 다중 이미지 처리에 강합니다.\n",
            "6.  **DeepSeek-OCR (DeepSeek)**: OCR에 특화된 VLM으로, 'Contexts Optical Compression' 개념을 통해 문서 텍스트를 이미지로 변환하여 토큰 수를 크게 줄입니다. 높은 OCR 정확도와 함께 레이아웃 분석, 테이블 추출, 차트 구문 분석 등 딥 파싱이 가능하며, 약 100개 언어를 지원합니다. 일반적인 시각 이해 능력도 갖추고 있습니다.\n",
            "7.  **Molmo (Allen Institute for AI)**: 1B, 7B, 72B 파라미터 크기로 제공되는 VLM 제품군입니다. PixMo라는 독특한 훈련 데이터를 사용하여 최첨단 성능을 달성했으며, 이미지 내 특정 객체를 \"가리킬(pointing)\" 수 있는 기능이 특징입니다.\n",
            "8.  **Llama 3.2 (Meta)**: Meta의 오픈소스 AI 모델로, 11B 및 90B 파라미터 크기가 있습니다. 텍스트와 시각 데이터를 원활하게 통합하는 멀티모달 기능을 도입하여 복잡한 추론을 처리합니다.\n",
            "\n",
            "**선택 가이드:**\n",
            "\n",
            "*   **최고 성능 및 범용성**: InternVL 3.5, GLM-4.5V, Qwen3-VL (특히 대규모 버전)\n",
            "*   **경량 모델 및 에이전트 기능**: Gemma 3\n",
            "*   **OCR 및 문서 분석 특화**: DeepSeek-OCR\n",
            "*   **지침 준수 및 다중 이미지 처리**: Pixtral\n",
            "*   **텍스트/시각 데이터 통합 추론**: Llama 3.2\n",
            "\n",
            "최종 답변은 이 정보를 바탕으로 구성합니다.Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"다음은 현재 사용 가능한 주요 오픈소스 멀티모달 LLM 모델 추천 목록입니다. 각 모델은 특정 강점과 활용 사례를 가지고 있습니다.\\n\\n1.  **InternVL 3.5**: 최고의 오픈소스 멀티모달 모델 중 하나로 평가되며, 1B부터 241B에 이르는 다양한 크기로 제공됩니다. MMMU, ChartQA, DocVQA 등 여러 벤치마크에서 뛰어난 성능을 보여줍니다. 영상 이해, 문서 분석, 차트 해석 등 복잡한 시각적 추론 작업에 특히 강력합니다.\\n\\n2.  **Gemma 3 (Google DeepMind)**: Google에서 개발한 경량 오픈 모델로, 1B, 4B, 12B, 27B 크기가 있습니다. 140개 이상의 언어를 지원하며, 이미지 및 짧은 영상 이해와 텍스트 출력에 특화되어 있습니다. 에이전트 워크플로우를 위한 함수 호출 및 구조화된 출력을 지원합니다.\\n\\n3.  **GLM-4.5V (Z.ai)**: 106B 파라미터(12B 활성) 모델로, 42개 공개 비전 언어 벤치마크에서 최첨단 성능을 달성했습니다. 'Thinking Mode'를 통해 깊은 멀티모달 추론을 수행하며, 고급 GUI 에이전트 기능과 시각적 현지화(Grounding)에 강합니다. (현재 영어와 중국어만 지원합니다.)\\n\\n4.  **Qwen3-VL (Alibaba Cloud)**: Qwen 시리즈의 최신 버전으로, 향상된 멀티모달 추론, 에이전트 기능, 긴 컨텍스트 이해를 제공합니다. 시각 에이전트 기능, 32개 언어를 지원하는 OCR, 256K 토큰의 긴 컨텍스트 윈도우를 통한 고급 영상 이해가 특징입니다.\\n\\n5.  **Pixtral (Mistral AI)**: Mistral AI의 첫 멀티모달 모델로, 12B 및 124B 파라미터 크기가 있습니다. 이미지와 텍스트 데이터를 효과적으로 처리하며, 뛰어난 지침 준수 능력과 다중 이미지 처리 능력이 강점입니다.\\n\\n6.  **DeepSeek-OCR (DeepSeek)**: OCR에 특화된 VLM으로, 'Contexts Optical Compression' 개념을 통해 문서 텍스트를 이미지로 변환하여 토큰 수를 크게 줄입니다. 높은 OCR 정확도와 함께 레이아웃 분석, 테이블 추출 등 딥 파싱이 가능하며, 약 100개 언어를 지원합니다.\\n\\n7.  **Molmo (Allen Institute for AI)**: 1B, 7B, 72B 파라미터 크기로 제공됩니다. PixMo라는 독특한 훈련 데이터를 사용하여 최첨단 성능을 달성했으며, 이미지 내 특정 객체를 \\\"가리킬(pointing)\\\" 수 있는 기능이 특징입니다.\\n\\n8.  **Llama 3.2 (Meta)**: Meta의 오픈소스 AI 모델로, 11B 및 90B 파라미터 크기가 있습니다. 텍스트와 시각 데이터를 원활하게 통합하는 멀티모달 기능을 도입하여 복잡한 추론을 처리합니다.\\n\\n**모델 선택 시 고려사항:**\\n*   **성능 및 범용성**: 최신 벤치마크에서 높은 점수를 기록하는 InternVL 3.5, GLM-4.5V, Qwen3-VL (대규모 버전) 등을 고려할 수 있습니다.\\n*   **자원 제약**: 경량 모델이 필요하다면 Gemma 3이나 InternVL 3.5의 작은 버전이 적합합니다.\\n*   **특정 작업**: OCR 및 문서 분석에는 DeepSeek-OCR, 에이전트 기능에는 GLM-4.5V나 Qwen3-VL이 유리할 수 있습니다.\\n*   **언어 지원**: 다국어 지원이 중요하다면 Gemma 3이나 Qwen3-VL을 검토하세요.\\n\\n각 모델의 문서와 커뮤니티를 통해 자세한 정보를 확인하고, 실제 사용 목적에 가장 적합한 모델을 선택하는 것이 중요합니다.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Open Source Multimodal LLM Model 추천해줘',\n",
              " 'output': '다음은 현재 사용 가능한 주요 오픈소스 멀티모달 LLM 모델 추천 목록입니다. 각 모델은 특정 강점과 활용 사례를 가지고 있습니다.\\n\\n1.  **InternVL 3.5**: 최고의 오픈소스 멀티모달 모델 중 하나로 평가되며, 1B부터 241B에 이르는 다양한 크기로 제공됩니다. MMMU, ChartQA, DocVQA 등 여러 벤치마크에서 뛰어난 성능을 보여줍니다. 영상 이해, 문서 분석, 차트 해석 등 복잡한 시각적 추론 작업에 특히 강력합니다.\\n\\n2.  **Gemma 3 (Google DeepMind)**: Google에서 개발한 경량 오픈 모델로, 1B, 4B, 12B, 27B 크기가 있습니다. 140개 이상의 언어를 지원하며, 이미지 및 짧은 영상 이해와 텍스트 출력에 특화되어 있습니다. 에이전트 워크플로우를 위한 함수 호출 및 구조화된 출력을 지원합니다.\\n\\n3.  **GLM-4.5V (Z.ai)**: 106B 파라미터(12B 활성) 모델로, 42개 공개 비전 언어 벤치마크에서 최첨단 성능을 달성했습니다. \\'Thinking Mode\\'를 통해 깊은 멀티모달 추론을 수행하며, 고급 GUI 에이전트 기능과 시각적 현지화(Grounding)에 강합니다. (현재 영어와 중국어만 지원합니다.)\\n\\n4.  **Qwen3-VL (Alibaba Cloud)**: Qwen 시리즈의 최신 버전으로, 향상된 멀티모달 추론, 에이전트 기능, 긴 컨텍스트 이해를 제공합니다. 시각 에이전트 기능, 32개 언어를 지원하는 OCR, 256K 토큰의 긴 컨텍스트 윈도우를 통한 고급 영상 이해가 특징입니다.\\n\\n5.  **Pixtral (Mistral AI)**: Mistral AI의 첫 멀티모달 모델로, 12B 및 124B 파라미터 크기가 있습니다. 이미지와 텍스트 데이터를 효과적으로 처리하며, 뛰어난 지침 준수 능력과 다중 이미지 처리 능력이 강점입니다.\\n\\n6.  **DeepSeek-OCR (DeepSeek)**: OCR에 특화된 VLM으로, \\'Contexts Optical Compression\\' 개념을 통해 문서 텍스트를 이미지로 변환하여 토큰 수를 크게 줄입니다. 높은 OCR 정확도와 함께 레이아웃 분석, 테이블 추출 등 딥 파싱이 가능하며, 약 100개 언어를 지원합니다.\\n\\n7.  **Molmo (Allen Institute for AI)**: 1B, 7B, 72B 파라미터 크기로 제공됩니다. PixMo라는 독특한 훈련 데이터를 사용하여 최첨단 성능을 달성했으며, 이미지 내 특정 객체를 \"가리킬(pointing)\" 수 있는 기능이 특징입니다.\\n\\n8.  **Llama 3.2 (Meta)**: Meta의 오픈소스 AI 모델로, 11B 및 90B 파라미터 크기가 있습니다. 텍스트와 시각 데이터를 원활하게 통합하는 멀티모달 기능을 도입하여 복잡한 추론을 처리합니다.\\n\\n**모델 선택 시 고려사항:**\\n*   **성능 및 범용성**: 최신 벤치마크에서 높은 점수를 기록하는 InternVL 3.5, GLM-4.5V, Qwen3-VL (대규모 버전) 등을 고려할 수 있습니다.\\n*   **자원 제약**: 경량 모델이 필요하다면 Gemma 3이나 InternVL 3.5의 작은 버전이 적합합니다.\\n*   **특정 작업**: OCR 및 문서 분석에는 DeepSeek-OCR, 에이전트 기능에는 GLM-4.5V나 Qwen3-VL이 유리할 수 있습니다.\\n*   **언어 지원**: 다국어 지원이 중요하다면 Gemma 3이나 Qwen3-VL을 검토하세요.\\n\\n각 모델의 문서와 커뮤니티를 통해 자세한 정보를 확인하고, 실제 사용 목적에 가장 적합한 모델을 선택하는 것이 중요합니다.'}"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True\n",
        ")\n",
        "\n",
        "agent_executor.invoke({'input':\"Open Source Multimodal LLM Model 추천해줘\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "53e00b3e",
      "metadata": {
        "id": "53e00b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: 먼저 레오나르도 디카프리오의 출생년도를 찾아야 합니다. 이를 위해 `tavily_search` 도구를 사용하겠습니다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"tavily_search\",\n",
            "  \"action_input\": {\n",
            "    \"query\": \"레오나르도 디카프리오 출생년도\"\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[36;1m\u001b[1;3mPOSSIBLE ANSWER: 레오나르도 디카프리오는 1974년 11월 11일에 태어났습니다. 그는 미국 출신의 배우입니다. 그의 본명은 레오나르도 빌헬름 디카프리오입니다.\n",
            "\n",
            "TITLE: 레오나르도 디카프리오 - 나무위키\n",
            "URL:https://namu.wiki/w/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84%20%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4\n",
            "Content:본명. Leonardo Wilhelm DiCaprio 레오나르도 빌헬름 디카프리오[1] ; 출생. 1974년 11월 11일 (50세) ; 출생 · 캘리포니아 주 로스앤젤레스 할리우드 ; 국적.\n",
            "---\n",
            "TITLE: 레오나르도 디카프리오 - Gaminme - 티스토리\n",
            "URL:https://gaminmint.tistory.com/entry/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84-%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4\n",
            "Content:# [Gaminme](https://gaminmint.tistory.com/)\n",
            "\n",
            "![블로그 이미지](https://tistory1.daumcdn.net/tistory/561722/attach/0d6a1cf23d6749c9af430acb8d4fc533)\n",
            "\n",
            "# 레오나르도 디카프리오\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/bqculS/btqNQbfI4Aw/AAAAAAAAAAAAAAAAAAAAAK0CCdFjlf7IJsm14PXHnNcjh45G2_Mk2gqobMebLbrR/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=Oh1Ss7vQDVp2NPsHLsq%2BNNvilW8%3D)\n",
            "![](https://blog.kakaocdn.net/dna/wheRx/btqNOJX8xZJ/AAAAAAAAAAAAAAAAAAAAAAIFjwQB5tNis8kpGfSWSj9MU4adu1tkosYlkQrOQefO/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=HGbGUbeSq8XtGanUKMC1qEYXtr4%3D)\n",
            "![](https://blog.kakaocdn.net/dna/QX15u/btqNMNzSTpj/AAAAAAAAAAAAAAAAAAAAAHlqxCXnvsMjuuOgAs0oWIA5kh1fuRBdab1JbS7Kv-cq/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=CRuXWFNdWQKg89tl1lP1Y8BlDHw%3D)\n",
            "![](https://blog.kakaocdn.net/dna/bxjgod/btqNOJwYpX1/AAAAAAAAAAAAAAAAAAAAADQ-nSgeOYFcSjXRphtbNizz2cv2rh2V4lIoTIaP4Bzq/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=qfKQgj57ZUZEHHlCeuBDHr8WvGc%3D)\n",
            "![](https://blog.kakaocdn.net/dna/Uc6cq/btqNQxiuf5Q/AAAAAAAAAAAAAAAAAAAAAJriCgif0ZyEXk2l-y5q1ZNRxQWIXaEQG3pTD6-oZ8Zo/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=zSwktZq7k3WdNxS4jkMLOp4h2pM%3D)\n",
            "![](https://blog.kakaocdn.net/dna/Wz09r/btqNMNfyieh/AAAAAAAAAAAAAAAAAAAAACMvVhfK_gDhaKD7lK66UoyfofotPsVv4IilqgfZEIEL/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=uF7mALPaZFAj38WYPlhCQc1ub9Q%3D)\n",
            "![](https://blog.kakaocdn.net/dna/Ca3cA/btqNNil5Dtj/AAAAAAAAAAAAAAAAAAAAAAjwTa0F1cMbBg8wyTekI_WH-od0EC55YUfIzGRtlgI9/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=eVXrfbnpwwjmOzWl%2BoXh490BNDw%3D)\n",
            "![](https://blog.kakaocdn.net/dna/dtx62t/btqNSyViBDD/AAAAAAAAAAAAAAAAAAAAAKz--va7i2pclkZQTiDpvEtO7lp2e_piokGjjxEqNWyT/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=svDwv%2Fw2lPMWnoOJ21%2BR9c%2F6VrQ%3D)\n",
            "![](https://blog.kakaocdn.net/dna/shXoD/btqNOKpaOkj/AAAAAAAAAAAAAAAAAAAAAIKmvua7WxVvl8i5IRafwRCnzE8SalVn7LzNtM-UToz2/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=Nq%2FP30EEL15W5c%2B%2FRyLSpE5Ds7c%3D)\n",
            "![](https://blog.kakaocdn.net/dna/dh0Sjl/btqNQbGMTiQ/AAAAAAAAAAAAAAAAAAAAAOd42zMhcy4Lor-nyAcaY1qqP0-5ctzzb1FNCKRUyKJk/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=xoWBFOW%2FJtwMjrO1f3%2FQJPhBdrk%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/bqculS/btqNQbfI4Aw/AAAAAAAAAAAAAAAAAAAAAK0CCdFjlf7IJsm14PXHnNcjh45G2_Mk2gqobMebLbrR/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=Oh1Ss7vQDVp2NPsHLsq%2BNNvilW8%3D)\n",
            "![](https://blog.kakaocdn.net/dna/wheRx/btqNOJX8xZJ/AAAAAAAAAAAAAAAAAAAAAAIFjwQB5tNis8kpGfSWSj9MU4adu1tkosYlkQrOQefO/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=HGbGUbeSq8XtGanUKMC1qEYXtr4%3D)\n",
            "![](https://blog.kakaocdn.net/dna/QX15u/btqNMNzSTpj/AAAAAAAAAAAAAAAAAAAAAHlqxCXnvsMjuuOgAs0oWIA5kh1fuRBdab1JbS7Kv-cq/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=CRuXWFNdWQKg89tl1lP1Y8BlDHw%3D)\n",
            "![](https://blog.kakaocdn.net/dna/bxjgod/btqNOJwYpX1/AAAAAAAAAAAAAAAAAAAAADQ-nSgeOYFcSjXRphtbNizz2cv2rh2V4lIoTIaP4Bzq/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=qfKQgj57ZUZEHHlCeuBDHr8WvGc%3D)\n",
            "![](https://blog.kakaocdn.net/dna/Uc6cq/btqNQxiuf5Q/AAAAAAAAAAAAAAAAAAAAAJriCgif0ZyEXk2l-y5q1ZNRxQWIXaEQG3pTD6-oZ8Zo/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=zSwktZq7k3WdNxS4jkMLOp4h2pM%3D)\n",
            "![](https://blog.kakaocdn.net/dna/Wz09r/btqNMNfyieh/AAAAAAAAAAAAAAAAAAAAACMvVhfK_gDhaKD7lK66UoyfofotPsVv4IilqgfZEIEL/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=uF7mALPaZFAj38WYPlhCQc1ub9Q%3D)\n",
            "![](https://blog.kakaocdn.net/dna/Ca3cA/btqNNil5Dtj/AAAAAAAAAAAAAAAAAAAAAAjwTa0F1cMbBg8wyTekI_WH-od0EC55YUfIzGRtlgI9/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=eVXrfbnpwwjmOzWl%2BoXh490BNDw%3D)\n",
            "![](https://blog.kakaocdn.net/dna/dtx62t/btqNSyViBDD/AAAAAAAAAAAAAAAAAAAAAKz--va7i2pclkZQTiDpvEtO7lp2e_piokGjjxEqNWyT/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=svDwv%2Fw2lPMWnoOJ21%2BR9c%2F6VrQ%3D)\n",
            "![](https://blog.kakaocdn.net/dna/shXoD/btqNOKpaOkj/AAAAAAAAAAAAAAAAAAAAAIKmvua7WxVvl8i5IRafwRCnzE8SalVn7LzNtM-UToz2/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=Nq%2FP30EEL15W5c%2B%2FRyLSpE5Ds7c%3D)\n",
            "![](https://blog.kakaocdn.net/dna/dh0Sjl/btqNQbGMTiQ/AAAAAAAAAAAAAAAAAAAAAOd42zMhcy4Lor-nyAcaY1qqP0-5ctzzb1FNCKRUyKJk/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=xoWBFOW%2FJtwMjrO1f3%2FQJPhBdrk%3D)\n",
            "\n",
            "**레오나르도 디카프리오** (Leonardo DiCaprio) 영화배우\n",
            "\n",
            "출생1974년 11월 11일, 미국\n",
            "\n",
            "신체183cm\n",
            "\n",
            "학력존마샬고등학교\n",
            "\n",
            "데뷔1991년 영화 '크리터스 3'\n",
            "\n",
            "수상 2016년 제25회 MTV영화제 남우주연상  \n",
            "      2016년 제88회 아카데미 시상식 남우주연상\n",
            "\n",
            "사이트 공식홈페이지, 인스타그램, 트위터, 페이스북\n",
            "\n",
            "#### '[People](/category/People) > [Entertainer](/category/People/Entertainer)' 카테고리의 다른 글\n",
            "\n",
            "|  |  |\n",
            "| --- | --- |\n",
            "| [공유(공지철)](/entry/%EA%B3%B5%EC%9C%A0%EA%B3%B5%EC%A7%80%EC%B2%A0)  (8) | 2020.12.06 |\n",
            "| [올리비아 허시](/entry/%EC%98%AC%EB%A6%AC%EB%B9%84%EC%95%84-%ED%97%88%EC%8B%9C)  (0) | 2020.11.19 |\n",
            "| [권정열(10CM 십센치)](/entry/%EA%B6%8C%EC%A0%95%EC%97%B410CM-%EC%8B%AD%EC%84%BC%EC%B9%98)  (0) | 2020.11.11 |\n",
            "| [미켈레 모로네](/entry/%EB%AF%B8%EC%BC%88%EB%A0%88-%EB%AA%A8%EB%A1%9C%EB%84%A4)  (0) | 2020.11.05 |\n",
            "| [채수빈](/entry/%EC%B1%84%EC%88%98%EB%B9%88)  (1) | 2015.08.18 |\n",
            "\n",
            "## 태그\n",
            "\n",
            "## 관련글\n",
            "\n",
            "![](//i1.daumcdn.net/thumb/C176x120.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FuevZt%2FbtqPnaexoOX%2FAAAAAAAAAAAAAAAAAAAAAMQ9w8MTg_figQJgKQUFu1iZpYrRF5YAy1yfYZigk__9%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DrLu0n%252BpadwVTmnvn51lQ3tApWXM%253D)\n",
            "![](//i1.daumcdn.net/thumb/C176x120.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FluXTA%2FbtqNSz7J5UW%2FAAAAAAAAAAAAAAAAAAAAADyw20LRdvVIwXe45lzCzoPxgcC84yevr2j1OyCPVLt_%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3Ddtt3xYhtc7uvFiQa54s9uKm1sw4%253D)\n",
            "![](//i1.daumcdn.net/thumb/C176x120.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FOvxgW%2FbtqNgsuUVlI%2FAAAAAAAAAAAAAAAAAAAAAM1UKSK2rnAsZFCr6YEB2N5M0AdRvdWntSnDvMe68xSG%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3Dbzt3%252FDqSBiiqTIjsa1E2iQ7hD64%253D)\n",
            "![](//i1.daumcdn.net/thumb/C176x120.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FlAKYA%2FbtqMCgpFBT0%2FAAAAAAAAAAAAAAAAAAAAANTCRB4yevDq_a-8_2tjWY4I6vSPKMqgN4ufA22gRMjo%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DRqn%252FcyszG4g188It0lv9d5Jy2Gc%253D)\n",
            "\n",
            "## 전체 방문자\n",
            "\n",
            "265,651\n",
            "\n",
            "Today : 4\n",
            "\n",
            "Yesterday : 10\n",
            "\n",
            "## 최근글\n",
            "\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fc6AoZp%2FbtqXXVVx0bP%2FAAAAAAAAAAAAAAAAAAAAABSql72PRk10gDxRVbVgLHMVzwM6l7OglWmqhd54_V4n%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DOgvC5Ke4Uwysfl0RVhItdAPY%252Fc0%253D)\n",
            "타트체리 맛집☞ 타트체리 콜라겐 1000 내돈내산⋯\n",
            "2021.02.20\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FKSK5t%2FbtqWWsy8eHc%2FAAAAAAAAAAAAAAAAAAAAAPS1r2F-r9u9VxWT3QXzkRGCarb3v6U9H-FjtrzZEYfv%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DKdWik76nJQAwSjzNcr5xNlv%252BCzo%253D)\n",
            "클럽하우스 어플, 초대장이 있어야만 가능한 인싸⋯\n",
            "2021.02.11\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F257FE24C5534F09F1E)\n",
            "대전 충대/궁동 디저트☞ 크라운 크레페, 추억 속⋯\n",
            "2021.02.10\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fc3U3vN%2FbtqWBzyaYC1%2FAAAAAAAAAAAAAAAAAAAAAPmpb7bav7xfdyyU3lndiktEDcKwcGy6fOqaVxnovR4a%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DzMFQgXg6bi3o44qGIcIo7qHjB9w%253D)\n",
            "아이스크림 맛집☞베스킨라빈스31 아이스크림 케이크⋯\n",
            "2021.02.10\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FXYyJ4%2FbtqWc9NTqfK%2FAAAAAAAAAAAAAAAAAAAAABWuGM4HV-J28_CDpK3EmZYtB7Qm9oCrax6-dPhzqRcR%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DlqiwuI0JmH6hoEHEthTDp0ndRzE%253D)\n",
            "\n",
            "## 인기글\n",
            "\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F236E1738560CF58A27)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FOqu3S%2FbtqUwy9OeDM%2FAAAAAAAAAAAAAAAAAAAAALqvJ79g5puidvwXFG_EXVhzq8eE78Bm5cN1P5WLWiKH%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DrzOXckoB8t6ea2PzOasxyn6LMTs%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FsItBq%2FbtqNHp7i9Do%2FAAAAAAAAAAAAAAAAAAAAAC2kSdn-r7et_2Q5_RI9Id0KIbr2TTOn4aC3Ed_5acWT%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DWM5gm5UJ8KNly5YnoKcbPBtEpCk%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F257C514853D71F8332)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fb237dE%2FbtqRL4bLEu4%2FAAAAAAAAAAAAAAAAAAAAAGnViIAa-UYsHQ1eI-t1OiO1zNneoAiSGxE5zzUYxB_n%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3Dc7nQ%252FrjReWnVGm7PUG%252Fv%252FcNdcMQ%253D)\n",
            "\n",
            "## 최근댓글\n",
            "\n",
            "## 태그\n",
            "\n",
            "Copyright 2020. Gaminmint all rights reserved.\n",
            "\n",
            "## 티스토리툴바\n",
            "---\n",
            "TITLE: 레오나르도 디카프리오 - DH 교육용 위키\n",
            "URL:https://dh.aks.ac.kr/Edu/wiki/index.php/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4\n",
            "Content:# 레오나르도 디카프리오\n",
            "\n",
            "| **인물 정보** | |\n",
            "| --- | --- |\n",
            "| [레오나르도 디카프리오.jpeg](/Edu/wiki/index.php/%ED%8C%8C%EC%9D%BC:%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4.jpeg) | |\n",
            "| **이름** | Leonardo Dicaprio |\n",
            "| **출생** | 1974년 11월 11일 |\n",
            "| **국적** | 미국 |\n",
            "| **직업** | 배우 |\n",
            "| **데뷔** | 크리터스 3 (1991) |\n",
            "\n",
            "![레오나르도 디카프리오.jpeg](/Edu/wiki/images/thumb/4/4b/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4.jpeg/300px-%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4.jpeg)\n",
            "\n",
            "## 목차\n",
            "\n",
            "## 기본정보\n",
            "\n",
            "### 인물정보\n",
            "\n",
            "### 다른 영화인과의 관계\n",
            "\n",
            "#### 감독\n",
            "\n",
            "#### 배우\n",
            "\n",
            "## 제작\n",
            "\n",
            "## 출연 영화\n",
            "\n",
            "## 배역\n",
            "\n",
            "## 수상내역\n",
            "\n",
            "### 베를린 국제 영화제\n",
            "\n",
            "### Mtv 무비어워즈\n",
            "\n",
            "### 미국 아카데미상\n",
            "\n",
            "### 영국 아카데미상\n",
            "\n",
            "### 골든 글로브상\n",
            "\n",
            "### 새틀 라이트상\n",
            "\n",
            "### 골든 래즈베리상\n",
            "\n",
            "## 관련항목\n",
            "\n",
            "| 노드 | 관계 | 노드 |\n",
            "| --- | --- | --- |\n",
            "| **레오나르도 디카프리오** | ~은 ~에 출연했다. | [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\") |\n",
            "\n",
            "## 기여\n",
            "\n",
            "**영화간 상관관계**\n",
            "\n",
            "**Class**\n",
            "\n",
            "| 클래스 | 노드 |\n",
            "| --- | --- |\n",
            "| **작품** | [믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\"), [빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\"), [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"), [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\"), [인터스텔라](/Edu/wiki/index.php/%EC%9D%B8%ED%84%B0%EC%8A%A4%ED%85%94%EB%9D%BC \"인터스텔라\"), [2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\"), [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\"), [007 네버다이](/Edu/wiki/index.php/007_%EB%84%A4%EB%B2%84%EB%8B%A4%EC%9D%B4 \"007 네버다이\"), [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\"), [007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\"), [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\"), [007 죽느냐 사느냐](/Edu/wiki/index.php/007_%EC%A3%BD%EB%8A%90%EB%83%90_%EC%82%AC%EB%8A%90%EB%83%90 \"007 죽느냐 사느냐\"), [400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\"), [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\"), [잠수종과 나비](/Edu/wiki/index.php/%EC%9E%A0%EC%88%98%EC%A2%85%EA%B3%BC_%EB%82%98%EB%B9%84 \"잠수종과 나비\"), [라라랜드2](/Edu/wiki/index.php/%EB%9D%BC%EB%9D%BC%EB%9E%9C%EB%93%9C2 \"라라랜드2\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\"), [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\"), [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\"), [언터쳐블](/Edu/wiki/index.php/%EC%96%B8%ED%84%B0%EC%B3%90%EB%B8%94 \"언터쳐블\"), [전함 포템킨](/Edu/wiki/index.php/%EC%A0%84%ED%95%A8_%ED%8F%AC%ED%85%9C%ED%82%A8 \"전함 포템킨\"), [스트레인저 댄 픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\"), [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\"), [500일의 썸머](/Edu/wiki/index.php/500%EC%9D%BC%EC%9D%98_%EC%8D%B8%EB%A8%B82 \"500일의 썸머2\"), [졸업](/Edu/wiki/index.php/%EC%A1%B8%EC%97%852 \"졸업2\"), [이유 없는 반항](/Edu/wiki/index.php/%EC%9D%B4%EC%9C%A0_%EC%97%86%EB%8A%94_%EB%B0%98%ED%95%AD \"이유 없는 반항\"), [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\"), [충격의 복도](/Edu/wiki/index.php/%EC%B6%A9%EA%B2%A9%EC%9D%98_%EB%B3%B5%EB%8F%84 \"충격의 복도\"), [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\"), [007 골드핑거](/Edu/wiki/index.php/007_%EA%B3%A8%EB%93%9C%ED%95%91%EA%B1%B0 \"007 골드핑거\"), [어바웃 타임](/Edu/wiki/index.php/%EC%96%B4%EB%B0%94%EC%9B%83_%ED%83%80%EC%9E%842 \"어바웃 타임2\"), [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\"), [로리타](/Edu/wiki/index.php/%EB%A1%9C%EB%A6%AC%ED%83%80 \"로리타\"), [프랑켄슈타인의 저주](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%BC%84%EC%8A%88%ED%83%80%EC%9D%B8%EC%9D%98_%EC%A0%80%EC%A3%BC \"프랑켄슈타인의 저주\"), [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\"), [세븐](/Edu/wiki/index.php/%EC%84%B8%EB%B8%90 \"세븐\"), [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\"), [하녀](/Edu/wiki/index.php/%ED%95%98%EB%85%80 \"하녀\"), [시계 태엽 오렌지](/Edu/wiki/index.php/%EC%8B%9C%EA%B3%84_%ED%83%9C%EC%97%BD_%EC%98%A4%EB%A0%8C%EC%A7%80 \"시계 태엽 오렌지\"), [의지의 승리](/Edu/wiki/index.php/%EC%9D%98%EC%A7%80%EC%9D%98_%EC%8A%B9%EB%A6%AC \"의지의 승리\") | [트로픽 썬더](/Edu/wiki/index.php/%ED%8A%B8%EB%A1%9C%ED%94%BD_%EC%8D%AC%EB%8D%94 \"트로픽 썬더\"), [사랑과 경멸](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EA%B3%BC_%EA%B2%BD%EB%A9%B8 \"사랑과 경멸\"), [휴고](/Edu/wiki/index.php/%ED%9C%B4%EA%B3%A0 \"휴고\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\"), [부기 나이트](/Edu/wiki/index.php/%EB%B6%80%EA%B8%B0_%EB%82%98%EC%9D%B4%ED%8A%B8 \"부기 나이트\"), [플레이어](/Edu/wiki/index.php/%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4 \"플레이어\"), [아티스트](/Edu/wiki/index.php/%EC%95%84%ED%8B%B0%EC%8A%A4%ED%8A%B8 \"아티스트\"), [에드 우드](/Edu/wiki/index.php/%EC%97%90%EB%93%9C_%EC%9A%B0%EB%93%9C \"에드 우드\"), [비카인드 리와인드](/Edu/wiki/index.php/%EB%B9%84%EC%B9%B4%EC%9D%B8%EB%93%9C_%EB%A6%AC%EC%99%80%EC%9D%B8%EB%93%9C \"비카인드 리와인드\"), [보우핑거](/Edu/wiki/index.php/%EB%B3%B4%EC%9A%B0%ED%95%91%EA%B1%B0 \"보우핑거\"), [어댑테이션](/Edu/wiki/index.php/%EC%96%B4%EB%8C%91%ED%85%8C%EC%9D%B4%EC%85%98 \"어댑테이션\"), [바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\"), [아메리카의 밤](/Edu/wiki/index.php/%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4%EC%9D%98_%EB%B0%A4 \"아메리카의 밤\"), [망각의 삶](/Edu/wiki/index.php/%EB%A7%9D%EA%B0%81%EC%9D%98_%EC%82%B6 \"망각의 삶\"), [선셋 대로](/Edu/wiki/index.php/%EC%84%A0%EC%85%8B_%EB%8C%80%EB%A1%9C \"선셋 대로\"), [8과 1/2](/Edu/wiki/index.php/8%EA%B3%BC_1/2 \"8과 1/2\") |\n",
            "| **배우** | [윌 페럴](/Edu/wiki/index.php/%EC%9C%8C_%ED%8E%98%EB%9F%B4 \"윌 페럴\"), [매기 질렌할](/Edu/wiki/index.php/%EB%A7%A4%EA%B8%B0_%EC%A7%88%EB%A0%8C%ED%95%A0 \"매기 질렌할\"), [엠마 톰슨](/Edu/wiki/index.php/%EC%97%A0%EB%A7%88_%ED%86%B0%EC%8A%A8 \"엠마 톰슨\"), [더스틴 호프만](/Edu/wiki/index.php/%EB%8D%94%EC%8A%A4%ED%8B%B4_%ED%98%B8%ED%94%84%EB%A7%8C \"더스틴 호프만\"), [그레이엄 채프만](/Edu/wiki/index.php/%EA%B7%B8%EB%A0%88%EC%9D%B4%EC%97%84_%EC%B1%84%ED%94%84%EB%A7%8C \"그레이엄 채프만\"), [존 클리즈](/Edu/wiki/index.php/%EC%A1%B4_%ED%81%B4%EB%A6%AC%EC%A6%88 \"존 클리즈\"), [윌리엄 홀든](/Edu/wiki/index.php/%EC%9C%8C%EB%A6%AC%EC%97%84_%ED%99%80%EB%93%A0 \"윌리엄 홀든\"), [글로리아 스완슨](/Edu/wiki/index.php/%EA%B8%80%EB%A1%9C%EB%A6%AC%EC%95%84_%EC%8A%A4%EC%99%84%EC%8A%A8 \"글로리아 스완슨\"), [조셉 고든 래빗](/Edu/wiki/index.php/%EC%A1%B0%EC%85%89_%EA%B3%A0%EB%93%A0_%EB%9E%98%EB%B9%97 \"조셉 고든 래빗\"), [주이 디샤넬](/Edu/wiki/index.php/%EC%A3%BC%EC%9D%B4_%EB%94%94%EC%83%A4%EB%84%AC \"주이 디샤넬\"), [앤 반크로프트](/Edu/wiki/index.php/%EC%95%A4_%EB%B0%98%ED%81%AC%EB%A1%9C%ED%94%84%ED%8A%B8 \"앤 반크로프트\"), [라이언 고슬링](/Edu/wiki/index.php/%EB%9D%BC%EC%9D%B4%EC%96%B8_%EA%B3%A0%EC%8A%AC%EB%A7%81 \"라이언 고슬링\"), [엠마 스톤](/Edu/wiki/index.php/%EC%97%A0%EB%A7%88_%EC%8A%A4%ED%86%A4 \"엠마 스톤\"), [제임스 딘](/Edu/wiki/index.php/%EC%A0%9C%EC%9E%84%EC%8A%A4_%EB%94%98 \"제임스 딘\"), [마이클 피트](/Edu/wiki/index.php/%EB%A7%88%EC%9D%B4%ED%81%B4_%ED%94%BC%ED%8A%B8 \"마이클 피트\"), [에바 그린](/Edu/wiki/index.php/%EC%97%90%EB%B0%94_%EA%B7%B8%EB%A6%B0 \"에바 그린\"), [루이스 가렐](/Edu/wiki/index.php/%EB%A3%A8%EC%9D%B4%EC%8A%A4_%EA%B0%80%EB%A0%90 \"루이스 가렐\"), [콘스탄스 타워스](/Edu/wiki/index.php/%EC%BD%98%EC%8A%A4%ED%83%84%EC%8A%A4_%ED%83%80%EC%9B%8C%EC%8A%A4 \"콘스탄스 타워스\"), [피터 브렉](/Edu/wiki/index.php/%ED%94%BC%ED%84%B0_%EB%B8%8C%EB%A0%89 \"피터 브렉\"), **레오나르도 디카프리오**, [톰 행크스](/Edu/wiki/index.php/%ED%86%B0_%ED%96%89%ED%81%AC%EC%8A%A4 \"톰 행크스\"), [도널 글리슨](/Edu/wiki/index.php/%EB%8F%84%EB%84%90_%EA%B8%80%EB%A6%AC%EC%8A%A8 \"도널 글리슨\"), [레이첼 맥아담스](/Edu/wiki/index.php/%EB%A0%88%EC%9D%B4%EC%B2%BC_%EB%A7%A5%EC%95%84%EB%8B%B4%EC%8A%A4 \"레이첼 맥아담스\"), [베르나 블룸](/Edu/wiki/index.php/%EB%B2%A0%EB%A5%B4%EB%82%98_%EB%B8%94%EB%A3%B8 \"베르나 블룸\"), [제레미 아이언스](/Edu/wiki/index.php/%EC%A0%9C%EB%A0%88%EB%AF%B8_%EC%95%84%EC%9D%B4%EC%96%B8%EC%8A%A4 \"제레미 아이언스\"), [도미니크 스웨인](/Edu/wiki/index.php/%EB%8F%84%EB%AF%B8%EB%8B%88%ED%81%AC_%EC%8A%A4%EC%9B%A8%EC%9D%B8 \"도미니크 스웨인\"), [피터 커싱](/Edu/wiki/index.php/%ED%94%BC%ED%84%B0_%EC%BB%A4%EC%8B%B1 \"피터 커싱\"), [하젤 코트](/Edu/wiki/index.php/%ED%95%98%EC%A0%A4_%EC%BD%94%ED%8A%B8 \"하젤 코트\"), [애쉬튼 커쳐](/Edu/wiki/index.php/%EC%95%A0%EC%89%AC%ED%8A%BC_%EC%BB%A4%EC%B3%90 \"애쉬튼 커쳐\"), [에이미 스마트](/Edu/wiki/index.php/%EC%97%90%EC%9D%B4%EB%AF%B8_%EC%8A%A4%EB%A7%88%ED%8A%B8 \"에이미 스마트\"),[브래드 피트](/Edu/wiki/index.php/%EB%B8%8C%EB%9E%98%EB%93%9C_%ED%94%BC%ED%8A%B8 \"브래드 피트\"), [모건 프리먼](/Edu/wiki/index.php/%EB%AA%A8%EA%B1%B4_%ED%94%84%EB%A6%AC%EB%A8%BC \"모건 프리먼\"), [김강우](/Edu/wiki/index.php/%EA%B9%80%EA%B0%95%EC%9A%B0 \"김강우\"), [백윤식](/Edu/wiki/index.php/%EB%B0%B1%EC%9C%A4%EC%8B%9D \"백윤식\"), [윤여정](/Edu/wiki/index.php/%EC%9C%A4%EC%97%AC%EC%A0%95 \"윤여정\"), [김효진](/Edu/wiki/index.php/%EA%B9%80%ED%9A%A8%EC%A7%84 \"김효진\"), [전도연](/Edu/wiki/index.php/%EC%A0%84%EB%8F%84%EC%97%B0 \"전도연\"), [말콤 맥도웰](/Edu/wiki/index.php/%EB%A7%90%EC%BD%A4_%EB%A7%A5%EB%8F%84%EC%9B%B0 \"말콤 맥도웰\"), [패드릭 마지](/Edu/wiki/index.php/%ED%8C%A8%EB%93%9C%EB%A6%AD_%EB%A7%88%EC%A7%80 \"패드릭 마지\"), [아돌프 히틀러](/Edu/wiki/index.php/%EC%95%84%EB%8F%8C%ED%94%84_%ED%9E%88%ED%8B%80%EB%9F%AC \"아돌프 히틀러\"), [벤 스틸러](/Edu/wiki/index.php/%EB%B2%A4_%EC%8A%A4%ED%8B%B8%EB%9F%AC \"벤 스틸러\"), [로버트 다우니 주니어](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EB%8B%A4%EC%9A%B0%EB%8B%88_%EC%A3%BC%EB%8B%88%EC%96%B4 \"로버트 다우니 주니어\"), [잭 블랙](/Edu/wiki/index.php/%EC%9E%AD_%EB%B8%94%EB%9E%99 \"잭 블랙\"), [브리지트 바르도](/Edu/wiki/index.php/%EB%B8%8C%EB%A6%AC%EC%A7%80%ED%8A%B8_%EB%B0%94%EB%A5%B4%EB%8F%84 \"브리지트 바르도\"), [미셸 피콜리](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%ED%94%BC%EC%BD%9C%EB%A6%AC \"미셸 피콜리\"), [아사 버터필드](/Edu/wiki/index.php/%EC%95%84%EC%82%AC_%EB%B2%84%ED%84%B0%ED%95%84%EB%93%9C \"아사 버터필드\"), [클로이 그레이스 모레츠](/Edu/wiki/index.php/%ED%81%B4%EB%A1%9C%EC%9D%B4_%EA%B7%B8%EB%A0%88%EC%9D%B4%EC%8A%A4_%EB%AA%A8%EB%A0%88%EC%B8%A0 \"클로이 그레이스 모레츠\"), [벤 킹슬리](/Edu/wiki/index.php/%EB%B2%A4_%ED%82%B9%EC%8A%AC%EB%A6%AC \"벤 킹슬리\"), [진 켈리](/Edu/wiki/index.php/%EC%A7%84_%EC%BC%88%EB%A6%AC \"진 켈리\"), [마크 월버그](/Edu/wiki/index.php/%EB%A7%88%ED%81%AC_%EC%9B%94%EB%B2%84%EA%B7%B8 \"마크 월버그\"), [줄리안 무어](/Edu/wiki/index.php/%EC%A4%84%EB%A6%AC%EC%95%88_%EB%AC%B4%EC%96%B4 \"줄리안 무어\"), [버트 레이놀즈](/Edu/wiki/index.php/%EB%B2%84%ED%8A%B8_%EB%A0%88%EC%9D%B4%EB%86%80%EC%A6%88 \"버트 레이놀즈\"), [팀 로빈스](/Edu/wiki/index.php/%ED%8C%80_%EB%A1%9C%EB%B9%88%EC%8A%A4 \"팀 로빈스\"), [장 뒤자르댕](/Edu/wiki/index.php/%EC%9E%A5_%EB%92%A4%EC%9E%90%EB%A5%B4%EB%8C%95 \"장 뒤자르댕\"), [베레니스 베조](/Edu/wiki/index.php/%EB%B2%A0%EB%A0%88%EB%8B%88%EC%8A%A4_%EB%B2%A0%EC%A1%B0 \"베레니스 베조\"), [조니 뎁](/Edu/wiki/index.php/%EC%A1%B0%EB%8B%88_%EB%8E%81 \"조니 뎁\"), [모스 데프](/Edu/wiki/index.php/%EB%AA%A8%EC%8A%A4_%EB%8D%B0%ED%94%84 \"모스 데프\"), [에디 머피](/Edu/wiki/index.php/%EC%97%90%EB%94%94_%EB%A8%B8%ED%94%BC \"에디 머피\"), [스티브 마틴](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%8C_%EB%A7%88%ED%8B%B4 \"스티브 마틴\"), [니콜라스 케이지](/Edu/wiki/index.php/%EB%8B%88%EC%BD%9C%EB%9D%BC%EC%8A%A4_%EC%BC%80%EC%9D%B4%EC%A7%80 \"니콜라스 케이지\"), [메릴 스트립](/Edu/wiki/index.php/%EB%A9%94%EB%A6%B4_%EC%8A%A4%ED%8A%B8%EB%A6%BD \"메릴 스트립\"), [존 굿맨](/Edu/wiki/index.php/%EC%A1%B4_%EA%B5%BF%EB%A7%A8 \"존 굿맨\"), [존 터투로](/Edu/wiki/index.php/%EC%A1%B4_%ED%84%B0%ED%88%AC%EB%A1%9C \"존 터투로\"), [마르첼로 마스트로얀니](/Edu/wiki/index.php/%EB%A7%88%EB%A5%B4%EC%B2%BC%EB%A1%9C_%EB%A7%88%EC%8A%A4%ED%8A%B8%EB%A1%9C%EC%96%80%EB%8B%88 \"마르첼로 마스트로얀니\"), [클라우디아 카르디날레](/Edu/wiki/index.php/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%94%94%EC%95%84_%EC%B9%B4%EB%A5%B4%EB%94%94%EB%82%A0%EB%A0%88 \"클라우디아 카르디날레\"), [숀 코너리](/Edu/wiki/index.php/%EC%88%80_%EC%BD%94%EB%84%88%EB%A6%AC \"숀 코너리\"), [피어스 브로스넌](/Edu/wiki/index.php/%ED%94%BC%EC%96%B4%EC%8A%A4_%EB%B8%8C%EB%A1%9C%EC%8A%A4%EB%84%8C \"피어스 브로스넌\"), [도널드 오코너](/Edu/wiki/index.php/%EB%8F%84%EB%84%90%EB%93%9C_%EC%98%A4%EC%BD%94%EB%84%88 \"도널드 오코너\"), [데비 레이놀즈](/Edu/wiki/index.php/%EB%8D%B0%EB%B9%84_%EB%A0%88%EC%9D%B4%EB%86%80%EC%A6%88 \"데비 레이놀즈\"), [그레타 스카치](/Edu/wiki/index.php/%EA%B7%B8%EB%A0%88%ED%83%80_%EC%8A%A4%EC%B9%B4%EC%B9%98 \"그레타 스카치\"), [크리스 쿠퍼](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%BF%A0%ED%8D%BC \"크리스 쿠퍼\"), [주디 데이비스](/Edu/wiki/index.php/%EC%A3%BC%EB%94%94_%EB%8D%B0%EC%9D%B4%EB%B9%84%EC%8A%A4 \"주디 데이비스\"), [마이클 러너](/Edu/wiki/index.php/%EB%A7%88%EC%9D%B4%ED%81%B4_%EB%9F%AC%EB%84%88 \"마이클 러너\"), [재클린 비솃](/Edu/wiki/index.php/%EC%9E%AC%ED%81%B4%EB%A6%B0_%EB%B9%84%EC%86%83 \"재클린 비솃\"), [장-피에르 오몽](/Edu/wiki/index.php/%EC%9E%A5-%ED%94%BC%EC%97%90%EB%A5%B4_%EC%98%A4%EB%AA%BD \"장-피에르 오몽\"), [스티브 부세미](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%8C_%EB%B6%80%EC%84%B8%EB%AF%B8 \"스티브 부세미\"), [캐서린 키너](/Edu/wiki/index.php/%EC%BA%90%EC%84%9C%EB%A6%B0_%ED%82%A4%EB%84%88 \"캐서린 키너\"), [대니 분](/Edu/wiki/index.php/%EB%8C%80%EB%8B%88_%EB%B6%84 \"대니 분\"), [오마 사이](/Edu/wiki/index.php/%EC%98%A4%EB%A7%88_%EC%82%AC%EC%9D%B4 \"오마 사이\"), [험프리 보가트](/Edu/wiki/index.php/%ED%97%98%ED%94%84%EB%A6%AC_%EB%B3%B4%EA%B0%80%ED%8A%B8 \"험프리 보가트\"), [로렌 바콜](/Edu/wiki/index.php/%EB%A1%9C%EB%A0%8C_%EB%B0%94%EC%BD%9C \"로렌 바콜\"), [크리스 에반스](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%97%90%EB%B0%98%EC%8A%A4 \"크리스 에반스\"), [스칼렛 요한슨](/Edu/wiki/index.php/%EC%8A%A4%EC%B9%BC%EB%A0%9B_%EC%9A%94%ED%95%9C%EC%8A%A8 \"스칼렛 요한슨\"), [존 트라볼타](/Edu/wiki/index.php/%EC%A1%B4_%ED%8A%B8%EB%9D%BC%EB%B3%BC%ED%83%80 \"존 트라볼타\"), [사무엘 L.잭슨](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_L.%EC%9E%AD%EC%8A%A8 \"사무엘 L.잭슨\"), [매튜 맥커너히](/Edu/wiki/index.php/%EB%A7%A4%ED%8A%9C_%EB%A7%A5%EC%BB%A4%EB%84%88%ED%9E%88 \"매튜 맥커너히\"), [앤 해서웨이](/Edu/wiki/index.php/%EC%95%A4_%ED%95%B4%EC%84%9C%EC%9B%A8%EC%9D%B4 \"앤 해서웨이\"), [케어 둘리](/Edu/wiki/index.php/%EC%BC%80%EC%96%B4_%EB%91%98%EB%A6%AC \"케어 둘리\"), [게리 록우드](/Edu/wiki/index.php/%EA%B2%8C%EB%A6%AC_%EB%A1%9D%EC%9A%B0%EB%93%9C \"게리 록우드\"), [콜린 퍼스](/Edu/wiki/index.php/%EC%BD%9C%EB%A6%B0_%ED%8D%BC%EC%8A%A4 \"콜린 퍼스\"),[태런 애저튼](/Edu/wiki/index.php/%ED%83%9C%EB%9F%B0_%EC%95%A0%EC%A0%80%ED%8A%BC \"태런 애저튼\"), [로저 무어](/Edu/wiki/index.php/%EB%A1%9C%EC%A0%80_%EB%AC%B4%EC%96%B4 \"로저 무어\"), [다니엘 크레이그](/Edu/wiki/index.php/%EB%8B%A4%EB%8B%88%EC%97%98_%ED%81%AC%EB%A0%88%EC%9D%B4%EA%B7%B8 \"다니엘 크레이그\"), [장 피에르 레오](/Edu/wiki/index.php/%EC%9E%A5_%ED%94%BC%EC%97%90%EB%A5%B4_%EB%A0%88%EC%98%A4 \"장 피에르 레오\"), [장 더스](/Edu/wiki/index.php/%EC%9E%A5_%EB%8D%94%EC%8A%A4 \"장 더스\"), [마티유 아말릭](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B0%EC%9C%A0_%EC%95%84%EB%A7%90%EB%A6%AD \"마티유 아말릭\"), [크리스 프랫](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%ED%94%84%EB%9E%AB \"크리스 프랫\"), [샘 닐](/Edu/wiki/index.php/%EC%83%98_%EB%8B%90 \"샘 닐\"), [케빈 코스트너](/Edu/wiki/index.php/%EC%BC%80%EB%B9%88_%EC%BD%94%EC%8A%A4%ED%8A%B8%EB%84%88 \"케빈 코스트너\"), [이반 보브로프](/Edu/wiki/index.php/%EC%9D%B4%EB%B0%98_%EB%B3%B4%EB%B8%8C%EB%A1%9C%ED%94%84 \"이반 보브로프\"), [레아 세이두](/Edu/wiki/index.php/%EB%A0%88%EC%95%84_%EC%84%B8%EC%9D%B4%EB%91%90 \"레아 세이두\"), [제인 시모어](/Edu/wiki/index.php/%EC%A0%9C%EC%9D%B8_%EC%8B%9C%EB%AA%A8%EC%96%B4 \"제인 시모어\"), [클레어 모리어](/Edu/wiki/index.php/%ED%81%B4%EB%A0%88%EC%96%B4_%EB%AA%A8%EB%A6%AC%EC%96%B4 \"클레어 모리어\"), [레옹 라리베](/Edu/wiki/index.php/%EB%A0%88%EC%98%B9_%EB%9D%BC%EB%A6%AC%EB%B2%A0 \"레옹 라리베\"), [엠마누엘 자이그너](/Edu/wiki/index.php/%EC%97%A0%EB%A7%88%EB%88%84%EC%97%98_%EC%9E%90%EC%9D%B4%EA%B7%B8%EB%84%88 \"엠마누엘 자이그너\"), [로라 던](/Edu/wiki/index.php/%EB%A1%9C%EB%9D%BC_%EB%8D%98 \"로라 던\"),[브라이스 달라스 하워드](/Edu/wiki/index.php/%EB%B8%8C%EB%9D%BC%EC%9D%B4%EC%8A%A4_%EB%8B%AC%EB%9D%BC%EC%8A%A4_%ED%95%98%EC%9B%8C%EB%93%9C \"브라이스 달라스 하워드\"), [클린트 이스트우드](/Edu/wiki/index.php/%ED%81%B4%EB%A6%B0%ED%8A%B8_%EC%9D%B4%EC%8A%A4%ED%8A%B8%EC%9A%B0%EB%93%9C \"클린트 이스트우드\") |\n",
            "| **유형** | [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\") |\n",
            "| **감독** | [마크 포스터](/Edu/wiki/index.php/%EB%A7%88%ED%81%AC_%ED%8F%AC%EC%8A%A4%ED%84%B0 \"마크 포스터\"), [테리 존스](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EC%A1%B4%EC%8A%A4 \"테리 존스\"), [테리 길리엄](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EA%B8%B8%EB%A6%AC%EC%97%84 \"테리 길리엄\"), [마크 웹](/Edu/wiki/index.php/%EB%A7%88%ED%81%AC_%EC%9B%B9 \"마크 웹\"), [마이크 니콜스](/Edu/wiki/index.php/%EB%A7%88%EC%9D%B4%ED%81%AC_%EB%8B%88%EC%BD%9C%EC%8A%A4 \"마이크 니콜스\"), [다미엔 차젤레](/Edu/wiki/index.php/%EB%8B%A4%EB%AF%B8%EC%97%94_%EC%B0%A8%EC%A0%A4%EB%A0%88 \"다미엔 차젤레\"), [니콜라스 레이](/Edu/wiki/index.php/%EB%8B%88%EC%BD%9C%EB%9D%BC%EC%8A%A4_%EB%A0%88%EC%9D%B4 \"니콜라스 레이\"), [베르나르도 베르톨루치](/Edu/wiki/index.php/%EB%B2%A0%EB%A5%B4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%B2%A0%EB%A5%B4%ED%86%A8%EB%A3%A8%EC%B9%98 \"베르나르도 베르톨루치\"), [사무엘 풀러](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_%ED%92%80%EB%9F%AC \"사무엘 풀러\"), [빌리 와인더](/Edu/wiki/index.php/%EB%B9%8C%EB%A6%AC_%EC%99%80%EC%9D%B8%EB%8D%94 \"빌리 와인더\"), [스티븐 스필버그](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%90_%EC%8A%A4%ED%95%84%EB%B2%84%EA%B7%B8 \"스티븐 스필버그\"), [리차드 커티스](/Edu/wiki/index.php/%EB%A6%AC%EC%B0%A8%EB%93%9C_%EC%BB%A4%ED%8B%B0%EC%8A%A4 \"리차드 커티스\"), [클린트 이스트우드](/Edu/wiki/index.php/%ED%81%B4%EB%A6%B0%ED%8A%B8_%EC%9D%B4%EC%8A%A4%ED%8A%B8%EC%9A%B0%EB%93%9C \"클린트 이스트우드\"), [애드리안 라인](/Edu/wiki/index.php/%EC%95%A0%EB%93%9C%EB%A6%AC%EC%95%88_%EB%9D%BC%EC%9D%B8 \"애드리안 라인\"), [테런스 피셔](/Edu/wiki/index.php/%ED%85%8C%EB%9F%B0%EC%8A%A4_%ED%94%BC%EC%85%94 \"테런스 피셔\"), [에릭 브래스](/Edu/wiki/index.php/%EC%97%90%EB%A6%AD_%EB%B8%8C%EB%9E%98%EC%8A%A4 \"에릭 브래스\"), [J.마키에 그러버](/Edu/wiki/index.php/J.%EB%A7%88%ED%82%A4%EC%97%90_%EA%B7%B8%EB%9F%AC%EB%B2%84 \"J.마키에 그러버\"), [데이빗 핀처](/Edu/wiki/index.php/%EB%8D%B0%EC%9D%B4%EB%B9%97_%ED%95%80%EC%B2%98 \"데이빗 핀처\"), [임상수](/Edu/wiki/index.php/%EC%9E%84%EC%83%81%EC%88%98 \"임상수\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\"), [레니 리펜슈탈](/Edu/wiki/index.php/%EB%A0%88%EB%8B%88_%EB%A6%AC%ED%8E%9C%EC%8A%88%ED%83%88 \"레니 리펜슈탈\"), [벤 스틸러](/Edu/wiki/index.php/%EB%B2%A4_%EC%8A%A4%ED%8B%B8%EB%9F%AC \"벤 스틸러\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\"), [마틴 스콜세지](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B4_%EC%8A%A4%EC%BD%9C%EC%84%B8%EC%A7%80 \"마틴 스콜세지\"), [진 켈리](/Edu/wiki/index.php/%EC%A7%84_%EC%BC%88%EB%A6%AC \"진 켈리\"), [폴 토마스 앤더슨](/Edu/wiki/index.php/%ED%8F%B4_%ED%86%A0%EB%A7%88%EC%8A%A4_%EC%95%A4%EB%8D%94%EC%8A%A8 \"폴 토마스 앤더슨\"), [로버트 알트만](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EC%95%8C%ED%8A%B8%EB%A7%8C \"로버트 알트만\"), [미셸 아자나비슈스](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%EC%95%84%EC%9E%90%EB%82%98%EB%B9%84%EC%8A%88%EC%8A%A4 \"미셸 아자나비슈스\"), [팀 버튼](/Edu/wiki/index.php/%ED%8C%80_%EB%B2%84%ED%8A%BC \"팀 버튼\"), [미셸 공드리](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%EA%B3%B5%EB%93%9C%EB%A6%AC \"미셸 공드리\"), [프랭크 오즈](/Edu/wiki/index.php/%ED%94%84%EB%9E%AD%ED%81%AC_%EC%98%A4%EC%A6%88 \"프랭크 오즈\"), [스파이크 존즈](/Edu/wiki/index.php/%EC%8A%A4%ED%8C%8C%EC%9D%B4%ED%81%AC_%EC%A1%B4%EC%A6%88 \"스파이크 존즈\"), [조엘 코엔](/Edu/wiki/index.php/%EC%A1%B0%EC%97%98_%EC%BD%94%EC%97%94 \"조엘 코엔\"), [페데리코 펠리니](/Edu/wiki/index.php/%ED%8E%98%EB%8D%B0%EB%A6%AC%EC%BD%94_%ED%8E%A0%EB%A6%AC%EB%8B%88 \"페데리코 펠리니\"), [프랑수와 트뤼포](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%88%98%EC%99%80_%ED%8A%B8%EB%A4%BC%ED%8F%AC \"프랑수와 트뤼포\"), [제임스 웨스트비](/Edu/wiki/index.php/%EC%A0%9C%EC%9E%84%EC%8A%A4_%EC%9B%A8%EC%8A%A4%ED%8A%B8%EB%B9%84 \"제임스 웨스트비\"), [페드로 알모도바르](/Edu/wiki/index.php/%ED%8E%98%EB%93%9C%EB%A1%9C_%EC%95%8C%EB%AA%A8%EB%8F%84%EB%B0%94%EB%A5%B4 \"페드로 알모도바르\"), [에두아르도 산체스](/Edu/wiki/index.php/%EC%97%90%EB%91%90%EC%95%84%EB%A5%B4%EB%8F%84_%EC%82%B0%EC%B2%B4%EC%8A%A4 \"에두아르도 산체스\"), [다니엘 미릭](/Edu/wiki/index.php/%EB%8B%A4%EB%8B%88%EC%97%98_%EB%AF%B8%EB%A6%AD \"다니엘 미릭\"), [커비 딕](/Edu/wiki/index.php/%EC%BB%A4%EB%B9%84_%EB%94%95 \"커비 딕\"), [데이빗 린치](/Edu/wiki/index.php/%EB%8D%B0%EC%9D%B4%EB%B9%97_%EB%A6%B0%EC%B9%98 \"데이빗 린치\"), [E.엘리어스 머리지](/Edu/wiki/index.php/E.%EC%97%98%EB%A6%AC%EC%96%B4%EC%8A%A4_%EB%A8%B8%EB%A6%AC%EC%A7%80 \"E.엘리어스 머리지\"), [크리스 스미스](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%8A%A4%EB%AF%B8%EC%8A%A4 \"크리스 스미스\"), [우디 앨런](/Edu/wiki/index.php/%EC%9A%B0%EB%94%94_%EC%95%A8%EB%9F%B0 \"우디 앨런\"), [프레스턴 스터지스](/Edu/wiki/index.php/%ED%94%84%EB%A0%88%EC%8A%A4%ED%84%B4_%EC%8A%A4%ED%84%B0%EC%A7%80%EC%8A%A4 \"프레스턴 스터지스\"), [주세페 토르나토레](/Edu/wiki/index.php/%EC%A3%BC%EC%84%B8%ED%8E%98_%ED%86%A0%EB%A5%B4%EB%82%98%ED%86%A0%EB%A0%88 \"주세페 토르나토레\"), [스텐리 도넌](/Edu/wiki/index.php/%EC%8A%A4%ED%85%90%EB%A6%AC_%EB%8F%84%EB%84%8C \"스텐리 도넌\"), [톰 디칠로](/Edu/wiki/index.php/%ED%86%B0_%EB%94%94%EC%B9%A0%EB%A1%9C \"톰 디칠로\"), [장 피에르 주네](/Edu/wiki/index.php/%EC%9E%A5_%ED%94%BC%EC%97%90%EB%A5%B4_%EC%A3%BC%EB%84%A4 \"장 피에르 주네\"), [하워드 호크스](/Edu/wiki/index.php/%ED%95%98%EC%9B%8C%EB%93%9C_%ED%98%B8%ED%81%AC%EC%8A%A4 \"하워드 호크스\"), [조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\"), [안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\"), [쿠엔틴 타란티노](/Edu/wiki/index.php/%EC%BF%A0%EC%97%94%ED%8B%B4_%ED%83%80%EB%9E%80%ED%8B%B0%EB%85%B8 \"쿠엔틴 타란티노\"), [크리스토퍼 놀란](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%86%A0%ED%8D%BC_%EB%86%80%EB%9E%80 \"크리스토퍼 놀란\"), [매튜 본](/Edu/wiki/index.php/%EB%A7%A4%ED%8A%9C_%EB%B3%B8 \"매튜 본\"), [로저 스포티스우드](/Edu/wiki/index.php/%EB%A1%9C%EC%A0%80_%EC%8A%A4%ED%8F%AC%ED%8B%B0%EC%8A%A4%EC%9A%B0%EB%93%9C \"로저 스포티스우드\"), [루이스 길버트](/Edu/wiki/index.php/%EB%A3%A8%EC%9D%B4%EC%8A%A4_%EA%B8%B8%EB%B2%84%ED%8A%B8 \"루이스 길버트\"), [가이 해밀턴](/Edu/wiki/index.php/%EA%B0%80%EC%9D%B4_%ED%95%B4%EB%B0%80%ED%84%B4 \"가이 해밀턴\"), [샘 멘데스](/Edu/wiki/index.php/%EC%83%98_%EB%A9%98%EB%8D%B0%EC%8A%A4 \"샘 멘데스\"), [장 비고](/Edu/wiki/index.php/%EC%9E%A5_%EB%B9%84%EA%B3%A0 \"장 비고\"), [줄리안 슈나벨](/Edu/wiki/index.php/%EC%A4%84%EB%A6%AC%EC%95%88_%EC%8A%88%EB%82%98%EB%B2%A8 \"줄리안 슈나벨\"), [진 켈리](/Edu/wiki/index.php/%EC%A7%84_%EC%BC%88%EB%A6%AC \"진 켈리\"), [콜린 트레보로우](/Edu/wiki/index.php/%EC%BD%9C%EB%A6%B0_%ED%8A%B8%EB%A0%88%EB%B3%B4%EB%A1%9C%EC%9A%B0 \"콜린 트레보로우\"), [브라이언 드 팔마](/Edu/wiki/index.php/%EB%B8%8C%EB%9D%BC%EC%9D%B4%EC%96%B8_%EB%93%9C_%ED%8C%94%EB%A7%88 \"브라이언 드 팔마\"), [세르게이 에이젠슈타인](/Edu/wiki/index.php/%EC%84%B8%EB%A5%B4%EA%B2%8C%EC%9D%B4_%EC%97%90%EC%9D%B4%EC%A0%A0%EC%8A%88%ED%83%80%EC%9D%B8 \"세르게이 에이젠슈타인\") |\n",
            "| **대사** | [“Welcome to Jurassic Park”](/Edu/wiki/index.php/%E2%80%9CWelcome_to_Jurassic_Park%E2%80%9D \"“Welcome to Jurassic Park”\"), [\"The path of the righteous man: Ezekiel 25: 17\"](/Edu/wiki/index.php/%22The_path_of_the_righteous_man:_Ezekiel_25:_17%22 \"\\\"The path of the righteous man: Ezekiel 25: 17\\\"\"), [보드카 마티니 젓지 말고 흔들어서](/Edu/wiki/index.php/%EB%B3%B4%EB%93%9C%EC%B9%B4_%EB%A7%88%ED%8B%B0%EB%8B%88_%EC%A0%93%EC%A7%80_%EB%A7%90%EA%B3%A0_%ED%9D%94%EB%93%A4%EC%96%B4%EC%84%9C \"보드카 마티니 젓지 말고 흔들어서\"), [\"Bottoms Up\"](/Edu/wiki/index.php/%22Bottoms_Up%22 \"\\\"Bottoms Up\\\"\") |\n",
            "| **장르** | [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%882 \"드라마2\"), [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [SF](/Edu/wiki/index.php/SF \"SF\"), [갱스터](/Edu/wiki/index.php/%EA%B0%B1%EC%8A%A4%ED%84%B0 \"갱스터\"), [공포](/Edu/wiki/index.php/%EA%B3%B5%ED%8F%AC \"공포\"), [뮤지컬](/Edu/wiki/index.php/%EB%AE%A4%EC%A7%80%EC%BB%AC \"뮤지컬\"), [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [로맨틱 코미디](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%ED%8B%B1_%EC%BD%94%EB%AF%B8%EB%94%94 \"로맨틱 코미디\"), [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [멜로](/Edu/wiki/index.php/%EB%A9%9C%EB%A1%9C \"멜로\"), [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [서부](/Edu/wiki/index.php/%EC%84%9C%EB%B6%80 \"서부\"), [느와르](/Edu/wiki/index.php/%EB%8A%90%EC%99%80%EB%A5%B4 \"느와르\"), [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [미스터리](/Edu/wiki/index.php/%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%A6%AC \"미스터리\"), [전쟁](/Edu/wiki/index.php/%EC%A0%84%EC%9F%81 \"전쟁\"), [판타지](/Edu/wiki/index.php/%ED%8C%90%ED%83%80%EC%A7%80 \"판타지\"), [다큐멘터리](/Edu/wiki/index.php/%EB%8B%A4%ED%81%90%EB%A9%98%ED%84%B0%EB%A6%AC \"다큐멘터리\"), [모험](/Edu/wiki/index.php/%EB%AA%A8%ED%97%98 \"모험\") |\n",
            "| **개념** | [자기 반영성](/Edu/wiki/index.php/%EC%9E%90%EA%B8%B0_%EB%B0%98%EC%98%81%EC%84%B1 \"자기 반영성\"), [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [익스트림 롱 쇼트](/Edu/wiki/index.php/%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%A6%BC_%EB%A1%B1_%EC%87%BC%ED%8A%B8 \"익스트림 롱 쇼트\"), [롱 쇼트](/Edu/wiki/index.php/%EB%A1%B1_%EC%87%BC%ED%8A%B8 \"롱 쇼트\"), [미디엄 쇼트](/Edu/wiki/index.php/%EB%AF%B8%EB%94%94%EC%97%84_%EC%87%BC%ED%8A%B8 \"미디엄 쇼트\"), [클로즈업 쇼트](/Edu/wiki/index.php/%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"클로즈업 쇼트\"), [익스트림 클로즈업 쇼트](/Edu/wiki/index.php/%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%A6%BC_%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"익스트림 클로즈업 쇼트\"), [풀 쇼트](/Edu/wiki/index.php/%ED%92%80_%EC%87%BC%ED%8A%B8 \"풀 쇼트\"), [니 쇼트](/Edu/wiki/index.php/%EB%8B%88_%EC%87%BC%ED%8A%B8 \"니 쇼트\"), [웨이스트 쇼트](/Edu/wiki/index.php/%EC%9B%A8%EC%9D%B4%EC%8A%A4%ED%8A%B8_%EC%87%BC%ED%8A%B8 \"웨이스트 쇼트\"), [바스트 쇼트](/Edu/wiki/index.php/%EB%B0%94%EC%8A%A4%ED%8A%B8_%EC%87%BC%ED%8A%B8 \"바스트 쇼트\"), [클로즈업 쇼트](/Edu/wiki/index.php/%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"클로즈업 쇼트\"), [빅 클로즈업 쇼트](/Edu/wiki/index.php/%EB%B9%85_%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"빅 클로즈업 쇼트\"), [오버 더 숄더 쇼트](/Edu/wiki/index.php/%EC%98%A4%EB%B2%84_%EB%8D%94_%EC%88%84%EB%8D%94_%EC%87%BC%ED%8A%B8 \"오버 더 숄더 쇼트\"), [하이앵글](/Edu/wiki/index.php/%ED%95%98%EC%9D%B4%EC%95%B5%EA%B8%80 \"하이앵글\"), [아이 레벨](/Edu/wiki/index.php/%EC%95%84%EC%9D%B4_%EB%A0%88%EB%B2%A8 \"아이 레벨\"), [로우앵글](/Edu/wiki/index.php/%EB%A1%9C%EC%9A%B0%EC%95%B5%EA%B8%80 \"로우앵글\"), [버즈 아이 뷰](/Edu/wiki/index.php/%EB%B2%84%EC%A6%88_%EC%95%84%EC%9D%B4_%EB%B7%B0 \"버즈 아이 뷰\"), [사각앵글](/Edu/wiki/index.php/%EC%82%AC%EA%B0%81%EC%95%B5%EA%B8%80 \"사각앵글\"), [헤드룸](/Edu/wiki/index.php/%ED%97%A4%EB%93%9C%EB%A3%B8 \"헤드룸\"), [노즈룸](/Edu/wiki/index.php/%EB%85%B8%EC%A6%88%EB%A3%B8 \"노즈룸\"), [팬](/Edu/wiki/index.php/%ED%8C%AC \"팬\"), [퀵 팬](/Edu/wiki/index.php/%ED%80%B5_%ED%8C%AC \"퀵 팬\"), [스위시 팬](/Edu/wiki/index.php/%EC%8A%A4%EC%9C%84%EC%8B%9C_%ED%8C%AC \"스위시 팬\"), [플래시 팬](/Edu/wiki/index.php/%ED%94%8C%EB%9E%98%EC%8B%9C_%ED%8C%AC \"플래시 팬\"), [틸트](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8 \"틸트\"), [틸트 업](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8_%EC%97%85 \"틸트 업\"), [틸트 다운](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8_%EB%8B%A4%EC%9A%B4 \"틸트 다운\"), [페디스털 쇼트](/Edu/wiki/index.php/%ED%8E%98%EB%94%94%EC%8A%A4%ED%84%B8_%EC%87%BC%ED%8A%B8 \"페디스털 쇼트\"), [설정 쇼트](/Edu/wiki/index.php/%EC%84%A4%EC%A0%95_%EC%87%BC%ED%8A%B8 \"설정 쇼트\"), [빅 클로즈업 쇼트](/Edu/wiki/index.php/%EB%B9%85_%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"빅 클로즈업 쇼트\"), [미디엄 클로즈업 쇼트](/Edu/wiki/index.php/%EB%AF%B8%EB%94%94%EC%97%84_%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"미디엄 클로즈업 쇼트\"), [부감](/Edu/wiki/index.php/%EB%B6%80%EA%B0%90 \"부감\"), [시퀀스](/Edu/wiki/index.php/%EC%8B%9C%ED%80%80%EC%8A%A4 \"시퀀스\"), [몽타주](/Edu/wiki/index.php/%EB%AA%BD%ED%83%80%EC%A3%BC \"몽타주\"), [신](/Edu/wiki/index.php/%EC%8B%A0 \"신\"), [메타포](/Edu/wiki/index.php/%EB%A9%94%ED%83%80%ED%8F%AC \"메타포\"), [이스터 에그](/Edu/wiki/index.php/%EC%9D%B4%EC%8A%A4%ED%84%B0_%EC%97%90%EA%B7%B8 \"이스터 에그\"), [레퍼런스](/Edu/wiki/index.php/%EB%A0%88%ED%8D%BC%EB%9F%B0%EC%8A%A4 \"레퍼런스\"), [미장센](/Edu/wiki/index.php/%EB%AF%B8%EC%9E%A5%EC%84%BC \"미장센\"), [오마주](/Edu/wiki/index.php/%EC%98%A4%EB%A7%88%EC%A3%BC \"오마주\"), [페르소나](/Edu/wiki/index.php/%ED%8E%98%EB%A5%B4%EC%86%8C%EB%82%98 \"페르소나\"), [모티프](/Edu/wiki/index.php/%EB%AA%A8%ED%8B%B0%ED%94%84 \"모티프\"), [패러디](/Edu/wiki/index.php/%ED%8C%A8%EB%9F%AC%EB%94%94 \"패러디\"), [롱 테이크](/Edu/wiki/index.php/%EB%A1%B1_%ED%85%8C%EC%9D%B4%ED%81%AC \"롱 테이크\"), [딥 포커스](/Edu/wiki/index.php/%EB%94%A5_%ED%8F%AC%EC%BB%A4%EC%8A%A4 \"딥 포커스\"), [표절](/Edu/wiki/index.php/%ED%91%9C%EC%A0%88 \"표절\"), [테이크](/Edu/wiki/index.php/%ED%85%8C%EC%9D%B4%ED%81%AC \"테이크\"), [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\") |\n",
            "| **모티프** | [자유 모티프](/Edu/wiki/index.php/%EC%9E%90%EC%9C%A0_%EB%AA%A8%ED%8B%B0%ED%94%84 \"자유 모티프\"), [한정 모티프](/Edu/wiki/index.php/%ED%95%9C%EC%A0%95_%EB%AA%A8%ED%8B%B0%ED%94%84 \"한정 모티프\"), [동적 모티프](/Edu/wiki/index.php/%EB%8F%99%EC%A0%81_%EB%AA%A8%ED%8B%B0%ED%94%84 \"동적 모티프\"), [정적 모티프](/Edu/wiki/index.php/%EC%A0%95%EC%A0%81_%EB%AA%A8%ED%8B%B0%ED%94%84 \"정적 모티프\") |\n",
            "\n",
            "**Relation**\n",
            "\n",
            "| 관계어 | 노드 |\n",
            "| --- | --- |\n",
            "| ~에 출연했다 | [로버트 다우니 주니어](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EB%8B%A4%EC%9A%B0%EB%8B%88_%EC%A3%BC%EB%8B%88%EC%96%B4 \"로버트 다우니 주니어\") → [트로픽 썬더](/Edu/wiki/index.php/%ED%8A%B8%EB%A1%9C%ED%94%BD_%EC%8D%AC%EB%8D%94 \"트로픽 썬더\"), [로버트 다우니 주니어](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EB%8B%A4%EC%9A%B0%EB%8B%88_%EC%A3%BC%EB%8B%88%EC%96%B4 \"로버트 다우니 주니어\") → [보우핑거](/Edu/wiki/index.php/%EB%B3%B4%EC%9A%B0%ED%95%91%EA%B1%B0 \"보우핑거\"), [윌 페럴](/Edu/wiki/index.php/%EC%9C%8C_%ED%8E%98%EB%9F%B4 \"윌 페럴\") → [스트레인저\\_댄\\_픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\"), [매기 질렌할](/Edu/wiki/index.php/%EB%A7%A4%EA%B8%B0_%EC%A7%88%EB%A0%8C%ED%95%A0 \"매기 질렌할\") → [스트레인저 댄 픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\"), [엠마 톰슨](/Edu/wiki/index.php/%EC%97%A0%EB%A7%88_%ED%86%B0%EC%8A%A8 \"엠마 톰슨\") → [스트레인저\\_댄\\_픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\"), [더스틴 호프만](/Edu/wiki/index.php/%EB%8D%94%EC%8A%A4%ED%8B%B4_%ED%98%B8%ED%94%84%EB%A7%8C \"더스틴 호프만\") → [스트레인저\\_댄\\_픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\"), [졸업](/Edu/wiki/index.php/%EC%A1%B8%EC%97%85 \"졸업\"), [그레이엄 채프만](/Edu/wiki/index.php/%EA%B7%B8%EB%A0%88%EC%9D%B4%EC%97%84_%EC%B1%84%ED%94%84%EB%A7%8C \"그레이엄 채프만\") → [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\"), [존 클리즈](/Edu/wiki/index.php/%EC%A1%B4_%ED%81%B4%EB%A6%AC%EC%A6%88 \"존 클리즈\") → [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\"), [윌리엄 홀든](/Edu/wiki/index.php/%EC%9C%8C%EB%A6%AC%EC%97%84_%ED%99%80%EB%93%A0 \"윌리엄 홀든\") → [선셋 대로](/Edu/wiki/index.php/%EC%84%A0%EC%85%8B_%EB%8C%80%EB%A1%9C \"선셋 대로\") , [글로리아 스완슨](/Edu/wiki/index.php/%EA%B8%80%EB%A1%9C%EB%A6%AC%EC%95%84_%EC%8A%A4%EC%99%84%EC%8A%A8 \"글로리아 스완슨\") → [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\"), [조셉 고든 래빗](/Edu/wiki/index.php/%EC%A1%B0%EC%85%89_%EA%B3%A0%EB%93%A0_%EB%9E%98%EB%B9%97 \"조셉 고든 래빗\") → [500일의 썸머](/Edu/wiki/index.php/500%EC%9D%BC%EC%9D%98_%EC%8D%B8%EB%A8%B8 \"500일의 썸머\") , [주이 디샤넬](/Edu/wiki/index.php/%EC%A3%BC%EC%9D%B4_%EB%94%94%EC%83%A4%EB%84%AC \"주이 디샤넬\") → [500일의 썸머](/Edu/wiki/index.php/500%EC%9D%BC%EC%9D%98_%EC%8D%B8%EB%A8%B8 \"500일의 썸머\"), [앤 반크로프트](/Edu/wiki/index.php/%EC%95%A4_%EB%B0%98%ED%81%AC%EB%A1%9C%ED%94%84%ED%8A%B8 \"앤 반크로프트\") → [졸업](/Edu/wiki/index.php/%EC%A1%B8%EC%97%85 \"졸업\"), [라이언 고슬링](/Edu/wiki/index.php/%EB%9D%BC%EC%9D%B4%EC%96%B8_%EA%B3%A0%EC%8A%AC%EB%A7%81 \"라이언 고슬링\") → [라라랜드](/Edu/wiki/index.php/%EB%9D%BC%EB%9D%BC%EB%9E%9C%EB%93%9C \"라라랜드\"), [엠마 스톤](/Edu/wiki/index.php/%EC%97%A0%EB%A7%88_%EC%8A%A4%ED%86%A4 \"엠마 스톤\") → [라라랜드](/Edu/wiki/index.php/%EB%9D%BC%EB%9D%BC%EB%9E%9C%EB%93%9C \"라라랜드\"), [제임스 딘](/Edu/wiki/index.php/%EC%A0%9C%EC%9E%84%EC%8A%A4_%EB%94%98 \"제임스 딘\") → [이유 없는 반항](/Edu/wiki/index.php/%EC%9D%B4%EC%9C%A0_%EC%97%86%EB%8A%94_%EB%B0%98%ED%95%AD \"이유 없는 반항\"), [마이클 피트](/Edu/wiki/index.php/%EB%A7%88%EC%9D%B4%ED%81%B4_%ED%94%BC%ED%8A%B8 \"마이클 피트\") → [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\"), [에바 그린](/Edu/wiki/index.php/%EC%97%90%EB%B0%94_%EA%B7%B8%EB%A6%B0 \"에바 그린\") → [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\"), [루이스 가렐](/Edu/wiki/index.php/%EB%A3%A8%EC%9D%B4%EC%8A%A4_%EA%B0%80%EB%A0%90 \"루이스 가렐\") → [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\"), [콘스탄스 타워스](/Edu/wiki/index.php/%EC%BD%98%EC%8A%A4%ED%83%84%EC%8A%A4_%ED%83%80%EC%9B%8C%EC%8A%A4 \"콘스탄스 타워스\") → [충격의 복도](/Edu/wiki/index.php/%EC%B6%A9%EA%B2%A9%EC%9D%98_%EB%B3%B5%EB%8F%84 \"충격의 복도\"), [피터 브렉](/Edu/wiki/index.php/%ED%94%BC%ED%84%B0_%EB%B8%8C%EB%A0%89 \"피터 브렉\") → [충격의 복도](/Edu/wiki/index.php/%EC%B6%A9%EA%B2%A9%EC%9D%98_%EB%B3%B5%EB%8F%84 \"충격의 복도\"), **레오나르도 디카프리오** → [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\"), [톰 행크스](/Edu/wiki/index.php/%ED%86%B0_%ED%96%89%ED%81%AC%EC%8A%A4 \"톰 행크스\") → [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\"), [도널 글리슨](/Edu/wiki/index.php/%EB%8F%84%EB%84%90_%EA%B8%80%EB%A6%AC%EC%8A%A8 \"도널 글리슨\") → [어바웃 타임](/Edu/wiki/index.php/%EC%96%B4%EB%B0%94%EC%9B%83_%ED%83%80%EC%9E%84 \"어바웃 타임\"), [레이첼 맥아담스](/Edu/wiki/index.php/%EB%A0%88%EC%9D%B4%EC%B2%BC_%EB%A7%A5%EC%95%84%EB%8B%B4%EC%8A%A4 \"레이첼 맥아담스\") → [어바웃 타임](/Edu/wiki/index.php/%EC%96%B4%EB%B0%94%EC%9B%83_%ED%83%80%EC%9E%84 \"어바웃 타임\"), [베르나 블룸](/Edu/wiki/index.php/%EB%B2%A0%EB%A5%B4%EB%82%98_%EB%B8%94%EB%A3%B8 \"베르나 블룸\") → [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\"), [제레미 아이언스](/Edu/wiki/index.php/%EC%A0%9C%EB%A0%88%EB%AF%B8_%EC%95%84%EC%9D%B4%EC%96%B8%EC%8A%A4 \"제레미 아이언스\") → [로리타](/Edu/wiki/index.php/%EB%A1%9C%EB%A6%AC%ED%83%80 \"로리타\"), [도미니크 스웨인](/Edu/wiki/index.php/%EB%8F%84%EB%AF%B8%EB%8B%88%ED%81%AC_%EC%8A%A4%EC%9B%A8%EC%9D%B8 \"도미니크 스웨인\") → [로리타](/Edu/wiki/index.php/%EB%A1%9C%EB%A6%AC%ED%83%80 \"로리타\"), [피터 커싱](/Edu/wiki/index.php/%ED%94%BC%ED%84%B0_%EC%BB%A4%EC%8B%B1 \"피터 커싱\") → [프랑켄슈타인의 저주](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%BC%84%EC%8A%88%ED%83%80%EC%9D%B8%EC%9D%98_%EC%A0%80%EC%A3%BC \"프랑켄슈타인의 저주\"), [하젤 코트](/Edu/wiki/index.php/%ED%95%98%EC%A0%A4_%EC%BD%94%ED%8A%B8 \"하젤 코트\") → [프랑켄슈타인의 저주](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%BC%84%EC%8A%88%ED%83%80%EC%9D%B8%EC%9D%98_%EC%A0%80%EC%A3%BC \"프랑켄슈타인의 저주\"), [애쉬튼 커쳐](/Edu/wiki/index.php/%EC%95%A0%EC%89%AC%ED%8A%BC_%EC%BB%A4%EC%B3%90 \"애쉬튼 커쳐\") → [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\"), [에이미 스마트](/Edu/wiki/index.php/%EC%97%90%EC%9D%B4%EB%AF%B8_%EC%8A%A4%EB%A7%88%ED%8A%B8 \"에이미 스마트\") → [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\"), [브래드 피트](/Edu/wiki/index.php/%EB%B8%8C%EB%9E%98%EB%93%9C_%ED%94%BC%ED%8A%B8 \"브래드 피트\") → [세븐](/Edu/wiki/index.php/%EC%84%B8%EB%B8%90 \"세븐\"), [바스터즈 : 거친 녀석들](/Edu/wiki/index.php/%EB%B0%94%EC%8A%A4%ED%84%B0%EC%A6%88_:_%EA%B1%B0%EC%B9%9C_%EB%85%80%EC%84%9D%EB%93%A4 \"바스터즈 : 거친 녀석들\"), [모건 프리먼](/Edu/wiki/index.php/%EB%AA%A8%EA%B1%B4_%ED%94%84%EB%A6%AC%EB%A8%BC \"모건 프리먼\") → [세븐](/Edu/wiki/index.php/%EC%84%B8%EB%B8%90 \"세븐\"), [김강우](/Edu/wiki/index.php/%EA%B9%80%EA%B0%95%EC%9A%B0 \"김강우\") → [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\"), [백윤식](/Edu/wiki/index.php/%EB%B0%B1%EC%9C%A4%EC%8B%9D \"백윤식\") → [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\"), [윤여정](/Edu/wiki/index.php/%EC%9C%A4%EC%97%AC%EC%A0%95 \"윤여정\") → [하녀](/Edu/wiki/index.php/%ED%95%98%EB%85%80 \"하녀\"), [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\"), [김효진](/Edu/wiki/index.php/%EA%B9%80%ED%9A%A8%EC%A7%84 \"김효진\") → [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\"), [전도연](/Edu/wiki/index.php/%EC%A0%84%EB%8F%84%EC%97%B0 \"전도연\") → [하녀](/Edu/wiki/index.php/%ED%95%98%EB%85%80 \"하녀\"), [말콤 맥도웰](/Edu/wiki/index.php/%EB%A7%90%EC%BD%A4_%EB%A7%A5%EB%8F%84%EC%9B%B0 \"말콤 맥도웰\") → [시계 태엽 오렌지](/Edu/wiki/index.php/%EC%8B%9C%EA%B3%84_%ED%83%9C%EC%97%BD_%EC%98%A4%EB%A0%8C%EC%A7%80 \"시계 태엽 오렌지\"), [플레이어](/Edu/wiki/index.php/%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4 \"플레이어\"), [아티스트](/Edu/wiki/index.php/%EC%95%84%ED%8B%B0%EC%8A%A4%ED%8A%B8 \"아티스트\"), [패드릭 마지](/Edu/wiki/index.php/%ED%8C%A8%EB%93%9C%EB%A6%AD_%EB%A7%88%EC%A7%80 \"패드릭 마지\") → [시계 태엽 오렌지](/Edu/wiki/index.php/%EC%8B%9C%EA%B3%84_%ED%83%9C%EC%97%BD_%EC%98%A4%EB%A0%8C%EC%A7%80 \"시계 태엽 오렌지\"), [아돌프 히틀러](/Edu/wiki/index.php/%EC%95%84%EB%8F%8C%ED%94%84_%ED%9E%88%ED%8B%80%EB%9F%AC \"아돌프 히틀러\") → [의지의 승리](/Edu/wiki/index.php/%EC%9D%98%EC%A7%80%EC%9D%98_%EC%8A%B9%EB%A6%AC \"의지의 승리\"), [벤 스틸러](/Edu/wiki/index.php/%EB%B2%A4_%EC%8A%A4%ED%8B%B8%EB%9F%AC \"벤 스틸러\") → [트로픽 썬더](/Edu/wiki/index.php/%ED%8A%B8%EB%A1%9C%ED%94%BD_%EC%8D%AC%EB%8D%94 \"트로픽 썬더\"), [잭 블랙](/Edu/wiki/index.php/%EC%9E%AD_%EB%B8%94%EB%9E%99 \"잭 블랙\") → [트로픽 썬더](/Edu/wiki/index.php/%ED%8A%B8%EB%A1%9C%ED%94%BD_%EC%8D%AC%EB%8D%94 \"트로픽 썬더\"), [보우핑거](/Edu/wiki/index.php/%EB%B3%B4%EC%9A%B0%ED%95%91%EA%B1%B0 \"보우핑거\"), [브리지트 바르도](/Edu/wiki/index.php/%EB%B8%8C%EB%A6%AC%EC%A7%80%ED%8A%B8_%EB%B0%94%EB%A5%B4%EB%8F%84 \"브리지트 바르도\") → [사랑과 경멸](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EA%B3%BC_%EA%B2%BD%EB%A9%B8 \"사랑과 경멸\"), [미셸 피콜리](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%ED%94%BC%EC%BD%9C%EB%A6%AC \"미셸 피콜리\") → [사랑과 경멸](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EA%B3%BC_%EA%B2%BD%EB%A9%B8 \"사랑과 경멸\"), [아사 버터필드](/Edu/wiki/index.php/%EC%95%84%EC%82%AC_%EB%B2%84%ED%84%B0%ED%95%84%EB%93%9C \"아사 버터필드\") → [휴고](/Edu/wiki/index.php/%ED%9C%B4%EA%B3%A0 \"휴고\"), [클로이 그레이스 모레츠](/Edu/wiki/index.php/%ED%81%B4%EB%A1%9C%EC%9D%B4_%EA%B7%B8%EB%A0%88%EC%9D%B4%EC%8A%A4_%EB%AA%A8%EB%A0%88%EC%B8%A0 \"클로이 그레이스 모레츠\") → [휴고](/Edu/wiki/index.php/%ED%9C%B4%EA%B3%A0 \"휴고\"), [벤 킹슬리](/Edu/wiki/index.php/%EB%B2%A4_%ED%82%B9%EC%8A%AC%EB%A6%AC \"벤 킹슬리\") → [휴고](/Edu/wiki/index.php/%ED%9C%B4%EA%B3%A0 \"휴고\"), [진 켈리](/Edu/wiki/index.php/%EC%A7%84_%EC%BC%88%EB%A6%AC \"진 켈리\") → [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\"), [마크 월버그](/Edu/wiki/index.php/%EB%A7%88%ED%81%AC_%EC%9B%94%EB%B2%84%EA%B7%B8 \"마크 월버그\") → [부기 나이트](/Edu/wiki/index.php/%EB%B6%80%EA%B8%B0_%EB%82%98%EC%9D%B4%ED%8A%B8 \"부기 나이트\"), [줄리안 무어](/Edu/wiki/index.php/%EC%A4%84%EB%A6%AC%EC%95%88_%EB%AC%B4%EC%96%B4 \"줄리안 무어\") → [부기 나이트](/Edu/wiki/index.php/%EB%B6%80%EA%B8%B0_%EB%82%98%EC%9D%B4%ED%8A%B8 \"부기 나이트\"), [버트 레이놀즈](/Edu/wiki/index.php/%EB%B2%84%ED%8A%B8_%EB%A0%88%EC%9D%B4%EB%86%80%EC%A6%88 \"버트 레이놀즈\") → [플레이어](/Edu/wiki/index.php/%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4 \"플레이어\"), [팀 로빈스](/Edu/wiki/index.php/%ED%8C%80_%EB%A1%9C%EB%B9%88%EC%8A%A4 \"팀 로빈스\") → [플레이어](/Edu/wiki/index.php/%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4 \"플레이어\"), [장 뒤자르댕](/Edu/wiki/index.php/%EC%9E%A5_%EB%92%A4%EC%9E%90%EB%A5%B4%EB%8C%95 \"장 뒤자르댕\") → [아티스트](/Edu/wiki/index.php/%EC%95%84%ED%8B%B0%EC%8A%A4%ED%8A%B8 \"아티스트\"), [베레니스 베조](/Edu/wiki/index.php/%EB%B2%A0%EB%A0%88%EB%8B%88%EC%8A%A4_%EB%B2%A0%EC%A1%B0 \"베레니스 베조\") → [아티스트](/Edu/wiki/index.php/%EC%95%84%ED%8B%B0%EC%8A%A4%ED%8A%B8 \"아티스트\"), [조니 뎁](/Edu/wiki/index.php/%EC%A1%B0%EB%8B%88_%EB%8E%81 \"조니 뎁\") → [에드 우드](/Edu/wiki/index.php/%EC%97%90%EB%93%9C_%EC%9A%B0%EB%93%9C \"에드 우드\"), [모스 데프](/Edu/wiki/index.php/%EB%AA%A8%EC%8A%A4_%EB%8D%B0%ED%94%84 \"모스 데프\") → [비카인드 리와인드](/Edu/wiki/index.php/%EB%B9%84%EC%B9%B4%EC%9D%B8%EB%93%9C_%EB%A6%AC%EC%99%80%EC%9D%B8%EB%93%9C \"비카인드 리와인드\") , [에디 머피](/Edu/wiki/index.php/%EC%97%90%EB%94%94_%EB%A8%B8%ED%94%BC \"에디 머피\") → [보우핑거](/Edu/wiki/index.php/%EB%B3%B4%EC%9A%B0%ED%95%91%EA%B1%B0 \"보우핑거\"), [스티브 마틴](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%8C_%EB%A7%88%ED%8B%B4 \"스티브 마틴\") → [보우핑거](/Edu/wiki/index.php/%EB%B3%B4%EC%9A%B0%ED%95%91%EA%B1%B0 \"보우핑거\"), [니콜라스 케이지](/Edu/wiki/index.php/%EB%8B%88%EC%BD%9C%EB%9D%BC%EC%8A%A4_%EC%BC%80%EC%9D%B4%EC%A7%80 \"니콜라스 케이지\") → [어댑테이션](/Edu/wiki/index.php/%EC%96%B4%EB%8C%91%ED%85%8C%EC%9D%B4%EC%85%98 \"어댑테이션\"), [메릴 스트립](/Edu/wiki/index.php/%EB%A9%94%EB%A6%B4_%EC%8A%A4%ED%8A%B8%EB%A6%BD \"메릴 스트립\") → [어댑테이션](/Edu/wiki/index.php/%EC%96%B4%EB%8C%91%ED%85%8C%EC%9D%B4%EC%85%98 \"어댑테이션\"), [존 굿맨](/Edu/wiki/index.php/%EC%A1%B4_%EA%B5%BF%EB%A7%A8 \"존 굿맨\") → [바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\"), [존 굿맨](/Edu/wiki/index.php/%EC%A1%B4_%EA%B5%BF%EB%A7%A8 \"존 굿맨\") → [아티스트](/Edu/wiki/index.php/%EC%95%84%ED%8B%B0%EC%8A%A4%ED%8A%B8 \"아티스트\"), [존 굿맨](/Edu/wiki/index.php/%EC%A1%B4_%EA%B5%BF%EB%A7%A8 \"존 굿맨\") → [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\"), [존 터투로](/Edu/wiki/index.php/%EC%A1%B4_%ED%84%B0%ED%88%AC%EB%A1%9C \"존 터투로\") → [바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\"), [마르첼로 마스트로얀니](/Edu/wiki/index.php/%EB%A7%88%EB%A5%B4%EC%B2%BC%EB%A1%9C_%EB%A7%88%EC%8A%A4%ED%8A%B8%EB%A1%9C%EC%96%80%EB%8B%88 \"마르첼로 마스트로얀니\") → [8과 1/2](/Edu/wiki/index.php/8%EA%B3%BC_1/2 \"8과 1/2\"), [클라우디아 카르디날레](/Edu/wiki/index.php/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%94%94%EC%95%84_%EC%B9%B4%EB%A5%B4%EB%94%94%EB%82%A0%EB%A0%88 \"클라우디아 카르디날레\") → [8과 1/2](/Edu/wiki/index.php/8%EA%B3%BC_1/2 \"8과 1/2\"), [숀 코너리](/Edu/wiki/index.php/%EC%88%80_%EC%BD%94%EB%84%88%EB%A6%AC \"숀 코너리\") → [007 골드핑거](/Edu/wiki/index.php/007_%EA%B3%A8%EB%93%9C%ED%95%91%EA%B1%B0 \"007 골드핑거\"), [숀 코너리](/Edu/wiki/index.php/%EC%88%80_%EC%BD%94%EB%84%88%EB%A6%AC \"숀 코너리\") → [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\"), [피어스 브로스넌](/Edu/wiki/index.php/%ED%94%BC%EC%96%B4%EC%8A%A4_%EB%B8%8C%EB%A1%9C%EC%8A%A4%EB%84%8C \"피어스 브로스넌\") → [007 네버다이](/Edu/wiki/index.php/007_%EB%84%A4%EB%B2%84%EB%8B%A4%EC%9D%B4 \"007 네버다이\"), [도널드 오코너](/Edu/wiki/index.php/%EB%8F%84%EB%84%90%EB%93%9C_%EC%98%A4%EC%BD%94%EB%84%88 \"도널드 오코너\") → [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\"), [데비 레이놀즈](/Edu/wiki/index.php/%EB%8D%B0%EB%B9%84_%EB%A0%88%EC%9D%B4%EB%86%80%EC%A6%88 \"데비 레이놀즈\") → [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\"), [그레타 스카치](/Edu/wiki/index.php/%EA%B7%B8%EB%A0%88%ED%83%80_%EC%8A%A4%EC%B9%B4%EC%B9%98 \"그레타 스카치\") → [플레이어](/Edu/wiki/index.php/%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4 \"플레이어\"), [크리스 쿠퍼](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%BF%A0%ED%8D%BC \"크리스 쿠퍼\") → [어댑테이션](/Edu/wiki/index.php/%EC%96%B4%EB%8C%91%ED%85%8C%EC%9D%B4%EC%85%98 \"어댑테이션\"), [주디 데이비스](/Edu/wiki/index.php/%EC%A3%BC%EB%94%94_%EB%8D%B0%EC%9D%B4%EB%B9%84%EC%8A%A4 \"주디 데이비스\") → [바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\"), [마이클 러너](/Edu/wiki/index.php/%EB%A7%88%EC%9D%B4%ED%81%B4_%EB%9F%AC%EB%84%88 \"마이클 러너\") → [바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\"), [재클린 비솃](/Edu/wiki/index.php/%EC%9E%AC%ED%81%B4%EB%A6%B0_%EB%B9%84%EC%86%83 \"재클린 비솃\") → [아메리카의 밤](/Edu/wiki/index.php/%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4%EC%9D%98_%EB%B0%A4 \"아메리카의 밤\"), [장-피에르 오몽](/Edu/wiki/index.php/%EC%9E%A5-%ED%94%BC%EC%97%90%EB%A5%B4_%EC%98%A4%EB%AA%BD \"장-피에르 오몽\") → [아메리카의 밤](/Edu/wiki/index.php/%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4%EC%9D%98_%EB%B0%A4 \"아메리카의 밤\"), [스티브 부세미](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%8C_%EB%B6%80%EC%84%B8%EB%AF%B8 \"스티브 부세미\") → [망각의 삶](/Edu/wiki/index.php/%EB%A7%9D%EA%B0%81%EC%9D%98_%EC%82%B6 \"망각의 삶\"), [스티브 부세미](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%8C_%EB%B6%80%EC%84%B8%EB%AF%B8 \"스티브 부세미\") → [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\"), [스티브 부세미](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%8C_%EB%B6%80%EC%84%B8%EB%AF%B8 \"스티브 부세미\") → [바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\"), [캐서린 키너](/Edu/wiki/index.php/%EC%BA%90%EC%84%9C%EB%A6%B0_%ED%82%A4%EB%84%88 \"캐서린 키너\") → [망각의 삶](/Edu/wiki/index.php/%EB%A7%9D%EA%B0%81%EC%9D%98_%EC%82%B6 \"망각의 삶\"), [캐서린 키너](/Edu/wiki/index.php/%EC%BA%90%EC%84%9C%EB%A6%B0_%ED%82%A4%EB%84%88 \"캐서린 키너\") → [어댑테이션](/Edu/wiki/index.php/%EC%96%B4%EB%8C%91%ED%85%8C%EC%9D%B4%EC%85%98 \"어댑테이션\"), [대니 분](/Edu/wiki/index.php/%EB%8C%80%EB%8B%88_%EB%B6%84 \"대니 분\") → [믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\"), [오마 사이](/Edu/wiki/index.php/%EC%98%A4%EB%A7%88_%EC%82%AC%EC%9D%B4 \"오마 사이\") → [믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\"), [오마 사이](/Edu/wiki/index.php/%EC%98%A4%EB%A7%88_%EC%82%AC%EC%9D%B4 \"오마 사이\") → [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\"), [험프리 보가트](/Edu/wiki/index.php/%ED%97%98%ED%94%84%EB%A6%AC_%EB%B3%B4%EA%B0%80%ED%8A%B8 \"험프리 보가트\") → [빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\"), [로렌 바콜](/Edu/wiki/index.php/%EB%A1%9C%EB%A0%8C_%EB%B0%94%EC%BD%9C \"로렌 바콜\") → [빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\"), [크리스 에반스](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%97%90%EB%B0%98%EC%8A%A4 \"크리스 에반스\") → [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"), [스칼렛 요한슨](/Edu/wiki/index.php/%EC%8A%A4%EC%B9%BC%EB%A0%9B_%EC%9A%94%ED%95%9C%EC%8A%A8 \"스칼렛 요한슨\") → [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"), [존 트라볼타](/Edu/wiki/index.php/%EC%A1%B4_%ED%8A%B8%EB%9D%BC%EB%B3%BC%ED%83%80 \"존 트라볼타\") → [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\"), [사무엘 L.잭슨](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_L.%EC%9E%AD%EC%8A%A8 \"사무엘 L.잭슨\") → [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\"), [사무엘 L.잭슨](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_L.%EC%9E%AD%EC%8A%A8 \"사무엘 L.잭슨\") → [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\") ,[사무엘 L.잭슨](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_L.%EC%9E%AD%EC%8A%A8 \"사무엘 L.잭슨\") → [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"), [매튜 맥커너히](/Edu/wiki/index.php/%EB%A7%A4%ED%8A%9C_%EB%A7%A5%EC%BB%A4%EB%84%88%ED%9E%88 \"매튜 맥커너히\") → [트로픽 썬더](/Edu/wiki/index.php/%ED%8A%B8%EB%A1%9C%ED%94%BD_%EC%8D%AC%EB%8D%94 \"트로픽 썬더\"), [매튜 맥커너히](/Edu/wiki/index.php/%EB%A7%A4%ED%8A%9C_%EB%A7%A5%EC%BB%A4%EB%84%88%ED%9E%88 \"매튜 맥커너히\") → [인터스텔라](/Edu/wiki/index.php/%EC%9D%B8%ED%84%B0%EC%8A%A4%ED%85%94%EB%9D%BC \"인터스텔라\"), [앤 해서웨이](/Edu/wiki/index.php/%EC%95%A4_%ED%95%B4%EC%84%9C%EC%9B%A8%EC%9D%B4 \"앤 해서웨이\") → [인터스텔라](/Edu/wiki/index.php/%EC%9D%B8%ED%84%B0%EC%8A%A4%ED%85%94%EB%9D%BC \"인터스텔라\"), [케어 둘리](/Edu/wiki/index.php/%EC%BC%80%EC%96%B4_%EB%91%98%EB%A6%AC \"케어 둘리\") → [2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\"), [게리 록우드](/Edu/wiki/index.php/%EA%B2%8C%EB%A6%AC_%EB%A1%9D%EC%9A%B0%EB%93%9C \"게리 록우드\") → [2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\"), [콜린 퍼스](/Edu/wiki/index.php/%EC%BD%9C%EB%A6%B0_%ED%8D%BC%EC%8A%A4 \"콜린 퍼스\") → [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\"), [태런 애저튼](/Edu/wiki/index.php/%ED%83%9C%EB%9F%B0_%EC%95%A0%EC%A0%80%ED%8A%BC \"태런 애저튼\") → [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\"), [로저 무어](/Edu/wiki/index.php/%EB%A1%9C%EC%A0%80_%EB%AC%B4%EC%96%B4 \"로저 무어\") → [007 죽느냐 사느냐](/Edu/wiki/index.php/007_%EC%A3%BD%EB%8A%90%EB%83%90_%EC%82%AC%EB%8A%90%EB%83%90 \"007 죽느냐 사느냐\"), [로저 무어](/Edu/wiki/index.php/%EB%A1%9C%EC%A0%80_%EB%AC%B4%EC%96%B4 \"로저 무어\") → [007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\"), [다니엘 크레이그](/Edu/wiki/index.php/%EB%8B%A4%EB%8B%88%EC%97%98_%ED%81%AC%EB%A0%88%EC%9D%B4%EA%B7%B8 \"다니엘 크레이그\") → [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\"), [장 피에르 레오](/Edu/wiki/index.php/%EC%9E%A5_%ED%94%BC%EC%97%90%EB%A5%B4_%EB%A0%88%EC%98%A4 \"장 피에르 레오\") → [400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\"), [장 더스](/Edu/wiki/index.php/%EC%9E%A5_%EB%8D%94%EC%8A%A4 \"장 더스\") → [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\"), [마티유 아말릭](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B0%EC%9C%A0_%EC%95%84%EB%A7%90%EB%A6%AD \"마티유 아말릭\") → [잠수종과 나비](/Edu/wiki/index.php/%EC%9E%A0%EC%88%98%EC%A2%85%EA%B3%BC_%EB%82%98%EB%B9%84 \"잠수종과 나비\"), [크리스 프랫](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%ED%94%84%EB%9E%AB \"크리스 프랫\") → [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\"), [샘 닐](/Edu/wiki/index.php/%EC%83%98_%EB%8B%90 \"샘 닐\") → [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\"), [케빈 코스트너](/Edu/wiki/index.php/%EC%BC%80%EB%B9%88_%EC%BD%94%EC%8A%A4%ED%8A%B8%EB%84%88 \"케빈 코스트너\") → [언터쳐블](/Edu/wiki/index.php/%EC%96%B8%ED%84%B0%EC%B3%90%EB%B8%94 \"언터쳐블\"), [이반 보브로프](/Edu/wiki/index.php/%EC%9D%B4%EB%B0%98_%EB%B3%B4%EB%B8%8C%EB%A1%9C%ED%94%84 \"이반 보브로프\") → [전함 포템킨](/Edu/wiki/index.php/%EC%A0%84%ED%95%A8_%ED%8F%AC%ED%85%9C%ED%82%A8 \"전함 포템킨\"), [레아 세이두](/Edu/wiki/index.php/%EB%A0%88%EC%95%84_%EC%84%B8%EC%9D%B4%EB%91%90 \"레아 세이두\") → [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\"), [제인 시모어](/Edu/wiki/index.php/%EC%A0%9C%EC%9D%B8_%EC%8B%9C%EB%AA%A8%EC%96%B4 \"제인 시모어\") → [007 죽느냐 사느냐](/Edu/wiki/index.php/007_%EC%A3%BD%EB%8A%90%EB%83%90_%EC%82%AC%EB%8A%90%EB%83%90 \"007 죽느냐 사느냐\"), [클레어 모리어](/Edu/wiki/index.php/%ED%81%B4%EB%A0%88%EC%96%B4_%EB%AA%A8%EB%A6%AC%EC%96%B4 \"클레어 모리어\") → [400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\"), [레옹 라리베](/Edu/wiki/index.php/%EB%A0%88%EC%98%B9_%EB%9D%BC%EB%A6%AC%EB%B2%A0 \"레옹 라리베\") → [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\"), [엠마누엘 자이그너](/Edu/wiki/index.php/%EC%97%A0%EB%A7%88%EB%88%84%EC%97%98_%EC%9E%90%EC%9D%B4%EA%B7%B8%EB%84%88 \"엠마누엘 자이그너\") → [잠수종과 나비](/Edu/wiki/index.php/%EC%9E%A0%EC%88%98%EC%A2%85%EA%B3%BC_%EB%82%98%EB%B9%84 \"잠수종과 나비\"), [로라 던](/Edu/wiki/index.php/%EB%A1%9C%EB%9D%BC_%EB%8D%98 \"로라 던\") → [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\"), [브라이스 달라스 하워드](/Edu/wiki/index.php/%EB%B8%8C%EB%9D%BC%EC%9D%B4%EC%8A%A4_%EB%8B%AC%EB%9D%BC%EC%8A%A4_%ED%95%98%EC%9B%8C%EB%93%9C \"브라이스 달라스 하워드\") → [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\"), [클린트 이스트우드](/Edu/wiki/index.php/%ED%81%B4%EB%A6%B0%ED%8A%B8_%EC%9D%B4%EC%8A%A4%ED%8A%B8%EC%9A%B0%EB%93%9C \"클린트 이스트우드\") → [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\") |\n",
            "| ~와 작업했다 | [그레이엄 채프만](/Edu/wiki/index.php/%EA%B7%B8%EB%A0%88%EC%9D%B4%EC%97%84_%EC%B1%84%ED%94%84%EB%A7%8C \"그레이엄 채프만\") → [존 클리즈](/Edu/wiki/index.php/%EC%A1%B4_%ED%81%B4%EB%A6%AC%EC%A6%88 \"존 클리즈\"), [윌리엄 홀든](/Edu/wiki/index.php/%EC%9C%8C%EB%A6%AC%EC%97%84_%ED%99%80%EB%93%A0 \"윌리엄 홀든\") → [글로리아 스완슨](/Edu/wiki/index.php/%EA%B8%80%EB%A1%9C%EB%A6%AC%EC%95%84_%EC%8A%A4%EC%99%84%EC%8A%A8 \"글로리아 스완슨\"), [라이언 고슬링](/Edu/wiki/index.php/%EB%9D%BC%EC%9D%B4%EC%96%B8_%EA%B3%A0%EC%8A%AC%EB%A7%81 \"라이언 고슬링\") → [엠마 스톤](/Edu/wiki/index.php/%EC%97%A0%EB%A7%88_%EC%8A%A4%ED%86%A4 \"엠마 스톤\"), [에바 그린](/Edu/wiki/index.php/%EC%97%90%EB%B0%94_%EA%B7%B8%EB%A6%B0 \"에바 그린\") → [팀 버튼](/Edu/wiki/index.php/%ED%8C%80_%EB%B2%84%ED%8A%BC \"팀 버튼\"), [벤 스틸러](/Edu/wiki/index.php/%EB%B2%A4_%EC%8A%A4%ED%8B%B8%EB%9F%AC \"벤 스틸러\") → [잭 블랙](/Edu/wiki/index.php/%EC%9E%AD_%EB%B8%94%EB%9E%99 \"잭 블랙\"), [잭 블랙](/Edu/wiki/index.php/%EC%9E%AD_%EB%B8%94%EB%9E%99 \"잭 블랙\") → [벤 스틸러](/Edu/wiki/index.php/%EB%B2%A4_%EC%8A%A4%ED%8B%B8%EB%9F%AC \"벤 스틸러\"), [팀 로빈스](/Edu/wiki/index.php/%ED%8C%80_%EB%A1%9C%EB%B9%88%EC%8A%A4 \"팀 로빈스\"), [벤 킹슬리](/Edu/wiki/index.php/%EB%B2%A4_%ED%82%B9%EC%8A%AC%EB%A6%AC \"벤 킹슬리\") → [아사 버터필드](/Edu/wiki/index.php/%EC%95%84%EC%82%AC_%EB%B2%84%ED%84%B0%ED%95%84%EB%93%9C \"아사 버터필드\"), [버트 레이놀즈](/Edu/wiki/index.php/%EB%B2%84%ED%8A%B8_%EB%A0%88%EC%9D%B4%EB%86%80%EC%A6%88 \"버트 레이놀즈\") → [잭 블랙](/Edu/wiki/index.php/%EC%9E%AD_%EB%B8%94%EB%9E%99 \"잭 블랙\"), [베레니스 베조](/Edu/wiki/index.php/%EB%B2%A0%EB%A0%88%EB%8B%88%EC%8A%A4_%EB%B2%A0%EC%A1%B0 \"베레니스 베조\") → [장 뒤자르댕](/Edu/wiki/index.php/%EC%9E%A5_%EB%92%A4%EC%9E%90%EB%A5%B4%EB%8C%95 \"장 뒤자르댕\"), [조니 뎁](/Edu/wiki/index.php/%EC%A1%B0%EB%8B%88_%EB%8E%81 \"조니 뎁\") → [니콜라스 케이지](/Edu/wiki/index.php/%EB%8B%88%EC%BD%9C%EB%9D%BC%EC%8A%A4_%EC%BC%80%EC%9D%B4%EC%A7%80 \"니콜라스 케이지\"), [니콜라스 케이지](/Edu/wiki/index.php/%EB%8B%88%EC%BD%9C%EB%9D%BC%EC%8A%A4_%EC%BC%80%EC%9D%B4%EC%A7%80 \"니콜라스 케이지\") → [조니 뎁](/Edu/wiki/index.php/%EC%A1%B0%EB%8B%88_%EB%8E%81 \"조니 뎁\"),[테리 존스](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EC%A1%B4%EC%8A%A4 \"테리 존스\") → [테리 길리엄](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EA%B8%B8%EB%A6%AC%EC%97%84 \"테리 길리엄\"), [테리 길리엄](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EA%B8%B8%EB%A6%AC%EC%97%84 \"테리 길리엄\") → [테리 존스](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EC%A1%B4%EC%8A%A4 \"테리 존스\"), [사무엘 풀러](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_%ED%92%80%EB%9F%AC \"사무엘 풀러\") → [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\"), [스티븐 스필버그](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%90_%EC%8A%A4%ED%95%84%EB%B2%84%EA%B7%B8 \"스티븐 스필버그\") →[마틴 스콜세지](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B4_%EC%8A%A4%EC%BD%9C%EC%84%B8%EC%A7%80 \"마틴 스콜세지\"), [에릭 브래스](/Edu/wiki/index.php/%EC%97%90%EB%A6%AD_%EB%B8%8C%EB%9E%98%EC%8A%A4 \"에릭 브래스\") → [J.마키에 그러버](/Edu/wiki/index.php/J.%EB%A7%88%ED%82%A4%EC%97%90_%EA%B7%B8%EB%9F%AC%EB%B2%84 \"J.마키에 그러버\"), [J.마키에 그러버](/Edu/wiki/index.php/J.%EB%A7%88%ED%82%A4%EC%97%90_%EA%B7%B8%EB%9F%AC%EB%B2%84 \"J.마키에 그러버\") → [에릭 브래스](/Edu/wiki/index.php/%EC%97%90%EB%A6%AD_%EB%B8%8C%EB%9E%98%EC%8A%A4 \"에릭 브래스\"), [데이빗 핀처](/Edu/wiki/index.php/%EB%8D%B0%EC%9D%B4%EB%B9%97_%ED%95%80%EC%B2%98 \"데이빗 핀처\") → [스파이크 존즈](/Edu/wiki/index.php/%EC%8A%A4%ED%8C%8C%EC%9D%B4%ED%81%AC_%EC%A1%B4%EC%A6%88 \"스파이크 존즈\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") → [스티븐 스필버그](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%90_%EC%8A%A4%ED%95%84%EB%B2%84%EA%B7%B8 \"스티븐 스필버그\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") →[마틴 스콜세지](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B4_%EC%8A%A4%EC%BD%9C%EC%84%B8%EC%A7%80 \"마틴 스콜세지\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") →[테리 길리엄](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EA%B8%B8%EB%A6%AC%EC%97%84 \"테리 길리엄\"),[스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") →[우디 앨런](/Edu/wiki/index.php/%EC%9A%B0%EB%94%94_%EC%95%A8%EB%9F%B0 \"우디 앨런\"), [레니 리펜슈탈](/Edu/wiki/index.php/%EB%A0%88%EB%8B%88_%EB%A6%AC%ED%8E%9C%EC%8A%88%ED%83%88 \"레니 리펜슈탈\") → [아돌프 히틀러](/Edu/wiki/index.php/%EC%95%84%EB%8F%8C%ED%94%84_%ED%9E%88%ED%8B%80%EB%9F%AC \"아돌프 히틀러\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\") → [사무엘 풀러](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_%ED%92%80%EB%9F%AC \"사무엘 풀러\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\")→[장 비고](/Edu/wiki/index.php/%EC%9E%A5_%EB%B9%84%EA%B3%A0 \"장 비고\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\")→[프랑수와 트뤼포](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%88%98%EC%99%80_%ED%8A%B8%EB%A4%BC%ED%8F%AC \"프랑수와 트뤼포\"), [폴 토마스 앤더슨](/Edu/wiki/index.php/%ED%8F%B4_%ED%86%A0%EB%A7%88%EC%8A%A4_%EC%95%A4%EB%8D%94%EC%8A%A8 \"폴 토마스 앤더슨\") → [로버트 알트만](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EC%95%8C%ED%8A%B8%EB%A7%8C \"로버트 알트만\"), [로버트 알트만](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EC%95%8C%ED%8A%B8%EB%A7%8C \"로버트 알트만\")→[폴 토마스 앤더슨](/Edu/wiki/index.php/%ED%8F%B4_%ED%86%A0%EB%A7%88%EC%8A%A4_%EC%95%A4%EB%8D%94%EC%8A%A8 \"폴 토마스 앤더슨\"), [미셸 아자나비슈스](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%EC%95%84%EC%9E%90%EB%82%98%EB%B9%84%EC%8A%88%EC%8A%A4 \"미셸 아자나비슈스\")→[장 뒤자르댕](/Edu/wiki/index.php/%EC%9E%A5_%EB%92%A4%EC%9E%90%EB%A5%B4%EB%8C%95 \"장 뒤자르댕\"),[페데리코 펠리니](/Edu/wiki/index.php/%ED%8E%98%EB%8D%B0%EB%A6%AC%EC%BD%94_%ED%8E%A0%EB%A6%AC%EB%8B%88 \"페데리코 펠리니\")→[마르첼로 마스트로얀니](/Edu/wiki/index.php/%EB%A7%88%EB%A5%B4%EC%B2%BC%EB%A1%9C_%EB%A7%88%EC%8A%A4%ED%8A%B8%EB%A1%9C%EC%96%80%EB%8B%88 \"마르첼로 마스트로얀니\") ,[프랑수와 트뤼포](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%88%98%EC%99%80_%ED%8A%B8%EB%A4%BC%ED%8F%AC \"프랑수와 트뤼포\")→[장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\"),[우디 앨런](/Edu/wiki/index.php/%EC%9A%B0%EB%94%94_%EC%95%A8%EB%9F%B0 \"우디 앨런\")→[스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\"),[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\")→[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\"),[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\")→[크리스 에반스](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%97%90%EB%B0%98%EC%8A%A4 \"크리스 에반스\"),[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\")→[스칼렛 요한슨](/Edu/wiki/index.php/%EC%8A%A4%EC%B9%BC%EB%A0%9B_%EC%9A%94%ED%95%9C%EC%8A%A8 \"스칼렛 요한슨\"),[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\"),[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[크리스 에반스](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%97%90%EB%B0%98%EC%8A%A4 \"크리스 에반스\"),[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[스칼렛 요한슨](/Edu/wiki/index.php/%EC%8A%A4%EC%B9%BC%EB%A0%9B_%EC%9A%94%ED%95%9C%EC%8A%A8 \"스칼렛 요한슨\"), [안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[로버트 다우니 주니어](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EB%8B%A4%EC%9A%B0%EB%8B%88_%EC%A3%BC%EB%8B%88%EC%96%B4 \"로버트 다우니 주니어\"),[매튜 본](/Edu/wiki/index.php/%EB%A7%A4%ED%8A%9C_%EB%B3%B8 \"매튜 본\")→[콜린 퍼스](/Edu/wiki/index.php/%EC%BD%9C%EB%A6%B0_%ED%8D%BC%EC%8A%A4 \"콜린 퍼스\"),[장 비고](/Edu/wiki/index.php/%EC%9E%A5_%EB%B9%84%EA%B3%A0 \"장 비고\")→[장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\"),[세르게이 에이젠슈타인](/Edu/wiki/index.php/%EC%84%B8%EB%A5%B4%EA%B2%8C%EC%9D%B4_%EC%97%90%EC%9D%B4%EC%A0%A0%EC%8A%88%ED%83%80%EC%9D%B8 \"세르게이 에이젠슈타인\")→[찰리 채플린](/Edu/wiki/index.php/%EC%B0%B0%EB%A6%AC_%EC%B1%84%ED%94%8C%EB%A6%B0 \"찰리 채플린\") |\n",
            "| ~을 연출했다 | [조니 뎁](/Edu/wiki/index.php/%EC%A1%B0%EB%8B%88_%EB%8E%81 \"조니 뎁\") → [휴고](/Edu/wiki/index.php/%ED%9C%B4%EA%B3%A0 \"휴고\"), [클린트 이스트우드](/Edu/wiki/index.php/%ED%81%B4%EB%A6%B0%ED%8A%B8_%EC%9D%B4%EC%8A%A4%ED%8A%B8%EC%9A%B0%EB%93%9C \"클린트 이스트우드\") → [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\"),[마크 포스터](/Edu/wiki/index.php/%EB%A7%88%ED%81%AC_%ED%8F%AC%EC%8A%A4%ED%84%B0 \"마크 포스터\") → [스트레인저 댄 픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\"), [테리 존스](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EC%A1%B4%EC%8A%A4 \"테리 존스\") → [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\"), [테리 길리엄](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EA%B8%B8%EB%A6%AC%EC%97%84 \"테리 길리엄\") → [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\"), [마크 웹](/Edu/wiki/index.php/%EB%A7%88%ED%81%AC_%EC%9B%B9 \"마크 웹\") → [500일의 썸머](/Edu/wiki/index.php/500%EC%9D%BC%EC%9D%98_%EC%8D%B8%EB%A8%B8 \"500일의 썸머\"), [마이크 니콜스](/Edu/wiki/index.php/%EB%A7%88%EC%9D%B4%ED%81%AC_%EB%8B%88%EC%BD%9C%EC%8A%A4 \"마이크 니콜스\") → [졸업2](/Edu/wiki/index.php/%EC%A1%B8%EC%97%852 \"졸업2\"), [니콜라스 레이](/Edu/wiki/index.php/%EB%8B%88%EC%BD%9C%EB%9D%BC%EC%8A%A4_%EB%A0%88%EC%9D%B4 \"니콜라스 레이\") → [이유 없는 반항](/Edu/wiki/index.php/%EC%9D%B4%EC%9C%A0_%EC%97%86%EB%8A%94_%EB%B0%98%ED%95%AD \"이유 없는 반항\"), [베르나르도 베르톨루치](/Edu/wiki/index.php/%EB%B2%A0%EB%A5%B4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%B2%A0%EB%A5%B4%ED%86%A8%EB%A3%A8%EC%B9%98 \"베르나르도 베르톨루치\") → [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\"), [사무엘 풀러](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_%ED%92%80%EB%9F%AC \"사무엘 풀러\") → [충격의 복도](/Edu/wiki/index.php/%EC%B6%A9%EA%B2%A9%EC%9D%98_%EB%B3%B5%EB%8F%84 \"충격의 복도\"), [빌리 와인더](/Edu/wiki/index.php/%EB%B9%8C%EB%A6%AC_%EC%99%80%EC%9D%B8%EB%8D%94 \"빌리 와인더\") → [선셋 대로](/Edu/wiki/index.php/%EC%84%A0%EC%85%8B_%EB%8C%80%EB%A1%9C \"선셋 대로\"), [스티븐 스필버그](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%90_%EC%8A%A4%ED%95%84%EB%B2%84%EA%B7%B8 \"스티븐 스필버그\") → [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\"), [리차드 커티스](/Edu/wiki/index.php/%EB%A6%AC%EC%B0%A8%EB%93%9C_%EC%BB%A4%ED%8B%B0%EC%8A%A4 \"리차드 커티스\") → [어바웃 타임2](/Edu/wiki/index.php/%EC%96%B4%EB%B0%94%EC%9B%83_%ED%83%80%EC%9E%842 \"어바웃 타임2\"), [클린트 이스트우드](/Edu/wiki/index.php/%ED%81%B4%EB%A6%B0%ED%8A%B8_%EC%9D%B4%EC%8A%A4%ED%8A%B8%EC%9A%B0%EB%93%9C \"클린트 이스트우드\") → [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\"), [애드리안 라인](/Edu/wiki/index.php/%EC%95%A0%EB%93%9C%EB%A6%AC%EC%95%88_%EB%9D%BC%EC%9D%B8 \"애드리안 라인\") → [로리타](/Edu/wiki/index.php/%EB%A1%9C%EB%A6%AC%ED%83%80 \"로리타\"), [테런스 피셔](/Edu/wiki/index.php/%ED%85%8C%EB%9F%B0%EC%8A%A4_%ED%94%BC%EC%85%94 \"테런스 피셔\") → [프랑켄슈타인의 저주](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%BC%84%EC%8A%88%ED%83%80%EC%9D%B8%EC%9D%98_%EC%A0%80%EC%A3%BC \"프랑켄슈타인의 저주\"), [에릭 브래스](/Edu/wiki/index.php/%EC%97%90%EB%A6%AD_%EB%B8%8C%EB%9E%98%EC%8A%A4 \"에릭 브래스\") → [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\"), [J.마키에 그러버](/Edu/wiki/index.php/J.%EB%A7%88%ED%82%A4%EC%97%90_%EA%B7%B8%EB%9F%AC%EB%B2%84 \"J.마키에 그러버\") → [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\"), [데이빗 핀처](/Edu/wiki/index.php/%EB%8D%B0%EC%9D%B4%EB%B9%97_%ED%95%80%EC%B2%98 \"데이빗 핀처\") → [세븐](/Edu/wiki/index.php/%EC%84%B8%EB%B8%90 \"세븐\"), [임상수](/Edu/wiki/index.php/%EC%9E%84%EC%83%81%EC%88%98 \"임상수\") → [하녀](/Edu/wiki/index.php/%ED%95%98%EB%85%80 \"하녀\"), [임상수](/Edu/wiki/index.php/%EC%9E%84%EC%83%81%EC%88%98 \"임상수\") →[돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") → [2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") →[시계 태엽 오렌지](/Edu/wiki/index.php/%EC%8B%9C%EA%B3%84_%ED%83%9C%EC%97%BD_%EC%98%A4%EB%A0%8C%EC%A7%80 \"시계 태엽 오렌지\"), [레니 리펜슈탈](/Edu/wiki/index.php/%EB%A0%88%EB%8B%88_%EB%A6%AC%ED%8E%9C%EC%8A%88%ED%83%88 \"레니 리펜슈탈\") → [의지의 승리](/Edu/wiki/index.php/%EC%9D%98%EC%A7%80%EC%9D%98_%EC%8A%B9%EB%A6%AC \"의지의 승리\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\") → [사랑과 경멸](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EA%B3%BC_%EA%B2%BD%EB%A9%B8 \"사랑과 경멸\"),[마틴 스콜세지](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B4_%EC%8A%A4%EC%BD%9C%EC%84%B8%EC%A7%80 \"마틴 스콜세지\")→[휴고](/Edu/wiki/index.php/%ED%9C%B4%EA%B3%A0 \"휴고\"),[진 켈리](/Edu/wiki/index.php/%EC%A7%84_%EC%BC%88%EB%A6%AC \"진 켈리\")→[사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\"), [폴 토마스 앤더슨](/Edu/wiki/index.php/%ED%8F%B4_%ED%86%A0%EB%A7%88%EC%8A%A4_%EC%95%A4%EB%8D%94%EC%8A%A8 \"폴 토마스 앤더슨\") → [부기 나이트](/Edu/wiki/index.php/%EB%B6%80%EA%B8%B0_%EB%82%98%EC%9D%B4%ED%8A%B8 \"부기 나이트\"),[로버트 알트만](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EC%95%8C%ED%8A%B8%EB%A7%8C \"로버트 알트만\")→[플레이어](/Edu/wiki/index.php/%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4 \"플레이어\"),[미셸 아자나비슈스](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%EC%95%84%EC%9E%90%EB%82%98%EB%B9%84%EC%8A%88%EC%8A%A4 \"미셸 아자나비슈스\")→[아티스트](/Edu/wiki/index.php/%EC%95%84%ED%8B%B0%EC%8A%A4%ED%8A%B8 \"아티스트\"), [팀 버튼](/Edu/wiki/index.php/%ED%8C%80_%EB%B2%84%ED%8A%BC \"팀 버튼\")→[에드 우드](/Edu/wiki/index.php/%EC%97%90%EB%93%9C_%EC%9A%B0%EB%93%9C \"에드 우드\"), [미셸 공드리](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%EA%B3%B5%EB%93%9C%EB%A6%AC \"미셸 공드리\")→[비카인드 리와인드](/Edu/wiki/index.php/%EB%B9%84%EC%B9%B4%EC%9D%B8%EB%93%9C_%EB%A6%AC%EC%99%80%EC%9D%B8%EB%93%9C \"비카인드 리와인드\"),[프랭크 오즈](/Edu/wiki/index.php/%ED%94%84%EB%9E%AD%ED%81%AC_%EC%98%A4%EC%A6%88 \"프랭크 오즈\")→[보우핑거](/Edu/wiki/index.php/%EB%B3%B4%EC%9A%B0%ED%95%91%EA%B1%B0 \"보우핑거\"), [스파이크 존즈](/Edu/wiki/index.php/%EC%8A%A4%ED%8C%8C%EC%9D%B4%ED%81%AC_%EC%A1%B4%EC%A6%88 \"스파이크 존즈\")→[어댑테이션](/Edu/wiki/index.php/%EC%96%B4%EB%8C%91%ED%85%8C%EC%9D%B4%EC%85%98 \"어댑테이션\"), [조엘 코엔](/Edu/wiki/index.php/%EC%A1%B0%EC%97%98_%EC%BD%94%EC%97%94 \"조엘 코엔\")→[바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\"),[페데리코 펠리니](/Edu/wiki/index.php/%ED%8E%98%EB%8D%B0%EB%A6%AC%EC%BD%94_%ED%8E%A0%EB%A6%AC%EB%8B%88 \"페데리코 펠리니\")→[8과 1/2](/Edu/wiki/index.php/8%EA%B3%BC_1/2 \"8과 1/2\"), [프랑수와 트뤼포](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%88%98%EC%99%80_%ED%8A%B8%EB%A4%BC%ED%8F%AC \"프랑수와 트뤼포\")→[400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\"),[프랑수와 트뤼포](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%88%98%EC%99%80_%ED%8A%B8%EB%A4%BC%ED%8F%AC \"프랑수와 트뤼포\")→[아메리카의 밤](/Edu/wiki/index.php/%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4%EC%9D%98_%EB%B0%A4 \"아메리카의 밤\"),[스텐리 도넌](/Edu/wiki/index.php/%EC%8A%A4%ED%85%90%EB%A6%AC_%EB%8F%84%EB%84%8C \"스텐리 도넌\")→[사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\"), [톰 디칠로](/Edu/wiki/index.php/%ED%86%B0_%EB%94%94%EC%B9%A0%EB%A1%9C \"톰 디칠로\")→[망각의 삶](/Edu/wiki/index.php/%EB%A7%9D%EA%B0%81%EC%9D%98_%EC%82%B6 \"망각의 삶\"),[장 피에르 주네](/Edu/wiki/index.php/%EC%9E%A5_%ED%94%BC%EC%97%90%EB%A5%B4_%EC%A3%BC%EB%84%A4 \"장 피에르 주네\")→[믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\"),[하워드 호크스](/Edu/wiki/index.php/%ED%95%98%EC%9B%8C%EB%93%9C_%ED%98%B8%ED%81%AC%EC%8A%A4 \"하워드 호크스\")→[빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\"),[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\")→[캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"),[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"),[쿠엔틴 타란티노](/Edu/wiki/index.php/%EC%BF%A0%EC%97%94%ED%8B%B4_%ED%83%80%EB%9E%80%ED%8B%B0%EB%85%B8 \"쿠엔틴 타란티노\")→[펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\"), [쿠엔틴 타란티노](/Edu/wiki/index.php/%EC%BF%A0%EC%97%94%ED%8B%B4_%ED%83%80%EB%9E%80%ED%8B%B0%EB%85%B8 \"쿠엔틴 타란티노\")→[바스터즈 : 거친 녀석들](/Edu/wiki/index.php/%EB%B0%94%EC%8A%A4%ED%84%B0%EC%A6%88_:_%EA%B1%B0%EC%B9%9C_%EB%85%80%EC%84%9D%EB%93%A4 \"바스터즈 : 거친 녀석들\"), [크리스토퍼 놀란](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%86%A0%ED%8D%BC_%EB%86%80%EB%9E%80 \"크리스토퍼 놀란\")→[인터스텔라](/Edu/wiki/index.php/%EC%9D%B8%ED%84%B0%EC%8A%A4%ED%85%94%EB%9D%BC \"인터스텔라\"),[매튜 본](/Edu/wiki/index.php/%EB%A7%A4%ED%8A%9C_%EB%B3%B8 \"매튜 본\")→[킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\"),[로저 스포티스우드](/Edu/wiki/index.php/%EB%A1%9C%EC%A0%80_%EC%8A%A4%ED%8F%AC%ED%8B%B0%EC%8A%A4%EC%9A%B0%EB%93%9C \"로저 스포티스우드\")→[007 네버다이](/Edu/wiki/index.php/007_%EB%84%A4%EB%B2%84%EB%8B%A4%EC%9D%B4 \"007 네버다이\"),[루이스 길버트](/Edu/wiki/index.php/%EB%A3%A8%EC%9D%B4%EC%8A%A4_%EA%B8%B8%EB%B2%84%ED%8A%B8 \"루이스 길버트\")→[007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\"),[가이 해밀턴](/Edu/wiki/index.php/%EA%B0%80%EC%9D%B4_%ED%95%B4%EB%B0%80%ED%84%B4 \"가이 해밀턴\")→[007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\"),[샘 멘데스](/Edu/wiki/index.php/%EC%83%98_%EB%A9%98%EB%8D%B0%EC%8A%A4 \"샘 멘데스\")→[007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\"),[장 비고](/Edu/wiki/index.php/%EC%9E%A5_%EB%B9%84%EA%B3%A0 \"장 비고\")→[품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\"),[줄리안 슈나벨](/Edu/wiki/index.php/%EC%A4%84%EB%A6%AC%EC%95%88_%EC%8A%88%EB%82%98%EB%B2%A8 \"줄리안 슈나벨\")→[잠수종과 나비](/Edu/wiki/index.php/%EC%9E%A0%EC%88%98%EC%A2%85%EA%B3%BC_%EB%82%98%EB%B9%84 \"잠수종과 나비\"), [콜린 트레보로우](/Edu/wiki/index.php/%EC%BD%9C%EB%A6%B0_%ED%8A%B8%EB%A0%88%EB%B3%B4%EB%A1%9C%EC%9A%B0 \"콜린 트레보로우\")→[쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\"),[브라이언 드 팔마](/Edu/wiki/index.php/%EB%B8%8C%EB%9D%BC%EC%9D%B4%EC%96%B8_%EB%93%9C_%ED%8C%94%EB%A7%88 \"브라이언 드 팔마\")→[언터쳐블](/Edu/wiki/index.php/%EC%96%B8%ED%84%B0%EC%B3%90%EB%B8%94 \"언터쳐블\"),[세르게이 에이젠슈타인](/Edu/wiki/index.php/%EC%84%B8%EB%A5%B4%EA%B2%8C%EC%9D%B4_%EC%97%90%EC%9D%B4%EC%A0%A0%EC%8A%88%ED%83%80%EC%9D%B8 \"세르게이 에이젠슈타인\")→[전함 포템킨](/Edu/wiki/index.php/%EC%A0%84%ED%95%A8_%ED%8F%AC%ED%85%9C%ED%82%A8 \"전함 포템킨\") |\n",
            "| ~에 등장한다 | [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\") → [스트레인저 댄 픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\"), [졸업](/Edu/wiki/index.php/%EC%A1%B8%EC%97%852 \"졸업2\") → [500일의 썸머](/Edu/wiki/index.php/500%EC%9D%BC%EC%9D%98_%EC%8D%B8%EB%A8%B82 \"500일의 썸머2\"), [이유 없는 반항](/Edu/wiki/index.php/%EC%9D%B4%EC%9C%A0_%EC%97%86%EB%8A%94_%EB%B0%98%ED%95%AD \"이유 없는 반항\") → [라라랜드](/Edu/wiki/index.php/%EB%9D%BC%EB%9D%BC%EB%9E%9C%EB%93%9C2 \"라라랜드2\"), [충격의 복도](/Edu/wiki/index.php/%EC%B6%A9%EA%B2%A9%EC%9D%98_%EB%B3%B5%EB%8F%84 \"충격의 복도\") → [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\"), [007 골드핑거](/Edu/wiki/index.php/007_%EA%B3%A8%EB%93%9C%ED%95%91%EA%B1%B0 \"007 골드핑거\") → [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\"), [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\") → [어바웃 타임](/Edu/wiki/index.php/%EC%96%B4%EB%B0%94%EC%9B%83_%ED%83%80%EC%9E%842 \"어바웃 타임2\"), [프랑켄슈타인의 저주](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%BC%84%EC%8A%88%ED%83%80%EC%9D%B8%EC%9D%98_%EC%A0%80%EC%A3%BC \"프랑켄슈타인의 저주\") → [로리타](/Edu/wiki/index.php/%EB%A1%9C%EB%A6%AC%ED%83%80 \"로리타\"), [세븐](/Edu/wiki/index.php/%EC%84%B8%EB%B8%90 \"세븐\") → [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\"), [하녀](/Edu/wiki/index.php/%ED%95%98%EB%85%80 \"하녀\") → [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\"), [의지의 승리](/Edu/wiki/index.php/%EC%9D%98%EC%A7%80%EC%9D%98_%EC%8A%B9%EB%A6%AC \"의지의 승리\") → [시계 태엽 오렌지](/Edu/wiki/index.php/%EC%8B%9C%EA%B3%84_%ED%83%9C%EC%97%BD_%EC%98%A4%EB%A0%8C%EC%A7%80 \"시계 태엽 오렌지\"), [빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\") → [믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\"), [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\") → [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"), [2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\") → [인터스텔라](/Edu/wiki/index.php/%EC%9D%B8%ED%84%B0%EC%8A%A4%ED%85%94%EB%9D%BC \"인터스텔라\"), [007 네버다이](/Edu/wiki/index.php/007_%EB%84%A4%EB%B2%84%EB%8B%A4%EC%9D%B4 \"007 네버다이\") → [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\"), [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\") → [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\"), [007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\")→ [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\"), [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\")→ [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\"), [007 죽느냐 사느냐](/Edu/wiki/index.php/007_%EC%A3%BD%EB%8A%90%EB%83%90_%EC%82%AC%EB%8A%90%EB%83%90 \"007 죽느냐 사느냐\") → [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\"), [400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\") → [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\"), [잠수종과 나비](/Edu/wiki/index.php/%EC%9E%A0%EC%88%98%EC%A2%85%EA%B3%BC_%EB%82%98%EB%B9%84 \"잠수종과 나비\") → [400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\") → [라라랜드](/Edu/wiki/index.php/%EB%9D%BC%EB%9D%BC%EB%9E%9C%EB%93%9C2 \"라라랜드2\"), [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\") → [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\"), [언터쳐블](/Edu/wiki/index.php/%EC%96%B8%ED%84%B0%EC%B3%90%EB%B8%94 \"언터쳐블\") → [전함 포템킨](/Edu/wiki/index.php/%EC%A0%84%ED%95%A8_%ED%8F%AC%ED%85%9C%ED%82%A8 \"전함 포템킨\"), [“Welcome to Jurassic Park”](/Edu/wiki/index.php/%E2%80%9CWelcome_to_Jurassic_Park%E2%80%9D \"“Welcome to Jurassic Park”\") → [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\"), [“Welcome to Jurassic Park”](/Edu/wiki/index.php/%E2%80%9CWelcome_to_Jurassic_Park%E2%80%9D \"“Welcome to Jurassic Park”\")→ [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\"), [\"The path of the righteous man: Ezekiel 25: 17\"](/Edu/wiki/index.php/%22The_path_of_the_righteous_man:_Ezekiel_25:_17%22 \"\\\"The path of the righteous man: Ezekiel 25: 17\\\"\") → [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\"), [\"The path of the righteous man: Ezekiel 25: 17\"](/Edu/wiki/index.php/%22The_path_of_the_righteous_man:_Ezekiel_25:_17%22 \"\\\"The path of the righteous man: Ezekiel 25: 17\\\"\") → [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\"), [보드카 마티니 젓지 말고 흔들어서](/Edu/wiki/index.php/%EB%B3%B4%EB%93%9C%EC%B9%B4_%EB%A7%88%ED%8B%B0%EB%8B%88_%EC%A0%93%EC%A7%80_%EB%A7%90%EA%B3%A0_%ED%9D%94%EB%93%A4%EC%96%B4%EC%84%9C \"보드카 마티니 젓지 말고 흔들어서\") → [007 시리즈](/Edu/wiki/index.php/007_%EC%8B%9C%EB%A6%AC%EC%A6%88 \"007 시리즈\"), [보드카 마티니 젓지 말고 흔들어서](/Edu/wiki/index.php/%EB%B3%B4%EB%93%9C%EC%B9%B4_%EB%A7%88%ED%8B%B0%EB%8B%88_%EC%A0%93%EC%A7%80_%EB%A7%90%EA%B3%A0_%ED%9D%94%EB%93%A4%EC%96%B4%EC%84%9C \"보드카 마티니 젓지 말고 흔들어서\") → [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\"), [\"Bottoms Up\"](/Edu/wiki/index.php/%22Bottoms_Up%22 \"\\\"Bottoms Up\\\"\") → [007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\"), [\"Bottoms Up\"](/Edu/wiki/index.php/%22Bottoms_Up%22 \"\\\"Bottoms Up\\\"\") → [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\") |\n",
            "| ~에 해당된다 | [스트레인저 댄 픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\") → [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [판타지](/Edu/wiki/index.php/%ED%8C%90%ED%83%80%EC%A7%80 \"판타지\"), [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\") → [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [판타지](/Edu/wiki/index.php/%ED%8C%90%ED%83%80%EC%A7%80 \"판타지\"), [뮤지컬](/Edu/wiki/index.php/%EB%AE%A4%EC%A7%80%EC%BB%AC \"뮤지컬\"), [500일의 썸머](/Edu/wiki/index.php/500%EC%9D%BC%EC%9D%98_%EC%8D%B8%EB%A8%B82 \"500일의 썸머2\") → [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [졸업](/Edu/wiki/index.php/%EC%A1%B8%EC%97%852 \"졸업2\") → [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [라라랜드](/Edu/wiki/index.php/%EB%9D%BC%EB%9D%BC%EB%9E%9C%EB%93%9C2 \"라라랜드2\") → [뮤지컬](/Edu/wiki/index.php/%EB%AE%A4%EC%A7%80%EC%BB%AC \"뮤지컬\"), [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [이유 없는 반항](/Edu/wiki/index.php/%EC%9D%B4%EC%9C%A0_%EC%97%86%EB%8A%94_%EB%B0%98%ED%95%AD \"이유 없는 반항\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [충격의 복도](/Edu/wiki/index.php/%EC%B6%A9%EA%B2%A9%EC%9D%98_%EB%B3%B5%EB%8F%84 \"충격의 복도\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [미스터리](/Edu/wiki/index.php/%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%A6%AC \"미스터리\"), [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [007 골드핑거](/Edu/wiki/index.php/007_%EA%B3%A8%EB%93%9C%ED%95%91%EA%B1%B0 \"007 골드핑거\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [어바웃 타임](/Edu/wiki/index.php/%EC%96%B4%EB%B0%94%EC%9B%83_%ED%83%80%EC%9E%842 \"어바웃 타임2\") → [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\") → [서부](/Edu/wiki/index.php/%EC%84%9C%EB%B6%80 \"서부\"), [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [로리타](/Edu/wiki/index.php/%EB%A1%9C%EB%A6%AC%ED%83%80 \"로리타\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [프랑켄슈타인의 저주](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%BC%84%EC%8A%88%ED%83%80%EC%9D%B8%EC%9D%98_%EC%A0%80%EC%A3%BC \"프랑켄슈타인의 저주\") → [공포](/Edu/wiki/index.php/%EA%B3%B5%ED%8F%AC \"공포\"), [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\") → [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [SF](/Edu/wiki/index.php/SF \"SF\"), [세븐](/Edu/wiki/index.php/%EC%84%B8%EB%B8%90 \"세븐\") → [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\") →[드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\") , [하녀](/Edu/wiki/index.php/%ED%95%98%EB%85%80 \"하녀\") → [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [시계 태엽 오렌지](/Edu/wiki/index.php/%EC%8B%9C%EA%B3%84_%ED%83%9C%EC%97%BD_%EC%98%A4%EB%A0%8C%EC%A7%80 \"시계 태엽 오렌지\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [SF](/Edu/wiki/index.php/SF \"SF\"), [의지의 승리](/Edu/wiki/index.php/%EC%9D%98%EC%A7%80%EC%9D%98_%EC%8A%B9%EB%A6%AC \"의지의 승리\") → [다큐멘터리](/Edu/wiki/index.php/%EB%8B%A4%ED%81%90%EB%A9%98%ED%84%B0%EB%A6%AC \"다큐멘터리\"), [믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\") → [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\") → [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\") → [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\") → [모험](/Edu/wiki/index.php/%EB%AA%A8%ED%97%98 \"모험\"), [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\") → [SF](/Edu/wiki/index.php/SF \"SF\"), [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\") → [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\") → [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\") → [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [인터스텔라](/Edu/wiki/index.php/%EC%9D%B8%ED%84%B0%EC%8A%A4%ED%85%94%EB%9D%BC \"인터스텔라\") → [SF](/Edu/wiki/index.php/SF \"SF\"),[2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\") → [SF](/Edu/wiki/index.php/SF \"SF\"), [2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\") → [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [007 네버다이](/Edu/wiki/index.php/007_%EB%84%A4%EB%B2%84%EB%8B%A4%EC%9D%B4 \"007 네버다이\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\") → [모험](/Edu/wiki/index.php/%EB%AA%A8%ED%97%98 \"모험\"), [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\") → [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\") → [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\") → [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [007 죽느냐 사느냐](/Edu/wiki/index.php/007_%EC%A3%BD%EB%8A%90%EB%83%90_%EC%82%AC%EB%8A%90%EB%83%90 \"007 죽느냐 사느냐\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [007 죽느냐 사느냐](/Edu/wiki/index.php/007_%EC%A3%BD%EB%8A%90%EB%83%90_%EC%82%AC%EB%8A%90%EB%83%90 \"007 죽느냐 사느냐\") →[범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\") → [다큐멘터리](/Edu/wiki/index.php/%EB%8B%A4%ED%81%90%EB%A9%98%ED%84%B0%EB%A6%AC \"다큐멘터리\"), [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\") → [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\"), [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [잠수종과 나비](/Edu/wiki/index.php/%EC%9E%A0%EC%88%98%EC%A2%85%EA%B3%BC_%EB%82%98%EB%B9%84 \"잠수종과 나비\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\") → [뮤지컬](/Edu/wiki/index.php/%EB%AE%A4%EC%A7%80%EC%BB%AC \"뮤지컬\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\") → [멜로](/Edu/wiki/index.php/%EB%A9%9C%EB%A1%9C \"멜로\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\") → [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\"), [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\") → [모험](/Edu/wiki/index.php/%EB%AA%A8%ED%97%98 \"모험\"), [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\") → [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\"), [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\") → [모험](/Edu/wiki/index.php/%EB%AA%A8%ED%97%98 \"모험\"), [언터쳐블](/Edu/wiki/index.php/%EC%96%B8%ED%84%B0%EC%B3%90%EB%B8%94 \"언터쳐블\") → [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\"), [언터쳐블](/Edu/wiki/index.php/%EC%96%B8%ED%84%B0%EC%B3%90%EB%B8%94 \"언터쳐블\") → [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\"), [전함 포템킨](/Edu/wiki/index.php/%EC%A0%84%ED%95%A8_%ED%8F%AC%ED%85%9C%ED%82%A8 \"전함 포템킨\") → [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\") |\n",
            "| ~에 속한다 | [믹막 티르라리고 사람들](/Edu/wiki/index.php/%EB%AF%B9%EB%A7%89_%ED%8B%B0%EB%A5%B4%EB%9D%BC%EB%A6%AC%EA%B3%A0_%EC%82%AC%EB%9E%8C%EB%93%A4 \"믹막 티르라리고 사람들\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [빅슬립](/Edu/wiki/index.php/%EB%B9%85%EC%8A%AC%EB%A6%BD \"빅슬립\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [캡틴 아메리카 : 윈터솔져](/Edu/wiki/index.php/%EC%BA%A1%ED%8B%B4_%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4_:_%EC%9C%88%ED%84%B0%EC%86%94%EC%A0%B8 \"캡틴 아메리카 : 윈터솔져\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [펄프 픽션](/Edu/wiki/index.php/%ED%8E%84%ED%94%84_%ED%94%BD%EC%85%98 \"펄프 픽션\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [인터스텔라](/Edu/wiki/index.php/%EC%9D%B8%ED%84%B0%EC%8A%A4%ED%85%94%EB%9D%BC \"인터스텔라\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [2001 스페이스 오디세이](/Edu/wiki/index.php/2001_%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4_%EC%98%A4%EB%94%94%EC%84%B8%EC%9D%B4 \"2001 스페이스 오디세이\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [킹스맨](/Edu/wiki/index.php/%ED%82%B9%EC%8A%A4%EB%A7%A8 \"킹스맨\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [007 네버다이](/Edu/wiki/index.php/007_%EB%84%A4%EB%B2%84%EB%8B%A4%EC%9D%B4 \"007 네버다이\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [007 두 번 산다](/Edu/wiki/index.php/007_%EB%91%90_%EB%B2%88_%EC%82%B0%EB%8B%A4 \"007 두 번 산다\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [007 황금총을 가진 사나이](/Edu/wiki/index.php/007_%ED%99%A9%EA%B8%88%EC%B4%9D%EC%9D%84_%EA%B0%80%EC%A7%84_%EC%82%AC%EB%82%98%EC%9D%B4 \"007 황금총을 가진 사나이\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [007 스펙터](/Edu/wiki/index.php/007_%EC%8A%A4%ED%8E%99%ED%84%B0 \"007 스펙터\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [007 죽느냐 사느냐](/Edu/wiki/index.php/007_%EC%A3%BD%EB%8A%90%EB%83%90_%EC%82%AC%EB%8A%90%EB%83%90 \"007 죽느냐 사느냐\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [400번의 구타](/Edu/wiki/index.php/400%EB%B2%88%EC%9D%98_%EA%B5%AC%ED%83%80 \"400번의 구타\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [품행 제로](/Edu/wiki/index.php/%ED%92%88%ED%96%89_%EC%A0%9C%EB%A1%9C \"품행 제로\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [잠수종과 나비](/Edu/wiki/index.php/%EC%9E%A0%EC%88%98%EC%A2%85%EA%B3%BC_%EB%82%98%EB%B9%84 \"잠수종과 나비\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [라라랜드2](/Edu/wiki/index.php/%EB%9D%BC%EB%9D%BC%EB%9E%9C%EB%93%9C2 \"라라랜드2\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [쥬라기 월드](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EC%9B%94%EB%93%9C \"쥬라기 월드\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [쥬라기 공원](/Edu/wiki/index.php/%EC%A5%AC%EB%9D%BC%EA%B8%B0_%EA%B3%B5%EC%9B%90 \"쥬라기 공원\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [언터쳐블](/Edu/wiki/index.php/%EC%96%B8%ED%84%B0%EC%B3%90%EB%B8%94 \"언터쳐블\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [전함 포템킨](/Edu/wiki/index.php/%EC%A0%84%ED%95%A8_%ED%8F%AC%ED%85%9C%ED%82%A8 \"전함 포템킨\") → [영화 속 영화](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94 \"영화 속 영화\"), [스트레인저 댄 픽션](/Edu/wiki/index.php/%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B8%EC%A0%80_%EB%8C%84_%ED%94%BD%EC%85%98 \"스트레인저 댄 픽션\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [몬티 파이톤의 삶의 의미](/Edu/wiki/index.php/%EB%AA%AC%ED%8B%B0_%ED%8C%8C%EC%9D%B4%ED%86%A4%EC%9D%98_%EC%82%B6%EC%9D%98_%EC%9D%98%EB%AF%B8 \"몬티 파이톤의 삶의 의미\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [500일의 썸머](/Edu/wiki/index.php/500%EC%9D%BC%EC%9D%98_%EC%8D%B8%EB%A8%B82 \"500일의 썸머2\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [졸업](/Edu/wiki/index.php/%EC%A1%B8%EC%97%852 \"졸업2\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [이유 없는 반항](/Edu/wiki/index.php/%EC%9D%B4%EC%9C%A0_%EC%97%86%EB%8A%94_%EB%B0%98%ED%95%AD \"이유 없는 반항\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [몽상가들](/Edu/wiki/index.php/%EB%AA%BD%EC%83%81%EA%B0%80%EB%93%A4 \"몽상가들\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [충격의 복도](/Edu/wiki/index.php/%EC%B6%A9%EA%B2%A9%EC%9D%98_%EB%B3%B5%EB%8F%84 \"충격의 복도\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [캐치 미 이프 유 캔](/Edu/wiki/index.php/%EC%BA%90%EC%B9%98_%EB%AF%B8_%EC%9D%B4%ED%94%84_%EC%9C%A0_%EC%BA%94 \"캐치 미 이프 유 캔\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [007 골드핑거](/Edu/wiki/index.php/007_%EA%B3%A8%EB%93%9C%ED%95%91%EA%B1%B0 \"007 골드핑거\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [어바웃 타임](/Edu/wiki/index.php/%EC%96%B4%EB%B0%94%EC%9B%83_%ED%83%80%EC%9E%842 \"어바웃 타임2\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [평원의 무법자](/Edu/wiki/index.php/%ED%8F%89%EC%9B%90%EC%9D%98_%EB%AC%B4%EB%B2%95%EC%9E%90 \"평원의 무법자\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [로리타](/Edu/wiki/index.php/%EB%A1%9C%EB%A6%AC%ED%83%80 \"로리타\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [프랑켄슈타인의 저주](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%BC%84%EC%8A%88%ED%83%80%EC%9D%B8%EC%9D%98_%EC%A0%80%EC%A3%BC \"프랑켄슈타인의 저주\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [나비효과](/Edu/wiki/index.php/%EB%82%98%EB%B9%84%ED%9A%A8%EA%B3%BC \"나비효과\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [세븐](/Edu/wiki/index.php/%EC%84%B8%EB%B8%90 \"세븐\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [돈의 맛](/Edu/wiki/index.php/%EB%8F%88%EC%9D%98_%EB%A7%9B \"돈의 맛\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [하녀](/Edu/wiki/index.php/%ED%95%98%EB%85%80 \"하녀\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [시계 태엽 오렌지](/Edu/wiki/index.php/%EC%8B%9C%EA%B3%84_%ED%83%9C%EC%97%BD_%EC%98%A4%EB%A0%8C%EC%A7%80 \"시계 태엽 오렌지\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [의지의 승리](/Edu/wiki/index.php/%EC%9D%98%EC%A7%80%EC%9D%98_%EC%8A%B9%EB%A6%AC \"의지의 승리\") → [영화 속 영화관](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94%EA%B4%80 \"영화 속 영화관\"), [트로픽 썬더](/Edu/wiki/index.php/%ED%8A%B8%EB%A1%9C%ED%94%BD_%EC%8D%AC%EB%8D%94 \"트로픽 썬더\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [사랑과 경멸](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EA%B3%BC_%EA%B2%BD%EB%A9%B8 \"사랑과 경멸\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [휴고](/Edu/wiki/index.php/%ED%9C%B4%EA%B3%A0 \"휴고\"), → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [사랑은 비를 타고](/Edu/wiki/index.php/%EC%82%AC%EB%9E%91%EC%9D%80_%EB%B9%84%EB%A5%BC_%ED%83%80%EA%B3%A0 \"사랑은 비를 타고\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [부기 나이트](/Edu/wiki/index.php/%EB%B6%80%EA%B8%B0_%EB%82%98%EC%9D%B4%ED%8A%B8 \"부기 나이트\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [플레이어](/Edu/wiki/index.php/%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4 \"플레이어\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [아티스트](/Edu/wiki/index.php/%EC%95%84%ED%8B%B0%EC%8A%A4%ED%8A%B8 \"아티스트\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [에드 우드](/Edu/wiki/index.php/%EC%97%90%EB%93%9C_%EC%9A%B0%EB%93%9C \"에드 우드\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [비카인드 리와인드](/Edu/wiki/index.php/%EB%B9%84%EC%B9%B4%EC%9D%B8%EB%93%9C_%EB%A6%AC%EC%99%80%EC%9D%B8%EB%93%9C \"비카인드 리와인드\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [보우핑거](/Edu/wiki/index.php/%EB%B3%B4%EC%9A%B0%ED%95%91%EA%B1%B0 \"보우핑거\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [어댑테이션](/Edu/wiki/index.php/%EC%96%B4%EB%8C%91%ED%85%8C%EC%9D%B4%EC%85%98 \"어댑테이션\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [바톤 핑크](/Edu/wiki/index.php/%EB%B0%94%ED%86%A4_%ED%95%91%ED%81%AC \"바톤 핑크\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [아메리카의 밤](/Edu/wiki/index.php/%EC%95%84%EB%A9%94%EB%A6%AC%EC%B9%B4%EC%9D%98_%EB%B0%A4 \"아메리카의 밤\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [망각의 삶](/Edu/wiki/index.php/%EB%A7%9D%EA%B0%81%EC%9D%98_%EC%82%B6 \"망각의 삶\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [선셋 대로](/Edu/wiki/index.php/%EC%84%A0%EC%85%8B_%EB%8C%80%EB%A1%9C \"선셋 대로\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [8과 1/2](/Edu/wiki/index.php/8%EA%B3%BC_1/2 \"8과 1/2\") → [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\"), [드라마](/Edu/wiki/index.php/%EB%93%9C%EB%9D%BC%EB%A7%88 \"드라마\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [범죄](/Edu/wiki/index.php/%EB%B2%94%EC%A3%84 \"범죄\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [SF](/Edu/wiki/index.php/SF \"SF\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [갱스터](/Edu/wiki/index.php/%EA%B0%B1%EC%8A%A4%ED%84%B0 \"갱스터\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [공포](/Edu/wiki/index.php/%EA%B3%B5%ED%8F%AC \"공포\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [로맨스](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%EC%8A%A4 \"로맨스\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [로맨틱 코미디](/Edu/wiki/index.php/%EB%A1%9C%EB%A7%A8%ED%8B%B1_%EC%BD%94%EB%AF%B8%EB%94%94 \"로맨틱 코미디\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [코미디](/Edu/wiki/index.php/%EC%BD%94%EB%AF%B8%EB%94%94 \"코미디\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [멜로](/Edu/wiki/index.php/%EB%A9%9C%EB%A1%9C \"멜로\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [액션](/Edu/wiki/index.php/%EC%95%A1%EC%85%98 \"액션\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [서부](/Edu/wiki/index.php/%EC%84%9C%EB%B6%80 \"서부\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [느와르](/Edu/wiki/index.php/%EB%8A%90%EC%99%80%EB%A5%B4 \"느와르\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [스릴러](/Edu/wiki/index.php/%EC%8A%A4%EB%A6%B4%EB%9F%AC \"스릴러\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [미스터리](/Edu/wiki/index.php/%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%A6%AC \"미스터리\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [전쟁](/Edu/wiki/index.php/%EC%A0%84%EC%9F%81 \"전쟁\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [판타지](/Edu/wiki/index.php/%ED%8C%90%ED%83%80%EC%A7%80 \"판타지\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [다큐멘터리](/Edu/wiki/index.php/%EB%8B%A4%ED%81%90%EB%A9%98%ED%84%B0%EB%A6%AC \"다큐멘터리\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\"), [모험](/Edu/wiki/index.php/%EB%AA%A8%ED%97%98 \"모험\") → [장르](/Edu/wiki/index.php/%EC%9E%A5%EB%A5%B4 \"장르\") |\n",
            "| ~에 포함된다 | [자기 반영성](/Edu/wiki/index.php/%EC%9E%90%EA%B8%B0_%EB%B0%98%EC%98%81%EC%84%B1 \"자기 반영성\") → [동적 모티프](/Edu/wiki/index.php/%EB%8F%99%EC%A0%81_%EB%AA%A8%ED%8B%B0%ED%94%84 \"동적 모티프\") |\n",
            "| ~이다 | [영화 속 영화 제작](/Edu/wiki/index.php/%EC%98%81%ED%99%94_%EC%86%8D_%EC%98%81%ED%99%94_%EC%A0%9C%EC%9E%91 \"영화 속 영화 제작\") → [자기 반영성](/Edu/wiki/index.php/%EC%9E%90%EA%B8%B0_%EB%B0%98%EC%98%81%EC%84%B1 \"자기 반영성\") |\n",
            "| ~와 유사하다 | [레퍼런스](/Edu/wiki/index.php/%EB%A0%88%ED%8D%BC%EB%9F%B0%EC%8A%A4 \"레퍼런스\") → [자기 반영성](/Edu/wiki/index.php/%EC%9E%90%EA%B8%B0_%EB%B0%98%EC%98%81%EC%84%B1 \"자기 반영성\"), [표절](/Edu/wiki/index.php/%ED%91%9C%EC%A0%88 \"표절\") → [자기 반영성](/Edu/wiki/index.php/%EC%9E%90%EA%B8%B0_%EB%B0%98%EC%98%81%EC%84%B1 \"자기 반영성\"), [패러디](/Edu/wiki/index.php/%ED%8C%A8%EB%9F%AC%EB%94%94 \"패러디\") → [자기 반영성](/Edu/wiki/index.php/%EC%9E%90%EA%B8%B0_%EB%B0%98%EC%98%81%EC%84%B1 \"자기 반영성\"), [메타포](/Edu/wiki/index.php/%EB%A9%94%ED%83%80%ED%8F%AC \"메타포\") → [자기 반영성](/Edu/wiki/index.php/%EC%9E%90%EA%B8%B0_%EB%B0%98%EC%98%81%EC%84%B1 \"자기 반영성\") |\n",
            "| ~의 일부이다 | [익스트림 롱 쇼트](/Edu/wiki/index.php/%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%A6%BC_%EB%A1%B1_%EC%87%BC%ED%8A%B8 \"익스트림 롱 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [롱 쇼트](/Edu/wiki/index.php/%EB%A1%B1_%EC%87%BC%ED%8A%B8 \"롱 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [미디엄 쇼트](/Edu/wiki/index.php/%EB%AF%B8%EB%94%94%EC%97%84_%EC%87%BC%ED%8A%B8 \"미디엄 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [클로즈업 쇼트](/Edu/wiki/index.php/%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"클로즈업 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [익스트림 클로즈업 쇼트](/Edu/wiki/index.php/%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%A6%BC_%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"익스트림 클로즈업 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [풀 쇼트](/Edu/wiki/index.php/%ED%92%80_%EC%87%BC%ED%8A%B8 \"풀 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [니 쇼트](/Edu/wiki/index.php/%EB%8B%88_%EC%87%BC%ED%8A%B8 \"니 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [웨이스트 쇼트](/Edu/wiki/index.php/%EC%9B%A8%EC%9D%B4%EC%8A%A4%ED%8A%B8_%EC%87%BC%ED%8A%B8 \"웨이스트 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [바스트 쇼트](/Edu/wiki/index.php/%EB%B0%94%EC%8A%A4%ED%8A%B8_%EC%87%BC%ED%8A%B8 \"바스트 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [빅 클로즈업 쇼트](/Edu/wiki/index.php/%EB%B9%85_%ED%81%B4%EB%A1%9C%EC%A6%88%EC%97%85_%EC%87%BC%ED%8A%B8 \"빅 클로즈업 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [오버 더 숄더 쇼트](/Edu/wiki/index.php/%EC%98%A4%EB%B2%84_%EB%8D%94_%EC%88%84%EB%8D%94_%EC%87%BC%ED%8A%B8 \"오버 더 숄더 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [하이앵글](/Edu/wiki/index.php/%ED%95%98%EC%9D%B4%EC%95%B5%EA%B8%80 \"하이앵글\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [아이 레벨](/Edu/wiki/index.php/%EC%95%84%EC%9D%B4_%EB%A0%88%EB%B2%A8 \"아이 레벨\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [로우앵글](/Edu/wiki/index.php/%EB%A1%9C%EC%9A%B0%EC%95%B5%EA%B8%80 \"로우앵글\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [버즈 아이 뷰](/Edu/wiki/index.php/%EB%B2%84%EC%A6%88_%EC%95%84%EC%9D%B4_%EB%B7%B0 \"버즈 아이 뷰\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [사각앵글](/Edu/wiki/index.php/%EC%82%AC%EA%B0%81%EC%95%B5%EA%B8%80 \"사각앵글\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [헤드룸](/Edu/wiki/index.php/%ED%97%A4%EB%93%9C%EB%A3%B8 \"헤드룸\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [노즈룸](/Edu/wiki/index.php/%EB%85%B8%EC%A6%88%EB%A3%B8 \"노즈룸\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [리드룸](/Edu/wiki/index.php/%EB%A6%AC%EB%93%9C%EB%A3%B8 \"리드룸\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [팬](/Edu/wiki/index.php/%ED%8C%AC \"팬\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [틸트](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8 \"틸트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [익스트림 롱 쇼트](/Edu/wiki/index.php/%EC%9D%B5%EC%8A%A4%ED%8A%B8%EB%A6%BC_%EB%A1%B1_%EC%87%BC%ED%8A%B8 \"익스트림 롱 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [롱 쇼트](/Edu/wiki/index.php/%EB%A1%B1_%EC%87%BC%ED%8A%B8 \"롱 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [딥 포커스](/Edu/wiki/index.php/%EB%94%A5_%ED%8F%AC%EC%BB%A4%EC%8A%A4 \"딥 포커스\") → [롱 쇼트](/Edu/wiki/index.php/%EB%A1%B1_%EC%87%BC%ED%8A%B8 \"롱 쇼트\"), [퀵 팬](/Edu/wiki/index.php/%ED%80%B5_%ED%8C%AC \"퀵 팬\") → [팬](/Edu/wiki/index.php/%ED%8C%AC \"팬\"), [스위시 팬](/Edu/wiki/index.php/%EC%8A%A4%EC%9C%84%EC%8B%9C_%ED%8C%AC \"스위시 팬\") → [팬](/Edu/wiki/index.php/%ED%8C%AC \"팬\"), [플래시 팬](/Edu/wiki/index.php/%ED%94%8C%EB%9E%98%EC%8B%9C_%ED%8C%AC \"플래시 팬\") → [팬](/Edu/wiki/index.php/%ED%8C%AC \"팬\"), [틸트 업](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8_%EC%97%85 \"틸트 업\") → [틸트](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8 \"틸트\"), [틸트 다운](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8_%EB%8B%A4%EC%9A%B4 \"틸트 다운\") → [틸트](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8 \"틸트\"), [페디스털 쇼트](/Edu/wiki/index.php/%ED%8E%98%EB%94%94%EC%8A%A4%ED%84%B8_%EC%87%BC%ED%8A%B8 \"페디스털 쇼트\") → [틸트](/Edu/wiki/index.php/%ED%8B%B8%ED%8A%B8 \"틸트\"), [설정 쇼트](/Edu/wiki/index.php/%EC%84%A4%EC%A0%95_%EC%87%BC%ED%8A%B8 \"설정 쇼트\") → [재설정 쇼트](/Edu/wiki/index.php/%EC%9E%AC%EC%84%A4%EC%A0%95_%EC%87%BC%ED%8A%B8 \"재설정 쇼트\"), [부감](/Edu/wiki/index.php/%EB%B6%80%EA%B0%90 \"부감\") → [설정 쇼트](/Edu/wiki/index.php/%EC%84%A4%EC%A0%95_%EC%87%BC%ED%8A%B8 \"설정 쇼트\"), [설정 쇼트](/Edu/wiki/index.php/%EC%84%A4%EC%A0%95_%EC%87%BC%ED%8A%B8 \"설정 쇼트\") → [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\"), [신](/Edu/wiki/index.php/%EC%8B%A0 \"신\") → [시퀀스](/Edu/wiki/index.php/%EC%8B%9C%ED%80%80%EC%8A%A4 \"시퀀스\"), [테이크](/Edu/wiki/index.php/%ED%85%8C%EC%9D%B4%ED%81%AC \"테이크\") → [시퀀스](/Edu/wiki/index.php/%EC%8B%9C%ED%80%80%EC%8A%A4 \"시퀀스\"), [미장센](/Edu/wiki/index.php/%EB%AF%B8%EC%9E%A5%EC%84%BC \"미장센\") → [시퀀스](/Edu/wiki/index.php/%EC%8B%9C%ED%80%80%EC%8A%A4 \"시퀀스\"), [몽타주](/Edu/wiki/index.php/%EB%AA%BD%ED%83%80%EC%A3%BC \"몽타주\") → [시퀀스](/Edu/wiki/index.php/%EC%8B%9C%ED%80%80%EC%8A%A4 \"시퀀스\"), [쇼트](/Edu/wiki/index.php/%EC%87%BC%ED%8A%B8 \"쇼트\") → [시퀀스](/Edu/wiki/index.php/%EC%8B%9C%ED%80%80%EC%8A%A4 \"시퀀스\"), [이스터 에그](/Edu/wiki/index.php/%EC%9D%B4%EC%8A%A4%ED%84%B0_%EC%97%90%EA%B7%B8 \"이스터 에그\") → [자유 모티프](/Edu/wiki/index.php/%EC%9E%90%EC%9C%A0_%EB%AA%A8%ED%8B%B0%ED%94%84 \"자유 모티프\"), [오마주](/Edu/wiki/index.php/%EC%98%A4%EB%A7%88%EC%A3%BC \"오마주\") → [자유 모티프](/Edu/wiki/index.php/%EC%9E%90%EC%9C%A0_%EB%AA%A8%ED%8B%B0%ED%94%84 \"자유 모티프\"), [페르소나](/Edu/wiki/index.php/%ED%8E%98%EB%A5%B4%EC%86%8C%EB%82%98 \"페르소나\") → [자유 모티프](/Edu/wiki/index.php/%EC%9E%90%EC%9C%A0_%EB%AA%A8%ED%8B%B0%ED%94%84 \"자유 모티프\"), [자유 모티프](/Edu/wiki/index.php/%EC%9E%90%EC%9C%A0_%EB%AA%A8%ED%8B%B0%ED%94%84 \"자유 모티프\") → [모티프](/Edu/wiki/index.php/%EB%AA%A8%ED%8B%B0%ED%94%84 \"모티프\"), [한정 모티프](/Edu/wiki/index.php/%ED%95%9C%EC%A0%95_%EB%AA%A8%ED%8B%B0%ED%94%84 \"한정 모티프\") → [모티프](/Edu/wiki/index.php/%EB%AA%A8%ED%8B%B0%ED%94%84 \"모티프\"), [동적 모티프](/Edu/wiki/index.php/%EB%8F%99%EC%A0%81_%EB%AA%A8%ED%8B%B0%ED%94%84 \"동적 모티프\") → [모티프](/Edu/wiki/index.php/%EB%AA%A8%ED%8B%B0%ED%94%84 \"모티프\"), [정적 모티프](/Edu/wiki/index.php/%EC%A0%95%EC%A0%81_%EB%AA%A8%ED%8B%B0%ED%94%84 \"정적 모티프\") → [모티프](/Edu/wiki/index.php/%EB%AA%A8%ED%8B%B0%ED%94%84 \"모티프\"), [테이크](/Edu/wiki/index.php/%ED%85%8C%EC%9D%B4%ED%81%AC \"테이크\") → [시퀀스](/Edu/wiki/index.php/%EC%8B%9C%ED%80%80%EC%8A%A4 \"시퀀스\"), [롱 테이크](/Edu/wiki/index.php/%EB%A1%B1_%ED%85%8C%EC%9D%B4%ED%81%AC \"롱 테이크\") → [테이크](/Edu/wiki/index.php/%ED%85%8C%EC%9D%B4%ED%81%AC \"테이크\") |\n",
            "\n",
            "[스티븐 스필버그](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%90_%EC%8A%A4%ED%95%84%EB%B2%84%EA%B7%B8 \"스티븐 스필버그\") →[마틴 스콜세지](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B4_%EC%8A%A4%EC%BD%9C%EC%84%B8%EC%A7%80 \"마틴 스콜세지\"), [에릭 브래스](/Edu/wiki/index.php/%EC%97%90%EB%A6%AD_%EB%B8%8C%EB%9E%98%EC%8A%A4 \"에릭 브래스\") → [J.마키에 그러버](/Edu/wiki/index.php/J.%EB%A7%88%ED%82%A4%EC%97%90_%EA%B7%B8%EB%9F%AC%EB%B2%84 \"J.마키에 그러버\"), [J.마키에 그러버](/Edu/wiki/index.php/J.%EB%A7%88%ED%82%A4%EC%97%90_%EA%B7%B8%EB%9F%AC%EB%B2%84 \"J.마키에 그러버\") → [에릭 브래스](/Edu/wiki/index.php/%EC%97%90%EB%A6%AD_%EB%B8%8C%EB%9E%98%EC%8A%A4 \"에릭 브래스\"), [데이빗 핀처](/Edu/wiki/index.php/%EB%8D%B0%EC%9D%B4%EB%B9%97_%ED%95%80%EC%B2%98 \"데이빗 핀처\") → [스파이크 존즈](/Edu/wiki/index.php/%EC%8A%A4%ED%8C%8C%EC%9D%B4%ED%81%AC_%EC%A1%B4%EC%A6%88 \"스파이크 존즈\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") → [스티븐 스필버그](/Edu/wiki/index.php/%EC%8A%A4%ED%8B%B0%EB%B8%90_%EC%8A%A4%ED%95%84%EB%B2%84%EA%B7%B8 \"스티븐 스필버그\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") →[마틴 스콜세지](/Edu/wiki/index.php/%EB%A7%88%ED%8B%B4_%EC%8A%A4%EC%BD%9C%EC%84%B8%EC%A7%80 \"마틴 스콜세지\"), [스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") →[테리 길리엄](/Edu/wiki/index.php/%ED%85%8C%EB%A6%AC_%EA%B8%B8%EB%A6%AC%EC%97%84 \"테리 길리엄\"),[스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\") →[우디 앨런](/Edu/wiki/index.php/%EC%9A%B0%EB%94%94_%EC%95%A8%EB%9F%B0 \"우디 앨런\"), [레니 리펜슈탈](/Edu/wiki/index.php/%EB%A0%88%EB%8B%88_%EB%A6%AC%ED%8E%9C%EC%8A%88%ED%83%88 \"레니 리펜슈탈\") → [아돌프 히틀러](/Edu/wiki/index.php/%EC%95%84%EB%8F%8C%ED%94%84_%ED%9E%88%ED%8B%80%EB%9F%AC \"아돌프 히틀러\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\") → [사무엘 풀러](/Edu/wiki/index.php/%EC%82%AC%EB%AC%B4%EC%97%98_%ED%92%80%EB%9F%AC \"사무엘 풀러\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\")→[장 비고](/Edu/wiki/index.php/%EC%9E%A5_%EB%B9%84%EA%B3%A0 \"장 비고\"), [장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\")→[프랑수와 트뤼포](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%88%98%EC%99%80_%ED%8A%B8%EB%A4%BC%ED%8F%AC \"프랑수와 트뤼포\"), [폴 토마스 앤더슨](/Edu/wiki/index.php/%ED%8F%B4_%ED%86%A0%EB%A7%88%EC%8A%A4_%EC%95%A4%EB%8D%94%EC%8A%A8 \"폴 토마스 앤더슨\") → [로버트 알트만](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EC%95%8C%ED%8A%B8%EB%A7%8C \"로버트 알트만\"), [로버트 알트만](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EC%95%8C%ED%8A%B8%EB%A7%8C \"로버트 알트만\")→[폴 토마스 앤더슨](/Edu/wiki/index.php/%ED%8F%B4_%ED%86%A0%EB%A7%88%EC%8A%A4_%EC%95%A4%EB%8D%94%EC%8A%A8 \"폴 토마스 앤더슨\"), [미셸 아자나비슈스](/Edu/wiki/index.php/%EB%AF%B8%EC%85%B8_%EC%95%84%EC%9E%90%EB%82%98%EB%B9%84%EC%8A%88%EC%8A%A4 \"미셸 아자나비슈스\")→[장 뒤자르댕](/Edu/wiki/index.php/%EC%9E%A5_%EB%92%A4%EC%9E%90%EB%A5%B4%EB%8C%95 \"장 뒤자르댕\"),[페데리코 펠리니](/Edu/wiki/index.php/%ED%8E%98%EB%8D%B0%EB%A6%AC%EC%BD%94_%ED%8E%A0%EB%A6%AC%EB%8B%88 \"페데리코 펠리니\")→[마르첼로 마스트로얀니](/Edu/wiki/index.php/%EB%A7%88%EB%A5%B4%EC%B2%BC%EB%A1%9C_%EB%A7%88%EC%8A%A4%ED%8A%B8%EB%A1%9C%EC%96%80%EB%8B%88 \"마르첼로 마스트로얀니\")\n",
            ",[프랑수와 트뤼포](/Edu/wiki/index.php/%ED%94%84%EB%9E%91%EC%88%98%EC%99%80_%ED%8A%B8%EB%A4%BC%ED%8F%AC \"프랑수와 트뤼포\")→[장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\"),[우디 앨런](/Edu/wiki/index.php/%EC%9A%B0%EB%94%94_%EC%95%A8%EB%9F%B0 \"우디 앨런\")→[스탠리 큐브릭](/Edu/wiki/index.php/%EC%8A%A4%ED%83%A0%EB%A6%AC_%ED%81%90%EB%B8%8C%EB%A6%AD \"스탠리 큐브릭\"),[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\")→[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\"),[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\")→[크리스 에반스](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%97%90%EB%B0%98%EC%8A%A4 \"크리스 에반스\"),[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\")→[스칼렛 요한슨](/Edu/wiki/index.php/%EC%8A%A4%EC%B9%BC%EB%A0%9B_%EC%9A%94%ED%95%9C%EC%8A%A8 \"스칼렛 요한슨\"),[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[조 루소](/Edu/wiki/index.php/%EC%A1%B0_%EB%A3%A8%EC%86%8C \"조 루소\"),[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[크리스 에반스](/Edu/wiki/index.php/%ED%81%AC%EB%A6%AC%EC%8A%A4_%EC%97%90%EB%B0%98%EC%8A%A4 \"크리스 에반스\"),[안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[스칼렛 요한슨](/Edu/wiki/index.php/%EC%8A%A4%EC%B9%BC%EB%A0%9B_%EC%9A%94%ED%95%9C%EC%8A%A8 \"스칼렛 요한슨\"), [안소니 루소](/Edu/wiki/index.php/%EC%95%88%EC%86%8C%EB%8B%88_%EB%A3%A8%EC%86%8C \"안소니 루소\")→[로버트 다우니 주니어](/Edu/wiki/index.php/%EB%A1%9C%EB%B2%84%ED%8A%B8_%EB%8B%A4%EC%9A%B0%EB%8B%88_%EC%A3%BC%EB%8B%88%EC%96%B4 \"로버트 다우니 주니어\"),[매튜 본](/Edu/wiki/index.php/%EB%A7%A4%ED%8A%9C_%EB%B3%B8 \"매튜 본\")→[콜린 퍼스](/Edu/wiki/index.php/%EC%BD%9C%EB%A6%B0_%ED%8D%BC%EC%8A%A4 \"콜린 퍼스\"),[장 비고](/Edu/wiki/index.php/%EC%9E%A5_%EB%B9%84%EA%B3%A0 \"장 비고\")→[장 뤽 고다르](/Edu/wiki/index.php/%EC%9E%A5_%EB%A4%BD_%EA%B3%A0%EB%8B%A4%EB%A5%B4 \"장 뤽 고다르\"),[세르게이 에이젠슈타인](/Edu/wiki/index.php/%EC%84%B8%EB%A5%B4%EA%B2%8C%EC%9D%B4_%EC%97%90%EC%9D%B4%EC%A0%A0%EC%8A%88%ED%83%80%EC%9D%B8 \"세르게이 에이젠슈타인\")→[찰리 채플린](/Edu/wiki/index.php/%EC%B0%B0%EB%A6%AC_%EC%B1%84%ED%94%8C%EB%A6%B0 \"찰리 채플린\")\n",
            "\n",
            "## 둘러보기 메뉴\n",
            "\n",
            "### 개인 도구\n",
            "\n",
            "### 이름공간\n",
            "\n",
            "### \n",
            "\n",
            "### 변수\n",
            "\n",
            "### 보기\n",
            "\n",
            "### 행위\n",
            "\n",
            "### 검색\n",
            "\n",
            "### 둘러보기\n",
            "\n",
            "### 도구\n",
            "\n",
            "### 인쇄/내보내기\n",
            "\n",
            "![크리에이티브 커먼즈 저작자표시-동일조건변경허락](/Edu/wiki/skins/common/images/cc-by-sa.png)\n",
            "![Powered by MediaWiki](/Edu/wiki/skins/common/images/poweredby_mediawiki_88x31.png)\n",
            "---\n",
            "TITLE: 레오나르도 디카프리오 데뷔당시 나이가 몇살인가요? - 네이버 지식iN\n",
            "URL:https://m.kin.naver.com/qna/dirs/31401/docs/456986534?qnaDetailTrackingCode=end_similar_list\n",
            "Content:레오나르도 디카프리오는 1974년 11월 11일 미국 캘리포니아 주 할리우드에서 태어났으며, 부모는 조지 디카프리오와 이멀린 인덴비르켄입니다. 4살 무렵부터 CF나 TV\n",
            "---\n",
            "TITLE: [ 영화 정보 ] 레오나르도 디카프리오 출연작 - 에디의 영화감상\n",
            "URL:https://eddynote.tistory.com/entry/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84-%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4\n",
            "Content:# [에디의 영화감상](https://eddynote.tistory.com/)\n",
            "\n",
            "![블로그 이미지](https://tistory1.daumcdn.net/tistory/1481590/attach/f1afe320f86b49dd9e7d51aad8c74d9d)\n",
            "\n",
            "# [ 영화 정보 ] 레오나르도 디카프리오 출연작\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/ROiv3/btrJ70paUQh/AAAAAAAAAAAAAAAAAAAAAB-vWbOO9copVQuJUuvL98iCSeujD-TlJoXc_7Sf_DKa/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=9s5iooeCO2ggCG0T7lcJoZwxcAg%3D)![](https://blog.kakaocdn.net/dna/buDrWp/btrKcvHZrP8/AAAAAAAAAAAAAAAAAAAAAKLgDN6ARnNhrwQUOV8nDdEp2RwvEccKE1Y0oNdAPL8t/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=ZlsMo8AiTHoYrOM5Lka9Uv8mZjQ%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/ROiv3/btrJ70paUQh/AAAAAAAAAAAAAAAAAAAAAB-vWbOO9copVQuJUuvL98iCSeujD-TlJoXc_7Sf_DKa/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=9s5iooeCO2ggCG0T7lcJoZwxcAg%3D)\n",
            "![](https://blog.kakaocdn.net/dna/buDrWp/btrKcvHZrP8/AAAAAAAAAAAAAAAAAAAAAKLgDN6ARnNhrwQUOV8nDdEp2RwvEccKE1Y0oNdAPL8t/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=ZlsMo8AiTHoYrOM5Lka9Uv8mZjQ%3D)\n",
            "\n",
            "#### **- 출생: 1974년 11월 11일**\n",
            "\n",
            "#### **- 신체: 183cm,  83kg**\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/QTD3k/btrJ7SdUEBI/AAAAAAAAAAAAAAAAAAAAADRbWrUA3edOGmgvcbTholK14rx_S1eUt4Yx1osugVI6/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=aH2dorgPfC4IpE26Q%2F2UgaFWEKQ%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/QTD3k/btrJ7SdUEBI/AAAAAAAAAAAAAAAAAAAAADRbWrUA3edOGmgvcbTholK14rx_S1eUt4Yx1osugVI6/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=aH2dorgPfC4IpE26Q%2F2UgaFWEKQ%3D)\n",
            "\n",
            "#### **>>> 디카프리오 주연 작품 들**\n",
            "\n",
            "|  |  |  |  |  |\n",
            "| --- | --- | --- | --- | --- |\n",
            "| **년도** | **나이** | **작품명** | **등급** | **비고** |\n",
            "| **1991** | **17** | **크리터스 3** | **청불** | **데뷔작** |\n",
            "| **1993** | **19** | **이 소년의 삶** | **청불** |  |\n",
            "| **1993** | **19** | **길버트 그레이프** | **12세** |  |\n",
            "| **1995** | **21** | **퀵 앤 데드** | **15세** |  |\n",
            "| **1995** | **21** | **바스켓볼 다이어리** | **청불** |  |\n",
            "| **1995** | **21** | **토탈 이클립스** | **청불** |  |\n",
            "| **1996** | **22** | **로미오와 줄리엣** | **15세** |  |\n",
            "| **1997** | **23** | **타이타닉** | **15세** | **최고 흥행작** |\n",
            "| **1998** | **24** | **아이언 마스크** | **15세** |  |\n",
            "| **1998** | **24** | **셀러브리티** | **청불** |  |\n",
            "| **2000** | **26** | **비치** | 청불 |  |\n",
            "| **2002** | **28** | **갱스 오브 뉴욕** | 청불 |  |\n",
            "| **2002** | **28** | **캐치 미 이프 유 캔** | 15세 | 스티븐 스필버그 감독 |\n",
            "| **2004** | **30** | **에비에이터** | 15세 |  |\n",
            "| **2006** | **32** | **디파티드** | 15세 | With 맷 데이먼 ,  무간도? |\n",
            "| **2006** | **32** | **블러드 다이아몬드** | 청불 | 띵작 |\n",
            "| **2008** | **34** | **바디 오브 라이즈** | 15세 | 리들리 스콧 감독 |\n",
            "| **2008** | **34** | **레볼루셔너리 로드** | 청불 |  |\n",
            "| **2010** | **36** | **셔터 아일랜드** | 15세 |  |\n",
            "| **2010** | **36** | **인셉션** | 12세 |  |\n",
            "| **2011** | **37** | **J.에드가** | 청불 |  |\n",
            "| **2012** | **38** | **장고: 분노의 추적자** | 청불 |  |\n",
            "| **2013** | **39** | **위대한 개츠비** | 15세 |  |\n",
            "| **2013** | **39** | **더 울프 오브 월스트리트** | 청불 |  |\n",
            "| **2015** | **41** | **레버넌트: 죽음에서 돌아온자** | 15세 | **아카데미 남우주연상** |\n",
            "| **2019** | **45** | **원스 어폰 어 타임 인 헐리우드** | 청불 |  |\n",
            "| **2021** | **47** | **돈 룩 업** | 15세 | 넷플릭스 |\n",
            "| **2022.11(예정)** | **48** | **킬러스 오브 더 플라워 문** | - | 애플 TV+ |\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/biTcyY/btrJ9uwh9uE/AAAAAAAAAAAAAAAAAAAAACZXxcJkb5oZj3GYswtidohgbufutiuFNVP278VxqZNu/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=RNEYhqAmIdTHhmuIMF4xM0J5YKk%3D)\n",
            "\n",
            "토탈 이클립스\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/biTcyY/btrJ9uwh9uE/AAAAAAAAAAAAAAAAAAAAACZXxcJkb5oZj3GYswtidohgbufutiuFNVP278VxqZNu/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=RNEYhqAmIdTHhmuIMF4xM0J5YKk%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cjtABp/btrJ7TcOHRd/AAAAAAAAAAAAAAAAAAAAADaBNXM23L-lMhEme6ddCbu_XEj4zpZJZJ4X-MzKFEb-/img.gif?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=NMd%2B%2Bs2sG7XOFDE0XDKBw1UYj1M%3D)\n",
            "\n",
            "퀵앤데드\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cjtABp/btrJ7TcOHRd/AAAAAAAAAAAAAAAAAAAAADaBNXM23L-lMhEme6ddCbu_XEj4zpZJZJ4X-MzKFEb-/img.gif?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=NMd%2B%2Bs2sG7XOFDE0XDKBw1UYj1M%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/sxaPd/btrJ7mMmDIH/AAAAAAAAAAAAAAAAAAAAAE_jPKeQNty8sgMmMgy-jlD6vjqg1VIZUVqgd9VvhULl/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=qkjYRLoxsgI6kgplmFtbjWUfzzs%3D)\n",
            "\n",
            "타이타닉\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/sxaPd/btrJ7mMmDIH/AAAAAAAAAAAAAAAAAAAAAE_jPKeQNty8sgMmMgy-jlD6vjqg1VIZUVqgd9VvhULl/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=qkjYRLoxsgI6kgplmFtbjWUfzzs%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/H9wDd/btrJ8re42xW/AAAAAAAAAAAAAAAAAAAAAAyrc9fziT1KDd5tqlctn89svZPju98kcCyD3Csc7oPV/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=oUCwh%2Fn2UuWlg%2BiTH4DERYkYt3s%3D)\n",
            "\n",
            "캐치미 이프 유 캔\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/H9wDd/btrJ8re42xW/AAAAAAAAAAAAAAAAAAAAAAyrc9fziT1KDd5tqlctn89svZPju98kcCyD3Csc7oPV/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=oUCwh%2Fn2UuWlg%2BiTH4DERYkYt3s%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/biw5zZ/btrKcxlu8At/AAAAAAAAAAAAAAAAAAAAANhP79lBwFbKjkoKB0z6Y9uF6cbwcQxVXi192ExKwLVb/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=zXmeXJw%2BqXjNVHPTAHxGGYsP%2FLA%3D)\n",
            "\n",
            "에비에이터\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/biw5zZ/btrKcxlu8At/AAAAAAAAAAAAAAAAAAAAANhP79lBwFbKjkoKB0z6Y9uF6cbwcQxVXi192ExKwLVb/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=zXmeXJw%2BqXjNVHPTAHxGGYsP%2FLA%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/MrwQE/btrKeuhwkFk/AAAAAAAAAAAAAAAAAAAAAMUwWZfVUo--PNyVFb_2tjh-9AomiOX71-y5SBHuzwDH/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=bUST7MQIIHX3JZXsTkzdIs%2F1VLo%3D)\n",
            "\n",
            "블러드 다이아몬드\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/MrwQE/btrKeuhwkFk/AAAAAAAAAAAAAAAAAAAAAMUwWZfVUo--PNyVFb_2tjh-9AomiOX71-y5SBHuzwDH/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=bUST7MQIIHX3JZXsTkzdIs%2F1VLo%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cuy7LR/btrKdQ6aLKZ/AAAAAAAAAAAAAAAAAAAAAJkkp8-PwZtbpaoN0iZHshNpqJ49ObW7vLaIHg6Y-KzR/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=%2FfR%2FEN0GlLtvK3dtyJtEOym9b1o%3D)\n",
            "\n",
            "인셉션\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cuy7LR/btrKdQ6aLKZ/AAAAAAAAAAAAAAAAAAAAAJkkp8-PwZtbpaoN0iZHshNpqJ49ObW7vLaIHg6Y-KzR/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=%2FfR%2FEN0GlLtvK3dtyJtEOym9b1o%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cLSaYJ/btrJ802AwBX/AAAAAAAAAAAAAAAAAAAAAFxMn3K0Peb4jnB5aH9qgv3WGISYhW9uO051XCLO82lV/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=HVSJzUIoEM%2BU9e%2Bj3pW50cI%2BShM%3D)\n",
            "\n",
            "더 울프 오브 월스트리트\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cLSaYJ/btrJ802AwBX/AAAAAAAAAAAAAAAAAAAAAFxMn3K0Peb4jnB5aH9qgv3WGISYhW9uO051XCLO82lV/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=HVSJzUIoEM%2BU9e%2Bj3pW50cI%2BShM%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cuOMcl/btrJ7SkEe8N/AAAAAAAAAAAAAAAAAAAAAAVRjaHZ8jFxCBWlAbjJsrn7zSkqDEBVs0VBixywg0-i/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=%2BhYwnJcLpWgUMiSqBXGlNFLTPIQ%3D)\n",
            "\n",
            "레버넌트\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cuOMcl/btrJ7SkEe8N/AAAAAAAAAAAAAAAAAAAAAAVRjaHZ8jFxCBWlAbjJsrn7zSkqDEBVs0VBixywg0-i/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=%2BhYwnJcLpWgUMiSqBXGlNFLTPIQ%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/EKDvl/btrJ9vaTJ07/AAAAAAAAAAAAAAAAAAAAAAT_cO-YYdDeCEVuflS0JcheNJ8JZVQt9NjYj5pLLnNq/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=NhbnKVtBLBJK9D%2FX9JHZE1s8wDA%3D)\n",
            "\n",
            "원스 어퍼폰 어 타임 인 할리우드\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/EKDvl/btrJ9vaTJ07/AAAAAAAAAAAAAAAAAAAAAAT_cO-YYdDeCEVuflS0JcheNJ8JZVQt9NjYj5pLLnNq/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=NhbnKVtBLBJK9D%2FX9JHZE1s8wDA%3D)\n",
            "\n",
            "#### **그의 영화들 ..**\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/croN38/btrJ74LgvXg/AAAAAAAAAAAAAAAAAAAAAAbAwZCRAI38tIlLa1TRV_DvcdfMxyKU843GOz4t46bF/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=MbS%2FF7PNtkJLO276jvoNJvjEljM%3D)![](https://blog.kakaocdn.net/dna/bfZStS/btrJ8IoclZO/AAAAAAAAAAAAAAAAAAAAAKs1zD7Gp2ME75yCScNCkWAmk7fuEyd3uqCVms7yDM5Q/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=7XQBrtRx6%2BkvV0%2BaMTQC89PSkYo%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/croN38/btrJ74LgvXg/AAAAAAAAAAAAAAAAAAAAAAbAwZCRAI38tIlLa1TRV_DvcdfMxyKU843GOz4t46bF/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=MbS%2FF7PNtkJLO276jvoNJvjEljM%3D)\n",
            "![](https://blog.kakaocdn.net/dna/bfZStS/btrJ8IoclZO/AAAAAAAAAAAAAAAAAAAAAKs1zD7Gp2ME75yCScNCkWAmk7fuEyd3uqCVms7yDM5Q/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=7XQBrtRx6%2BkvV0%2BaMTQC89PSkYo%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cPcfj9/btrJ9u4kogD/AAAAAAAAAAAAAAAAAAAAANu-Xj-8a_Tcak9PRYG8LAxGudE-xQBn8YuVGYCH7jk3/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=5F0wgAH0KmpJQ0npcSg42bfgESo%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/cPcfj9/btrJ9u4kogD/AAAAAAAAAAAAAAAAAAAAANu-Xj-8a_Tcak9PRYG8LAxGudE-xQBn8YuVGYCH7jk3/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=5F0wgAH0KmpJQ0npcSg42bfgESo%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/FgtIe/btrJ7bqOJde/AAAAAAAAAAAAAAAAAAAAABcA8Lj_2iZcRYGm5IQqsp7USM7PyUghbGj-f65bHy4o/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=tTo%2BsacDkXHHMcWYvRJqFgvDsgI%3D)![](https://blog.kakaocdn.net/dna/LfSS0/btrKb7mHZYe/AAAAAAAAAAAAAAAAAAAAALgzpiA2QmZr52bezVe6w6XKwn8kPGkWwp4FIdG6_vPP/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=mMrX7AFhxcnXYvg94qDshRsLTA4%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/FgtIe/btrJ7bqOJde/AAAAAAAAAAAAAAAAAAAAABcA8Lj_2iZcRYGm5IQqsp7USM7PyUghbGj-f65bHy4o/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=tTo%2BsacDkXHHMcWYvRJqFgvDsgI%3D)\n",
            "![](https://blog.kakaocdn.net/dna/LfSS0/btrKb7mHZYe/AAAAAAAAAAAAAAAAAAAAALgzpiA2QmZr52bezVe6w6XKwn8kPGkWwp4FIdG6_vPP/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=mMrX7AFhxcnXYvg94qDshRsLTA4%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/blozBf/btrJ8ZJthLH/AAAAAAAAAAAAAAAAAAAAAAHvrKj00gqQs88BB_9015iZqEyFS9Usu_QE9TY5lma4/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=0x6pyXWNoIUunPJwbrSZcGzw%2Bd0%3D)![](https://blog.kakaocdn.net/dna/60nlT/btrJ7ndsRz0/AAAAAAAAAAAAAAAAAAAAANnS3s9AASO3qEdhN8L9uRkw0uJ0sDp0BymccR6ab1Bl/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=1QKO5ubpdu%2BCXISsvsu8T1Ow5CM%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/blozBf/btrJ8ZJthLH/AAAAAAAAAAAAAAAAAAAAAAHvrKj00gqQs88BB_9015iZqEyFS9Usu_QE9TY5lma4/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=0x6pyXWNoIUunPJwbrSZcGzw%2Bd0%3D)\n",
            "![](https://blog.kakaocdn.net/dna/60nlT/btrJ7ndsRz0/AAAAAAAAAAAAAAAAAAAAANnS3s9AASO3qEdhN8L9uRkw0uJ0sDp0BymccR6ab1Bl/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=1QKO5ubpdu%2BCXISsvsu8T1Ow5CM%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/crSwWO/btrKevt7JlX/AAAAAAAAAAAAAAAAAAAAALoUQZw34HUDdyoNauyCtdwUI24K9Q-8N93E6gY5RjVn/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=XW2TnSVk4udLEgKHsA2FVmKXxvo%3D)![](https://blog.kakaocdn.net/dna/cifXTn/btrJ71aIjgb/AAAAAAAAAAAAAAAAAAAAAGR58uvzb2NBixIguKiJjx10ZoDTht5ZM9BkzK40njQr/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=RsWds1JoUHGK1K4UotwH6f%2BJgUQ%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/crSwWO/btrKevt7JlX/AAAAAAAAAAAAAAAAAAAAALoUQZw34HUDdyoNauyCtdwUI24K9Q-8N93E6gY5RjVn/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=XW2TnSVk4udLEgKHsA2FVmKXxvo%3D)\n",
            "![](https://blog.kakaocdn.net/dna/cifXTn/btrJ71aIjgb/AAAAAAAAAAAAAAAAAAAAAGR58uvzb2NBixIguKiJjx10ZoDTht5ZM9BkzK40njQr/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=RsWds1JoUHGK1K4UotwH6f%2BJgUQ%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/TSLqL/btrJ8I9x1Lx/AAAAAAAAAAAAAAAAAAAAAKgANYvOUFcDTUV5CcD9lEB7Ct0RNjYvKWuK2rkZgs-k/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=YsFU8SjAnZR2VK0lZ2Z2DYp3HWo%3D)![](https://blog.kakaocdn.net/dna/pkQJe/btrKb8y7LHK/AAAAAAAAAAAAAAAAAAAAANaUkTsupzajR_RVkV7NR28jr9wzBiJBhhmr-KI6fiWT/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=QHjjLy4Y7p54jX4v1nUfZOhmmic%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/TSLqL/btrJ8I9x1Lx/AAAAAAAAAAAAAAAAAAAAAKgANYvOUFcDTUV5CcD9lEB7Ct0RNjYvKWuK2rkZgs-k/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=YsFU8SjAnZR2VK0lZ2Z2DYp3HWo%3D)\n",
            "![](https://blog.kakaocdn.net/dna/pkQJe/btrKb8y7LHK/AAAAAAAAAAAAAAAAAAAAANaUkTsupzajR_RVkV7NR28jr9wzBiJBhhmr-KI6fiWT/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=QHjjLy4Y7p54jX4v1nUfZOhmmic%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/vyXmp/btrKax0Mv4h/AAAAAAAAAAAAAAAAAAAAADUO7appw4dUgmCHibvDOSKLcH74o9uoGcTCY2idsMSX/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=bvoVI%2FiHNKhQvfiw06A3STJa0wg%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/vyXmp/btrKax0Mv4h/AAAAAAAAAAAAAAAAAAAAADUO7appw4dUgmCHibvDOSKLcH74o9uoGcTCY2idsMSX/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=bvoVI%2FiHNKhQvfiw06A3STJa0wg%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/bwur09/btrKcvBolhj/AAAAAAAAAAAAAAAAAAAAAF8tHoSJ4yuACW8d4YnJPhDPSO9Swsa0_ldDzGgIg_Zd/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=U8tO6XcV2Wokzu3kY7y%2BasdinUc%3D)![](https://blog.kakaocdn.net/dna/PYJS8/btrKayZH7jk/AAAAAAAAAAAAAAAAAAAAADxClUoC9irX-ex_r1zaLKnY34UW-wNFjpAP7p46bX9S/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=sskqeQfmlUPHKRAeMMFXqFxmUiY%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/bwur09/btrKcvBolhj/AAAAAAAAAAAAAAAAAAAAAF8tHoSJ4yuACW8d4YnJPhDPSO9Swsa0_ldDzGgIg_Zd/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=U8tO6XcV2Wokzu3kY7y%2BasdinUc%3D)\n",
            "![](https://blog.kakaocdn.net/dna/PYJS8/btrKayZH7jk/AAAAAAAAAAAAAAAAAAAAADxClUoC9irX-ex_r1zaLKnY34UW-wNFjpAP7p46bX9S/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=sskqeQfmlUPHKRAeMMFXqFxmUiY%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/bLSzMU/btrJ75QVnmP/AAAAAAAAAAAAAAAAAAAAAPXefdUQ8lDacmWGu4iU10I1ZqKo4tWpJrwf3-FTVlQy/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=NZ2MlJxNPhwH1QLasvRpr%2BTqZa4%3D)![](https://blog.kakaocdn.net/dna/zCmYN/btrKetwj8qX/AAAAAAAAAAAAAAAAAAAAAEOQk-LjAV-Y70AEKYq7VAu0QbO8cfajrtNlSFW3CaLI/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=Z3yVhLKUrb0WMeeM2%2BU2L1FhZaA%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/bLSzMU/btrJ75QVnmP/AAAAAAAAAAAAAAAAAAAAAPXefdUQ8lDacmWGu4iU10I1ZqKo4tWpJrwf3-FTVlQy/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=NZ2MlJxNPhwH1QLasvRpr%2BTqZa4%3D)\n",
            "![](https://blog.kakaocdn.net/dna/zCmYN/btrKetwj8qX/AAAAAAAAAAAAAAAAAAAAAEOQk-LjAV-Y70AEKYq7VAu0QbO8cfajrtNlSFW3CaLI/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=Z3yVhLKUrb0WMeeM2%2BU2L1FhZaA%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/vd6q3/btrJ70QnNuT/AAAAAAAAAAAAAAAAAAAAADkXESe9TT1ilhtcYlldZxgk1k8voEGJZkzpQVMbIMqD/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=PLXi0FZUOv94jwpf4DIMOwqI%2F7w%3D)![](https://blog.kakaocdn.net/dna/dtE5M2/btrJ71PhD7q/AAAAAAAAAAAAAAAAAAAAAPWe4uiqW3QLaGnoH7PLgeNWeDmMRzkiBr4v2uYGQNLA/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=dsPDbE471xd%2FXecMwFEbx%2Fu4tVs%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/vd6q3/btrJ70QnNuT/AAAAAAAAAAAAAAAAAAAAADkXESe9TT1ilhtcYlldZxgk1k8voEGJZkzpQVMbIMqD/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=PLXi0FZUOv94jwpf4DIMOwqI%2F7w%3D)\n",
            "![](https://blog.kakaocdn.net/dna/dtE5M2/btrJ71PhD7q/AAAAAAAAAAAAAAAAAAAAAPWe4uiqW3QLaGnoH7PLgeNWeDmMRzkiBr4v2uYGQNLA/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=dsPDbE471xd%2FXecMwFEbx%2Fu4tVs%3D)\n",
            "\n",
            "마지막으로.. 그의 화려한 여성편력을 정리한 Reddit 자료\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/A1AAd/btrJ8Ihop3r/AAAAAAAAAAAAAAAAAAAAAEyM_XWUacdc0gi5dkBNwE2GP6jduYLXAKkF4bC8SJu9/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=wTqp6ul8bywBrEoISw7oEWum0JI%3D)\n",
            "\n",
            "![](https://blog.kakaocdn.net/dna/A1AAd/btrJ8Ihop3r/AAAAAAAAAAAAAAAAAAAAAEyM_XWUacdc0gi5dkBNwE2GP6jduYLXAKkF4bC8SJu9/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1761922799&allow_ip=&allow_referer=&signature=wTqp6ul8bywBrEoISw7oEWum0JI%3D)\n",
            "\n",
            "## 공지사항\n",
            "\n",
            "## 최근글\n",
            "\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FcLzNrT%2Fbtr891bdKXr%2FAAAAAAAAAAAAAAAAAAAAABjLShBPF9s2H1XxMqnTR41ChFNl2AmilpuexdHco-bH%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DofmGDGJ0ZVxcbDpVrUxnAOZ9gqc%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FyVKiU%2Fbtr9kPDaQfq%2FAAAAAAAAAAAAAAAAAAAAADL-zm5I2yHoJinEmpUd6eG0uUJpNbugwfQez8OtLYcA%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3Dj6xR7y6%252FEVTrGIJyAnd8VcYQo7g%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FbS2HPx%2Fbtr6BBfGG9n%2FAAAAAAAAAAAAAAAAAAAAAJ6Gvgdkz3FEAqOhaLYt-KEz2Nxls20uWOdK0ZdSJTJP%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3D1MT656cEx%252FX1r8tr0Y6rkxroa6g%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fs91wc%2Fbtr43P7eykY%2FAAAAAAAAAAAAAAAAAAAAAP3lxetzmnjaUrJoH1akFAcrOyuksV0JgqCwC5afnWM3%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DccpUSHhR92CzEeIy8xb1l4y2gKc%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FdB67yP%2Fbtr4Ds0alpx%2FAAAAAAAAAAAAAAAAAAAAABmydiPIvMwO1yBZB0TeetTXlWIbmqAW4pVwDSBHyKNO%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3D4kTvA2ABRuZzdHLN96zp8k2NHLo%253D)\n",
            "\n",
            "## 인기글\n",
            "\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fbcskvn%2FbtrLgTI9agz%2FAAAAAAAAAAAAAAAAAAAAALX8O9vTYsbubcMVbtsrRS5CPsJvIsFgZlqJBBdw2zUp%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3Dt%252FBE9fg3dlqJGc9TlcBnWLSmlfI%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FbI1rgU%2FbtrPNbZfNPl%2FAAAAAAAAAAAAAAAAAAAAADAFKCLIU-v-4dkw62_EcrJnSnY0i1QA3uT493C13pO0%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3Dw0zvi%252FIEmGy7g3%252Fw702KAm38%252BOo%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2F2XlWk%2FbtrZYS8HZjY%2FAAAAAAAAAAAAAAAAAAAAAJU5daQLQCf4eEF7yhnAvLjYETUgmYz2OEdvOoIWAyJ9%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DrFYWMDanxY%252FRaep9St41BgcWENM%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FdhrpWw%2FbtrVqf1NTON%2FAAAAAAAAAAAAAAAAAAAAANup-vvwNr8AsZRIxrxrESVPw6nf0QwQIji3wlsAGrOL%2Fimg.jpg%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DLmvscUf36aZiqRcbsoFFSLl1JSE%253D)\n",
            "![](//i1.daumcdn.net/thumb/C58x58.fwebp.q85/?fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fblc43G%2FbtrUdfXPJra%2FAAAAAAAAAAAAAAAAAAAAAFxsFiENcV8ul55fGUglMZ86GP_AxnJDJ7yAzKRUHYy-%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1761922799%26allow_ip%3D%26allow_referer%3D%26signature%3DWbdbNZkL7OPcz8CoJV28aGRufjg%253D)\n",
            "\n",
            "## 최근댓글\n",
            "\n",
            "## 전체 방문자\n",
            "\n",
            "71,363\n",
            "\n",
            "Today : 4\n",
            "\n",
            "Yesterday : 7\n",
            "\n",
            "Designed by 티스토리\n",
            "\n",
            "© Kakao Corp.\n",
            "\n",
            "## 티스토리툴바\n",
            "---\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mThought: 레오나르도 디카프리오의 출생년도는 1974년입니다. 이제 이 숫자의 각 자리를 순서대로 곱해야 합니다.\n",
            "1 * 9를 먼저 계산합니다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"multiply\",\n",
            "  \"action_input\": {\n",
            "    \"x\": 1,\n",
            "    \"y\": 9\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m9\u001b[0m\u001b[32;1m\u001b[1;3m다음으로 9에 7을 곱합니다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"multiply\",\n",
            "  \"action_input\": {\n",
            "    \"x\": 9,\n",
            "    \"y\": 7\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m63\u001b[0m\u001b[32;1m\u001b[1;3m다음으로 63에 4를 곱합니다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"multiply\",\n",
            "  \"action_input\": {\n",
            "    \"x\": 63,\n",
            "    \"y\": 4\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\u001b[33;1m\u001b[1;3m252\u001b[0m\u001b[32;1m\u001b[1;3m이제 모든 숫자를 순서대로 곱했습니다. 결과는 252입니다.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"레오나르도 디카프리오의 출생년도 1974년의 각 숫자를 순서대로 곱한 값은 252입니다.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': '레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.',\n",
              " 'output': '레오나르도 디카프리오의 출생년도 1974년의 각 숫자를 순서대로 곱한 값은 252입니다.'}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke({'input':\"레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e2c8f4",
      "metadata": {
        "id": "84e2c8f4"
      },
      "source": [
        "랭체인의 에이전트 구조는 매우 간결하지만, 컨트롤하기가 매우 어려운데요.    \n",
        "실제로 우리가 개발하는 구조에서는, 모든 단계에서 LLM이 컨텍스트를 저장하여 판단을 내릴 필요는 없습니다.   \n",
        "또한, 모든 과정이 자연어로 구성되기 때문에 중간에 파싱 오류가 발생하는 경우에 동작이 멈추기도 합니다.   \n",
        "\n",
        "\n",
        "특정 작업을 반복 실행하거나, 정해진 순서에 따라 실행해야 하는 상황이라면 어떻게 해야 할까요?    \n",
        "랭체인으로 이와 같은 기능을 구현하는 것도 가능하지만, 다소 복잡한데요.   \n",
        "\n",
        "\n",
        "랭그래프를 이용하면 구체적인 Workflow를 바탕으로 Agent 형태의 어플리케이션을 효과적으로 만들 수 있습니다.   \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzedOJ6Xc_YN"
      },
      "source": [
        "# [실습] 그래프에 메모리 추가하기   \n",
        "\n",
        "랭그래프의 메모리 기능을 통해, 이전의 실행 내용을 기억하도록 설정할 수 있습니다.   \n",
        "\n",
        "세션 내부의 단기 기억에 해당하는 Checkpoint와, 장기 기억에 해당하는 Storage를 사용합니다.\n",
        "<br><br>\n",
        "\n",
        "**이번 실습은 GPU가 필요합니다. 오른쪽 탭의 \"런타임 유형 변경\"을 통해 T4 GPU로 체크하고 진행해 주세요!**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRTPqNYOc_YO"
      },
      "source": [
        "기본 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6ZLhY9hc_YO"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langgraph langchain langchain_google_genai langchain_community google_generativeai langgraph-checkpoint-sqlite -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uivwnmsc_YO"
      },
      "source": [
        "API 키와 LLM을 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vped4RdNc_YO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = ''\n",
        "\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Gemini API는 분당 10개 요청으로 제한\n",
        "# 즉, 초당 약 0.167개 요청 (10/60)\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 분당 10개 요청\n",
        "    check_every_n_seconds=0.1,  # 100ms마다 체크\n",
        "    max_bucket_size=10,  # 최대 버스트 크기\n",
        ")\n",
        "\n",
        "# rate limiter를 LLM에 적용\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    rate_limiter=rate_limiter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwsmW0edc_YO"
      },
      "source": [
        "중간 과정 확인을 위해, LangSmith를 연동합니다.\n",
        "https://smith.langchain.com 에서 등록 후 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz82pgiMc_YP"
      },
      "outputs": [],
      "source": [
        "os.environ['LANGCHAIN_API_KEY'] = ''\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LangGraph_FastCampus'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4MRLJRdc_YP"
      },
      "source": [
        "## Checkpoint(체크포인트)\n",
        "\n",
        "체크포인트는 그래프 실행의 상태와 중간 단계를 저장하고 관리합니다.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgo7P78xc_YP"
      },
      "source": [
        "<br><br>체크포인트를 저장하기 위해 MemorySaver를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrH0xkgrc_YP"
      },
      "outputs": [],
      "source": [
        "# 메모리 세팅\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3EqwnDXc_YP"
      },
      "source": [
        "구성된 체크포인터는 `compile`에 포함하여 실행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KquynAnmc_YP"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict, List\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, state, START\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    foo: str\n",
        "\n",
        "\n",
        "def call_model(state: State):\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"call_model\", call_model)\n",
        "builder.add_edge(START, \"call_model\")\n",
        "graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "graph\n",
        "# memory에 기록 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8cvyRXAc_YP"
      },
      "source": [
        "체크포인터에서, 각각의 실행은 `thread`라는 이름으로 구분됩니다.   \n",
        "thread_id를 활용해, 이전 출력의 정보를 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tbf3IFgc_YP"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "# thread_id를 통해 매 실행의 체크포인트 저장\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "\n",
        "input_message = HumanMessage(input())\n",
        "\n",
        "for chunk in graph.stream({\"messages\": [input_message]},\n",
        "                          config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osjraGxRc_YP"
      },
      "outputs": [],
      "source": [
        "input_message = {\"role\": \"user\", \"content\": \"내가 뭐라고 했지?\"}\n",
        "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sM1YKIgc_YP"
      },
      "source": [
        "해당 체크포인트의 내용은 `thread_id`에 귀속됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-xROVaRc_YP"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "input_message = {\"role\": \"user\", \"content\": \"내가 뭐라고 했지?\"}\n",
        "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSN-nBjBc_YP"
      },
      "source": [
        "`get_state`를 통해 진행된 스레드의 마지막 상태를 볼 수 있습니다.   \n",
        "해당 상태에는 State의 스냅샷 정보가 저장되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8N6Seirc_YP"
      },
      "outputs": [],
      "source": [
        "from rich import print as rprint\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "rprint(graph.get_state(config))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA92cncuc_YQ"
      },
      "source": [
        "`get_state_history()`는 전체 스냅샷 목록을 순서대로 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr0tKxaJc_YQ"
      },
      "outputs": [],
      "source": [
        "history = list(graph.get_state_history(config))\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzzjFMpKc_YQ"
      },
      "outputs": [],
      "source": [
        "for i in range(len(history)):\n",
        "    print(history[i].config, len(history[i].values['messages']))\n",
        "    # 메시지 개수와 config 정보"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaT5t16hc_YQ"
      },
      "source": [
        "## Replay\n",
        "\n",
        "위에서 얻은 Snapshot을 활용하면, 특정 시점부터 시작하는 것도 가능합니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cB4KuZnc_YQ"
      },
      "outputs": [],
      "source": [
        "history[1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALUgDC5Uc_YQ"
      },
      "source": [
        "HumanMessage의 특정 시점부터 재시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alid1Crjc_YQ"
      },
      "outputs": [],
      "source": [
        "graph.invoke(None, config = history[1].config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciIXhCwec_YQ"
      },
      "source": [
        "Replay를 수행하면, graph의 history에는 해당 실행 결과가 추가됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2TlIIYkc_YQ"
      },
      "outputs": [],
      "source": [
        "history = list(graph.get_state_history(config))\n",
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuZU4Yavc_YQ"
      },
      "source": [
        "특정 스냅샷의 값을 수정할 수도 있습니다. 이 경우, Reducer의 정의에 맞게 처리됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElGs2TA-c_YQ"
      },
      "outputs": [],
      "source": [
        "graph.update_state(config = history[0].config, values= {'messages':'저녁 뭐 먹을까?'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td5Thpnbc_YQ"
      },
      "outputs": [],
      "source": [
        "history = list(graph.get_state_history(config))\n",
        "rprint(history[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYdayqyic_YQ"
      },
      "outputs": [],
      "source": [
        "graph.invoke(None, config = history[0].config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SQLite를 이용한 Checkpointing"
      ],
      "metadata": {
        "id": "PYHw6rhIeQwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SqliteSaver`를 사용해, 체크포인팅을 저장할 수 있습니다."
      ],
      "metadata": {
        "id": "RMeF0TXbeeMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"checkpoints.sqlite\", check_same_thread=False)\n",
        "checkpointer = SqliteSaver(conn)\n",
        "\n",
        "graph = builder.compile(checkpointer=checkpointer)\n"
      ],
      "metadata": {
        "id": "k6P-QVy2eQKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "\n",
        "input_message = HumanMessage(input())\n",
        "\n",
        "for chunk in graph.stream({\"messages\": [input_message]},\n",
        "                          config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "y51DH3RUgLRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = {\"role\": \"user\", \"content\": \"오늘 저녁은 뭐 먹을까?\"}\n",
        "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    chunk[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "s3qzfldmgs83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGolsE_rc_YQ"
      },
      "source": [
        "## Store를 이용한 장기 메모리 추가하기   \n",
        "\n",
        "Thread Checkpoint는 단일 세션의 메모리를 저장하기에는 효과적이지만,   \n",
        "세션이 유지되지 않는 경우에는 다른 방법이 필요합니다.   \n",
        "\n",
        "InMemoryStore를 통해, 장기 메모리를 추가할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugR2D-yQc_YQ"
      },
      "outputs": [],
      "source": [
        "from langgraph.store.memory import InMemoryStore\n",
        "in_memory_store = InMemoryStore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vwV1gyUc_YQ"
      },
      "source": [
        "Namespace를 통해 메모리 위치를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPdOsjE6c_YQ"
      },
      "outputs": [],
      "source": [
        "namespace_for_memory = ('1', 'memories')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruj4D-ekc_YQ"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "memory_id = str(uuid.uuid4())\n",
        "\n",
        "memory = {'information' : \"지금은 랭그래프 메모리 실습 중입니다.\"}\n",
        "in_memory_store.put(namespace_for_memory, memory_id, memory)\n",
        "memories = in_memory_store.search(namespace_for_memory)\n",
        "memories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M174_QRNc_YR"
      },
      "outputs": [],
      "source": [
        "memory = {'name' : \"FastCampus\"}\n",
        "memory_id = str(uuid.uuid4())\n",
        "\n",
        "in_memory_store.put(namespace_for_memory, memory_id, memory)\n",
        "# memory_id에 매핑되는 구조\n",
        "\n",
        "memories = in_memory_store.search(namespace_for_memory)\n",
        "memories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kagTVnIc_YR"
      },
      "outputs": [],
      "source": [
        "# 메모리 레코드 추가하하기\n",
        "memory_id = str(uuid.uuid4())\n",
        "new_memory  = {'name' : \"LangGraph\"}\n",
        "\n",
        "in_memory_store.put(namespace_for_memory, memory_id, new_memory)\n",
        "# memory_id에 매핑되는 구조\n",
        "\n",
        "memories = in_memory_store.search(namespace_for_memory)\n",
        "memories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTMXsqd1c_YW"
      },
      "outputs": [],
      "source": [
        "# 메모리 덮어씌우기\n",
        "new_memory  = {'name' : \"패스트캠퍼스\"}\n",
        "\n",
        "in_memory_store.put(namespace_for_memory, memory_id, new_memory)\n",
        "# memory_id에 매핑되는 구조\n",
        "\n",
        "memories = in_memory_store.search(namespace_for_memory)\n",
        "memories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pop9L8FTc_YW"
      },
      "outputs": [],
      "source": [
        "memories[-1].dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we0phY9Kc_YW"
      },
      "source": [
        "## memory 검색    \n",
        "메모리에 임베딩 모델을 설정하면 임베딩 기반의 인덱싱/검색이 가능합니다.    \n",
        "주로 사용할 수 있는 다국어 임베딩은 다음과 같습니다.   \n",
        "1. 온라인/ OpenAI의 `text-embedding-3-small`, `text-embedding-3-large` (유료)\n",
        "2. 온라인/ Google `gemini-embedding-exp-03-07` (유료, 무료 제한 1일 100개)\n",
        "3. 오프라인/ HuggingFace에서 지원하는 `bge-m3`, `multilingual-e5`, `KURE-v1`    \n",
        "\n",
        "이번 실습에서는 가장 작은 임베딩 모델 중 하나인 `text-embedding-3-small`를 사용합니다.   \n",
        "\n",
        "**실제 임베딩 모델을 선정하실 때는 GPU 자원에 따라 MTEB 리더보드 (https://huggingface.co/spaces/mteb/leaderboard) 에서 한국어 성능 순위를 참고하시는 것을 추천합니다!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m1mUU-Sc_YW"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-huggingface sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUBgB-fsc_YW"
      },
      "source": [
        "HuggingFace에서 임베딩을 다운로드하여 로컬 폴더에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12rUAkjrc_YW"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# HuggingFace 임베딩 주소 지정하기\n",
        "# nlpai-lab/KURE-v1 , baai/bge-m3, 등의 주소를 입력하여 지정\n",
        "\n",
        "model_name = 'intfloat/multilingual-e5-small'\n",
        "\n",
        "# CPU 설정으로 모델 불러오기\n",
        "# device='cuda'로 변경하면 GPU에서 로드\n",
        "emb_model = SentenceTransformer(model_name, device='cpu')\n",
        "\n",
        "# 로컬 폴더에 모델 저장하기\n",
        "emb_model.save('./embedding')\n",
        "del emb_model\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "# 메모리 정리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO0pezeTc_YW"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# 허깅페이스 포맷의 임베딩 모델 불러오기\n",
        "embeddings = HuggingFaceEmbeddings(model_name= './embedding',\n",
        "                                   model_kwargs={'device':'cuda'})\n",
        "# GPU가 있는 경우, CUDA(GPU) 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14hRqp_ac_YW"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore(\n",
        "    index={\n",
        "        \"embed\": embeddings,\n",
        "        \"dims\": 1024, # 임베딩 차원(모델마다 다름)\n",
        "        \"fields\": [\"comments\"] # 임베딩을 활용해 저장할 필드 지정\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ECD-Ly0c_YW"
      },
      "outputs": [],
      "source": [
        "memory_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awue0iGZc_YW"
      },
      "outputs": [],
      "source": [
        "namespace_for_memory = ('1', 'information')\n",
        "memory_id = str(uuid.uuid4())\n",
        "\n",
        "store.put(namespace_for_memory,\n",
        "          memory_id,\n",
        "          {'ID':'JohnDoe1', 'comments':'안녕하세요! 저는 John Doe이고, 23살입니다.'})\n",
        "\n",
        "store.search(namespace_for_memory, limit=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cf_m1Lmc_YW"
      },
      "outputs": [],
      "source": [
        "def add_records(store, namespace, data_records):\n",
        "    for data in data_records:\n",
        "        store.put(namespace, str(uuid.uuid4()), data)\n",
        "\n",
        "example_data = [\n",
        "    {'Hello':'world'},\n",
        "    {'ID':'Admin', 'comments':'이 계정은 운영 전용 계정입니다.'},\n",
        "    {'ID':'GPT_Agent1', 'comments':'GPT-4o Agent 전용 계정'},\n",
        "    {'ID':'Gemini_Agent1', 'comments':'Gemini-2.0-flash Agent 전용 계정'}\n",
        "]\n",
        "\n",
        "add_records(store,namespace_for_memory, example_data)\n",
        "\n",
        "\n",
        "history = store.search(namespace_for_memory)\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aBGmi9Ec_YW"
      },
      "outputs": [],
      "source": [
        "print('\\n'.join(['['+str(i.created_at)[0:10] + '] ' + i.value['comments'] if 'comments' in i.value else '' for i in history]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaFjsgL9c_YX"
      },
      "outputs": [],
      "source": [
        "result = store.search(\n",
        "    namespace_for_memory,\n",
        "    query = 'Gemini Agent 버전은 뭔가요?',\n",
        "    limit = 2\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKHoy-Zqc_YX"
      },
      "outputs": [],
      "source": [
        "type(result[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVSPdRaGc_YX"
      },
      "source": [
        "이렇게 생성된 store는 각 Node에 State와 함께 포함할 수 있습니다.  \n",
        "실제 채팅 시나리오를 통해 구현해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6QrPWbbc_YX"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "\n",
        "memory = MemorySaver()\n",
        "in_memory_store = InMemoryStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfUcO2ZVc_YX"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict, List\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, RemoveMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, state, START, END\n",
        "from langgraph.store.base import BaseStore\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    summary: str\n",
        "\n",
        "\n",
        "\n",
        "def call_model(state: State, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    user_id = config['configurable']['user_id']\n",
        "    namespace = (user_id, \"information\")\n",
        "\n",
        "    def gen_memories(history):\n",
        "        return '\\n'.join(['['+str(i.created_at)[0:10] + '] ' + i.value['memory'] if 'memory' in i.value else '' for i in history])\n",
        "\n",
        "    summary = gen_memories(store.search(namespace))\n",
        "\n",
        "    prompt = [SystemMessage(content=f\"\"\"\n",
        "당신은 고객 상담 챗봇입니다.\n",
        "고객은 이전에 아래의 상담을 한 적이 있습니다. 과거 내역을 참고하여 응답하세요.\n",
        "첫 대화는 친절한 인사로 시작하세요.\n",
        "---\n",
        "Previous Conversation Summary: {summary}\"\"\"), HumanMessage(content=\"안녕하세요!\")] + state['messages']\n",
        "\n",
        "     # 과거 정보를 상위 Context에 포함하기\n",
        "    response = llm.invoke(prompt)\n",
        "    print('Assistant:', response.content)\n",
        "\n",
        "    user_message = HumanMessage(content = input())\n",
        "\n",
        "\n",
        "    return {\"messages\": [response, user_message]}\n",
        "\n",
        "def summarize_conversation(state: State, config: RunnableConfig, store: BaseStore):\n",
        "\n",
        "    summary_prompt = \"\"\"현재까지의 대화 내용을 요약하여 데이터베이스에 저장하려고 합니다.\n",
        "이전의 Summary 내용과 이어지는 경우, 해당 내용을 포함하여 요약하세요.\n",
        "만약 새로운 주제인 경우, 새로운 대화 내용만 요약하세요.\n",
        "대화 내용을 3~5문장 길이로 요약하세요. 요약 이외의 다른 내용은 출력하지 마세요.\n",
        "또한, 요약을 요청했다는 사실도 작성하지 마세요.\n",
        "\"\"\"\n",
        "    prompt = state['messages'][:-1] + [HumanMessage(content = summary_prompt)]\n",
        "    # END 제외\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state['messages']]\n",
        "    return {'summary': response.content, 'messages':delete_messages}\n",
        "\n",
        "\n",
        "\n",
        "def update_memory(state:State, config: RunnableConfig, store:BaseStore):\n",
        "\n",
        "    user_id = config['configurable']['user_id']\n",
        "    namespace = (user_id, \"information\")\n",
        "\n",
        "    memory_id = str(uuid.uuid4())\n",
        "\n",
        "\n",
        "    memory = state[\"summary\"]\n",
        "\n",
        "    store.put(namespace, memory_id, {'memory':memory})\n",
        "\n",
        "def check_end(state:State):\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "\n",
        "    if last_msg.content.upper()=='END':\n",
        "        return 'END'\n",
        "    return 'RESUME'\n",
        "\n",
        "builder = StateGraph(State)\n",
        "\n",
        "\n",
        "builder.add_node('update_memory', update_memory)\n",
        "builder.add_node(\"call_model\", call_model)\n",
        "builder.add_node('summarize_conversation', summarize_conversation)\n",
        "\n",
        "builder.add_edge(START, \"call_model\")\n",
        "builder.add_conditional_edges('call_model',\n",
        "                              check_end,\n",
        "                              {'END':'summarize_conversation',\n",
        "                               'RESUME':'call_model'})\n",
        "builder.add_edge('summarize_conversation','update_memory')\n",
        "builder.add_edge('update_memory', END)\n",
        "\n",
        "graph = builder.compile(checkpointer=memory, store=in_memory_store)\n",
        "\n",
        "graph\n",
        "# memory에 기록 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onD4mIggc_YX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3laWr9EVc_YX"
      },
      "outputs": [],
      "source": [
        "print('END를 입력하면 대화가 종료됩니다.')\n",
        "\n",
        "config = {'configurable':{'thread_id':'2', 'user_id':'admin'}}\n",
        "for data in graph.stream(\n",
        "    {'messages':[]},\n",
        "    config,stream_mode=\"updates\"):\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcIVjFUyc_YX"
      },
      "outputs": [],
      "source": [
        "config = {'configurable':{'thread_id':'8', 'user_id':'admin'}}\n",
        "graph.invoke({'messages':[]}, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKQ6nCH4c_YX"
      },
      "outputs": [],
      "source": [
        "graph.get_state(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfu1n3gUc_YX"
      },
      "outputs": [],
      "source": [
        "in_memory_store.list_namespaces()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUzuioD7c_YX"
      },
      "outputs": [],
      "source": [
        "in_memory_store.search(('HH', 'information'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU9DPl1yc_YX"
      },
      "outputs": [],
      "source": [
        "# 다른 thread id로 해도 이전 정보를 참고함\n",
        "config = {'configurable':{'thread_id':'9', 'user_id':'admin'}}\n",
        "for data in graph.stream(\n",
        "    {'messages':[]},\n",
        "    config,stream_mode=\"updates\"):\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEQw-Ewuc_YX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqWxKCxVc_YX"
      },
      "source": [
        "# SQLite Store 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJhzBhvyc_YY"
      },
      "source": [
        "외부 DB를 연동하는 기능은 현재 직접 지원하지 않으며, BaseStore Class를 이용해 구현해야 합니다.   \n",
        "PostGresStore를 사용하는 경우: https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.postgres.PostgresStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58oFJuRZc_YY"
      },
      "outputs": [],
      "source": [
        "from langgraph.store.base import BaseStore, SearchItem\n",
        "from typing import List, Optional, Dict, Any, Tuple\n",
        "import sqlite3\n",
        "import json\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class SQLiteStore(BaseStore):\n",
        "    def __init__(self, db_path: str = \"store.db\", embedding_model: str = 'intfloat/multilingual-e5-large'):\n",
        "        self.db_path = db_path\n",
        "        self.conn = sqlite3.connect(db_path, check_same_thread=False)\n",
        "        self.embedding_model = embedding_model\n",
        "        self._setup()\n",
        "\n",
        "    def _setup(self):\n",
        "        \"\"\"데이터베이스 테이블 생성\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "\n",
        "        # 메인 스토어 테이블\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS store (\n",
        "                namespace TEXT,\n",
        "                key TEXT,\n",
        "                value TEXT,\n",
        "                created_at TEXT,\n",
        "                updated_at TEXT,\n",
        "                PRIMARY KEY (namespace, key)\n",
        "            )\n",
        "        \"\"\")\n",
        "\n",
        "        # 임베딩 테이블\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS embeddings (\n",
        "                namespace TEXT,\n",
        "                key TEXT,\n",
        "                embedding BLOB,\n",
        "                text TEXT,\n",
        "                PRIMARY KEY (namespace, key),\n",
        "                FOREIGN KEY (namespace, key) REFERENCES store(namespace, key)\n",
        "            )\n",
        "        \"\"\")\n",
        "\n",
        "        self.conn.commit()\n",
        "\n",
        "    def _get_embedding(self, text: str) -> np.ndarray:\n",
        "        \"\"\"텍스트의 임베딩 벡터 생성\"\"\"\n",
        "        model = SentenceTransformer(self.embedding_model)\n",
        "        return model.encode(text)\n",
        "\n",
        "    def _cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:\n",
        "        \"\"\"코사인 유사도 계산\"\"\"\n",
        "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "\n",
        "    def batch(self, operations: List[Tuple[str, Tuple[str, ...], str, Dict[str, Any]]]) -> None:\n",
        "        \"\"\"일괄 작업 처리\"\"\"\n",
        "        for op, namespace, key, value in operations:\n",
        "            if op == \"put\":\n",
        "                self.put(namespace, key, value)\n",
        "            elif op == \"delete\":\n",
        "                self.delete(namespace, key)\n",
        "    async def abatch(self, operations: List[Tuple[str, Tuple[str, ...], str, Dict[str, Any]]]) -> None:\n",
        "        \"\"\"비동기 일괄 작업 처리\"\"\"\n",
        "        self.batch(operations)  # SQLite는 기본적으로 동기식이므로 동기 메서드를 호출\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def put(self, namespace: Tuple[str, ...], key: str, value: Dict[str, Any], index: bool = True) -> None:\n",
        "        \"\"\"데이터 저장\"\"\"\n",
        "        namespace_str = json.dumps(namespace)\n",
        "        value_str = json.dumps(value)\n",
        "        now = datetime.utcnow().isoformat()\n",
        "\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT OR REPLACE INTO store (namespace, key, value, created_at, updated_at)\n",
        "            VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\", (namespace_str, key, value_str, now, now))\n",
        "\n",
        "        # 임베딩 저장\n",
        "        if index:\n",
        "            # value에서 텍스트 추출 (예: 'memory' 필드)\n",
        "            text_to_embed = value.get('memory', '') if isinstance(value, dict) else str(value)\n",
        "            if text_to_embed:\n",
        "                embedding = self._get_embedding(text_to_embed)\n",
        "                cursor.execute(\"\"\"\n",
        "                    INSERT OR REPLACE INTO embeddings (namespace, key, embedding, text)\n",
        "                    VALUES (?, ?, ?, ?)\n",
        "                \"\"\", (namespace_str, key, embedding.tobytes(), text_to_embed))\n",
        "\n",
        "        self.conn.commit()\n",
        "\n",
        "    def get(self, namespace: Tuple[str, ...], key: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"데이터 조회\"\"\"\n",
        "        namespace_str = json.dumps(namespace)\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT value FROM store WHERE namespace = ? AND key = ?\n",
        "        \"\"\", (namespace_str, key))\n",
        "        result = cursor.fetchone()\n",
        "\n",
        "        if result:\n",
        "            return json.loads(result[0])\n",
        "        return None\n",
        "\n",
        "    def search(self, namespace: Tuple[str, ...], query: Optional[str] = None, limit: int = 20) -> List[SearchItem]:\n",
        "        \"\"\"데이터 검색 (임베딩 기반 또는 텍스트 기반)\"\"\"\n",
        "        namespace_str = json.dumps(namespace)\n",
        "        cursor = self.conn.cursor()\n",
        "\n",
        "        if query:\n",
        "            # 임베딩 기반 검색\n",
        "            query_embedding = self._get_embedding(query)\n",
        "\n",
        "            # 모든 임베딩 가져오기\n",
        "            cursor.execute(\"\"\"\n",
        "                SELECT e.embedding, e.text, s.key, s.value, s.created_at, s.updated_at\n",
        "                FROM embeddings e\n",
        "                JOIN store s ON e.namespace = s.namespace AND e.key = s.key\n",
        "                WHERE e.namespace = ?\n",
        "            \"\"\", (namespace_str,))\n",
        "\n",
        "            results = []\n",
        "            for row in cursor.fetchall():\n",
        "                embedding = np.frombuffer(row[0], dtype=np.float32)\n",
        "                similarity = self._cosine_similarity(query_embedding, embedding)\n",
        "                results.append(SearchItem(\n",
        "                key=row[2],          # key는 세 번째 컬럼\n",
        "                value=json.loads(row[3]),  # value는 네 번째 컬럼\n",
        "                created_at=datetime.fromisoformat(row[4]),  # created_at은 다섯 번째 컬럼\n",
        "                updated_at=datetime.fromisoformat(row[5]),  # updated_at은 여섯 번째 컬럼\n",
        "                namespace=namespace,\n",
        "                score = similarity\n",
        "            ))\n",
        "\n",
        "            # 유사도 기준으로 정렬\n",
        "            results.sort(key=lambda x: x.score, reverse=True)\n",
        "            return results[:limit]\n",
        "        else:\n",
        "            # 일반 텍스트 검색\n",
        "            cursor.execute(\"\"\"\n",
        "                SELECT key, value, created_at, updated_at\n",
        "                FROM store\n",
        "                WHERE namespace = ?\n",
        "                ORDER BY created_at DESC LIMIT ?\n",
        "            \"\"\", (namespace_str, limit))\n",
        "\n",
        "            results = []\n",
        "            for row in cursor.fetchall():\n",
        "                value = json.loads(row[1])\n",
        "                results.append(SearchItem(\n",
        "                key=row[0],\n",
        "                value=value,\n",
        "                created_at=datetime.fromisoformat(row[2]),\n",
        "                updated_at=datetime.fromisoformat(row[3]),\n",
        "                namespace=namespace  # 원래 search 메서드에 전달된 namespace 사용\n",
        "                ))\n",
        "\n",
        "            return results\n",
        "\n",
        "    def delete(self, namespace: Tuple[str, ...], key: str) -> None:\n",
        "        \"\"\"데이터 삭제\"\"\"\n",
        "        namespace_str = json.dumps(namespace)\n",
        "        cursor = self.conn.cursor()\n",
        "\n",
        "        # 임베딩도 함께 삭제\n",
        "        cursor.execute(\"\"\"\n",
        "            DELETE FROM embeddings WHERE namespace = ? AND key = ?\n",
        "        \"\"\", (namespace_str, key))\n",
        "\n",
        "        cursor.execute(\"\"\"\n",
        "            DELETE FROM store WHERE namespace = ? AND key = ?\n",
        "        \"\"\", (namespace_str, key))\n",
        "\n",
        "        self.conn.commit()\n",
        "\n",
        "    def list_namespaces(self) -> List[Tuple[str, ...]]:\n",
        "        \"\"\"네임스페이스 목록 조회\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"SELECT DISTINCT namespace FROM store\")\n",
        "        return [tuple(json.loads(row[0])) for row in cursor.fetchall()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUYTdfjwc_YY"
      },
      "outputs": [],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUY8NXa6c_YY"
      },
      "outputs": [],
      "source": [
        "# SQLite 스토어 인스턴스 생성\n",
        "sqlite_store = SQLiteStore(db_path = 'example.db', embedding_model = model_name)\n",
        "\n",
        "graph = builder.compile(checkpointer=memory, store=sqlite_store)\n",
        "\n",
        "print('END를 입력하면 대화가 종료됩니다.')\n",
        "\n",
        "config = {'configurable':{'thread_id':'1', 'user_id':'admin'}}\n",
        "for data in graph.stream(\n",
        "    {'messages':[]},\n",
        "    config,stream_mode=\"updates\"):\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjmgZLOhc_YY"
      },
      "outputs": [],
      "source": [
        "sqlite_store.list_namespaces()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZesOhjBTc_YY"
      },
      "outputs": [],
      "source": [
        "memories = sqlite_store.search(('admin', 'information'))\n",
        "for result in memories:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoPKMYqWc_YY"
      },
      "outputs": [],
      "source": [
        "# 임베딩 검색 사용 예시\n",
        "# memory에서 값을 검색하도록 설정(SQLite Store Class 참고)\n",
        "\n",
        "results = sqlite_store.search(('admin', 'information'), query=\"코딩\", limit=1)\n",
        "for result in results:\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langsmith (https://smith.langchain.com )에서 실행 결과를 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "b18UYEgUskcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAj_rMSOc_YY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}